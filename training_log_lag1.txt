



##########################################################

Epochs=30000 	batch=245 	lr=0.0003
window=2 	seq_len=7 	hidden_size=512 	layers=2

Start Time = 2021/04/19, 16:28:41
##########################################################


[Epoch 0] Rounded prediction: 
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([27., 22., 21., 24., 20., 23., 23., 26., 24., 19., 20., 16., 13., 15.,
         7.,  3.,  0.,  0.,  3., 14., 19.,  5.,  9., 17.,  0.,  0.,  3.,  3.,
         2.,  4., 14.,  0.,  0.,  8.,  0.,  2.,  0.,  2.,  0.,  4.,  3., 32.,
         2.,  7.,  0.,  0.,  0.,  1.,  1.,  0.,  2.,  1., 12.,  0., 26.,  0.,
         0.,  0.,  0.,  4.,  0.,  8.,  0.,  8.,  0., 14.,  1., 10., 17.,  0.,
         0.,  0.,  0.,  0.,  0.,  0., 21., 26., 22., 27., 30., 11., 23., 38.,
        13.,  0.,  0.,  0.,  0.,  0.,  0., 35., 49., 33., 30., 27., 22., 18.,
        28., 29., 14., 21., 22., 25., 18.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([22., 18., 13., 22., 21., 22., 21., 16., 11.,  1.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 11.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  4.,  0.,  0.,  0.,  0.,  0.,  0., 10., 23., 18.,  0.,  4.,  8.,
         0.,  0.,  4.,  0.,  0., 11.,  7.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128670.9844, Valid Loss: 208.7714
Epoch [101/30000], Step [1/1], Training Loss: 116707.1875, Valid Loss: 320.0191
Epoch [201/30000], Step [1/1], Training Loss: 110340.3672, Valid Loss: 999.3048
Epoch [301/30000], Step [1/1], Training Loss: 104599.0625, Valid Loss: 2119.1238
Epoch [401/30000], Step [1/1], Training Loss: 99354.1641, Valid Loss: 1316.0381
Epoch [501/30000], Step [1/1], Training Loss: 94059.8828, Valid Loss: 50.1048
Epoch [601/30000], Step [1/1], Training Loss: 89241.6953, Valid Loss: 73.7714
Epoch [701/30000], Step [1/1], Training Loss: 84689.4297, Valid Loss: 117.1429
Epoch [801/30000], Step [1/1], Training Loss: 80431.0938, Valid Loss: 105.6762
Epoch [901/30000], Step [1/1], Training Loss: 76436.8438, Valid Loss: 128.4952
Epoch [1001/30000], Step [1/1], Training Loss: 72699.0625, Valid Loss: 121.7048
Epoch [1101/30000], Step [1/1], Training Loss: 69199.5234, Valid Loss: 115.5619
Epoch [1201/30000], Step [1/1], Training Loss: 65930.3047, Valid Loss: 118.1333
Epoch [1301/30000], Step [1/1], Training Loss: 62880.4375, Valid Loss: 127.3429
Epoch [1401/30000], Step [1/1], Training Loss: 60043.3242, Valid Loss: 152.4286
Epoch [1501/30000], Step [1/1], Training Loss: 57403.2617, Valid Loss: 126.4762
Epoch [1601/30000], Step [1/1], Training Loss: 54867.9258, Valid Loss: 96.7524
Epoch [1701/30000], Step [1/1], Training Loss: 52354.2344, Valid Loss: 82.3048
Epoch [1801/30000], Step [1/1], Training Loss: 50017.6797, Valid Loss: 67.4762
Epoch [1901/30000], Step [1/1], Training Loss: 47755.4688, Valid Loss: 60.8095
Epoch [2001/30000], Step [1/1], Training Loss: 45615.1250, Valid Loss: 72.6381
Epoch [2101/30000], Step [1/1], Training Loss: 43578.8320, Valid Loss: 71.2762
Epoch [2201/30000], Step [1/1], Training Loss: 41739.8438, Valid Loss: 80.0571
Epoch [2301/30000], Step [1/1], Training Loss: 39968.5312, Valid Loss: 77.6286
Epoch [2401/30000], Step [1/1], Training Loss: 38385.8672, Valid Loss: 70.0952
Epoch [2501/30000], Step [1/1], Training Loss: 37049.2148, Valid Loss: 64.9333
Epoch [2601/30000], Step [1/1], Training Loss: 35367.9180, Valid Loss: 69.8191
Epoch [2701/30000], Step [1/1], Training Loss: 34041.1211, Valid Loss: 69.4191
Epoch [2801/30000], Step [1/1], Training Loss: 32589.7207, Valid Loss: 73.8667
Epoch [2901/30000], Step [1/1], Training Loss: 31346.5547, Valid Loss: 72.8571
Epoch [3001/30000], Step [1/1], Training Loss: 30065.6797, Valid Loss: 81.7714
Epoch [3101/30000], Step [1/1], Training Loss: 28976.1543, Valid Loss: 85.5048
Epoch [3201/30000], Step [1/1], Training Loss: 27979.2422, Valid Loss: 104.4667
Epoch [3301/30000], Step [1/1], Training Loss: 26718.3984, Valid Loss: 87.9238
Epoch [3401/30000], Step [1/1], Training Loss: 25605.1738, Valid Loss: 91.0095
Epoch [3501/30000], Step [1/1], Training Loss: 24374.9277, Valid Loss: 91.5429
Epoch [3601/30000], Step [1/1], Training Loss: 23723.1113, Valid Loss: 83.2476
Epoch [3701/30000], Step [1/1], Training Loss: 22516.1016, Valid Loss: 96.7810
Epoch [3801/30000], Step [1/1], Training Loss: 22520.3574, Valid Loss: 94.2381
Epoch [3901/30000], Step [1/1], Training Loss: 20935.5117, Valid Loss: 101.1524
Epoch [4001/30000], Step [1/1], Training Loss: 19823.0586, Valid Loss: 99.3714
Epoch [4101/30000], Step [1/1], Training Loss: 18825.3906, Valid Loss: 111.4191
Epoch [4201/30000], Step [1/1], Training Loss: 17928.0430, Valid Loss: 112.4476
Epoch [4301/30000], Step [1/1], Training Loss: 17175.2988, Valid Loss: 109.4762
Epoch [4401/30000], Step [1/1], Training Loss: 16391.8965, Valid Loss: 118.6190
Epoch [4501/30000], Step [1/1], Training Loss: 15982.0605, Valid Loss: 104.7238
Epoch [4601/30000], Step [1/1], Training Loss: 15359.2256, Valid Loss: 109.0095
Epoch [4701/30000], Step [1/1], Training Loss: 14916.1338, Valid Loss: 117.5143
Epoch [4801/30000], Step [1/1], Training Loss: 14436.8594, Valid Loss: 107.2952
Epoch [4901/30000], Step [1/1], Training Loss: 14296.7188, Valid Loss: 111.1524
Epoch [5001/30000], Step [1/1], Training Loss: 14373.3184, Valid Loss: 123.1048
Epoch [5101/30000], Step [1/1], Training Loss: 13544.8242, Valid Loss: 104.0857
Epoch [5201/30000], Step [1/1], Training Loss: 13074.0527, Valid Loss: 108.8191
Epoch [5301/30000], Step [1/1], Training Loss: 12405.8770, Valid Loss: 105.9714
Epoch [5401/30000], Step [1/1], Training Loss: 12092.8555, Valid Loss: 104.4571
Epoch [5501/30000], Step [1/1], Training Loss: 11174.9268, Valid Loss: 110.1429
Epoch [5601/30000], Step [1/1], Training Loss: 11088.7324, Valid Loss: 108.3905
Epoch [5701/30000], Step [1/1], Training Loss: 10897.4365, Valid Loss: 106.8286
Epoch [5801/30000], Step [1/1], Training Loss: 10512.7539, Valid Loss: 97.9429
Epoch [5901/30000], Step [1/1], Training Loss: 9565.1074, Valid Loss: 106.0762
Epoch [6001/30000], Step [1/1], Training Loss: 9185.9375, Valid Loss: 100.6572
Epoch [6101/30000], Step [1/1], Training Loss: 9156.0352, Valid Loss: 106.3048
Epoch [6201/30000], Step [1/1], Training Loss: 8810.7998, Valid Loss: 99.1714
Epoch [6301/30000], Step [1/1], Training Loss: 8272.0674, Valid Loss: 106.1905
Epoch [6401/30000], Step [1/1], Training Loss: 8195.1318, Valid Loss: 110.8286
Epoch [6501/30000], Step [1/1], Training Loss: 8082.9941, Valid Loss: 104.0571
Epoch [6601/30000], Step [1/1], Training Loss: 8013.4233, Valid Loss: 107.3714
Epoch [6701/30000], Step [1/1], Training Loss: 7662.2114, Valid Loss: 100.6286
Epoch [6801/30000], Step [1/1], Training Loss: 7445.3105, Valid Loss: 94.6000
Epoch [6901/30000], Step [1/1], Training Loss: 7737.1890, Valid Loss: 114.5714
Epoch [7001/30000], Step [1/1], Training Loss: 7005.1226, Valid Loss: 111.4000
Epoch [7101/30000], Step [1/1], Training Loss: 6787.9614, Valid Loss: 118.4667
Epoch [7201/30000], Step [1/1], Training Loss: 8029.5625, Valid Loss: 112.8952
Epoch [7301/30000], Step [1/1], Training Loss: 5927.4858, Valid Loss: 112.2286
Epoch [7401/30000], Step [1/1], Training Loss: 5560.5044, Valid Loss: 113.6952
Epoch [7501/30000], Step [1/1], Training Loss: 5033.3369, Valid Loss: 114.9524
Epoch [7601/30000], Step [1/1], Training Loss: 4647.3667, Valid Loss: 115.9333
Epoch [7701/30000], Step [1/1], Training Loss: 6751.1450, Valid Loss: 114.7810
Epoch [7801/30000], Step [1/1], Training Loss: 6219.6553, Valid Loss: 133.4476
Epoch [7901/30000], Step [1/1], Training Loss: 5674.3979, Valid Loss: 128.4952
Epoch [8001/30000], Step [1/1], Training Loss: 4965.4746, Valid Loss: 142.8190
Epoch [8101/30000], Step [1/1], Training Loss: 4820.1836, Valid Loss: 130.8762
Epoch [8201/30000], Step [1/1], Training Loss: 4826.6362, Valid Loss: 139.4000
Epoch [8301/30000], Step [1/1], Training Loss: 4513.4839, Valid Loss: 125.0667
Epoch [8401/30000], Step [1/1], Training Loss: 4241.3428, Valid Loss: 123.4952
Epoch [8501/30000], Step [1/1], Training Loss: 4043.4636, Valid Loss: 116.7524
Epoch [8601/30000], Step [1/1], Training Loss: 4001.2144, Valid Loss: 115.3143
Epoch [8701/30000], Step [1/1], Training Loss: 4191.9570, Valid Loss: 116.5905
Epoch [8801/30000], Step [1/1], Training Loss: 4644.4355, Valid Loss: 125.9619
Epoch [8901/30000], Step [1/1], Training Loss: 3680.7488, Valid Loss: 121.9143
Epoch [9001/30000], Step [1/1], Training Loss: 3643.8669, Valid Loss: 123.3333
Epoch [9101/30000], Step [1/1], Training Loss: 3467.7729, Valid Loss: 134.3905
Epoch [9201/30000], Step [1/1], Training Loss: 3368.6160, Valid Loss: 152.7143
Epoch [9301/30000], Step [1/1], Training Loss: 3339.5452, Valid Loss: 125.4476
Epoch [9401/30000], Step [1/1], Training Loss: 2845.3127, Valid Loss: 156.6476
Epoch [9501/30000], Step [1/1], Training Loss: 2919.5210, Valid Loss: 136.1905
Epoch [9601/30000], Step [1/1], Training Loss: 4960.9653, Valid Loss: 174.7524
Epoch [9701/30000], Step [1/1], Training Loss: 3076.0933, Valid Loss: 130.6381
Epoch [9801/30000], Step [1/1], Training Loss: 3343.2439, Valid Loss: 158.2667
Epoch [9901/30000], Step [1/1], Training Loss: 4036.9915, Valid Loss: 172.3619
Epoch [10001/30000], Step [1/1], Training Loss: 2608.5002, Valid Loss: 188.2286
Epoch [10101/30000], Step [1/1], Training Loss: 2294.4666, Valid Loss: 173.2572
Epoch [10201/30000], Step [1/1], Training Loss: 2129.7542, Valid Loss: 166.6572

[Epoch 15000] Rounded prediction: 
tensor([18., 17., 22., 22., 21., 21., 24., 21., 17., 17., 10.,  8., 11., 14.,
         5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 28.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 21.,
         5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 21.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 19.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0., 34.,  3.,  0., 36.,  5., 22., 37.,
         0.,  0.,  0.,  4.,  0.,  0.,  0.,  0., 30., 68., 56., 21.,  0., 11.,
         0.,  0.,  8.,  0.,  0., 28.,  5.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([21., 12.,  7., 13.,  9.,  8.,  8.,  6.,  7.,  8.,  8., 10., 14., 13.,
        16., 10., 31., 26., 46., 38., 31., 40., 20., 49.,  0.,  0.,  0.,  0.,
         0.,  0.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 23.,
        21.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 13.,  0., 14., 12.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 14., 18., 25., 70., 41.,
        33., 71., 37., 43.,  6., 80., 40., 52., 72., 57., 64., 54., 29., 71.,
        45., 40.,  2.,  3.,  4.,  7.,  0., 48., 61., 68., 64., 53., 25., 47.,
        30., 20., 31., 37., 15., 18., 32.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [10301/30000], Step [1/1], Training Loss: 2834.2778, Valid Loss: 166.6857
Epoch [10401/30000], Step [1/1], Training Loss: 1881.9515, Valid Loss: 167.1048
Epoch [10501/30000], Step [1/1], Training Loss: 1873.2148, Valid Loss: 188.7333
Epoch [10601/30000], Step [1/1], Training Loss: 2653.0330, Valid Loss: 173.3810
Epoch [10701/30000], Step [1/1], Training Loss: 1833.4164, Valid Loss: 156.6476
Epoch [10801/30000], Step [1/1], Training Loss: 1770.9424, Valid Loss: 146.7048
Epoch [10901/30000], Step [1/1], Training Loss: 1678.6191, Valid Loss: 171.6381
Epoch [11001/30000], Step [1/1], Training Loss: 1625.9731, Valid Loss: 149.6857
Epoch [11101/30000], Step [1/1], Training Loss: 1546.7882, Valid Loss: 160.4191
Epoch [11201/30000], Step [1/1], Training Loss: 1503.2073, Valid Loss: 163.8191
Epoch [11301/30000], Step [1/1], Training Loss: 1429.9773, Valid Loss: 163.5333
Epoch [11401/30000], Step [1/1], Training Loss: 1388.9724, Valid Loss: 157.8762
Epoch [11501/30000], Step [1/1], Training Loss: 1376.7648, Valid Loss: 148.5905
Epoch [11601/30000], Step [1/1], Training Loss: 1392.4952, Valid Loss: 159.4000
Epoch [11701/30000], Step [1/1], Training Loss: 1312.6143, Valid Loss: 158.2857
Epoch [11801/30000], Step [1/1], Training Loss: 1285.6473, Valid Loss: 159.3619
Epoch [11901/30000], Step [1/1], Training Loss: 1230.6500, Valid Loss: 169.6667
Epoch [12001/30000], Step [1/1], Training Loss: 1274.5981, Valid Loss: 167.4000
Epoch [12101/30000], Step [1/1], Training Loss: 1269.2006, Valid Loss: 150.0095
Epoch [12201/30000], Step [1/1], Training Loss: 1192.5024, Valid Loss: 150.6286
Epoch [12301/30000], Step [1/1], Training Loss: 1154.1155, Valid Loss: 149.5429
Epoch [12401/30000], Step [1/1], Training Loss: 1153.9803, Valid Loss: 154.3333
Epoch [12501/30000], Step [1/1], Training Loss: 6837.3052, Valid Loss: 184.4762
Epoch [12601/30000], Step [1/1], Training Loss: 3397.5068, Valid Loss: 169.9429
Epoch [12701/30000], Step [1/1], Training Loss: 3266.5840, Valid Loss: 175.0000
Epoch [12801/30000], Step [1/1], Training Loss: 2503.7510, Valid Loss: 179.5238
Epoch [12901/30000], Step [1/1], Training Loss: 1987.8160, Valid Loss: 177.1714
Epoch [13001/30000], Step [1/1], Training Loss: 2586.5518, Valid Loss: 179.9238
Epoch [13101/30000], Step [1/1], Training Loss: 3252.0791, Valid Loss: 169.5238
Epoch [13201/30000], Step [1/1], Training Loss: 2896.1282, Valid Loss: 164.2286
Epoch [13301/30000], Step [1/1], Training Loss: 1981.6461, Valid Loss: 171.6190
Epoch [13401/30000], Step [1/1], Training Loss: 3909.2764, Valid Loss: 177.9810
Epoch [13501/30000], Step [1/1], Training Loss: 2826.8938, Valid Loss: 179.4762
Epoch [13601/30000], Step [1/1], Training Loss: 2662.7893, Valid Loss: 182.1238
Epoch [13701/30000], Step [1/1], Training Loss: 2708.4504, Valid Loss: 186.5619
Epoch [13801/30000], Step [1/1], Training Loss: 2544.4119, Valid Loss: 189.2095
Epoch [13901/30000], Step [1/1], Training Loss: 2601.2629, Valid Loss: 182.2762
Epoch [14001/30000], Step [1/1], Training Loss: 2391.6233, Valid Loss: 192.6286
Epoch [14101/30000], Step [1/1], Training Loss: 2542.1243, Valid Loss: 193.9524
Epoch [14201/30000], Step [1/1], Training Loss: 3053.1350, Valid Loss: 193.6857
Epoch [14301/30000], Step [1/1], Training Loss: 2420.7161, Valid Loss: 190.5429
Epoch [14401/30000], Step [1/1], Training Loss: 2577.8799, Valid Loss: 199.7429
Epoch [14501/30000], Step [1/1], Training Loss: 2256.1047, Valid Loss: 193.0286
Epoch [14601/30000], Step [1/1], Training Loss: 2214.4749, Valid Loss: 200.4952
Epoch [14701/30000], Step [1/1], Training Loss: 2262.1729, Valid Loss: 204.8095
Epoch [14801/30000], Step [1/1], Training Loss: 2331.0645, Valid Loss: 219.1333
Epoch [14901/30000], Step [1/1], Training Loss: 2190.2961, Valid Loss: 198.2952
Epoch [15001/30000], Step [1/1], Training Loss: 2202.1936, Valid Loss: 205.7048
Epoch [15101/30000], Step [1/1], Training Loss: 2280.5977, Valid Loss: 211.4667
Epoch [15201/30000], Step [1/1], Training Loss: 2173.9023, Valid Loss: 208.1429
Epoch [15301/30000], Step [1/1], Training Loss: 3102.3289, Valid Loss: 203.7143
Epoch [15401/30000], Step [1/1], Training Loss: 2211.3250, Valid Loss: 202.5429
Epoch [15501/30000], Step [1/1], Training Loss: 2158.2166, Valid Loss: 181.1143
Epoch [15601/30000], Step [1/1], Training Loss: 2116.4507, Valid Loss: 203.8000
Epoch [15701/30000], Step [1/1], Training Loss: 2149.0461, Valid Loss: 200.5429
Epoch [15801/30000], Step [1/1], Training Loss: 2033.8615, Valid Loss: 192.7619
Epoch [15901/30000], Step [1/1], Training Loss: 2082.0525, Valid Loss: 199.4952
Epoch [16001/30000], Step [1/1], Training Loss: 2063.9915, Valid Loss: 197.5905
Epoch [16101/30000], Step [1/1], Training Loss: 2037.6921, Valid Loss: 202.8571
Epoch [16201/30000], Step [1/1], Training Loss: 2011.1016, Valid Loss: 197.7048
Epoch [16301/30000], Step [1/1], Training Loss: 2844.0745, Valid Loss: 195.5619
Epoch [16401/30000], Step [1/1], Training Loss: 4115.6396, Valid Loss: 162.2286
Epoch [16501/30000], Step [1/1], Training Loss: 3919.8640, Valid Loss: 157.0476
Epoch [16601/30000], Step [1/1], Training Loss: 8779.2139, Valid Loss: 138.1524
Epoch [16701/30000], Step [1/1], Training Loss: 5693.0371, Valid Loss: 140.6952
Epoch [16801/30000], Step [1/1], Training Loss: 3441.8625, Valid Loss: 146.2191
Epoch [16901/30000], Step [1/1], Training Loss: 2564.1453, Valid Loss: 183.7333
Epoch [17001/30000], Step [1/1], Training Loss: 2538.6445, Valid Loss: 210.3143
Epoch [17101/30000], Step [1/1], Training Loss: 3964.7402, Valid Loss: 365.1238
Epoch [17201/30000], Step [1/1], Training Loss: 2101.0100, Valid Loss: 370.2000
Epoch [17301/30000], Step [1/1], Training Loss: 2190.9702, Valid Loss: 310.0381
Epoch [17401/30000], Step [1/1], Training Loss: 2208.2224, Valid Loss: 302.6953
Epoch [17501/30000], Step [1/1], Training Loss: 2171.7788, Valid Loss: 224.9048
Epoch [17601/30000], Step [1/1], Training Loss: 1632.9000, Valid Loss: 298.8095
Epoch [17701/30000], Step [1/1], Training Loss: 1660.9314, Valid Loss: 279.5143
Epoch [17801/30000], Step [1/1], Training Loss: 3466.7729, Valid Loss: 276.2000
Epoch [17901/30000], Step [1/1], Training Loss: 2329.2629, Valid Loss: 302.5810
Epoch [18001/30000], Step [1/1], Training Loss: 1601.2881, Valid Loss: 387.9810
Epoch [18101/30000], Step [1/1], Training Loss: 1874.7804, Valid Loss: 418.8953
Epoch [18201/30000], Step [1/1], Training Loss: 459.7631, Valid Loss: 379.8191
Epoch [18301/30000], Step [1/1], Training Loss: 313.6124, Valid Loss: 434.3143
Epoch [18401/30000], Step [1/1], Training Loss: 258.1740, Valid Loss: 417.9238
Epoch [18501/30000], Step [1/1], Training Loss: 217.0805, Valid Loss: 405.7810
Epoch [18601/30000], Step [1/1], Training Loss: 159.7367, Valid Loss: 491.8191
Epoch [18701/30000], Step [1/1], Training Loss: 132.0459, Valid Loss: 451.6095
Epoch [18801/30000], Step [1/1], Training Loss: 125.4033, Valid Loss: 401.1810
Epoch [18901/30000], Step [1/1], Training Loss: 107.6380, Valid Loss: 483.0762
Epoch [19001/30000], Step [1/1], Training Loss: 105.5065, Valid Loss: 465.8571
Epoch [19101/30000], Step [1/1], Training Loss: 100.9918, Valid Loss: 484.9429
Epoch [19201/30000], Step [1/1], Training Loss: 97.3629, Valid Loss: 475.3238
Epoch [19301/30000], Step [1/1], Training Loss: 123.3127, Valid Loss: 461.6857
Epoch [19401/30000], Step [1/1], Training Loss: 73.2300, Valid Loss: 463.6381
Epoch [19501/30000], Step [1/1], Training Loss: 70.4806, Valid Loss: 492.1048
Epoch [19601/30000], Step [1/1], Training Loss: 63.9025, Valid Loss: 416.5238
Epoch [19701/30000], Step [1/1], Training Loss: 66.3659, Valid Loss: 442.6095
Epoch [19801/30000], Step [1/1], Training Loss: 56.7838, Valid Loss: 439.0572
Epoch [19901/30000], Step [1/1], Training Loss: 49.9473, Valid Loss: 477.5810
Epoch [20001/30000], Step [1/1], Training Loss: 47.3308, Valid Loss: 473.2191
Epoch [20101/30000], Step [1/1], Training Loss: 47.4329, Valid Loss: 499.2953
Epoch [20201/30000], Step [1/1], Training Loss: 45.6061, Valid Loss: 453.1238
Epoch [20301/30000], Step [1/1], Training Loss: 4939.7285, Valid Loss: 396.3810
Epoch [20401/30000], Step [1/1], Training Loss: 3390.7178, Valid Loss: 495.7810

[Epoch 25000] Rounded prediction: 
tensor([ 26.,  21.,  22.,  22.,  19.,  17.,  19.,  23.,  24.,  30.,  27.,  44.,
         39.,  41.,  50.,  59., 100.,  85., 119.,  64.,  38.,  35.,  29.,  66.,
          0.,   0.,   0.,   2.,   0.,   6.,   9.,   0.,   0.,   9.,   0.,   0.,
          0.,   0.,   0.,   4.,   0.,  39.,  18.,   0.,   0.,   0.,   0.,   0.,
          0.,   0.,   0.,   0.,  48.,   3.,  43.,  13.,   0.,   0.,   0.,   2.,
          0.,   6.,   0.,  15.,   3.,  42.,  22.,  55.,  68.,  39.,  62.,  76.,
        108., 104.,  80.,  95., 141., 127., 131., 102., 120.,  79.,  97., 127.,
         82.,  52.,  75.,  48.,  31.,  40.,  49., 154., 106.,  96.,  87.,  96.,
         63.,  76.,  75.,   7.,  31.,  85.,  21.,   9.,  58.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [20501/30000], Step [1/1], Training Loss: 1226.0270, Valid Loss: 545.2571
Epoch [20601/30000], Step [1/1], Training Loss: 1059.9584, Valid Loss: 617.2286
Epoch [20701/30000], Step [1/1], Training Loss: 894.9683, Valid Loss: 666.3048
Epoch [20801/30000], Step [1/1], Training Loss: 234.9061, Valid Loss: 572.8762
Epoch [20901/30000], Step [1/1], Training Loss: 167.0255, Valid Loss: 581.2667
Epoch [21001/30000], Step [1/1], Training Loss: 139.1915, Valid Loss: 557.7905
Epoch [21101/30000], Step [1/1], Training Loss: 2231.0586, Valid Loss: 648.6286
Epoch [21201/30000], Step [1/1], Training Loss: 701.7535, Valid Loss: 701.1334
Epoch [21301/30000], Step [1/1], Training Loss: 271.1486, Valid Loss: 483.9048
Epoch [21401/30000], Step [1/1], Training Loss: 151.0033, Valid Loss: 617.1048
Epoch [21501/30000], Step [1/1], Training Loss: 116.5590, Valid Loss: 573.7809
Epoch [21601/30000], Step [1/1], Training Loss: 78.0083, Valid Loss: 602.8857
Epoch [21701/30000], Step [1/1], Training Loss: 82.7012, Valid Loss: 646.1048
Epoch [21801/30000], Step [1/1], Training Loss: 3566.6733, Valid Loss: 673.7619
Epoch [21901/30000], Step [1/1], Training Loss: 2358.1914, Valid Loss: 669.1810
Epoch [22001/30000], Step [1/1], Training Loss: 2507.5979, Valid Loss: 513.2953
Epoch [22101/30000], Step [1/1], Training Loss: 2611.6885, Valid Loss: 641.7238
Epoch [22201/30000], Step [1/1], Training Loss: 2528.3970, Valid Loss: 738.0762
Epoch [22301/30000], Step [1/1], Training Loss: 2142.4854, Valid Loss: 661.7048
Epoch [22401/30000], Step [1/1], Training Loss: 2083.4971, Valid Loss: 856.8572
Epoch [22501/30000], Step [1/1], Training Loss: 1816.9147, Valid Loss: 860.9429
Epoch [22601/30000], Step [1/1], Training Loss: 2649.8218, Valid Loss: 967.5239
Epoch [22701/30000], Step [1/1], Training Loss: 3002.9573, Valid Loss: 791.5143
Epoch [22801/30000], Step [1/1], Training Loss: 2167.0295, Valid Loss: 954.1429
Epoch [22901/30000], Step [1/1], Training Loss: 3592.6743, Valid Loss: 866.4667
Epoch [23001/30000], Step [1/1], Training Loss: 1972.3977, Valid Loss: 739.4381
Epoch [23101/30000], Step [1/1], Training Loss: 2031.2379, Valid Loss: 800.5905
Epoch [23201/30000], Step [1/1], Training Loss: 1640.0094, Valid Loss: 768.8572
Epoch [23301/30000], Step [1/1], Training Loss: 1223.4097, Valid Loss: 678.8572
Epoch [23401/30000], Step [1/1], Training Loss: 760.8989, Valid Loss: 739.0762
Epoch [23501/30000], Step [1/1], Training Loss: 1165.3107, Valid Loss: 763.0477
Epoch [23601/30000], Step [1/1], Training Loss: 769.6339, Valid Loss: 860.3143
Epoch [23701/30000], Step [1/1], Training Loss: 1814.9921, Valid Loss: 1014.7429
Epoch [23801/30000], Step [1/1], Training Loss: 1295.8147, Valid Loss: 1187.8667
Epoch [23901/30000], Step [1/1], Training Loss: 3307.8972, Valid Loss: 1239.0858
Epoch [24001/30000], Step [1/1], Training Loss: 953.3484, Valid Loss: 1064.1429
Epoch [24101/30000], Step [1/1], Training Loss: 242.7730, Valid Loss: 1180.0381
Epoch [24201/30000], Step [1/1], Training Loss: 1505.3972, Valid Loss: 1517.7524
Epoch [24301/30000], Step [1/1], Training Loss: 1046.9148, Valid Loss: 1566.7905
Epoch [24401/30000], Step [1/1], Training Loss: 901.6185, Valid Loss: 1728.2858
Epoch [24501/30000], Step [1/1], Training Loss: 1387.3116, Valid Loss: 2112.9524
Epoch [24601/30000], Step [1/1], Training Loss: 292.0536, Valid Loss: 2044.3905
Epoch [24701/30000], Step [1/1], Training Loss: 192.5117, Valid Loss: 2300.6287
Epoch [24801/30000], Step [1/1], Training Loss: 219.5303, Valid Loss: 2391.1047
Epoch [24901/30000], Step [1/1], Training Loss: 77.0993, Valid Loss: 2381.9238
Epoch [25001/30000], Step [1/1], Training Loss: 57.1929, Valid Loss: 2280.0381
Epoch [25101/30000], Step [1/1], Training Loss: 39.2371, Valid Loss: 2744.0286
Epoch [25201/30000], Step [1/1], Training Loss: 56.2176, Valid Loss: 2679.7239
Epoch [25301/30000], Step [1/1], Training Loss: 24.6241, Valid Loss: 2699.0476
Epoch [25401/30000], Step [1/1], Training Loss: 16.9707, Valid Loss: 2683.7429
Epoch [25501/30000], Step [1/1], Training Loss: 18.0527, Valid Loss: 2629.9429
Epoch [25601/30000], Step [1/1], Training Loss: 27.8303, Valid Loss: 2683.8096
Epoch [25701/30000], Step [1/1], Training Loss: 13.8399, Valid Loss: 2690.4478
Epoch [25801/30000], Step [1/1], Training Loss: 16.7809, Valid Loss: 2586.2383
Epoch [25901/30000], Step [1/1], Training Loss: 23.4941, Valid Loss: 2624.5906
Epoch [26001/30000], Step [1/1], Training Loss: 13.6351, Valid Loss: 2512.8477
Epoch [26101/30000], Step [1/1], Training Loss: 2077.3164, Valid Loss: 2119.5525
Epoch [26201/30000], Step [1/1], Training Loss: 466.1703, Valid Loss: 1962.2286
Epoch [26301/30000], Step [1/1], Training Loss: 212.6628, Valid Loss: 1605.0763
Epoch [26401/30000], Step [1/1], Training Loss: 119.7345, Valid Loss: 1727.4954
Epoch [26501/30000], Step [1/1], Training Loss: 54.2454, Valid Loss: 1811.9524
Epoch [26601/30000], Step [1/1], Training Loss: 44.2986, Valid Loss: 1593.8000
Epoch [26701/30000], Step [1/1], Training Loss: 30.0743, Valid Loss: 1530.1429
Epoch [26801/30000], Step [1/1], Training Loss: 19.8635, Valid Loss: 1568.7048
Epoch [26901/30000], Step [1/1], Training Loss: 26.8936, Valid Loss: 1497.0953
Epoch [27001/30000], Step [1/1], Training Loss: 18.8537, Valid Loss: 1413.5906
Epoch [27101/30000], Step [1/1], Training Loss: 14.7845, Valid Loss: 1272.9619
Epoch [27201/30000], Step [1/1], Training Loss: 1163.9358, Valid Loss: 1395.7715
Epoch [27301/30000], Step [1/1], Training Loss: 643.5413, Valid Loss: 1027.2858
Epoch [27401/30000], Step [1/1], Training Loss: 118.4118, Valid Loss: 1201.6667
Epoch [27501/30000], Step [1/1], Training Loss: 85.1631, Valid Loss: 1173.2762
Epoch [27601/30000], Step [1/1], Training Loss: 67.3587, Valid Loss: 1245.4857
Epoch [27701/30000], Step [1/1], Training Loss: 48.1280, Valid Loss: 1392.6382
Epoch [27801/30000], Step [1/1], Training Loss: 66.4851, Valid Loss: 1279.9714
Epoch [27901/30000], Step [1/1], Training Loss: 12.0598, Valid Loss: 1273.0286
Epoch [28001/30000], Step [1/1], Training Loss: 73.6432, Valid Loss: 1205.9238
Epoch [28101/30000], Step [1/1], Training Loss: 12.6793, Valid Loss: 1280.3334
Epoch [28201/30000], Step [1/1], Training Loss: 7.0206, Valid Loss: 1341.8572
Epoch [28301/30000], Step [1/1], Training Loss: 1551.1813, Valid Loss: 526.6953
Epoch [28401/30000], Step [1/1], Training Loss: 266.3814, Valid Loss: 891.9524
Epoch [28501/30000], Step [1/1], Training Loss: 34.6941, Valid Loss: 830.8191
Epoch [28601/30000], Step [1/1], Training Loss: 19.7082, Valid Loss: 880.2762
Epoch [28701/30000], Step [1/1], Training Loss: 15.9922, Valid Loss: 865.6572
Epoch [28801/30000], Step [1/1], Training Loss: 12.4616, Valid Loss: 914.7905
Epoch [28901/30000], Step [1/1], Training Loss: 8.2610, Valid Loss: 919.5143
Epoch [29001/30000], Step [1/1], Training Loss: 6.1187, Valid Loss: 924.9524
Epoch [29101/30000], Step [1/1], Training Loss: 7.0857, Valid Loss: 900.4381
Epoch [29201/30000], Step [1/1], Training Loss: 6.8441, Valid Loss: 991.7334
Epoch [29301/30000], Step [1/1], Training Loss: 4.4226, Valid Loss: 964.0381
Epoch [29401/30000], Step [1/1], Training Loss: 4.4252, Valid Loss: 902.1048
Epoch [29501/30000], Step [1/1], Training Loss: 3.4039, Valid Loss: 939.7334
Epoch [29601/30000], Step [1/1], Training Loss: 5.8492, Valid Loss: 943.6476
Epoch [29701/30000], Step [1/1], Training Loss: 3.1599, Valid Loss: 989.8191
Epoch [29801/30000], Step [1/1], Training Loss: 4.5564, Valid Loss: 985.5048
Epoch [29901/30000], Step [1/1], Training Loss: 3.4496, Valid Loss: 1028.9524

 End Time: 2021/04/19, 16:35:26




##########################################################

Epochs=30000 	batch=245 	lr=0.0003
window=2 	seq_len=7 	hidden_size=512 	layers=2

Start Time = 2021/04/19, 16:35:27
##########################################################


[Epoch 0] Rounded prediction: 
tensor([1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.],
       device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([18., 13., 16., 16., 17., 15., 17., 14., 14., 11.,  8., 10., 10.,  9.,
        11.,  5.,  0.,  2.,  1., 12., 28., 10., 17., 20.,  0.,  0.,  8.,  6.,
        11.,  8., 16.,  0.,  0., 12.,  5.,  8.,  0.,  9.,  0., 14.,  7., 23.,
         6., 10.,  0.,  0.,  1.,  8.,  7.,  4.,  6., 10., 24.,  0., 23.,  0.,
         0.,  6.,  2., 10.,  0., 17.,  0., 23.,  0., 26.,  0., 24., 18.,  3.,
         4.,  1.,  6.,  2.,  1., 12.,  8., 54.,  2., 21., 29.,  4., 41., 28.,
         7.,  0.,  0.,  6.,  0.,  0., 14., 51., 63., 56., 35., 21., 26., 37.,
        40., 32., 31., 40., 23., 19., 30.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([17., 14., 18., 21., 19., 19., 19., 23., 23., 24., 12., 26., 27., 31.,
        32., 51., 29., 31., 37., 25., 41.,  0.,  0.,  7.,  0.,  0.,  6.,  7.,
         4.,  0., 16.,  0.,  0., 10.,  2.,  0.,  0.,  0.,  0.,  4.,  6., 25.,
         3.,  0.,  0.,  0.,  0.,  3.,  0.,  0.,  0.,  6., 22.,  0.,  9.,  0.,
         0.,  0.,  0., 14.,  0.,  6.,  0., 11.,  0., 13.,  0.,  3., 16.,  2.,
         6., 17., 28., 17., 21., 51., 32., 50., 26., 21., 19.,  8., 28., 41.,
         8.,  0.,  0., 11.,  4., 31., 52., 54., 54., 40., 39., 20., 25., 17.,
        28., 36., 48., 30., 37., 38., 40.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128684.8906, Valid Loss: 223.1048
Epoch [101/30000], Step [1/1], Training Loss: 116856.2578, Valid Loss: 295.3714
Epoch [201/30000], Step [1/1], Training Loss: 110465.0781, Valid Loss: 999.3048
Epoch [301/30000], Step [1/1], Training Loss: 104709.8750, Valid Loss: 2093.8572
Epoch [401/30000], Step [1/1], Training Loss: 99454.8203, Valid Loss: 1363.2858
Epoch [501/30000], Step [1/1], Training Loss: 94166.9609, Valid Loss: 48.6476
Epoch [601/30000], Step [1/1], Training Loss: 89329.2188, Valid Loss: 64.5143
Epoch [701/30000], Step [1/1], Training Loss: 84784.0312, Valid Loss: 53.7619
Epoch [801/30000], Step [1/1], Training Loss: 80515.2891, Valid Loss: 68.6286
Epoch [901/30000], Step [1/1], Training Loss: 76513.9766, Valid Loss: 68.7143
Epoch [1001/30000], Step [1/1], Training Loss: 72767.5312, Valid Loss: 65.8191
Epoch [1101/30000], Step [1/1], Training Loss: 69263.9609, Valid Loss: 76.0571
Epoch [1201/30000], Step [1/1], Training Loss: 65989.8047, Valid Loss: 72.2762
Epoch [1301/30000], Step [1/1], Training Loss: 62937.4336, Valid Loss: 79.3810
Epoch [1401/30000], Step [1/1], Training Loss: 60093.9180, Valid Loss: 80.2190
Epoch [1501/30000], Step [1/1], Training Loss: 57491.6758, Valid Loss: 68.1429
Epoch [1601/30000], Step [1/1], Training Loss: 54758.6484, Valid Loss: 114.9333
Epoch [1701/30000], Step [1/1], Training Loss: 52332.4180, Valid Loss: 162.8476
Epoch [1801/30000], Step [1/1], Training Loss: 49894.1406, Valid Loss: 132.7619
Epoch [1901/30000], Step [1/1], Training Loss: 47644.8047, Valid Loss: 159.0381
Epoch [2001/30000], Step [1/1], Training Loss: 45575.1875, Valid Loss: 125.4381
Epoch [2101/30000], Step [1/1], Training Loss: 43569.9375, Valid Loss: 125.6857
Epoch [2201/30000], Step [1/1], Training Loss: 41604.2812, Valid Loss: 135.7429
Epoch [2301/30000], Step [1/1], Training Loss: 39888.4414, Valid Loss: 130.9619
Epoch [2401/30000], Step [1/1], Training Loss: 38189.7617, Valid Loss: 113.5143
Epoch [2501/30000], Step [1/1], Training Loss: 36628.0469, Valid Loss: 117.7429
Epoch [2601/30000], Step [1/1], Training Loss: 35244.4961, Valid Loss: 122.6667
Epoch [2701/30000], Step [1/1], Training Loss: 36487.9805, Valid Loss: 62.4095
Epoch [2801/30000], Step [1/1], Training Loss: 32429.3906, Valid Loss: 115.3524
Epoch [2901/30000], Step [1/1], Training Loss: 30965.4707, Valid Loss: 111.2381
Epoch [3001/30000], Step [1/1], Training Loss: 30076.9141, Valid Loss: 94.9048
Epoch [3101/30000], Step [1/1], Training Loss: 29070.7930, Valid Loss: 125.6476
Epoch [3201/30000], Step [1/1], Training Loss: 27676.2031, Valid Loss: 69.3619
Epoch [3301/30000], Step [1/1], Training Loss: 26249.0254, Valid Loss: 104.6381
Epoch [3401/30000], Step [1/1], Training Loss: 25117.2695, Valid Loss: 113.5714
Epoch [3501/30000], Step [1/1], Training Loss: 24309.1914, Valid Loss: 105.1905
Epoch [3601/30000], Step [1/1], Training Loss: 23190.2637, Valid Loss: 85.0286
Epoch [3701/30000], Step [1/1], Training Loss: 22734.9238, Valid Loss: 106.6667
Epoch [3801/30000], Step [1/1], Training Loss: 21861.6074, Valid Loss: 145.2857
Epoch [3901/30000], Step [1/1], Training Loss: 21301.7969, Valid Loss: 117.9905
Epoch [4001/30000], Step [1/1], Training Loss: 20080.2637, Valid Loss: 113.6762
Epoch [4101/30000], Step [1/1], Training Loss: 18885.6953, Valid Loss: 124.3048
Epoch [4201/30000], Step [1/1], Training Loss: 17884.0234, Valid Loss: 141.3048
Epoch [4301/30000], Step [1/1], Training Loss: 17088.6113, Valid Loss: 121.9143
Epoch [4401/30000], Step [1/1], Training Loss: 16353.1250, Valid Loss: 115.9429
Epoch [4501/30000], Step [1/1], Training Loss: 15811.0547, Valid Loss: 115.7905
Epoch [4601/30000], Step [1/1], Training Loss: 15038.4531, Valid Loss: 120.1714
Epoch [4701/30000], Step [1/1], Training Loss: 14464.5508, Valid Loss: 122.9048
Epoch [4801/30000], Step [1/1], Training Loss: 13932.0400, Valid Loss: 127.8667
Epoch [4901/30000], Step [1/1], Training Loss: 13429.1865, Valid Loss: 127.6000
Epoch [5001/30000], Step [1/1], Training Loss: 12984.3242, Valid Loss: 135.7333
Epoch [5101/30000], Step [1/1], Training Loss: 12554.3691, Valid Loss: 138.7905
Epoch [5201/30000], Step [1/1], Training Loss: 12153.1328, Valid Loss: 147.8952
Epoch [5301/30000], Step [1/1], Training Loss: 11820.7803, Valid Loss: 129.6190
Epoch [5401/30000], Step [1/1], Training Loss: 11615.2217, Valid Loss: 134.2095
Epoch [5501/30000], Step [1/1], Training Loss: 11521.4336, Valid Loss: 199.8191
Epoch [5601/30000], Step [1/1], Training Loss: 10565.2402, Valid Loss: 225.8857
Epoch [5701/30000], Step [1/1], Training Loss: 10173.3779, Valid Loss: 257.8381
Epoch [5801/30000], Step [1/1], Training Loss: 10430.5283, Valid Loss: 182.2667
Epoch [5901/30000], Step [1/1], Training Loss: 10288.2373, Valid Loss: 156.2952
Epoch [6001/30000], Step [1/1], Training Loss: 9445.6025, Valid Loss: 124.1524
Epoch [6101/30000], Step [1/1], Training Loss: 9288.0723, Valid Loss: 155.2000
Epoch [6201/30000], Step [1/1], Training Loss: 8105.7451, Valid Loss: 173.2857
Epoch [6301/30000], Step [1/1], Training Loss: 7599.5273, Valid Loss: 194.0476
Epoch [6401/30000], Step [1/1], Training Loss: 7270.0957, Valid Loss: 235.3524
Epoch [6501/30000], Step [1/1], Training Loss: 7010.4438, Valid Loss: 182.1810
Epoch [6601/30000], Step [1/1], Training Loss: 6772.9731, Valid Loss: 169.5048
Epoch [6701/30000], Step [1/1], Training Loss: 6708.1343, Valid Loss: 210.3810
Epoch [6801/30000], Step [1/1], Training Loss: 6359.8062, Valid Loss: 193.1714
Epoch [6901/30000], Step [1/1], Training Loss: 5942.7949, Valid Loss: 163.5048
Epoch [7001/30000], Step [1/1], Training Loss: 5527.3047, Valid Loss: 217.5333
Epoch [7101/30000], Step [1/1], Training Loss: 5264.4238, Valid Loss: 202.4476
Epoch [7201/30000], Step [1/1], Training Loss: 5468.7910, Valid Loss: 208.2191
Epoch [7301/30000], Step [1/1], Training Loss: 5430.6577, Valid Loss: 221.8571
Epoch [7401/30000], Step [1/1], Training Loss: 4696.6167, Valid Loss: 377.9619
Epoch [7501/30000], Step [1/1], Training Loss: 4518.9448, Valid Loss: 398.4667
Epoch [7601/30000], Step [1/1], Training Loss: 4339.7148, Valid Loss: 320.7238
Epoch [7701/30000], Step [1/1], Training Loss: 4006.9167, Valid Loss: 278.1524
Epoch [7801/30000], Step [1/1], Training Loss: 3848.8127, Valid Loss: 257.1524
Epoch [7901/30000], Step [1/1], Training Loss: 3713.9128, Valid Loss: 335.4191
Epoch [8001/30000], Step [1/1], Training Loss: 3576.1990, Valid Loss: 340.3905
Epoch [8101/30000], Step [1/1], Training Loss: 3446.3057, Valid Loss: 319.5810
Epoch [8201/30000], Step [1/1], Training Loss: 3312.4082, Valid Loss: 347.6286
Epoch [8301/30000], Step [1/1], Training Loss: 3117.8264, Valid Loss: 285.0476
Epoch [8401/30000], Step [1/1], Training Loss: 2954.7639, Valid Loss: 252.6572
Epoch [8501/30000], Step [1/1], Training Loss: 2834.7742, Valid Loss: 273.5524
Epoch [8601/30000], Step [1/1], Training Loss: 2714.2134, Valid Loss: 260.1810
Epoch [8701/30000], Step [1/1], Training Loss: 2609.7686, Valid Loss: 259.0762
Epoch [8801/30000], Step [1/1], Training Loss: 2494.9490, Valid Loss: 268.0000
Epoch [8901/30000], Step [1/1], Training Loss: 2383.7800, Valid Loss: 254.4857
Epoch [9001/30000], Step [1/1], Training Loss: 2296.7510, Valid Loss: 290.3619
Epoch [9101/30000], Step [1/1], Training Loss: 2191.4241, Valid Loss: 292.1143
Epoch [9201/30000], Step [1/1], Training Loss: 2099.4460, Valid Loss: 357.4762
Epoch [9301/30000], Step [1/1], Training Loss: 2012.5199, Valid Loss: 268.7810
Epoch [9401/30000], Step [1/1], Training Loss: 1939.1608, Valid Loss: 317.7143
Epoch [9501/30000], Step [1/1], Training Loss: 7069.0308, Valid Loss: 232.7810
Epoch [9601/30000], Step [1/1], Training Loss: 3933.4333, Valid Loss: 187.0000
Epoch [9701/30000], Step [1/1], Training Loss: 3409.8713, Valid Loss: 161.5810
Epoch [9801/30000], Step [1/1], Training Loss: 3171.3882, Valid Loss: 273.6000
Epoch [9901/30000], Step [1/1], Training Loss: 2947.6545, Valid Loss: 254.5048
Epoch [10001/30000], Step [1/1], Training Loss: 1979.0063, Valid Loss: 199.3333
Epoch [10101/30000], Step [1/1], Training Loss: 2867.5969, Valid Loss: 186.3905

[Epoch 15000] Rounded prediction: 
tensor([17., 21., 30., 18., 20., 24., 23., 31., 18., 24., 19., 51., 40., 62.,
        60., 70., 87., 70., 30., 27., 59., 14.,  2., 15.,  0.,  0.,  0.,  7.,
         3.,  0.,  3.,  0.,  0.,  7.,  1.,  0.,  0.,  0.,  0.,  0.,  0., 25.,
        19.,  0.,  0.,  0.,  0.,  3.,  0.,  2.,  6., 15., 41.,  0.,  7.,  0.,
         0.,  0.,  2.,  3.,  0.,  5.,  0., 22.,  5., 27., 18., 26., 23., 11.,
        48., 72., 76., 53., 63., 75., 57., 53., 57.,  8., 40., 29., 45., 65.,
        38., 24., 40., 35., 36., 51., 89., 70., 73., 68., 55., 29., 18., 25.,
        25., 44., 59., 67., 54., 24., 55.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([ 13.,  21.,  22.,  11.,  16.,  15.,  21.,  24.,  25.,  38.,  33.,  63.,
         53.,  83.,  91.,  96., 120.,  77.,  42.,  39.,  56.,  21.,   0.,   0.,
          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
          0.,   0.,   0.,   0.,   0.,  19.,   0.,   0.,  72.,  65.,  70.,  91.,
         87.,  78.,  83., 110.,  79.,  67.,  65.,  79.,  82.,  82.,  70.,  76.,
         62.,  39.,  43.,  56.,  53.,  55.,  72.,  84.,  83., 100., 102.,  88.,
         47.,  35.,  31.,  40.,  74.,  41.,  53.,  17.,  36.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [10201/30000], Step [1/1], Training Loss: 1313.3558, Valid Loss: 160.2095
Epoch [10301/30000], Step [1/1], Training Loss: 1231.0178, Valid Loss: 147.7905
Epoch [10401/30000], Step [1/1], Training Loss: 1150.4930, Valid Loss: 141.8571
Epoch [10501/30000], Step [1/1], Training Loss: 1088.3054, Valid Loss: 149.5238
Epoch [10601/30000], Step [1/1], Training Loss: 1027.7203, Valid Loss: 145.4667
Epoch [10701/30000], Step [1/1], Training Loss: 1015.3307, Valid Loss: 153.8476
Epoch [10801/30000], Step [1/1], Training Loss: 944.0334, Valid Loss: 167.3238
Epoch [10901/30000], Step [1/1], Training Loss: 908.7479, Valid Loss: 181.5143
Epoch [11001/30000], Step [1/1], Training Loss: 868.7798, Valid Loss: 161.7905
Epoch [11101/30000], Step [1/1], Training Loss: 830.7489, Valid Loss: 152.8000
Epoch [11201/30000], Step [1/1], Training Loss: 797.8101, Valid Loss: 158.5524
Epoch [11301/30000], Step [1/1], Training Loss: 778.3577, Valid Loss: 174.7810
Epoch [11401/30000], Step [1/1], Training Loss: 735.6251, Valid Loss: 155.2762
Epoch [11501/30000], Step [1/1], Training Loss: 707.1258, Valid Loss: 172.7810
Epoch [11601/30000], Step [1/1], Training Loss: 680.2384, Valid Loss: 187.4095
Epoch [11701/30000], Step [1/1], Training Loss: 657.5488, Valid Loss: 169.7714
Epoch [11801/30000], Step [1/1], Training Loss: 628.6001, Valid Loss: 171.5333
Epoch [11901/30000], Step [1/1], Training Loss: 622.1246, Valid Loss: 155.5714
Epoch [12001/30000], Step [1/1], Training Loss: 582.8599, Valid Loss: 163.4857
Epoch [12101/30000], Step [1/1], Training Loss: 558.2517, Valid Loss: 168.4667
Epoch [12201/30000], Step [1/1], Training Loss: 536.5796, Valid Loss: 171.2572
Epoch [12301/30000], Step [1/1], Training Loss: 512.2460, Valid Loss: 159.2952
Epoch [12401/30000], Step [1/1], Training Loss: 490.8644, Valid Loss: 182.8000
Epoch [12501/30000], Step [1/1], Training Loss: 471.4669, Valid Loss: 175.0762
Epoch [12601/30000], Step [1/1], Training Loss: 454.4323, Valid Loss: 171.8762
Epoch [12701/30000], Step [1/1], Training Loss: 430.4608, Valid Loss: 194.0381
Epoch [12801/30000], Step [1/1], Training Loss: 413.7579, Valid Loss: 191.1429
Epoch [12901/30000], Step [1/1], Training Loss: 394.7928, Valid Loss: 184.8000
Epoch [13001/30000], Step [1/1], Training Loss: 377.4373, Valid Loss: 181.6095
Epoch [13101/30000], Step [1/1], Training Loss: 359.6214, Valid Loss: 177.2476
Epoch [13201/30000], Step [1/1], Training Loss: 341.9869, Valid Loss: 196.2857
Epoch [13301/30000], Step [1/1], Training Loss: 324.7502, Valid Loss: 169.4476
Epoch [13401/30000], Step [1/1], Training Loss: 308.9617, Valid Loss: 194.2762
Epoch [13501/30000], Step [1/1], Training Loss: 290.7487, Valid Loss: 182.3238
Epoch [13601/30000], Step [1/1], Training Loss: 275.9619, Valid Loss: 205.5810
Epoch [13701/30000], Step [1/1], Training Loss: 259.2588, Valid Loss: 167.6381
Epoch [13801/30000], Step [1/1], Training Loss: 244.6274, Valid Loss: 234.1714
Epoch [13901/30000], Step [1/1], Training Loss: 228.7616, Valid Loss: 209.2952
Epoch [14001/30000], Step [1/1], Training Loss: 213.3715, Valid Loss: 210.9333
Epoch [14101/30000], Step [1/1], Training Loss: 5531.2095, Valid Loss: 776.4000
Epoch [14201/30000], Step [1/1], Training Loss: 4530.5283, Valid Loss: 681.1810
Epoch [14301/30000], Step [1/1], Training Loss: 2418.5039, Valid Loss: 869.0096
Epoch [14401/30000], Step [1/1], Training Loss: 1931.6852, Valid Loss: 1099.6572
Epoch [14501/30000], Step [1/1], Training Loss: 2086.0244, Valid Loss: 1046.8381
Epoch [14601/30000], Step [1/1], Training Loss: 978.3550, Valid Loss: 933.1524
Epoch [14701/30000], Step [1/1], Training Loss: 805.3652, Valid Loss: 1109.5048
Epoch [14801/30000], Step [1/1], Training Loss: 799.4524, Valid Loss: 1087.0095
Epoch [14901/30000], Step [1/1], Training Loss: 804.9066, Valid Loss: 1165.4762
Epoch [15001/30000], Step [1/1], Training Loss: 1361.7229, Valid Loss: 764.8191
Epoch [15101/30000], Step [1/1], Training Loss: 3197.1499, Valid Loss: 966.3619
Epoch [15201/30000], Step [1/1], Training Loss: 2226.6968, Valid Loss: 697.1334
Epoch [15301/30000], Step [1/1], Training Loss: 1564.8400, Valid Loss: 554.5238
Epoch [15401/30000], Step [1/1], Training Loss: 1015.7743, Valid Loss: 786.0953
Epoch [15501/30000], Step [1/1], Training Loss: 876.9824, Valid Loss: 709.2381
Epoch [15601/30000], Step [1/1], Training Loss: 593.9268, Valid Loss: 915.5810
Epoch [15701/30000], Step [1/1], Training Loss: 512.0247, Valid Loss: 945.9905
Epoch [15801/30000], Step [1/1], Training Loss: 390.0288, Valid Loss: 895.0762
Epoch [15901/30000], Step [1/1], Training Loss: 630.5100, Valid Loss: 883.7810
Epoch [16001/30000], Step [1/1], Training Loss: 407.3356, Valid Loss: 694.3715
Epoch [16101/30000], Step [1/1], Training Loss: 319.7573, Valid Loss: 716.7333
Epoch [16201/30000], Step [1/1], Training Loss: 286.8833, Valid Loss: 773.2286
Epoch [16301/30000], Step [1/1], Training Loss: 281.8634, Valid Loss: 748.7429
Epoch [16401/30000], Step [1/1], Training Loss: 289.0521, Valid Loss: 758.3619
Epoch [16501/30000], Step [1/1], Training Loss: 261.2358, Valid Loss: 825.4476
Epoch [16601/30000], Step [1/1], Training Loss: 980.2451, Valid Loss: 615.4000
Epoch [16701/30000], Step [1/1], Training Loss: 309.7814, Valid Loss: 714.6381
Epoch [16801/30000], Step [1/1], Training Loss: 269.4935, Valid Loss: 760.9333
Epoch [16901/30000], Step [1/1], Training Loss: 243.7880, Valid Loss: 758.5620
Epoch [17001/30000], Step [1/1], Training Loss: 231.3628, Valid Loss: 832.6667
Epoch [17101/30000], Step [1/1], Training Loss: 236.7191, Valid Loss: 825.4476
Epoch [17201/30000], Step [1/1], Training Loss: 211.1107, Valid Loss: 835.5905
Epoch [17301/30000], Step [1/1], Training Loss: 206.7343, Valid Loss: 880.3239
Epoch [17401/30000], Step [1/1], Training Loss: 212.2216, Valid Loss: 797.8667
Epoch [17501/30000], Step [1/1], Training Loss: 2998.4839, Valid Loss: 431.8571
Epoch [17601/30000], Step [1/1], Training Loss: 2835.0244, Valid Loss: 297.6190
Epoch [17701/30000], Step [1/1], Training Loss: 1866.8259, Valid Loss: 436.0857
Epoch [17801/30000], Step [1/1], Training Loss: 1427.6112, Valid Loss: 536.0572
Epoch [17901/30000], Step [1/1], Training Loss: 397.9150, Valid Loss: 594.6572
Epoch [18001/30000], Step [1/1], Training Loss: 305.2439, Valid Loss: 710.7905
Epoch [18101/30000], Step [1/1], Training Loss: 227.1355, Valid Loss: 628.7524
Epoch [18201/30000], Step [1/1], Training Loss: 173.2200, Valid Loss: 754.2191
Epoch [18301/30000], Step [1/1], Training Loss: 149.7421, Valid Loss: 723.4572
Epoch [18401/30000], Step [1/1], Training Loss: 141.6375, Valid Loss: 742.1714
Epoch [18501/30000], Step [1/1], Training Loss: 119.3429, Valid Loss: 795.5715
Epoch [18601/30000], Step [1/1], Training Loss: 116.7572, Valid Loss: 708.2858
Epoch [18701/30000], Step [1/1], Training Loss: 138.6597, Valid Loss: 578.8762
Epoch [18801/30000], Step [1/1], Training Loss: 104.9006, Valid Loss: 655.8953
Epoch [18901/30000], Step [1/1], Training Loss: 76.0988, Valid Loss: 575.2476
Epoch [19001/30000], Step [1/1], Training Loss: 81.6414, Valid Loss: 712.3810
Epoch [19101/30000], Step [1/1], Training Loss: 93.9556, Valid Loss: 560.9810
Epoch [19201/30000], Step [1/1], Training Loss: 103.0526, Valid Loss: 700.0286
Epoch [19301/30000], Step [1/1], Training Loss: 62.8300, Valid Loss: 664.6096
Epoch [19401/30000], Step [1/1], Training Loss: 84.5803, Valid Loss: 575.8191
Epoch [19501/30000], Step [1/1], Training Loss: 57.9976, Valid Loss: 624.4000
Epoch [19601/30000], Step [1/1], Training Loss: 74.0446, Valid Loss: 663.4952
Epoch [19701/30000], Step [1/1], Training Loss: 4539.1670, Valid Loss: 632.8762
Epoch [19801/30000], Step [1/1], Training Loss: 1033.9664, Valid Loss: 1320.6667
Epoch [19901/30000], Step [1/1], Training Loss: 3018.7202, Valid Loss: 2222.6667
Epoch [20001/30000], Step [1/1], Training Loss: 3803.4758, Valid Loss: 1538.0096
Epoch [20101/30000], Step [1/1], Training Loss: 3224.1582, Valid Loss: 2572.8096
Epoch [20201/30000], Step [1/1], Training Loss: 2249.0967, Valid Loss: 2450.7620
Epoch [20301/30000], Step [1/1], Training Loss: 2037.1162, Valid Loss: 2352.8857
Epoch [20401/30000], Step [1/1], Training Loss: 3735.8198, Valid Loss: 2283.9619

[Epoch 25000] Rounded prediction: 
tensor([ 16.,  22.,  24.,  20.,  26.,  24.,  26.,  35.,  38.,  49.,  53.,  91.,
         84., 106., 119., 116., 136.,  57.,  55.,  31.,  68.,  51.,  72.,  88.,
         40.,   0.,   0.,   0.,  15.,   7.,   0.,   0.,   0.,   0.,   3.,   0.,
          0.,   0.,   0.,   0.,   0.,  14.,  81.,  42.,   0.,   0.,   0.,   0.,
          5.,  19.,  16.,  23.,  59.,  53.,  23.,  34.,   0.,   0.,   0.,   0.,
          2.,   5.,   4.,  29.,  33.,  36.,  61.,  67.,  97.,  71.,  83.,  90.,
         97.,  82.,  83., 103., 115.,  50., 103.,  83.,  66., 101.,  18.,  35.,
         60.,  37.,  58.,  64.,  80.,  92.,  58.,  47.,  46.,  70.,  84.,  90.,
         25.,   0.,   0.,  21.,  42.,  49.,  57.,  52.,  52.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [20501/30000], Step [1/1], Training Loss: 1622.4631, Valid Loss: 1870.0858
Epoch [20601/30000], Step [1/1], Training Loss: 1804.6588, Valid Loss: 2404.3716
Epoch [20701/30000], Step [1/1], Training Loss: 1065.3402, Valid Loss: 2566.7620
Epoch [20801/30000], Step [1/1], Training Loss: 1346.7220, Valid Loss: 2576.7810
Epoch [20901/30000], Step [1/1], Training Loss: 2517.9836, Valid Loss: 2443.6763
Epoch [21001/30000], Step [1/1], Training Loss: 819.0137, Valid Loss: 2803.8000
Epoch [21101/30000], Step [1/1], Training Loss: 1004.0733, Valid Loss: 2891.8000
Epoch [21201/30000], Step [1/1], Training Loss: 668.4534, Valid Loss: 2550.0095
Epoch [21301/30000], Step [1/1], Training Loss: 772.0312, Valid Loss: 2509.5906
Epoch [21401/30000], Step [1/1], Training Loss: 822.5227, Valid Loss: 2785.4097
Epoch [21501/30000], Step [1/1], Training Loss: 3206.1377, Valid Loss: 2533.1145
Epoch [21601/30000], Step [1/1], Training Loss: 1575.8284, Valid Loss: 2178.2002
Epoch [21701/30000], Step [1/1], Training Loss: 608.9224, Valid Loss: 2373.1716
Epoch [21801/30000], Step [1/1], Training Loss: 1588.0490, Valid Loss: 2593.1240
Epoch [21901/30000], Step [1/1], Training Loss: 610.4197, Valid Loss: 2153.4192
Epoch [22001/30000], Step [1/1], Training Loss: 1421.3396, Valid Loss: 1974.8096
Epoch [22101/30000], Step [1/1], Training Loss: 6319.6572, Valid Loss: 1822.9716
Epoch [22201/30000], Step [1/1], Training Loss: 3127.2942, Valid Loss: 1933.6001
Epoch [22301/30000], Step [1/1], Training Loss: 2000.1572, Valid Loss: 1775.8477
Epoch [22401/30000], Step [1/1], Training Loss: 756.0806, Valid Loss: 2263.1716
Epoch [22501/30000], Step [1/1], Training Loss: 425.1074, Valid Loss: 2421.5049
Epoch [22601/30000], Step [1/1], Training Loss: 530.0360, Valid Loss: 2232.1526
Epoch [22701/30000], Step [1/1], Training Loss: 1122.0538, Valid Loss: 2211.0476
Epoch [22801/30000], Step [1/1], Training Loss: 679.1047, Valid Loss: 2099.5525
Epoch [22901/30000], Step [1/1], Training Loss: 720.4189, Valid Loss: 2101.0571
Epoch [23001/30000], Step [1/1], Training Loss: 1069.6036, Valid Loss: 1494.7048
Epoch [23101/30000], Step [1/1], Training Loss: 1103.6112, Valid Loss: 1277.8667
Epoch [23201/30000], Step [1/1], Training Loss: 1696.5546, Valid Loss: 1480.0763
Epoch [23301/30000], Step [1/1], Training Loss: 867.4529, Valid Loss: 1481.9048
Epoch [23401/30000], Step [1/1], Training Loss: 3448.9690, Valid Loss: 1331.7144
Epoch [23501/30000], Step [1/1], Training Loss: 1235.9705, Valid Loss: 1286.5525
Epoch [23601/30000], Step [1/1], Training Loss: 1344.1222, Valid Loss: 1234.8762
Epoch [23701/30000], Step [1/1], Training Loss: 1043.9647, Valid Loss: 1083.1334
Epoch [23801/30000], Step [1/1], Training Loss: 862.6920, Valid Loss: 1442.5811
Epoch [23901/30000], Step [1/1], Training Loss: 1512.4755, Valid Loss: 1208.4000
Epoch [24001/30000], Step [1/1], Training Loss: 639.2822, Valid Loss: 1371.6763
Epoch [24101/30000], Step [1/1], Training Loss: 5492.5386, Valid Loss: 1097.5143
Epoch [24201/30000], Step [1/1], Training Loss: 3655.1514, Valid Loss: 2753.6191
Epoch [24301/30000], Step [1/1], Training Loss: 1911.7264, Valid Loss: 2349.9810
Epoch [24401/30000], Step [1/1], Training Loss: 1578.2476, Valid Loss: 2202.1621
Epoch [24501/30000], Step [1/1], Training Loss: 1548.0912, Valid Loss: 2580.0000
Epoch [24601/30000], Step [1/1], Training Loss: 1249.9027, Valid Loss: 2139.9619
Epoch [24701/30000], Step [1/1], Training Loss: 1575.2235, Valid Loss: 2784.1335
Epoch [24801/30000], Step [1/1], Training Loss: 1111.1130, Valid Loss: 2326.6763
Epoch [24901/30000], Step [1/1], Training Loss: 2010.4771, Valid Loss: 2524.7524
Epoch [25001/30000], Step [1/1], Training Loss: 1529.6003, Valid Loss: 2189.3716
Epoch [25101/30000], Step [1/1], Training Loss: 790.4968, Valid Loss: 2837.2383
Epoch [25201/30000], Step [1/1], Training Loss: 942.7393, Valid Loss: 2906.3906
Epoch [25301/30000], Step [1/1], Training Loss: 745.6810, Valid Loss: 2749.8286
Epoch [25401/30000], Step [1/1], Training Loss: 3662.0872, Valid Loss: 4107.7812
Epoch [25501/30000], Step [1/1], Training Loss: 1688.4854, Valid Loss: 6043.4575
Epoch [25601/30000], Step [1/1], Training Loss: 870.7487, Valid Loss: 4299.2095
Epoch [25701/30000], Step [1/1], Training Loss: 774.6337, Valid Loss: 4444.6191
Epoch [25801/30000], Step [1/1], Training Loss: 453.7739, Valid Loss: 4031.1812
Epoch [25901/30000], Step [1/1], Training Loss: 4047.1770, Valid Loss: 4201.7812
Epoch [26001/30000], Step [1/1], Training Loss: 2436.6321, Valid Loss: 2839.2383
Epoch [26101/30000], Step [1/1], Training Loss: 1651.9707, Valid Loss: 3606.7048
Epoch [26201/30000], Step [1/1], Training Loss: 1813.5739, Valid Loss: 2558.5525
Epoch [26301/30000], Step [1/1], Training Loss: 979.1150, Valid Loss: 2850.9238
Epoch [26401/30000], Step [1/1], Training Loss: 624.2504, Valid Loss: 2896.8667
Epoch [26501/30000], Step [1/1], Training Loss: 766.8293, Valid Loss: 3346.6572
Epoch [26601/30000], Step [1/1], Training Loss: 381.7284, Valid Loss: 3216.2859
Epoch [26701/30000], Step [1/1], Training Loss: 220.1461, Valid Loss: 3348.1812
Epoch [26801/30000], Step [1/1], Training Loss: 226.0964, Valid Loss: 3002.2192
Epoch [26901/30000], Step [1/1], Training Loss: 132.9127, Valid Loss: 3210.5620
Epoch [27001/30000], Step [1/1], Training Loss: 114.0283, Valid Loss: 3129.1812
Epoch [27101/30000], Step [1/1], Training Loss: 97.0202, Valid Loss: 2824.5811
Epoch [27201/30000], Step [1/1], Training Loss: 134.2622, Valid Loss: 2955.3335
Epoch [27301/30000], Step [1/1], Training Loss: 112.4559, Valid Loss: 2865.6953
Epoch [27401/30000], Step [1/1], Training Loss: 92.3947, Valid Loss: 2771.7715
Epoch [27501/30000], Step [1/1], Training Loss: 1362.8982, Valid Loss: 3007.8191
Epoch [27601/30000], Step [1/1], Training Loss: 1591.3621, Valid Loss: 3618.4668
Epoch [27701/30000], Step [1/1], Training Loss: 912.2219, Valid Loss: 3450.6001
Epoch [27801/30000], Step [1/1], Training Loss: 1559.3926, Valid Loss: 3670.3716
Epoch [27901/30000], Step [1/1], Training Loss: 436.4933, Valid Loss: 3079.4192
Epoch [28001/30000], Step [1/1], Training Loss: 589.6558, Valid Loss: 2529.4001
Epoch [28101/30000], Step [1/1], Training Loss: 1980.1162, Valid Loss: 2640.4668
Epoch [28201/30000], Step [1/1], Training Loss: 373.4775, Valid Loss: 2922.2954
Epoch [28301/30000], Step [1/1], Training Loss: 171.0871, Valid Loss: 2587.6191
Epoch [28401/30000], Step [1/1], Training Loss: 120.1379, Valid Loss: 2735.1812
Epoch [28501/30000], Step [1/1], Training Loss: 112.8146, Valid Loss: 2597.5049
Epoch [28601/30000], Step [1/1], Training Loss: 101.1888, Valid Loss: 2649.3145
Epoch [28701/30000], Step [1/1], Training Loss: 111.2762, Valid Loss: 2504.9619
Epoch [28801/30000], Step [1/1], Training Loss: 86.6676, Valid Loss: 2379.0857
Epoch [28901/30000], Step [1/1], Training Loss: 59.7667, Valid Loss: 2523.0952
Epoch [29001/30000], Step [1/1], Training Loss: 81.2729, Valid Loss: 2477.1526
Epoch [29101/30000], Step [1/1], Training Loss: 67.1756, Valid Loss: 2493.1716
Epoch [29201/30000], Step [1/1], Training Loss: 40.1110, Valid Loss: 2501.1716
Epoch [29301/30000], Step [1/1], Training Loss: 1781.7192, Valid Loss: 3070.4001
Epoch [29401/30000], Step [1/1], Training Loss: 370.1875, Valid Loss: 3272.0859
Epoch [29501/30000], Step [1/1], Training Loss: 121.3169, Valid Loss: 2975.4097
Epoch [29601/30000], Step [1/1], Training Loss: 102.3110, Valid Loss: 3252.7810
Epoch [29701/30000], Step [1/1], Training Loss: 79.8198, Valid Loss: 3368.8762
Epoch [29801/30000], Step [1/1], Training Loss: 101.3964, Valid Loss: 3083.4954
Epoch [29901/30000], Step [1/1], Training Loss: 908.3718, Valid Loss: 3252.3430

 End Time: 2021/04/19, 16:42:13




##########################################################

Epochs=30000 	batch=245 	lr=0.0003
window=2 	seq_len=7 	hidden_size=512 	layers=2

Start Time = 2021/04/19, 16:42:13
##########################################################


[Epoch 0] Rounded prediction: 
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([23., 22., 13., 13.,  5., 12., 17., 13., 17., 11., 10.,  8.,  4.,  5.,
         5., 13., 11., 11., 14., 17., 20., 14., 13., 17.,  9.,  6., 12.,  8.,
         8., 10., 14.,  1.,  2., 20.,  3.,  9.,  3., 13.,  1., 20.,  3., 22.,
        11.,  7.,  1.,  9.,  5.,  8.,  9., 11., 11., 10., 16.,  2., 21., 11.,
         1., 10., 12., 12.,  1., 15.,  2., 27.,  1., 25., 12., 19., 13., 15.,
         9.,  8., 14., 10., 11., 20., 16., 19., 17., 12., 19.,  9., 26., 20.,
         3., 11., 18., 10.,  4., 12., 27., 48., 37., 26., 21., 18., 27., 40.,
        35., 34., 32., 26., 29., 30., 36.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([27., 25., 22., 11., 12., 16., 28., 27., 30., 31., 28., 33., 19., 18.,
        25., 13., 40., 31., 32., 22., 29., 28., 21., 20., 16.,  9.,  0., 12.,
         9.,  6., 11.,  1.,  2., 14., 17.,  2.,  0.,  6.,  4., 13.,  0., 17.,
        16.,  3.,  0., 14.,  0.,  7.,  2., 10., 22., 24., 18., 10., 25., 13.,
         4.,  0., 15.,  9.,  3.,  5.,  7., 29., 20., 33., 26., 25., 32., 47.,
        37., 47., 55., 44., 40., 39., 45., 33., 32., 28., 30., 39., 19., 22.,
        55., 57., 54., 23., 12., 14., 15., 30., 35., 41., 43., 53., 55., 56.,
        49., 58., 55., 43., 62., 54., 43.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128681.7500, Valid Loss: 208.9238
Epoch [101/30000], Step [1/1], Training Loss: 116830.5547, Valid Loss: 311.7524
Epoch [201/30000], Step [1/1], Training Loss: 110448.1719, Valid Loss: 999.3048
Epoch [301/30000], Step [1/1], Training Loss: 104694.3984, Valid Loss: 2094.5715
Epoch [401/30000], Step [1/1], Training Loss: 99280.6641, Valid Loss: 85.4191
Epoch [501/30000], Step [1/1], Training Loss: 94096.1953, Valid Loss: 48.1333
Epoch [601/30000], Step [1/1], Training Loss: 89274.1250, Valid Loss: 60.4952
Epoch [701/30000], Step [1/1], Training Loss: 84740.0000, Valid Loss: 81.0857
Epoch [801/30000], Step [1/1], Training Loss: 80485.3516, Valid Loss: 75.7429
Epoch [901/30000], Step [1/1], Training Loss: 76498.4844, Valid Loss: 92.0667
Epoch [1001/30000], Step [1/1], Training Loss: 72758.9688, Valid Loss: 90.3429
Epoch [1101/30000], Step [1/1], Training Loss: 69260.2031, Valid Loss: 101.6286
Epoch [1201/30000], Step [1/1], Training Loss: 65992.6328, Valid Loss: 104.3524
Epoch [1301/30000], Step [1/1], Training Loss: 62946.9453, Valid Loss: 81.2571
Epoch [1401/30000], Step [1/1], Training Loss: 60108.6953, Valid Loss: 76.9429
Epoch [1501/30000], Step [1/1], Training Loss: 57471.7617, Valid Loss: 78.8000
Epoch [1601/30000], Step [1/1], Training Loss: 54828.1914, Valid Loss: 112.8381
Epoch [1701/30000], Step [1/1], Training Loss: 52323.8086, Valid Loss: 150.0000
Epoch [1801/30000], Step [1/1], Training Loss: 50037.6367, Valid Loss: 122.2762
Epoch [1901/30000], Step [1/1], Training Loss: 47699.3008, Valid Loss: 131.0000
Epoch [2001/30000], Step [1/1], Training Loss: 45570.1328, Valid Loss: 113.6572
Epoch [2101/30000], Step [1/1], Training Loss: 43789.9688, Valid Loss: 116.2667
Epoch [2201/30000], Step [1/1], Training Loss: 41789.9805, Valid Loss: 121.6857
Epoch [2301/30000], Step [1/1], Training Loss: 40034.3516, Valid Loss: 155.8952
Epoch [2401/30000], Step [1/1], Training Loss: 38460.6680, Valid Loss: 116.7619
Epoch [2501/30000], Step [1/1], Training Loss: 36921.4102, Valid Loss: 108.6667
Epoch [2601/30000], Step [1/1], Training Loss: 35428.8164, Valid Loss: 106.7714
Epoch [2701/30000], Step [1/1], Training Loss: 34026.6094, Valid Loss: 122.2381
Epoch [2801/30000], Step [1/1], Training Loss: 32702.3398, Valid Loss: 139.3524
Epoch [2901/30000], Step [1/1], Training Loss: 31542.6074, Valid Loss: 88.3810
Epoch [3001/30000], Step [1/1], Training Loss: 30703.5215, Valid Loss: 68.0667
Epoch [3101/30000], Step [1/1], Training Loss: 29063.5117, Valid Loss: 100.6476
Epoch [3201/30000], Step [1/1], Training Loss: 27962.6367, Valid Loss: 63.9143
Epoch [3301/30000], Step [1/1], Training Loss: 27244.9570, Valid Loss: 145.2762
Epoch [3401/30000], Step [1/1], Training Loss: 27162.5645, Valid Loss: 114.5810
Epoch [3501/30000], Step [1/1], Training Loss: 25202.0879, Valid Loss: 132.1333
Epoch [3601/30000], Step [1/1], Training Loss: 24174.2949, Valid Loss: 108.9143
Epoch [3701/30000], Step [1/1], Training Loss: 22819.5605, Valid Loss: 79.0191
Epoch [3801/30000], Step [1/1], Training Loss: 21755.7383, Valid Loss: 84.4000
Epoch [3901/30000], Step [1/1], Training Loss: 21078.7852, Valid Loss: 91.6667
Epoch [4001/30000], Step [1/1], Training Loss: 20261.6465, Valid Loss: 71.3905
Epoch [4101/30000], Step [1/1], Training Loss: 19440.5176, Valid Loss: 89.0476
Epoch [4201/30000], Step [1/1], Training Loss: 18505.2383, Valid Loss: 88.7429
Epoch [4301/30000], Step [1/1], Training Loss: 17821.2969, Valid Loss: 88.3714
Epoch [4401/30000], Step [1/1], Training Loss: 17133.1895, Valid Loss: 88.0952
Epoch [4501/30000], Step [1/1], Training Loss: 16588.9785, Valid Loss: 100.0571
Epoch [4601/30000], Step [1/1], Training Loss: 15850.2217, Valid Loss: 101.3429
Epoch [4701/30000], Step [1/1], Training Loss: 17641.8906, Valid Loss: 86.6095
Epoch [4801/30000], Step [1/1], Training Loss: 15608.1035, Valid Loss: 106.9810
Epoch [4901/30000], Step [1/1], Training Loss: 15990.0322, Valid Loss: 84.4952
Epoch [5001/30000], Step [1/1], Training Loss: 14641.2129, Valid Loss: 72.2667
Epoch [5101/30000], Step [1/1], Training Loss: 13619.5049, Valid Loss: 85.2952
Epoch [5201/30000], Step [1/1], Training Loss: 13583.2275, Valid Loss: 76.0952
Epoch [5301/30000], Step [1/1], Training Loss: 12970.5908, Valid Loss: 75.2000
Epoch [5401/30000], Step [1/1], Training Loss: 12120.2402, Valid Loss: 133.3429
Epoch [5501/30000], Step [1/1], Training Loss: 11258.5596, Valid Loss: 107.8762
Epoch [5601/30000], Step [1/1], Training Loss: 10587.5859, Valid Loss: 101.8571
Epoch [5701/30000], Step [1/1], Training Loss: 10214.1211, Valid Loss: 93.8286
Epoch [5801/30000], Step [1/1], Training Loss: 9878.5801, Valid Loss: 127.7143
Epoch [5901/30000], Step [1/1], Training Loss: 9254.4443, Valid Loss: 110.3429
Epoch [6001/30000], Step [1/1], Training Loss: 9322.9219, Valid Loss: 73.4381
Epoch [6101/30000], Step [1/1], Training Loss: 8638.9570, Valid Loss: 141.7333
Epoch [6201/30000], Step [1/1], Training Loss: 8136.9189, Valid Loss: 114.2571
Epoch [6301/30000], Step [1/1], Training Loss: 7372.5723, Valid Loss: 100.4191
Epoch [6401/30000], Step [1/1], Training Loss: 7092.7485, Valid Loss: 113.0095
Epoch [6501/30000], Step [1/1], Training Loss: 7006.9126, Valid Loss: 129.8190
Epoch [6601/30000], Step [1/1], Training Loss: 7154.3574, Valid Loss: 117.2381
Epoch [6701/30000], Step [1/1], Training Loss: 7415.5259, Valid Loss: 158.7048
Epoch [6801/30000], Step [1/1], Training Loss: 6102.8486, Valid Loss: 120.7048
Epoch [6901/30000], Step [1/1], Training Loss: 5802.5396, Valid Loss: 110.9429
Epoch [7001/30000], Step [1/1], Training Loss: 5416.5981, Valid Loss: 135.4286
Epoch [7101/30000], Step [1/1], Training Loss: 5146.2944, Valid Loss: 107.4191
Epoch [7201/30000], Step [1/1], Training Loss: 4907.0342, Valid Loss: 133.7143
Epoch [7301/30000], Step [1/1], Training Loss: 4678.2026, Valid Loss: 108.7619
Epoch [7401/30000], Step [1/1], Training Loss: 4615.9731, Valid Loss: 110.7143
Epoch [7501/30000], Step [1/1], Training Loss: 4348.4805, Valid Loss: 150.1905
Epoch [7601/30000], Step [1/1], Training Loss: 4133.9741, Valid Loss: 105.6857
Epoch [7701/30000], Step [1/1], Training Loss: 3943.8530, Valid Loss: 84.4476
Epoch [7801/30000], Step [1/1], Training Loss: 7692.4570, Valid Loss: 79.3810
Epoch [7901/30000], Step [1/1], Training Loss: 5378.0464, Valid Loss: 92.5810
Epoch [8001/30000], Step [1/1], Training Loss: 4406.0747, Valid Loss: 86.5333
Epoch [8101/30000], Step [1/1], Training Loss: 8549.6826, Valid Loss: 139.7429
Epoch [8201/30000], Step [1/1], Training Loss: 3730.6890, Valid Loss: 91.2667
Epoch [8301/30000], Step [1/1], Training Loss: 3462.0623, Valid Loss: 82.7905
Epoch [8401/30000], Step [1/1], Training Loss: 3465.5420, Valid Loss: 137.4191
Epoch [8501/30000], Step [1/1], Training Loss: 3794.4219, Valid Loss: 115.5905
Epoch [8601/30000], Step [1/1], Training Loss: 2756.4480, Valid Loss: 169.3714
Epoch [8701/30000], Step [1/1], Training Loss: 2460.6987, Valid Loss: 187.9905
Epoch [8801/30000], Step [1/1], Training Loss: 2889.9412, Valid Loss: 191.4857
Epoch [8901/30000], Step [1/1], Training Loss: 2435.4934, Valid Loss: 169.3619
Epoch [9001/30000], Step [1/1], Training Loss: 2370.6946, Valid Loss: 180.1524
Epoch [9101/30000], Step [1/1], Training Loss: 2143.1306, Valid Loss: 203.7143
Epoch [9201/30000], Step [1/1], Training Loss: 2034.8394, Valid Loss: 229.5714
Epoch [9301/30000], Step [1/1], Training Loss: 1945.6118, Valid Loss: 236.3714
Epoch [9401/30000], Step [1/1], Training Loss: 1864.8701, Valid Loss: 229.5524
Epoch [9501/30000], Step [1/1], Training Loss: 1777.0989, Valid Loss: 241.0476
Epoch [9601/30000], Step [1/1], Training Loss: 1705.9471, Valid Loss: 280.5238
Epoch [9701/30000], Step [1/1], Training Loss: 1642.3115, Valid Loss: 274.0000
Epoch [9801/30000], Step [1/1], Training Loss: 2236.3564, Valid Loss: 314.5810
Epoch [9901/30000], Step [1/1], Training Loss: 2521.2903, Valid Loss: 110.7524
Epoch [10001/30000], Step [1/1], Training Loss: 2243.4089, Valid Loss: 360.0191
Epoch [10101/30000], Step [1/1], Training Loss: 1906.9055, Valid Loss: 262.5429
Epoch [10201/30000], Step [1/1], Training Loss: 1794.4324, Valid Loss: 342.5143

[Epoch 15000] Rounded prediction: 
tensor([26., 25., 24., 22., 26., 27., 31., 33., 33., 38., 36., 45., 39., 37.,
        48., 34., 44., 18., 29., 21., 27., 25., 10.,  7.,  7.,  4.,  4., 11.,
         7.,  0., 10.,  6.,  3.,  6., 16.,  1.,  2.,  0.,  0.,  0.,  2., 33.,
         8.,  0.,  0.,  0.,  0.,  5.,  4., 10., 19., 16.,  8., 18., 10., 13.,
         0.,  1., 12.,  6.,  2.,  4., 16., 21., 23.,  0., 42., 14., 37., 34.,
        27., 31., 38., 21., 24.,  3., 11.,  0., 43.,  7., 12., 34.,  0., 10.,
        24., 39., 42., 42., 33., 25.,  0., 25., 38., 24., 10., 20., 41., 33.,
        28., 44., 40., 23., 42., 34., 29.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([ 29.,  11.,  13.,  12.,  23.,  25.,  34.,  41.,  26.,  48.,  32.,  77.,
         66.,  74.,  80.,  72., 123.,  74.,  89.,  57.,  35.,  46.,  22.,   8.,
         39.,  21.,   1.,  22.,  19.,   1.,   0.,  26.,  25.,   0.,  16.,   7.,
          0.,   0.,  19.,   5.,   0.,   6.,   0.,   0.,  14.,  12.,   0.,   7.,
         10.,   1.,  28.,  30.,  17.,  13.,   0.,   0.,  11.,  20.,   0.,  10.,
         11.,   7.,  23.,  48.,  33.,  16.,  55.,  22.,  52.,  90.,  70.,  89.,
         81.,  71.,  70.,  49.,  97.,  22.,  85.,  70.,  69.,  68.,  14.,  42.,
         61.,  42.,  61.,  55.,  52.,  39.,  27.,  53.,  41.,  37.,  18.,  47.,
         42.,  55.,  51.,  49.,  43.,  61.,  53.,  22.,  39.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [10301/30000], Step [1/1], Training Loss: 1622.4243, Valid Loss: 299.6000
Epoch [10401/30000], Step [1/1], Training Loss: 1578.8363, Valid Loss: 277.6190
Epoch [10501/30000], Step [1/1], Training Loss: 1498.8743, Valid Loss: 313.4095
Epoch [10601/30000], Step [1/1], Training Loss: 1415.6492, Valid Loss: 373.8191
Epoch [10701/30000], Step [1/1], Training Loss: 1648.6049, Valid Loss: 562.3048
Epoch [10801/30000], Step [1/1], Training Loss: 1374.8894, Valid Loss: 351.0000
Epoch [10901/30000], Step [1/1], Training Loss: 1894.9064, Valid Loss: 355.7429
Epoch [11001/30000], Step [1/1], Training Loss: 1276.7762, Valid Loss: 305.2476
Epoch [11101/30000], Step [1/1], Training Loss: 1199.1783, Valid Loss: 316.6190
Epoch [11201/30000], Step [1/1], Training Loss: 1156.1212, Valid Loss: 292.7333
Epoch [11301/30000], Step [1/1], Training Loss: 1134.9711, Valid Loss: 337.6572
Epoch [11401/30000], Step [1/1], Training Loss: 1095.1328, Valid Loss: 361.9714
Epoch [11501/30000], Step [1/1], Training Loss: 1048.7703, Valid Loss: 311.5048
Epoch [11601/30000], Step [1/1], Training Loss: 1051.8219, Valid Loss: 293.8381
Epoch [11701/30000], Step [1/1], Training Loss: 996.2022, Valid Loss: 323.3905
Epoch [11801/30000], Step [1/1], Training Loss: 979.9922, Valid Loss: 328.0095
Epoch [11901/30000], Step [1/1], Training Loss: 952.6721, Valid Loss: 299.9810
Epoch [12001/30000], Step [1/1], Training Loss: 940.6749, Valid Loss: 318.6286
Epoch [12101/30000], Step [1/1], Training Loss: 904.2369, Valid Loss: 325.1524
Epoch [12201/30000], Step [1/1], Training Loss: 888.0179, Valid Loss: 324.9238
Epoch [12301/30000], Step [1/1], Training Loss: 858.8500, Valid Loss: 294.3619
Epoch [12401/30000], Step [1/1], Training Loss: 831.9994, Valid Loss: 283.3524
Epoch [12501/30000], Step [1/1], Training Loss: 807.3956, Valid Loss: 275.0857
Epoch [12601/30000], Step [1/1], Training Loss: 796.1483, Valid Loss: 305.7905
Epoch [12701/30000], Step [1/1], Training Loss: 2755.8616, Valid Loss: 181.4095
Epoch [12801/30000], Step [1/1], Training Loss: 1456.8403, Valid Loss: 220.7714
Epoch [12901/30000], Step [1/1], Training Loss: 943.7536, Valid Loss: 213.4572
Epoch [13001/30000], Step [1/1], Training Loss: 855.7266, Valid Loss: 259.8000
Epoch [13101/30000], Step [1/1], Training Loss: 837.9304, Valid Loss: 244.1524
Epoch [13201/30000], Step [1/1], Training Loss: 845.5613, Valid Loss: 281.7524
Epoch [13301/30000], Step [1/1], Training Loss: 805.4992, Valid Loss: 283.9619
Epoch [13401/30000], Step [1/1], Training Loss: 739.3499, Valid Loss: 268.3619
Epoch [13501/30000], Step [1/1], Training Loss: 740.0352, Valid Loss: 305.4857
Epoch [13601/30000], Step [1/1], Training Loss: 712.5760, Valid Loss: 290.6953
Epoch [13701/30000], Step [1/1], Training Loss: 686.5682, Valid Loss: 316.4952
Epoch [13801/30000], Step [1/1], Training Loss: 666.9267, Valid Loss: 315.6667
Epoch [13901/30000], Step [1/1], Training Loss: 641.0790, Valid Loss: 317.8857
Epoch [14001/30000], Step [1/1], Training Loss: 636.1078, Valid Loss: 327.2191
Epoch [14101/30000], Step [1/1], Training Loss: 620.4551, Valid Loss: 301.6857
Epoch [14201/30000], Step [1/1], Training Loss: 646.4022, Valid Loss: 293.4762
Epoch [14301/30000], Step [1/1], Training Loss: 606.4133, Valid Loss: 300.2191
Epoch [14401/30000], Step [1/1], Training Loss: 577.1715, Valid Loss: 316.2667
Epoch [14501/30000], Step [1/1], Training Loss: 561.6552, Valid Loss: 289.5714
Epoch [14601/30000], Step [1/1], Training Loss: 572.2112, Valid Loss: 307.0286
Epoch [14701/30000], Step [1/1], Training Loss: 545.3564, Valid Loss: 337.4191
Epoch [14801/30000], Step [1/1], Training Loss: 517.6537, Valid Loss: 319.6857
Epoch [14901/30000], Step [1/1], Training Loss: 530.0378, Valid Loss: 325.6857
Epoch [15001/30000], Step [1/1], Training Loss: 509.0461, Valid Loss: 282.4191
Epoch [15101/30000], Step [1/1], Training Loss: 498.2964, Valid Loss: 301.6572
Epoch [15201/30000], Step [1/1], Training Loss: 495.8085, Valid Loss: 293.3619
Epoch [15301/30000], Step [1/1], Training Loss: 481.7021, Valid Loss: 327.3429
Epoch [15401/30000], Step [1/1], Training Loss: 465.1574, Valid Loss: 358.8953
Epoch [15501/30000], Step [1/1], Training Loss: 454.4785, Valid Loss: 374.4381
Epoch [15601/30000], Step [1/1], Training Loss: 446.4427, Valid Loss: 363.7143
Epoch [15701/30000], Step [1/1], Training Loss: 436.0398, Valid Loss: 361.0572
Epoch [15801/30000], Step [1/1], Training Loss: 425.6424, Valid Loss: 375.0381
Epoch [15901/30000], Step [1/1], Training Loss: 418.8129, Valid Loss: 377.5619
Epoch [16001/30000], Step [1/1], Training Loss: 400.7581, Valid Loss: 394.4095
Epoch [16101/30000], Step [1/1], Training Loss: 416.2913, Valid Loss: 391.5048
Epoch [16201/30000], Step [1/1], Training Loss: 397.4256, Valid Loss: 410.8762
Epoch [16301/30000], Step [1/1], Training Loss: 403.8987, Valid Loss: 405.8000
Epoch [16401/30000], Step [1/1], Training Loss: 389.8409, Valid Loss: 425.8286
Epoch [16501/30000], Step [1/1], Training Loss: 371.1524, Valid Loss: 416.7619
Epoch [16601/30000], Step [1/1], Training Loss: 3685.2095, Valid Loss: 168.1333
Epoch [16701/30000], Step [1/1], Training Loss: 4103.4922, Valid Loss: 556.6762
Epoch [16801/30000], Step [1/1], Training Loss: 1183.0668, Valid Loss: 530.9524
Epoch [16901/30000], Step [1/1], Training Loss: 756.3134, Valid Loss: 483.2095
Epoch [17001/30000], Step [1/1], Training Loss: 668.0031, Valid Loss: 577.3429
Epoch [17101/30000], Step [1/1], Training Loss: 613.4091, Valid Loss: 578.5524
Epoch [17201/30000], Step [1/1], Training Loss: 548.0319, Valid Loss: 641.4572
Epoch [17301/30000], Step [1/1], Training Loss: 545.0970, Valid Loss: 585.7619
Epoch [17401/30000], Step [1/1], Training Loss: 486.7353, Valid Loss: 601.7333
Epoch [17501/30000], Step [1/1], Training Loss: 480.0066, Valid Loss: 684.9143
Epoch [17601/30000], Step [1/1], Training Loss: 481.9628, Valid Loss: 678.5429
Epoch [17701/30000], Step [1/1], Training Loss: 485.8333, Valid Loss: 662.2858
Epoch [17801/30000], Step [1/1], Training Loss: 471.0804, Valid Loss: 665.5143
Epoch [17901/30000], Step [1/1], Training Loss: 451.9039, Valid Loss: 668.3524
Epoch [18001/30000], Step [1/1], Training Loss: 441.6982, Valid Loss: 688.5143
Epoch [18101/30000], Step [1/1], Training Loss: 437.7520, Valid Loss: 664.6286
Epoch [18201/30000], Step [1/1], Training Loss: 442.9469, Valid Loss: 711.4857
Epoch [18301/30000], Step [1/1], Training Loss: 433.8127, Valid Loss: 710.9714
Epoch [18401/30000], Step [1/1], Training Loss: 435.3539, Valid Loss: 698.3239
Epoch [18501/30000], Step [1/1], Training Loss: 435.9839, Valid Loss: 715.8762
Epoch [18601/30000], Step [1/1], Training Loss: 415.0681, Valid Loss: 677.5905
Epoch [18701/30000], Step [1/1], Training Loss: 429.4156, Valid Loss: 569.0477
Epoch [18801/30000], Step [1/1], Training Loss: 400.6109, Valid Loss: 599.8381
Epoch [18901/30000], Step [1/1], Training Loss: 416.0543, Valid Loss: 599.3619
Epoch [19001/30000], Step [1/1], Training Loss: 394.1848, Valid Loss: 629.7524
Epoch [19101/30000], Step [1/1], Training Loss: 383.8525, Valid Loss: 559.6762
Epoch [19201/30000], Step [1/1], Training Loss: 380.4149, Valid Loss: 630.9238
Epoch [19301/30000], Step [1/1], Training Loss: 5259.6040, Valid Loss: 516.5715
Epoch [19401/30000], Step [1/1], Training Loss: 3649.0310, Valid Loss: 654.4095
Epoch [19501/30000], Step [1/1], Training Loss: 1449.7997, Valid Loss: 823.5429
Epoch [19601/30000], Step [1/1], Training Loss: 859.2821, Valid Loss: 892.4762
Epoch [19701/30000], Step [1/1], Training Loss: 622.6570, Valid Loss: 1137.5333
Epoch [19801/30000], Step [1/1], Training Loss: 516.6647, Valid Loss: 1138.5333
Epoch [19901/30000], Step [1/1], Training Loss: 531.4474, Valid Loss: 1224.5048
Epoch [20001/30000], Step [1/1], Training Loss: 480.5954, Valid Loss: 1304.5333
Epoch [20101/30000], Step [1/1], Training Loss: 470.5070, Valid Loss: 1244.6191
Epoch [20201/30000], Step [1/1], Training Loss: 447.5314, Valid Loss: 1300.6096
Epoch [20301/30000], Step [1/1], Training Loss: 428.4952, Valid Loss: 1368.3619
Epoch [20401/30000], Step [1/1], Training Loss: 411.3738, Valid Loss: 1385.8191
Epoch [20501/30000], Step [1/1], Training Loss: 399.8769, Valid Loss: 1447.8857

[Epoch 25000] Rounded prediction: 
tensor([ 21.,  15.,   5.,  13.,  18.,  17.,  22.,  13.,  20.,  33.,  34.,  72.,
         45.,  68.,  95.,  77., 173., 114., 144., 141., 105., 144., 116., 128.,
        141.,  86.,  59.,  74.,  87.,  13.,  69.,  49.,  30.,  32.,  80.,  40.,
         16.,  22.,  25.,  19.,   9.,  53.,  63.,  11.,  14.,  13.,  13.,  29.,
         30.,  39.,  83.,  85.,  95., 120.,  79.,  97.,  79.,  66.,  20.,  47.,
         26.,  47.,  65.,  98., 131., 108., 149., 100., 115., 144., 111., 116.,
        110., 103., 126.,  56., 101.,  39., 128.,  65.,  57.,  98.,  33.,  48.,
         69.,  64.,  69.,  63.,  55.,  75.,  48.,  60.,  41.,  29.,   0.,  44.,
         46.,  41.,  56.,  50.,  54.,  53.,  53.,  45.,  51.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [20601/30000], Step [1/1], Training Loss: 399.9725, Valid Loss: 1338.1239
Epoch [20701/30000], Step [1/1], Training Loss: 418.6100, Valid Loss: 1447.4667
Epoch [20801/30000], Step [1/1], Training Loss: 389.6395, Valid Loss: 1325.6763
Epoch [20901/30000], Step [1/1], Training Loss: 386.2151, Valid Loss: 1452.2477
Epoch [21001/30000], Step [1/1], Training Loss: 389.2560, Valid Loss: 1435.7144
Epoch [21101/30000], Step [1/1], Training Loss: 384.7348, Valid Loss: 1343.1429
Epoch [21201/30000], Step [1/1], Training Loss: 375.7534, Valid Loss: 1416.7144
Epoch [21301/30000], Step [1/1], Training Loss: 7080.4761, Valid Loss: 920.1238
Epoch [21401/30000], Step [1/1], Training Loss: 4309.8750, Valid Loss: 1281.3905
Epoch [21501/30000], Step [1/1], Training Loss: 3006.4253, Valid Loss: 1473.2001
Epoch [21601/30000], Step [1/1], Training Loss: 3497.2446, Valid Loss: 1191.0190
Epoch [21701/30000], Step [1/1], Training Loss: 2783.7600, Valid Loss: 1551.0096
Epoch [21801/30000], Step [1/1], Training Loss: 3062.7927, Valid Loss: 1729.3334
Epoch [21901/30000], Step [1/1], Training Loss: 2327.7285, Valid Loss: 1767.3429
Epoch [22001/30000], Step [1/1], Training Loss: 1920.4441, Valid Loss: 1899.0382
Epoch [22101/30000], Step [1/1], Training Loss: 2335.7173, Valid Loss: 1795.8096
Epoch [22201/30000], Step [1/1], Training Loss: 1434.1523, Valid Loss: 2065.6287
Epoch [22301/30000], Step [1/1], Training Loss: 1840.6163, Valid Loss: 2044.9048
Epoch [22401/30000], Step [1/1], Training Loss: 2160.5774, Valid Loss: 1988.5525
Epoch [22501/30000], Step [1/1], Training Loss: 1975.8065, Valid Loss: 2321.2573
Epoch [22601/30000], Step [1/1], Training Loss: 2636.8140, Valid Loss: 2288.0000
Epoch [22701/30000], Step [1/1], Training Loss: 1501.1976, Valid Loss: 2274.1428
Epoch [22801/30000], Step [1/1], Training Loss: 1376.0298, Valid Loss: 2407.6667
Epoch [22901/30000], Step [1/1], Training Loss: 1499.3894, Valid Loss: 2486.9810
Epoch [23001/30000], Step [1/1], Training Loss: 1665.5776, Valid Loss: 2446.0381
Epoch [23101/30000], Step [1/1], Training Loss: 1537.5415, Valid Loss: 2338.7715
Epoch [23201/30000], Step [1/1], Training Loss: 1631.7173, Valid Loss: 2311.9048
Epoch [23301/30000], Step [1/1], Training Loss: 1557.6799, Valid Loss: 2806.7239
Epoch [23401/30000], Step [1/1], Training Loss: 1135.8638, Valid Loss: 2661.8762
Epoch [23501/30000], Step [1/1], Training Loss: 1325.2596, Valid Loss: 2775.2764
Epoch [23601/30000], Step [1/1], Training Loss: 1097.4155, Valid Loss: 2426.0000
Epoch [23701/30000], Step [1/1], Training Loss: 1618.0198, Valid Loss: 3277.6572
Epoch [23801/30000], Step [1/1], Training Loss: 1330.9622, Valid Loss: 2856.1431
Epoch [23901/30000], Step [1/1], Training Loss: 1173.5913, Valid Loss: 3497.6382
Epoch [24001/30000], Step [1/1], Training Loss: 1905.6729, Valid Loss: 3230.4192
Epoch [24101/30000], Step [1/1], Training Loss: 1332.1130, Valid Loss: 3298.0288
Epoch [24201/30000], Step [1/1], Training Loss: 1346.8851, Valid Loss: 3542.9812
Epoch [24301/30000], Step [1/1], Training Loss: 1515.6722, Valid Loss: 3034.6477
Epoch [24401/30000], Step [1/1], Training Loss: 1144.0616, Valid Loss: 3336.9429
Epoch [24501/30000], Step [1/1], Training Loss: 4437.6865, Valid Loss: 2770.5239
Epoch [24601/30000], Step [1/1], Training Loss: 1393.3779, Valid Loss: 3076.3621
Epoch [24701/30000], Step [1/1], Training Loss: 1225.8491, Valid Loss: 3026.6382
Epoch [24801/30000], Step [1/1], Training Loss: 1570.8859, Valid Loss: 3058.4382
Epoch [24901/30000], Step [1/1], Training Loss: 4734.9404, Valid Loss: 3540.8572
Epoch [25001/30000], Step [1/1], Training Loss: 3536.7429, Valid Loss: 4528.6382
Epoch [25101/30000], Step [1/1], Training Loss: 1398.0939, Valid Loss: 4762.0381
Epoch [25201/30000], Step [1/1], Training Loss: 534.5942, Valid Loss: 5636.9907
Epoch [25301/30000], Step [1/1], Training Loss: 324.3672, Valid Loss: 5679.4575
Epoch [25401/30000], Step [1/1], Training Loss: 311.1753, Valid Loss: 5845.3242
Epoch [25501/30000], Step [1/1], Training Loss: 247.1722, Valid Loss: 5494.9146
Epoch [25601/30000], Step [1/1], Training Loss: 190.1198, Valid Loss: 6180.8574
Epoch [25701/30000], Step [1/1], Training Loss: 165.8250, Valid Loss: 6339.7905
Epoch [25801/30000], Step [1/1], Training Loss: 160.8677, Valid Loss: 6336.6763
Epoch [25901/30000], Step [1/1], Training Loss: 126.2293, Valid Loss: 6571.7622
Epoch [26001/30000], Step [1/1], Training Loss: 125.8592, Valid Loss: 6670.7334
Epoch [26101/30000], Step [1/1], Training Loss: 109.0515, Valid Loss: 6657.0288
Epoch [26201/30000], Step [1/1], Training Loss: 98.7026, Valid Loss: 6199.5620
Epoch [26301/30000], Step [1/1], Training Loss: 86.0212, Valid Loss: 6612.0288
Epoch [26401/30000], Step [1/1], Training Loss: 84.7380, Valid Loss: 7016.6670
Epoch [26501/30000], Step [1/1], Training Loss: 77.9123, Valid Loss: 6952.4956
Epoch [26601/30000], Step [1/1], Training Loss: 74.5870, Valid Loss: 6762.1812
Epoch [26701/30000], Step [1/1], Training Loss: 59.2992, Valid Loss: 6018.8286
Epoch [26801/30000], Step [1/1], Training Loss: 105.7559, Valid Loss: 5991.3623
Epoch [26901/30000], Step [1/1], Training Loss: 45.0761, Valid Loss: 6009.9429
Epoch [27001/30000], Step [1/1], Training Loss: 53.7010, Valid Loss: 6118.5718
Epoch [27101/30000], Step [1/1], Training Loss: 42.3948, Valid Loss: 6270.2671
Epoch [27201/30000], Step [1/1], Training Loss: 54.8963, Valid Loss: 5579.0762
Epoch [27301/30000], Step [1/1], Training Loss: 51.8145, Valid Loss: 5560.9238
Epoch [27401/30000], Step [1/1], Training Loss: 58.9822, Valid Loss: 5448.5908
Epoch [27501/30000], Step [1/1], Training Loss: 21.1669, Valid Loss: 6116.9526
Epoch [27601/30000], Step [1/1], Training Loss: 49.2470, Valid Loss: 5892.7622
Epoch [27701/30000], Step [1/1], Training Loss: 15.1247, Valid Loss: 6306.1147
Epoch [27801/30000], Step [1/1], Training Loss: 12.3722, Valid Loss: 6521.2671
Epoch [27901/30000], Step [1/1], Training Loss: 13.0604, Valid Loss: 6491.7905
Epoch [28001/30000], Step [1/1], Training Loss: 10.5939, Valid Loss: 6537.4858
Epoch [28101/30000], Step [1/1], Training Loss: 11.3896, Valid Loss: 6643.8477
Epoch [28201/30000], Step [1/1], Training Loss: 9.4291, Valid Loss: 6533.7524
Epoch [28301/30000], Step [1/1], Training Loss: 9.1370, Valid Loss: 6426.4956
Epoch [28401/30000], Step [1/1], Training Loss: 6.3191, Valid Loss: 6406.0098
Epoch [28501/30000], Step [1/1], Training Loss: 6.5758, Valid Loss: 6856.1147
Epoch [28601/30000], Step [1/1], Training Loss: 5.5438, Valid Loss: 6494.3335
Epoch [28701/30000], Step [1/1], Training Loss: 3.9186, Valid Loss: 6838.3335
Epoch [28801/30000], Step [1/1], Training Loss: 3.2365, Valid Loss: 6787.3525
Epoch [28901/30000], Step [1/1], Training Loss: 2.6832, Valid Loss: 6393.5718
Epoch [29001/30000], Step [1/1], Training Loss: 2.8561, Valid Loss: 6549.8574
Epoch [29101/30000], Step [1/1], Training Loss: 2.2746, Valid Loss: 7015.2573
Epoch [29201/30000], Step [1/1], Training Loss: 2.2009, Valid Loss: 6656.0957
Epoch [29301/30000], Step [1/1], Training Loss: 1.3657, Valid Loss: 7139.3242
Epoch [29401/30000], Step [1/1], Training Loss: 1.2422, Valid Loss: 6927.6479
Epoch [29501/30000], Step [1/1], Training Loss: 1.4155, Valid Loss: 7195.7051
Epoch [29601/30000], Step [1/1], Training Loss: 1.6080, Valid Loss: 7379.7432
Epoch [29701/30000], Step [1/1], Training Loss: 9046.4648, Valid Loss: 1298.5811
Epoch [29801/30000], Step [1/1], Training Loss: 7321.0542, Valid Loss: 1769.7239
Epoch [29901/30000], Step [1/1], Training Loss: 5945.5137, Valid Loss: 2336.1143

 End Time: 2021/04/19, 16:49:16




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=512 	layers=2

Start Time = 2021/04/19, 16:57:50
##########################################################


[Epoch 0] Rounded prediction: 
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([16., 12., 18., 13., 16., 16., 30., 25., 29., 25., 17., 15., 16., 13.,
        11.,  5.,  1.,  4.,  4.,  5.,  7.,  6.,  7.,  8.,  6.,  0.,  5.,  5.,
         5.,  2.,  8.,  2.,  2.,  7.,  4.,  4.,  2.,  6.,  0.,  6.,  4., 14.,
        11., 12.,  3.,  4.,  3.,  4.,  2.,  2.,  2.,  3.,  5.,  2., 13.,  8.,
         4.,  5.,  3.,  5.,  3.,  7.,  2.,  9.,  1.,  9.,  4.,  9.,  9.,  7.,
         6.,  4.,  4.,  5.,  4.,  9., 11., 19., 15., 15., 16., 13., 25., 24.,
        19., 14., 11., 10., 11.,  0., 18., 25., 42., 41., 38., 28., 30., 34.,
        34., 32., 37., 42., 34., 37., 48.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([17., 14., 19., 17., 19., 21., 30., 26., 31., 24., 28., 25., 29., 20.,
        17., 13.,  7.,  2.,  0.,  0.,  0.,  0.,  3.,  6.,  0.,  0.,  3.,  0.,
         1.,  2.,  7.,  0.,  0.,  4.,  0.,  4.,  0.,  1.,  0.,  4.,  0., 13.,
         8., 10.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  3.,  0., 13.,  1.,
         0.,  2.,  0.,  3.,  0.,  5.,  0.,  7.,  0.,  7.,  0.,  5.,  2.,  2.,
         2.,  0.,  1.,  1.,  2.,  1.,  0., 15.,  5.,  8.,  9.,  7., 21., 16.,
        10.,  5.,  2.,  5.,  9.,  3., 24., 25., 36., 32., 31., 18., 22., 27.,
        34., 33., 35., 44., 28., 33., 38.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128668.8125, Valid Loss: 231.3048
Epoch [101/30000], Step [1/1], Training Loss: 121297.7188, Valid Loss: 107.8762
Epoch [201/30000], Step [1/1], Training Loss: 118852.0859, Valid Loss: 193.5905
Epoch [301/30000], Step [1/1], Training Loss: 116578.4297, Valid Loss: 320.0191
Epoch [401/30000], Step [1/1], Training Loss: 114407.4062, Valid Loss: 496.4476
Epoch [501/30000], Step [1/1], Training Loss: 112309.5781, Valid Loss: 722.8762
Epoch [601/30000], Step [1/1], Training Loss: 110280.7031, Valid Loss: 999.3048
Epoch [701/30000], Step [1/1], Training Loss: 108318.7734, Valid Loss: 1325.7334
Epoch [801/30000], Step [1/1], Training Loss: 106413.7734, Valid Loss: 1702.1620
Epoch [901/30000], Step [1/1], Training Loss: 104565.3125, Valid Loss: 2124.8953
Epoch [1001/30000], Step [1/1], Training Loss: 102767.0625, Valid Loss: 2548.1716
Epoch [1101/30000], Step [1/1], Training Loss: 101013.4062, Valid Loss: 1365.4572
Epoch [1201/30000], Step [1/1], Training Loss: 99265.0859, Valid Loss: 1176.7905
Epoch [1301/30000], Step [1/1], Training Loss: 97346.0312, Valid Loss: 79.2095
Epoch [1401/30000], Step [1/1], Training Loss: 95613.0234, Valid Loss: 45.6952
Epoch [1501/30000], Step [1/1], Training Loss: 93911.2422, Valid Loss: 43.5714
Epoch [1601/30000], Step [1/1], Training Loss: 92246.5000, Valid Loss: 39.0476
Epoch [1701/30000], Step [1/1], Training Loss: 90615.1797, Valid Loss: 47.0476
Epoch [1801/30000], Step [1/1], Training Loss: 89019.6016, Valid Loss: 47.8095
Epoch [1901/30000], Step [1/1], Training Loss: 87451.4062, Valid Loss: 54.2191
Epoch [2001/30000], Step [1/1], Training Loss: 85913.8906, Valid Loss: 56.9048
Epoch [2101/30000], Step [1/1], Training Loss: 84404.8125, Valid Loss: 60.7333
Epoch [2201/30000], Step [1/1], Training Loss: 82916.0234, Valid Loss: 57.1238
Epoch [2301/30000], Step [1/1], Training Loss: 81459.6562, Valid Loss: 68.5810
Epoch [2401/30000], Step [1/1], Training Loss: 80029.3828, Valid Loss: 67.4000
Epoch [2501/30000], Step [1/1], Training Loss: 78627.5781, Valid Loss: 68.9143
Epoch [2601/30000], Step [1/1], Training Loss: 77251.0859, Valid Loss: 71.4571
Epoch [2701/30000], Step [1/1], Training Loss: 75902.8125, Valid Loss: 80.8857
Epoch [2801/30000], Step [1/1], Training Loss: 74578.9062, Valid Loss: 88.3143
Epoch [2901/30000], Step [1/1], Training Loss: 73279.4062, Valid Loss: 86.2667
Epoch [3001/30000], Step [1/1], Training Loss: 72006.4609, Valid Loss: 77.3524
Epoch [3101/30000], Step [1/1], Training Loss: 70757.2969, Valid Loss: 80.2762
Epoch [3201/30000], Step [1/1], Training Loss: 69535.5625, Valid Loss: 71.4095
Epoch [3301/30000], Step [1/1], Training Loss: 68336.2266, Valid Loss: 83.5714
Epoch [3401/30000], Step [1/1], Training Loss: 67163.2578, Valid Loss: 77.9048
Epoch [3501/30000], Step [1/1], Training Loss: 66013.3516, Valid Loss: 76.8476
Epoch [3601/30000], Step [1/1], Training Loss: 64886.5078, Valid Loss: 79.4857
Epoch [3701/30000], Step [1/1], Training Loss: 63784.4492, Valid Loss: 80.5048
Epoch [3801/30000], Step [1/1], Training Loss: 62705.3281, Valid Loss: 78.0191
Epoch [3901/30000], Step [1/1], Training Loss: 61649.0781, Valid Loss: 73.2000
Epoch [4001/30000], Step [1/1], Training Loss: 60616.9336, Valid Loss: 80.3048
Epoch [4101/30000], Step [1/1], Training Loss: 59578.2266, Valid Loss: 65.1238
Epoch [4201/30000], Step [1/1], Training Loss: 58567.9258, Valid Loss: 67.5810
Epoch [4301/30000], Step [1/1], Training Loss: 57460.6172, Valid Loss: 61.3048
Epoch [4401/30000], Step [1/1], Training Loss: 56485.7539, Valid Loss: 62.5143
Epoch [4501/30000], Step [1/1], Training Loss: 55434.9375, Valid Loss: 58.3048
Epoch [4601/30000], Step [1/1], Training Loss: 54437.2891, Valid Loss: 57.1048
Epoch [4701/30000], Step [1/1], Training Loss: 53438.1055, Valid Loss: 65.7714
Epoch [4801/30000], Step [1/1], Training Loss: 52473.0508, Valid Loss: 58.5905
Epoch [4901/30000], Step [1/1], Training Loss: 51539.5625, Valid Loss: 59.9143
Epoch [5001/30000], Step [1/1], Training Loss: 50636.1719, Valid Loss: 65.4095
Epoch [5101/30000], Step [1/1], Training Loss: 49736.1406, Valid Loss: 64.7048
Epoch [5201/30000], Step [1/1], Training Loss: 48857.5820, Valid Loss: 66.5048
Epoch [5301/30000], Step [1/1], Training Loss: 47996.4727, Valid Loss: 69.9238
Epoch [5401/30000], Step [1/1], Training Loss: 47177.1406, Valid Loss: 68.6190
Epoch [5501/30000], Step [1/1], Training Loss: 46293.1562, Valid Loss: 77.0381
Epoch [5601/30000], Step [1/1], Training Loss: 45473.1484, Valid Loss: 85.0286
Epoch [5701/30000], Step [1/1], Training Loss: 44654.2461, Valid Loss: 78.4000
Epoch [5801/30000], Step [1/1], Training Loss: 43838.8398, Valid Loss: 76.9619
Epoch [5901/30000], Step [1/1], Training Loss: 43054.7812, Valid Loss: 84.7143
Epoch [6001/30000], Step [1/1], Training Loss: 42303.0352, Valid Loss: 78.3524
Epoch [6101/30000], Step [1/1], Training Loss: 41563.3477, Valid Loss: 83.7048
Epoch [6201/30000], Step [1/1], Training Loss: 40817.3789, Valid Loss: 85.4857
Epoch [6301/30000], Step [1/1], Training Loss: 40133.7461, Valid Loss: 94.8762
Epoch [6401/30000], Step [1/1], Training Loss: 39326.9531, Valid Loss: 82.8762
Epoch [6501/30000], Step [1/1], Training Loss: 38537.4219, Valid Loss: 88.8571
Epoch [6601/30000], Step [1/1], Training Loss: 37809.6992, Valid Loss: 79.6857
Epoch [6701/30000], Step [1/1], Training Loss: 37132.5312, Valid Loss: 76.8857
Epoch [6801/30000], Step [1/1], Training Loss: 36419.0469, Valid Loss: 84.3048
Epoch [6901/30000], Step [1/1], Training Loss: 35707.3438, Valid Loss: 82.3714
Epoch [7001/30000], Step [1/1], Training Loss: 35064.1562, Valid Loss: 82.6857
Epoch [7101/30000], Step [1/1], Training Loss: 34396.8477, Valid Loss: 86.3810
Epoch [7201/30000], Step [1/1], Training Loss: 33755.4297, Valid Loss: 96.3810
Epoch [7301/30000], Step [1/1], Training Loss: 33271.8164, Valid Loss: 98.0381
Epoch [7401/30000], Step [1/1], Training Loss: 32545.1328, Valid Loss: 99.7429
Epoch [7501/30000], Step [1/1], Training Loss: 31962.9512, Valid Loss: 89.8000
Epoch [7601/30000], Step [1/1], Training Loss: 31179.2969, Valid Loss: 99.6190
Epoch [7701/30000], Step [1/1], Training Loss: 30751.9453, Valid Loss: 94.5905
Epoch [7801/30000], Step [1/1], Training Loss: 30321.4121, Valid Loss: 111.1619
Epoch [7901/30000], Step [1/1], Training Loss: 29467.1914, Valid Loss: 102.1048
Epoch [8001/30000], Step [1/1], Training Loss: 28885.9941, Valid Loss: 102.9810
Epoch [8101/30000], Step [1/1], Training Loss: 28316.9512, Valid Loss: 110.3238
Epoch [8201/30000], Step [1/1], Training Loss: 27767.8125, Valid Loss: 105.0857
Epoch [8301/30000], Step [1/1], Training Loss: 27240.2793, Valid Loss: 103.9238
Epoch [8401/30000], Step [1/1], Training Loss: 26732.6914, Valid Loss: 105.1810
Epoch [8501/30000], Step [1/1], Training Loss: 26221.1914, Valid Loss: 103.9524
Epoch [8601/30000], Step [1/1], Training Loss: 25725.1426, Valid Loss: 112.2191
Epoch [8701/30000], Step [1/1], Training Loss: 25234.1797, Valid Loss: 108.6667
Epoch [8801/30000], Step [1/1], Training Loss: 24769.5312, Valid Loss: 106.3714
Epoch [8901/30000], Step [1/1], Training Loss: 24285.7461, Valid Loss: 112.2191
Epoch [9001/30000], Step [1/1], Training Loss: 23828.0605, Valid Loss: 111.4381
Epoch [9101/30000], Step [1/1], Training Loss: 23360.4629, Valid Loss: 113.0000
Epoch [9201/30000], Step [1/1], Training Loss: 22921.0137, Valid Loss: 114.5238
Epoch [9301/30000], Step [1/1], Training Loss: 22481.5957, Valid Loss: 115.2857
Epoch [9401/30000], Step [1/1], Training Loss: 22049.6230, Valid Loss: 109.8000
Epoch [9501/30000], Step [1/1], Training Loss: 21635.7832, Valid Loss: 106.2762
Epoch [9601/30000], Step [1/1], Training Loss: 21227.0742, Valid Loss: 114.5619
Epoch [9701/30000], Step [1/1], Training Loss: 20828.0918, Valid Loss: 109.3905
Epoch [9801/30000], Step [1/1], Training Loss: 20437.3086, Valid Loss: 106.7048
Epoch [9901/30000], Step [1/1], Training Loss: 20054.5449, Valid Loss: 111.2000
Epoch [10001/30000], Step [1/1], Training Loss: 19684.2734, Valid Loss: 100.0095
Epoch [10101/30000], Step [1/1], Training Loss: 19314.7812, Valid Loss: 110.5143

[Epoch 15000] Rounded prediction: 
tensor([19., 17., 21., 24., 21., 26., 35., 33., 30., 32., 30., 23., 29., 24.,
        23., 22., 20., 22., 14.,  9.,  9.,  7.,  9.,  8.,  6.,  2.,  6.,  6.,
         8.,  8.,  9.,  5.,  0.,  8.,  1.,  8.,  3.,  5.,  1.,  8.,  3., 11.,
        13., 12.,  4.,  5.,  5.,  5.,  5.,  4.,  4.,  7., 10.,  5., 12.,  6.,
         5.,  5.,  6.,  6.,  5.,  8.,  2., 10.,  3., 14.,  4., 11.,  7.,  8.,
         9., 13., 12., 11., 12., 20.,  6., 21., 11., 14., 14., 12., 25., 18.,
        16., 13., 13., 15., 15., 16., 42., 39., 33., 33., 30., 20., 28., 34.,
        44., 33., 37., 54., 29., 28., 46.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([15., 14., 15., 16., 17., 22., 27., 27., 28., 32., 36., 38., 37., 39.,
        37., 45., 50., 43., 22., 21., 12.,  7.,  9.,  6.,  6.,  4.,  4.,  3.,
         6.,  6.,  3.,  4.,  0.,  7.,  1.,  5.,  3.,  4.,  1.,  6.,  2.,  6.,
        11.,  7.,  4.,  1.,  3.,  4.,  4.,  5., 10., 10., 10.,  4., 10.,  5.,
         2.,  1.,  6.,  4.,  4.,  6.,  2.,  9.,  7., 11.,  5., 11.,  5., 11.,
        21., 27., 23., 24., 31., 33., 11., 25.,  8., 12.,  7., 10., 28.,  6.,
        15., 27., 29., 29., 33., 33., 56., 54., 26., 28., 21., 10., 29., 43.,
        45., 37., 42., 55., 31., 39., 53.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [10201/30000], Step [1/1], Training Loss: 19057.7539, Valid Loss: 88.0952
Epoch [10301/30000], Step [1/1], Training Loss: 18513.5098, Valid Loss: 93.2095
Epoch [10401/30000], Step [1/1], Training Loss: 18099.3164, Valid Loss: 86.9619
Epoch [10501/30000], Step [1/1], Training Loss: 17744.5078, Valid Loss: 84.9238
Epoch [10601/30000], Step [1/1], Training Loss: 17399.9297, Valid Loss: 87.9905
Epoch [10701/30000], Step [1/1], Training Loss: 17057.0566, Valid Loss: 90.9238
Epoch [10801/30000], Step [1/1], Training Loss: 16732.1836, Valid Loss: 90.8381
Epoch [10901/30000], Step [1/1], Training Loss: 16418.3418, Valid Loss: 96.8000
Epoch [11001/30000], Step [1/1], Training Loss: 16108.4873, Valid Loss: 90.8191
Epoch [11101/30000], Step [1/1], Training Loss: 15819.7578, Valid Loss: 91.1524
Epoch [11201/30000], Step [1/1], Training Loss: 15504.6787, Valid Loss: 94.2381
Epoch [11301/30000], Step [1/1], Training Loss: 15215.1113, Valid Loss: 91.5905
Epoch [11401/30000], Step [1/1], Training Loss: 14937.3047, Valid Loss: 88.6762
Epoch [11501/30000], Step [1/1], Training Loss: 14672.0234, Valid Loss: 93.0857
Epoch [11601/30000], Step [1/1], Training Loss: 14400.1533, Valid Loss: 94.7143
Epoch [11701/30000], Step [1/1], Training Loss: 14146.0752, Valid Loss: 97.7714
Epoch [11801/30000], Step [1/1], Training Loss: 13898.1924, Valid Loss: 95.2000
Epoch [11901/30000], Step [1/1], Training Loss: 13592.1436, Valid Loss: 101.5524
Epoch [12001/30000], Step [1/1], Training Loss: 13264.3418, Valid Loss: 99.1143
Epoch [12101/30000], Step [1/1], Training Loss: 13001.4258, Valid Loss: 107.7143
Epoch [12201/30000], Step [1/1], Training Loss: 12753.3809, Valid Loss: 108.8952
Epoch [12301/30000], Step [1/1], Training Loss: 12506.8428, Valid Loss: 107.7429
Epoch [12401/30000], Step [1/1], Training Loss: 12275.4502, Valid Loss: 112.2095
Epoch [12501/30000], Step [1/1], Training Loss: 12058.4141, Valid Loss: 105.7143
Epoch [12601/30000], Step [1/1], Training Loss: 11814.9678, Valid Loss: 108.0952
Epoch [12701/30000], Step [1/1], Training Loss: 11596.0850, Valid Loss: 112.5048
Epoch [12801/30000], Step [1/1], Training Loss: 11387.5293, Valid Loss: 109.1619
Epoch [12901/30000], Step [1/1], Training Loss: 11181.6299, Valid Loss: 103.0191
Epoch [13001/30000], Step [1/1], Training Loss: 10983.3652, Valid Loss: 110.4286
Epoch [13101/30000], Step [1/1], Training Loss: 10791.7705, Valid Loss: 109.0762
Epoch [13201/30000], Step [1/1], Training Loss: 10604.2539, Valid Loss: 106.9238
Epoch [13301/30000], Step [1/1], Training Loss: 10421.3496, Valid Loss: 112.8000
Epoch [13401/30000], Step [1/1], Training Loss: 10245.6982, Valid Loss: 110.2095
Epoch [13501/30000], Step [1/1], Training Loss: 10073.6924, Valid Loss: 110.8476
Epoch [13601/30000], Step [1/1], Training Loss: 9906.8174, Valid Loss: 115.9143
Epoch [13701/30000], Step [1/1], Training Loss: 9746.7998, Valid Loss: 113.7810
Epoch [13801/30000], Step [1/1], Training Loss: 9581.7012, Valid Loss: 113.0667
Epoch [13901/30000], Step [1/1], Training Loss: 9730.5361, Valid Loss: 102.3619
Epoch [14001/30000], Step [1/1], Training Loss: 9314.5371, Valid Loss: 99.7048
Epoch [14101/30000], Step [1/1], Training Loss: 9148.6328, Valid Loss: 93.1524
Epoch [14201/30000], Step [1/1], Training Loss: 8931.4160, Valid Loss: 93.8381
Epoch [14301/30000], Step [1/1], Training Loss: 8644.5088, Valid Loss: 94.4476
Epoch [14401/30000], Step [1/1], Training Loss: 8576.2900, Valid Loss: 99.4667
Epoch [14501/30000], Step [1/1], Training Loss: 7947.6592, Valid Loss: 108.4191
Epoch [14601/30000], Step [1/1], Training Loss: 7534.1577, Valid Loss: 94.7143
Epoch [14701/30000], Step [1/1], Training Loss: 7508.5342, Valid Loss: 94.6190
Epoch [14801/30000], Step [1/1], Training Loss: 7378.4473, Valid Loss: 107.1619
Epoch [14901/30000], Step [1/1], Training Loss: 7126.8608, Valid Loss: 95.4571
Epoch [15001/30000], Step [1/1], Training Loss: 6829.0850, Valid Loss: 105.8381
Epoch [15101/30000], Step [1/1], Training Loss: 6653.0420, Valid Loss: 109.3714
Epoch [15201/30000], Step [1/1], Training Loss: 6499.2036, Valid Loss: 119.9333
Epoch [15301/30000], Step [1/1], Training Loss: 6407.3989, Valid Loss: 119.2857
Epoch [15401/30000], Step [1/1], Training Loss: 6199.4326, Valid Loss: 124.7048
Epoch [15501/30000], Step [1/1], Training Loss: 6052.9619, Valid Loss: 116.2857
Epoch [15601/30000], Step [1/1], Training Loss: 5918.3711, Valid Loss: 124.2095
Epoch [15701/30000], Step [1/1], Training Loss: 5786.1948, Valid Loss: 115.3429
Epoch [15801/30000], Step [1/1], Training Loss: 5657.6421, Valid Loss: 121.7619
Epoch [15901/30000], Step [1/1], Training Loss: 5531.1353, Valid Loss: 119.0381
Epoch [16001/30000], Step [1/1], Training Loss: 5403.8970, Valid Loss: 123.9333
Epoch [16101/30000], Step [1/1], Training Loss: 5287.7314, Valid Loss: 123.6572
Epoch [16201/30000], Step [1/1], Training Loss: 5174.0552, Valid Loss: 126.1143
Epoch [16301/30000], Step [1/1], Training Loss: 5063.3281, Valid Loss: 125.0381
Epoch [16401/30000], Step [1/1], Training Loss: 4955.8677, Valid Loss: 116.7714
Epoch [16501/30000], Step [1/1], Training Loss: 4867.0947, Valid Loss: 111.7238
Epoch [16601/30000], Step [1/1], Training Loss: 4745.6616, Valid Loss: 123.9905
Epoch [16701/30000], Step [1/1], Training Loss: 4641.7803, Valid Loss: 121.6857
Epoch [16801/30000], Step [1/1], Training Loss: 4543.1318, Valid Loss: 119.2191
Epoch [16901/30000], Step [1/1], Training Loss: 4445.7808, Valid Loss: 127.7905
Epoch [17001/30000], Step [1/1], Training Loss: 4355.0854, Valid Loss: 127.7238
Epoch [17101/30000], Step [1/1], Training Loss: 4266.6704, Valid Loss: 137.2857
Epoch [17201/30000], Step [1/1], Training Loss: 4176.6753, Valid Loss: 129.7143
Epoch [17301/30000], Step [1/1], Training Loss: 4092.8276, Valid Loss: 135.1619
Epoch [17401/30000], Step [1/1], Training Loss: 4010.1736, Valid Loss: 137.6476
Epoch [17501/30000], Step [1/1], Training Loss: 3928.9778, Valid Loss: 139.8571
Epoch [17601/30000], Step [1/1], Training Loss: 3844.6907, Valid Loss: 128.0667
Epoch [17701/30000], Step [1/1], Training Loss: 4424.7339, Valid Loss: 129.4667
Epoch [17801/30000], Step [1/1], Training Loss: 3882.8562, Valid Loss: 168.7333
Epoch [17901/30000], Step [1/1], Training Loss: 3723.8176, Valid Loss: 166.8381
Epoch [18001/30000], Step [1/1], Training Loss: 3393.4326, Valid Loss: 175.2095
Epoch [18101/30000], Step [1/1], Training Loss: 3360.3030, Valid Loss: 173.7143
Epoch [18201/30000], Step [1/1], Training Loss: 3369.8623, Valid Loss: 153.3143
Epoch [18301/30000], Step [1/1], Training Loss: 3022.4639, Valid Loss: 159.2952
Epoch [18401/30000], Step [1/1], Training Loss: 2921.3477, Valid Loss: 163.8571
Epoch [18501/30000], Step [1/1], Training Loss: 2842.1047, Valid Loss: 167.4762
Epoch [18601/30000], Step [1/1], Training Loss: 2775.3064, Valid Loss: 169.0857
Epoch [18701/30000], Step [1/1], Training Loss: 2701.2334, Valid Loss: 160.7333
Epoch [18801/30000], Step [1/1], Training Loss: 2850.4604, Valid Loss: 168.0762
Epoch [18901/30000], Step [1/1], Training Loss: 2569.7290, Valid Loss: 191.3810
Epoch [19001/30000], Step [1/1], Training Loss: 2497.5793, Valid Loss: 186.9810
Epoch [19101/30000], Step [1/1], Training Loss: 2428.1841, Valid Loss: 199.4476
Epoch [19201/30000], Step [1/1], Training Loss: 2363.2271, Valid Loss: 192.4762
Epoch [19301/30000], Step [1/1], Training Loss: 2303.3904, Valid Loss: 193.7524
Epoch [19401/30000], Step [1/1], Training Loss: 2245.4026, Valid Loss: 208.9714
Epoch [19501/30000], Step [1/1], Training Loss: 2185.1172, Valid Loss: 207.5429
Epoch [19601/30000], Step [1/1], Training Loss: 2130.1433, Valid Loss: 204.0667
Epoch [19701/30000], Step [1/1], Training Loss: 2073.1453, Valid Loss: 217.4191
Epoch [19801/30000], Step [1/1], Training Loss: 2023.0504, Valid Loss: 209.8286
Epoch [19901/30000], Step [1/1], Training Loss: 1970.4031, Valid Loss: 209.3810
Epoch [20001/30000], Step [1/1], Training Loss: 1921.5870, Valid Loss: 212.6095
Epoch [20101/30000], Step [1/1], Training Loss: 1873.0731, Valid Loss: 210.4762
Epoch [20201/30000], Step [1/1], Training Loss: 1825.4109, Valid Loss: 214.5524
Epoch [20301/30000], Step [1/1], Training Loss: 1781.7820, Valid Loss: 218.6000

[Epoch 25000] Rounded prediction: 
tensor([17., 19., 19., 17., 18., 21., 28., 30., 34., 35., 32., 38., 36., 37.,
        36., 49., 52., 45., 27., 25., 16., 11., 11., 10.,  8.,  5.,  4.,  5.,
         6.,  7.,  4.,  4.,  0.,  5.,  3.,  4.,  2.,  4.,  2.,  4.,  2.,  4.,
        11.,  6.,  3.,  0.,  3.,  5.,  5.,  7., 12., 14., 13.,  8., 11.,  6.,
         2.,  0.,  7.,  5.,  5.,  6.,  5., 11., 12., 13., 10., 16., 14., 20.,
        29., 34., 31., 32., 34., 41., 22., 28., 15., 20., 15., 22., 34., 13.,
        26., 33., 33., 26., 25., 35., 61., 49., 12., 20., 16., 14., 37., 53.,
        50., 42., 47., 55., 34., 39., 56.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [20401/30000], Step [1/1], Training Loss: 1739.6279, Valid Loss: 219.2952
Epoch [20501/30000], Step [1/1], Training Loss: 1696.1663, Valid Loss: 221.0191
Epoch [20601/30000], Step [1/1], Training Loss: 1656.0840, Valid Loss: 213.2857
Epoch [20701/30000], Step [1/1], Training Loss: 1617.4226, Valid Loss: 224.4476
Epoch [20801/30000], Step [1/1], Training Loss: 1580.2469, Valid Loss: 211.5524
Epoch [20901/30000], Step [1/1], Training Loss: 1544.8204, Valid Loss: 197.6857
Epoch [21001/30000], Step [1/1], Training Loss: 1509.9420, Valid Loss: 212.6572
Epoch [21101/30000], Step [1/1], Training Loss: 1476.8203, Valid Loss: 209.6857
Epoch [21201/30000], Step [1/1], Training Loss: 1443.8342, Valid Loss: 222.8667
Epoch [21301/30000], Step [1/1], Training Loss: 2122.1389, Valid Loss: 186.7429
Epoch [21401/30000], Step [1/1], Training Loss: 1527.9927, Valid Loss: 213.9429
Epoch [21501/30000], Step [1/1], Training Loss: 1410.0103, Valid Loss: 218.9714
Epoch [21601/30000], Step [1/1], Training Loss: 1348.8802, Valid Loss: 234.7143
Epoch [21701/30000], Step [1/1], Training Loss: 1306.0485, Valid Loss: 236.0572
Epoch [21801/30000], Step [1/1], Training Loss: 1283.1990, Valid Loss: 236.9810
Epoch [21901/30000], Step [1/1], Training Loss: 1252.7605, Valid Loss: 244.2857
Epoch [22001/30000], Step [1/1], Training Loss: 1219.8573, Valid Loss: 242.6667
Epoch [22101/30000], Step [1/1], Training Loss: 1195.8522, Valid Loss: 241.9524
Epoch [22201/30000], Step [1/1], Training Loss: 1168.9084, Valid Loss: 234.2857
Epoch [22301/30000], Step [1/1], Training Loss: 1145.3224, Valid Loss: 255.6572
Epoch [22401/30000], Step [1/1], Training Loss: 1120.7430, Valid Loss: 245.9714
Epoch [22501/30000], Step [1/1], Training Loss: 1097.4651, Valid Loss: 251.1810
Epoch [22601/30000], Step [1/1], Training Loss: 1074.5178, Valid Loss: 247.0381
Epoch [22701/30000], Step [1/1], Training Loss: 1050.9200, Valid Loss: 233.3429
Epoch [22801/30000], Step [1/1], Training Loss: 1028.6172, Valid Loss: 242.3333
Epoch [22901/30000], Step [1/1], Training Loss: 1006.0742, Valid Loss: 233.5238
Epoch [23001/30000], Step [1/1], Training Loss: 984.3915, Valid Loss: 248.2191
Epoch [23101/30000], Step [1/1], Training Loss: 961.3845, Valid Loss: 240.0762
Epoch [23201/30000], Step [1/1], Training Loss: 940.7866, Valid Loss: 246.0762
Epoch [23301/30000], Step [1/1], Training Loss: 919.1769, Valid Loss: 239.4476
Epoch [23401/30000], Step [1/1], Training Loss: 898.7580, Valid Loss: 242.0286
Epoch [23501/30000], Step [1/1], Training Loss: 878.4679, Valid Loss: 246.7619
Epoch [23601/30000], Step [1/1], Training Loss: 859.0074, Valid Loss: 241.8000
Epoch [23701/30000], Step [1/1], Training Loss: 840.1592, Valid Loss: 256.9143
Epoch [23801/30000], Step [1/1], Training Loss: 820.7258, Valid Loss: 253.7810
Epoch [23901/30000], Step [1/1], Training Loss: 801.9736, Valid Loss: 240.6191
Epoch [24001/30000], Step [1/1], Training Loss: 784.5584, Valid Loss: 240.0762
Epoch [24101/30000], Step [1/1], Training Loss: 766.7886, Valid Loss: 258.7524
Epoch [24201/30000], Step [1/1], Training Loss: 750.4457, Valid Loss: 261.8000
Epoch [24301/30000], Step [1/1], Training Loss: 734.5494, Valid Loss: 263.2095
Epoch [24401/30000], Step [1/1], Training Loss: 718.1729, Valid Loss: 261.4952
Epoch [24501/30000], Step [1/1], Training Loss: 702.2054, Valid Loss: 258.4286
Epoch [24601/30000], Step [1/1], Training Loss: 688.3395, Valid Loss: 238.0095
Epoch [24701/30000], Step [1/1], Training Loss: 673.2938, Valid Loss: 241.1810
Epoch [24801/30000], Step [1/1], Training Loss: 658.3670, Valid Loss: 261.2476
Epoch [24901/30000], Step [1/1], Training Loss: 643.4692, Valid Loss: 252.0476
Epoch [25001/30000], Step [1/1], Training Loss: 630.3284, Valid Loss: 254.9524
Epoch [25101/30000], Step [1/1], Training Loss: 616.5426, Valid Loss: 334.1810
Epoch [25201/30000], Step [1/1], Training Loss: 602.2150, Valid Loss: 318.6000
Epoch [25301/30000], Step [1/1], Training Loss: 588.4703, Valid Loss: 330.5429
Epoch [25401/30000], Step [1/1], Training Loss: 574.9692, Valid Loss: 351.3524
Epoch [25501/30000], Step [1/1], Training Loss: 561.7981, Valid Loss: 336.6572
Epoch [25601/30000], Step [1/1], Training Loss: 549.4649, Valid Loss: 343.4000
Epoch [25701/30000], Step [1/1], Training Loss: 535.6379, Valid Loss: 346.8286
Epoch [25801/30000], Step [1/1], Training Loss: 523.5076, Valid Loss: 357.2000
Epoch [25901/30000], Step [1/1], Training Loss: 510.9082, Valid Loss: 367.9429
Epoch [26001/30000], Step [1/1], Training Loss: 499.0273, Valid Loss: 360.5810
Epoch [26101/30000], Step [1/1], Training Loss: 486.7648, Valid Loss: 357.4857
Epoch [26201/30000], Step [1/1], Training Loss: 475.8337, Valid Loss: 356.3905
Epoch [26301/30000], Step [1/1], Training Loss: 463.8532, Valid Loss: 347.5048
Epoch [26401/30000], Step [1/1], Training Loss: 452.6371, Valid Loss: 366.9524
Epoch [26501/30000], Step [1/1], Training Loss: 441.5573, Valid Loss: 364.3429
Epoch [26601/30000], Step [1/1], Training Loss: 431.5723, Valid Loss: 354.1714
Epoch [26701/30000], Step [1/1], Training Loss: 421.6379, Valid Loss: 352.8095
Epoch [26801/30000], Step [1/1], Training Loss: 410.5862, Valid Loss: 386.2000
Epoch [26901/30000], Step [1/1], Training Loss: 401.5422, Valid Loss: 371.2381
Epoch [27001/30000], Step [1/1], Training Loss: 391.6002, Valid Loss: 368.1810
Epoch [27101/30000], Step [1/1], Training Loss: 381.6064, Valid Loss: 377.3238
Epoch [27201/30000], Step [1/1], Training Loss: 371.4897, Valid Loss: 380.5048
Epoch [27301/30000], Step [1/1], Training Loss: 361.7935, Valid Loss: 374.5238
Epoch [27401/30000], Step [1/1], Training Loss: 352.5808, Valid Loss: 363.3048
Epoch [27501/30000], Step [1/1], Training Loss: 342.7845, Valid Loss: 371.9333
Epoch [27601/30000], Step [1/1], Training Loss: 333.3719, Valid Loss: 366.7715
Epoch [27701/30000], Step [1/1], Training Loss: 324.2165, Valid Loss: 385.4952
Epoch [27801/30000], Step [1/1], Training Loss: 314.8597, Valid Loss: 371.2476
Epoch [27901/30000], Step [1/1], Training Loss: 305.8261, Valid Loss: 377.1238
Epoch [28001/30000], Step [1/1], Training Loss: 296.6781, Valid Loss: 392.4667
Epoch [28101/30000], Step [1/1], Training Loss: 288.3341, Valid Loss: 396.6190
Epoch [28201/30000], Step [1/1], Training Loss: 279.9489, Valid Loss: 390.8762
Epoch [28301/30000], Step [1/1], Training Loss: 272.5040, Valid Loss: 391.3905
Epoch [28401/30000], Step [1/1], Training Loss: 262.2497, Valid Loss: 385.9810
Epoch [28501/30000], Step [1/1], Training Loss: 253.9995, Valid Loss: 387.4191
Epoch [28601/30000], Step [1/1], Training Loss: 245.6123, Valid Loss: 400.5048
Epoch [28701/30000], Step [1/1], Training Loss: 237.5109, Valid Loss: 385.6857
Epoch [28801/30000], Step [1/1], Training Loss: 229.5405, Valid Loss: 379.2762
Epoch [28901/30000], Step [1/1], Training Loss: 221.9763, Valid Loss: 401.6190
Epoch [29001/30000], Step [1/1], Training Loss: 214.4287, Valid Loss: 406.4191
Epoch [29101/30000], Step [1/1], Training Loss: 207.0629, Valid Loss: 402.3524
Epoch [29201/30000], Step [1/1], Training Loss: 199.4292, Valid Loss: 419.8000
Epoch [29301/30000], Step [1/1], Training Loss: 192.2946, Valid Loss: 404.8476
Epoch [29401/30000], Step [1/1], Training Loss: 185.0073, Valid Loss: 434.9333
Epoch [29501/30000], Step [1/1], Training Loss: 178.3118, Valid Loss: 413.8571
Epoch [29601/30000], Step [1/1], Training Loss: 171.4643, Valid Loss: 438.4572
Epoch [29701/30000], Step [1/1], Training Loss: 165.1023, Valid Loss: 440.4095
Epoch [29801/30000], Step [1/1], Training Loss: 158.2339, Valid Loss: 414.2953
Epoch [29901/30000], Step [1/1], Training Loss: 153.3188, Valid Loss: 424.2095

 End Time: 2021/04/19, 17:04:33




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=512 	layers=2

Start Time = 2021/04/19, 17:04:34
##########################################################


[Epoch 0] Rounded prediction: 
tensor([0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.],
       device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([20., 16., 21., 14., 16., 17., 22., 35., 27., 31., 31., 28., 29., 31.,
        22., 25., 30., 20.,  8., 11.,  0.,  1.,  7., 14.,  4.,  3.,  7.,  6.,
         7.,  8., 11.,  4.,  6., 10.,  6.,  9.,  5.,  8.,  1., 10.,  7., 19.,
        14., 13.,  4.,  9.,  6.,  7.,  6.,  6.,  2.,  1.,  6.,  0., 15.,  8.,
         6.,  7.,  7.,  7.,  5., 10.,  3.,  9.,  2., 10.,  4.,  8.,  6.,  5.,
         2.,  1.,  0.,  0.,  7.,  0.,  0., 11., 11., 17., 12., 11.,  8., 10.,
        18., 15.,  9., 21., 21., 10., 17., 24., 42., 55., 41., 23., 28., 26.,
        28., 34., 37., 34., 40., 40., 26.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([16., 14., 16., 10., 15., 16., 23., 27., 27., 26., 26., 26., 28., 20.,
        24., 17., 19., 14.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0., 13.,
         5.,  4.,  0.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  2.,  0.,  0.,  7.,  6.,  0.,  4.,  2.,  0.,  9.,
        10.,  9., 14., 20., 19., 10.,  0.,  8., 32., 32., 27., 19., 23., 29.,
        28., 44., 39., 33., 48., 41., 18.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128606.6562, Valid Loss: 224.8476
Epoch [101/30000], Step [1/1], Training Loss: 121025.7578, Valid Loss: 117.1619
Epoch [201/30000], Step [1/1], Training Loss: 118575.5625, Valid Loss: 193.5905
Epoch [301/30000], Step [1/1], Training Loss: 116311.2891, Valid Loss: 351.3048
Epoch [401/30000], Step [1/1], Training Loss: 114134.2578, Valid Loss: 537.7333
Epoch [501/30000], Step [1/1], Training Loss: 112041.4922, Valid Loss: 774.1619
Epoch [601/30000], Step [1/1], Training Loss: 110018.0938, Valid Loss: 1060.5906
Epoch [701/30000], Step [1/1], Training Loss: 108059.9688, Valid Loss: 1397.0190
Epoch [801/30000], Step [1/1], Training Loss: 106160.1250, Valid Loss: 1782.5430
Epoch [901/30000], Step [1/1], Training Loss: 104315.0078, Valid Loss: 2182.4382
Epoch [1001/30000], Step [1/1], Training Loss: 102521.8047, Valid Loss: 2600.8477
Epoch [1101/30000], Step [1/1], Training Loss: 100771.5703, Valid Loss: 2160.7429
Epoch [1201/30000], Step [1/1], Training Loss: 99058.8828, Valid Loss: 2338.6953
Epoch [1301/30000], Step [1/1], Training Loss: 97208.7031, Valid Loss: 510.3238
Epoch [1401/30000], Step [1/1], Training Loss: 95405.3594, Valid Loss: 106.7143
Epoch [1501/30000], Step [1/1], Training Loss: 93705.7891, Valid Loss: 92.7429
Epoch [1601/30000], Step [1/1], Training Loss: 92048.4688, Valid Loss: 82.9905
Epoch [1701/30000], Step [1/1], Training Loss: 90418.0703, Valid Loss: 71.0476
Epoch [1801/30000], Step [1/1], Training Loss: 88821.3594, Valid Loss: 65.9238
Epoch [1901/30000], Step [1/1], Training Loss: 87256.2734, Valid Loss: 82.8286
Epoch [2001/30000], Step [1/1], Training Loss: 85715.3672, Valid Loss: 101.4857
Epoch [2101/30000], Step [1/1], Training Loss: 84204.7656, Valid Loss: 97.0667
Epoch [2201/30000], Step [1/1], Training Loss: 82720.1172, Valid Loss: 70.2000
Epoch [2301/30000], Step [1/1], Training Loss: 81271.5391, Valid Loss: 87.0571
Epoch [2401/30000], Step [1/1], Training Loss: 79846.0781, Valid Loss: 99.3429
Epoch [2501/30000], Step [1/1], Training Loss: 78439.0156, Valid Loss: 83.0857
Epoch [2601/30000], Step [1/1], Training Loss: 77056.0859, Valid Loss: 132.2857
Epoch [2701/30000], Step [1/1], Training Loss: 75706.0859, Valid Loss: 123.8762
Epoch [2801/30000], Step [1/1], Training Loss: 74384.0781, Valid Loss: 130.8095
Epoch [2901/30000], Step [1/1], Training Loss: 73090.0859, Valid Loss: 132.2000
Epoch [3001/30000], Step [1/1], Training Loss: 71819.6250, Valid Loss: 117.1905
Epoch [3101/30000], Step [1/1], Training Loss: 70563.8828, Valid Loss: 133.8952
Epoch [3201/30000], Step [1/1], Training Loss: 69306.9844, Valid Loss: 126.8286
Epoch [3301/30000], Step [1/1], Training Loss: 68106.0547, Valid Loss: 154.5619
Epoch [3401/30000], Step [1/1], Training Loss: 66923.7344, Valid Loss: 114.5143
Epoch [3501/30000], Step [1/1], Training Loss: 65767.4219, Valid Loss: 106.9905
Epoch [3601/30000], Step [1/1], Training Loss: 64634.9375, Valid Loss: 95.1048
Epoch [3701/30000], Step [1/1], Training Loss: 63534.2148, Valid Loss: 93.7619
Epoch [3801/30000], Step [1/1], Training Loss: 62436.4805, Valid Loss: 105.5429
Epoch [3901/30000], Step [1/1], Training Loss: 61352.7188, Valid Loss: 98.7524
Epoch [4001/30000], Step [1/1], Training Loss: 60239.1211, Valid Loss: 112.6190
Epoch [4101/30000], Step [1/1], Training Loss: 59189.6641, Valid Loss: 101.1048
Epoch [4201/30000], Step [1/1], Training Loss: 58138.9609, Valid Loss: 105.2857
Epoch [4301/30000], Step [1/1], Training Loss: 57110.6680, Valid Loss: 111.4952
Epoch [4401/30000], Step [1/1], Training Loss: 56080.4805, Valid Loss: 121.0286
Epoch [4501/30000], Step [1/1], Training Loss: 55091.1133, Valid Loss: 121.2476
Epoch [4601/30000], Step [1/1], Training Loss: 54112.5781, Valid Loss: 115.7524
Epoch [4701/30000], Step [1/1], Training Loss: 53152.8047, Valid Loss: 116.5905
Epoch [4801/30000], Step [1/1], Training Loss: 52211.2852, Valid Loss: 123.5048
Epoch [4901/30000], Step [1/1], Training Loss: 51293.6641, Valid Loss: 114.3810
Epoch [5001/30000], Step [1/1], Training Loss: 50400.5625, Valid Loss: 116.9619
Epoch [5101/30000], Step [1/1], Training Loss: 49497.2461, Valid Loss: 131.9048
Epoch [5201/30000], Step [1/1], Training Loss: 48624.5430, Valid Loss: 122.5619
Epoch [5301/30000], Step [1/1], Training Loss: 47761.2852, Valid Loss: 122.2667
Epoch [5401/30000], Step [1/1], Training Loss: 46927.2812, Valid Loss: 121.3619
Epoch [5501/30000], Step [1/1], Training Loss: 46098.2812, Valid Loss: 127.0571
Epoch [5601/30000], Step [1/1], Training Loss: 45326.3203, Valid Loss: 123.1238
Epoch [5701/30000], Step [1/1], Training Loss: 44499.9570, Valid Loss: 125.3048
Epoch [5801/30000], Step [1/1], Training Loss: 43725.1836, Valid Loss: 120.8857
Epoch [5901/30000], Step [1/1], Training Loss: 42875.8633, Valid Loss: 123.3333
Epoch [6001/30000], Step [1/1], Training Loss: 42086.0195, Valid Loss: 122.0476
Epoch [6101/30000], Step [1/1], Training Loss: 41344.6016, Valid Loss: 117.5714
Epoch [6201/30000], Step [1/1], Training Loss: 40508.7539, Valid Loss: 127.9143
Epoch [6301/30000], Step [1/1], Training Loss: 39947.1250, Valid Loss: 109.0667
Epoch [6401/30000], Step [1/1], Training Loss: 39101.9727, Valid Loss: 116.0476
Epoch [6501/30000], Step [1/1], Training Loss: 38404.2930, Valid Loss: 113.0762
Epoch [6601/30000], Step [1/1], Training Loss: 37687.6875, Valid Loss: 104.9810
Epoch [6701/30000], Step [1/1], Training Loss: 36988.7617, Valid Loss: 114.3714
Epoch [6801/30000], Step [1/1], Training Loss: 36317.8672, Valid Loss: 112.8095
Epoch [6901/30000], Step [1/1], Training Loss: 35581.9180, Valid Loss: 115.4286
Epoch [7001/30000], Step [1/1], Training Loss: 34918.1602, Valid Loss: 113.7143
Epoch [7101/30000], Step [1/1], Training Loss: 34249.5469, Valid Loss: 112.6476
Epoch [7201/30000], Step [1/1], Training Loss: 33644.3750, Valid Loss: 123.9524
Epoch [7301/30000], Step [1/1], Training Loss: 32935.0039, Valid Loss: 105.6572
Epoch [7401/30000], Step [1/1], Training Loss: 32302.8301, Valid Loss: 113.9429
Epoch [7501/30000], Step [1/1], Training Loss: 31660.1699, Valid Loss: 128.4191
Epoch [7601/30000], Step [1/1], Training Loss: 31053.6680, Valid Loss: 126.3048
Epoch [7701/30000], Step [1/1], Training Loss: 30466.9492, Valid Loss: 123.2381
Epoch [7801/30000], Step [1/1], Training Loss: 29877.1309, Valid Loss: 129.9143
Epoch [7901/30000], Step [1/1], Training Loss: 29303.4219, Valid Loss: 134.6762
Epoch [8001/30000], Step [1/1], Training Loss: 28748.3145, Valid Loss: 133.2952
Epoch [8101/30000], Step [1/1], Training Loss: 28192.6504, Valid Loss: 131.6000
Epoch [8201/30000], Step [1/1], Training Loss: 27652.8906, Valid Loss: 138.5048
Epoch [8301/30000], Step [1/1], Training Loss: 27121.0430, Valid Loss: 142.0857
Epoch [8401/30000], Step [1/1], Training Loss: 26607.5352, Valid Loss: 133.3048
Epoch [8501/30000], Step [1/1], Training Loss: 26100.2422, Valid Loss: 135.4286
Epoch [8601/30000], Step [1/1], Training Loss: 25602.2109, Valid Loss: 137.3429
Epoch [8701/30000], Step [1/1], Training Loss: 25120.5000, Valid Loss: 136.6762
Epoch [8801/30000], Step [1/1], Training Loss: 24635.8047, Valid Loss: 142.6381
Epoch [8901/30000], Step [1/1], Training Loss: 24173.7969, Valid Loss: 146.0286
Epoch [9001/30000], Step [1/1], Training Loss: 23709.2656, Valid Loss: 149.8095
Epoch [9101/30000], Step [1/1], Training Loss: 23262.2656, Valid Loss: 133.4286
Epoch [9201/30000], Step [1/1], Training Loss: 22816.5977, Valid Loss: 137.6667
Epoch [9301/30000], Step [1/1], Training Loss: 22385.9023, Valid Loss: 140.6000
Epoch [9401/30000], Step [1/1], Training Loss: 21962.5742, Valid Loss: 148.0667
Epoch [9501/30000], Step [1/1], Training Loss: 21628.7383, Valid Loss: 145.9238
Epoch [9601/30000], Step [1/1], Training Loss: 21165.3105, Valid Loss: 143.2667
Epoch [9701/30000], Step [1/1], Training Loss: 20766.6348, Valid Loss: 141.8381
Epoch [9801/30000], Step [1/1], Training Loss: 20378.0527, Valid Loss: 136.2952
Epoch [9901/30000], Step [1/1], Training Loss: 20000.4863, Valid Loss: 140.9333
Epoch [10001/30000], Step [1/1], Training Loss: 19640.5684, Valid Loss: 134.9048
Epoch [10101/30000], Step [1/1], Training Loss: 19271.7617, Valid Loss: 146.7524

[Epoch 15000] Rounded prediction: 
tensor([17., 12., 14.,  7., 13., 11., 14., 19., 16., 15., 12., 13., 12.,  8.,
        15.,  2.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         4.,  8.,  7.,  9., 11.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  4.,
        12., 17., 17., 20., 17.,  0.,  0.,  5., 30., 25., 15.,  7., 21., 31.,
        39., 51., 35., 33., 47., 47., 11.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([15.,  9., 13.,  5., 13., 11., 11., 16.,  9., 10.,  5.,  5.,  7.,  1.,
         4.,  0.,  0.,  0.,  2., 11.,  5.,  6.,  6.,  2.,  0.,  2.,  5.,  1.,
         2.,  0.,  0.,  0.,  3.,  3.,  0.,  0.,  0.,  0.,  3.,  4.,  0.,  0.,
         0.,  0.,  0.,  0.,  5.,  5.,  4., 11., 16., 18., 10.,  9.,  1.,  0.,
         0.,  0.,  4.,  1.,  2.,  0.,  2.,  2., 15.,  6.,  7.,  6.,  6., 13.,
        17., 17., 10., 15.,  8.,  0.,  0.,  6., 10.,  0.,  8.,  8.,  0., 12.,
        17., 19., 17., 17., 16.,  0.,  0., 37., 35., 24.,  9.,  1., 19., 32.,
        38., 53., 20., 17., 46., 33.,  2.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [10201/30000], Step [1/1], Training Loss: 18921.5957, Valid Loss: 142.4286
Epoch [10301/30000], Step [1/1], Training Loss: 18576.6719, Valid Loss: 142.2095
Epoch [10401/30000], Step [1/1], Training Loss: 18250.7461, Valid Loss: 148.5238
Epoch [10501/30000], Step [1/1], Training Loss: 18150.2988, Valid Loss: 146.6762
Epoch [10601/30000], Step [1/1], Training Loss: 17676.5957, Valid Loss: 140.6000
Epoch [10701/30000], Step [1/1], Training Loss: 17209.7578, Valid Loss: 136.6667
Epoch [10801/30000], Step [1/1], Training Loss: 16819.7715, Valid Loss: 128.6572
Epoch [10901/30000], Step [1/1], Training Loss: 16381.4238, Valid Loss: 121.3905
Epoch [11001/30000], Step [1/1], Training Loss: 16021.1641, Valid Loss: 121.0476
Epoch [11101/30000], Step [1/1], Training Loss: 15667.7471, Valid Loss: 128.0667
Epoch [11201/30000], Step [1/1], Training Loss: 15348.2148, Valid Loss: 127.7619
Epoch [11301/30000], Step [1/1], Training Loss: 15071.5342, Valid Loss: 124.8286
Epoch [11401/30000], Step [1/1], Training Loss: 14739.6182, Valid Loss: 123.9619
Epoch [11501/30000], Step [1/1], Training Loss: 14444.5088, Valid Loss: 123.0857
Epoch [11601/30000], Step [1/1], Training Loss: 14222.3857, Valid Loss: 129.2000
Epoch [11701/30000], Step [1/1], Training Loss: 14013.0654, Valid Loss: 127.1714
Epoch [11801/30000], Step [1/1], Training Loss: 13638.5293, Valid Loss: 125.4952
Epoch [11901/30000], Step [1/1], Training Loss: 13350.1621, Valid Loss: 120.3619
Epoch [12001/30000], Step [1/1], Training Loss: 13092.0889, Valid Loss: 123.4571
Epoch [12101/30000], Step [1/1], Training Loss: 12864.2412, Valid Loss: 120.9333
Epoch [12201/30000], Step [1/1], Training Loss: 12579.5312, Valid Loss: 118.5429
Epoch [12301/30000], Step [1/1], Training Loss: 12447.3877, Valid Loss: 119.2095
Epoch [12401/30000], Step [1/1], Training Loss: 11883.4688, Valid Loss: 121.4571
Epoch [12501/30000], Step [1/1], Training Loss: 11638.8428, Valid Loss: 125.1048
Epoch [12601/30000], Step [1/1], Training Loss: 11306.7305, Valid Loss: 126.2667
Epoch [12701/30000], Step [1/1], Training Loss: 11045.2207, Valid Loss: 120.6476
Epoch [12801/30000], Step [1/1], Training Loss: 10818.9668, Valid Loss: 125.5143
Epoch [12901/30000], Step [1/1], Training Loss: 10573.7021, Valid Loss: 123.8000
Epoch [13001/30000], Step [1/1], Training Loss: 10346.6377, Valid Loss: 122.5524
Epoch [13101/30000], Step [1/1], Training Loss: 10135.1934, Valid Loss: 127.2381
Epoch [13201/30000], Step [1/1], Training Loss: 9920.3750, Valid Loss: 124.5048
Epoch [13301/30000], Step [1/1], Training Loss: 9711.5156, Valid Loss: 125.8571
Epoch [13401/30000], Step [1/1], Training Loss: 9506.3535, Valid Loss: 130.1524
Epoch [13501/30000], Step [1/1], Training Loss: 9307.1328, Valid Loss: 130.0191
Epoch [13601/30000], Step [1/1], Training Loss: 9118.5801, Valid Loss: 126.7905
Epoch [13701/30000], Step [1/1], Training Loss: 8926.0273, Valid Loss: 127.9238
Epoch [13801/30000], Step [1/1], Training Loss: 8751.4248, Valid Loss: 123.8857
Epoch [13901/30000], Step [1/1], Training Loss: 8786.5078, Valid Loss: 126.3905
Epoch [14001/30000], Step [1/1], Training Loss: 8481.9092, Valid Loss: 129.9810
Epoch [14101/30000], Step [1/1], Training Loss: 8243.0156, Valid Loss: 128.4191
Epoch [14201/30000], Step [1/1], Training Loss: 8060.9067, Valid Loss: 129.2571
Epoch [14301/30000], Step [1/1], Training Loss: 7885.9131, Valid Loss: 124.5333
Epoch [14401/30000], Step [1/1], Training Loss: 7723.0498, Valid Loss: 127.2952
Epoch [14501/30000], Step [1/1], Training Loss: 7566.6104, Valid Loss: 127.3048
Epoch [14601/30000], Step [1/1], Training Loss: 7415.0063, Valid Loss: 127.0095
Epoch [14701/30000], Step [1/1], Training Loss: 7264.9355, Valid Loss: 127.6476
Epoch [14801/30000], Step [1/1], Training Loss: 7057.9834, Valid Loss: 120.4476
Epoch [14901/30000], Step [1/1], Training Loss: 6821.7886, Valid Loss: 124.8667
Epoch [15001/30000], Step [1/1], Training Loss: 6665.5728, Valid Loss: 129.2191
Epoch [15101/30000], Step [1/1], Training Loss: 6575.4727, Valid Loss: 132.9333
Epoch [15201/30000], Step [1/1], Training Loss: 6374.7144, Valid Loss: 134.9524
Epoch [15301/30000], Step [1/1], Training Loss: 6230.6426, Valid Loss: 133.8000
Epoch [15401/30000], Step [1/1], Training Loss: 6090.4512, Valid Loss: 132.7810
Epoch [15501/30000], Step [1/1], Training Loss: 6330.3428, Valid Loss: 136.0000
Epoch [15601/30000], Step [1/1], Training Loss: 6757.6753, Valid Loss: 143.8190
Epoch [15701/30000], Step [1/1], Training Loss: 5737.8555, Valid Loss: 152.0286
Epoch [15801/30000], Step [1/1], Training Loss: 5604.6484, Valid Loss: 148.2476
Epoch [15901/30000], Step [1/1], Training Loss: 5474.0835, Valid Loss: 152.8571
Epoch [16001/30000], Step [1/1], Training Loss: 5358.4448, Valid Loss: 153.9429
Epoch [16101/30000], Step [1/1], Training Loss: 5237.6265, Valid Loss: 147.9810
Epoch [16201/30000], Step [1/1], Training Loss: 5121.9019, Valid Loss: 144.2857
Epoch [16301/30000], Step [1/1], Training Loss: 5054.4985, Valid Loss: 140.2286
Epoch [16401/30000], Step [1/1], Training Loss: 5001.9854, Valid Loss: 138.8667
Epoch [16501/30000], Step [1/1], Training Loss: 4852.4595, Valid Loss: 138.7524
Epoch [16601/30000], Step [1/1], Training Loss: 4707.4741, Valid Loss: 139.6286
Epoch [16701/30000], Step [1/1], Training Loss: 4611.9336, Valid Loss: 139.4857
Epoch [16801/30000], Step [1/1], Training Loss: 4515.8652, Valid Loss: 139.1143
Epoch [16901/30000], Step [1/1], Training Loss: 4435.7148, Valid Loss: 139.8190
Epoch [17001/30000], Step [1/1], Training Loss: 4323.4771, Valid Loss: 139.4095
Epoch [17101/30000], Step [1/1], Training Loss: 4236.0298, Valid Loss: 139.5333
Epoch [17201/30000], Step [1/1], Training Loss: 4149.5728, Valid Loss: 136.6476
Epoch [17301/30000], Step [1/1], Training Loss: 4066.2869, Valid Loss: 137.8095
Epoch [17401/30000], Step [1/1], Training Loss: 3987.9993, Valid Loss: 139.0286
Epoch [17501/30000], Step [1/1], Training Loss: 3908.8325, Valid Loss: 137.2952
Epoch [17601/30000], Step [1/1], Training Loss: 3834.5266, Valid Loss: 137.0381
Epoch [17701/30000], Step [1/1], Training Loss: 3758.4185, Valid Loss: 133.9333
Epoch [17801/30000], Step [1/1], Training Loss: 3693.2061, Valid Loss: 140.6381
Epoch [17901/30000], Step [1/1], Training Loss: 3624.5464, Valid Loss: 129.0095
Epoch [18001/30000], Step [1/1], Training Loss: 3552.3623, Valid Loss: 134.4667
Epoch [18101/30000], Step [1/1], Training Loss: 3497.8577, Valid Loss: 136.0095
Epoch [18201/30000], Step [1/1], Training Loss: 3417.3499, Valid Loss: 131.0667
Epoch [18301/30000], Step [1/1], Training Loss: 3344.9851, Valid Loss: 134.5238
Epoch [18401/30000], Step [1/1], Training Loss: 3279.7571, Valid Loss: 130.1810
Epoch [18501/30000], Step [1/1], Training Loss: 3182.4802, Valid Loss: 131.3810
Epoch [18601/30000], Step [1/1], Training Loss: 3125.1968, Valid Loss: 111.2571
Epoch [18701/30000], Step [1/1], Training Loss: 2730.7014, Valid Loss: 115.6952
Epoch [18801/30000], Step [1/1], Training Loss: 2642.7642, Valid Loss: 114.6476
Epoch [18901/30000], Step [1/1], Training Loss: 2572.5027, Valid Loss: 118.8000
Epoch [19001/30000], Step [1/1], Training Loss: 2501.0017, Valid Loss: 113.6190
Epoch [19101/30000], Step [1/1], Training Loss: 2433.0928, Valid Loss: 113.3810
Epoch [19201/30000], Step [1/1], Training Loss: 2366.9451, Valid Loss: 116.7429
Epoch [19301/30000], Step [1/1], Training Loss: 2302.6787, Valid Loss: 115.7333
Epoch [19401/30000], Step [1/1], Training Loss: 2241.5024, Valid Loss: 115.9333
Epoch [19501/30000], Step [1/1], Training Loss: 2182.1174, Valid Loss: 111.9810
Epoch [19601/30000], Step [1/1], Training Loss: 2124.1418, Valid Loss: 109.6762
Epoch [19701/30000], Step [1/1], Training Loss: 2072.8276, Valid Loss: 106.4381
Epoch [19801/30000], Step [1/1], Training Loss: 2016.0483, Valid Loss: 111.6381
Epoch [19901/30000], Step [1/1], Training Loss: 1963.1630, Valid Loss: 110.5714
Epoch [20001/30000], Step [1/1], Training Loss: 1914.4844, Valid Loss: 112.5714
Epoch [20101/30000], Step [1/1], Training Loss: 1865.3241, Valid Loss: 116.0952
Epoch [20201/30000], Step [1/1], Training Loss: 1817.7280, Valid Loss: 112.2286

[Epoch 25000] Rounded prediction: 
tensor([19.,  8.,  9.,  4.,  9., 11., 11., 16., 10., 12.,  4.,  8.,  7.,  2.,
         6.,  0.,  0.,  0.,  9., 20.,  9., 10.,  5.,  2.,  0.,  0.,  4.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  3.,  3.,  1.,  6., 15., 18., 13.,  9.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  1., 12.,  3.,  7.,  6., 10., 12.,
        16., 18., 15., 14., 11.,  0.,  7., 18.,  6.,  0.,  4.,  5.,  0.,  5.,
        10., 16., 13., 12.,  9.,  0.,  0., 47., 39., 17.,  7.,  0., 18., 38.,
        45., 55., 24., 24., 47., 27.,  2.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [20301/30000], Step [1/1], Training Loss: 1773.1862, Valid Loss: 112.3429
Epoch [20401/30000], Step [1/1], Training Loss: 1729.7120, Valid Loss: 109.6190
Epoch [20501/30000], Step [1/1], Training Loss: 1687.2151, Valid Loss: 112.5143
Epoch [20601/30000], Step [1/1], Training Loss: 1647.8575, Valid Loss: 110.5810
Epoch [20701/30000], Step [1/1], Training Loss: 1609.5607, Valid Loss: 114.6095
Epoch [20801/30000], Step [1/1], Training Loss: 1572.2684, Valid Loss: 115.7905
Epoch [20901/30000], Step [1/1], Training Loss: 1535.4897, Valid Loss: 114.4667
Epoch [21001/30000], Step [1/1], Training Loss: 1500.9487, Valid Loss: 114.4571
Epoch [21101/30000], Step [1/1], Training Loss: 1467.2292, Valid Loss: 113.0571
Epoch [21201/30000], Step [1/1], Training Loss: 1434.1046, Valid Loss: 109.9238
Epoch [21301/30000], Step [1/1], Training Loss: 1403.0524, Valid Loss: 111.2667
Epoch [21401/30000], Step [1/1], Training Loss: 1372.1328, Valid Loss: 109.6095
Epoch [21501/30000], Step [1/1], Training Loss: 1341.3365, Valid Loss: 108.6952
Epoch [21601/30000], Step [1/1], Training Loss: 1312.2122, Valid Loss: 108.0095
Epoch [21701/30000], Step [1/1], Training Loss: 1283.5635, Valid Loss: 110.6095
Epoch [21801/30000], Step [1/1], Training Loss: 1255.6183, Valid Loss: 112.3048
Epoch [21901/30000], Step [1/1], Training Loss: 1228.5948, Valid Loss: 113.7810
Epoch [22001/30000], Step [1/1], Training Loss: 1202.6176, Valid Loss: 113.9429
Epoch [22101/30000], Step [1/1], Training Loss: 1176.6521, Valid Loss: 112.0095
Epoch [22201/30000], Step [1/1], Training Loss: 1151.4714, Valid Loss: 111.9048
Epoch [22301/30000], Step [1/1], Training Loss: 1127.3651, Valid Loss: 115.0857
Epoch [22401/30000], Step [1/1], Training Loss: 1103.1650, Valid Loss: 114.1143
Epoch [22501/30000], Step [1/1], Training Loss: 1079.2445, Valid Loss: 118.8000
Epoch [22601/30000], Step [1/1], Training Loss: 1056.0446, Valid Loss: 117.8952
Epoch [22701/30000], Step [1/1], Training Loss: 1032.1215, Valid Loss: 118.0762
Epoch [22801/30000], Step [1/1], Training Loss: 1008.9891, Valid Loss: 115.5524
Epoch [22901/30000], Step [1/1], Training Loss: 986.1965, Valid Loss: 117.6667
Epoch [23001/30000], Step [1/1], Training Loss: 964.4106, Valid Loss: 122.0857
Epoch [23101/30000], Step [1/1], Training Loss: 942.6426, Valid Loss: 122.3143
Epoch [23201/30000], Step [1/1], Training Loss: 921.6639, Valid Loss: 123.0381
Epoch [23301/30000], Step [1/1], Training Loss: 900.4414, Valid Loss: 123.6286
Epoch [23401/30000], Step [1/1], Training Loss: 880.3443, Valid Loss: 120.3143
Epoch [23501/30000], Step [1/1], Training Loss: 860.1250, Valid Loss: 121.9333
Epoch [23601/30000], Step [1/1], Training Loss: 840.8051, Valid Loss: 121.7143
Epoch [23701/30000], Step [1/1], Training Loss: 821.3872, Valid Loss: 122.9524
Epoch [23801/30000], Step [1/1], Training Loss: 802.8817, Valid Loss: 124.2000
Epoch [23901/30000], Step [1/1], Training Loss: 784.8298, Valid Loss: 121.5238
Epoch [24001/30000], Step [1/1], Training Loss: 768.1185, Valid Loss: 120.3048
Epoch [24101/30000], Step [1/1], Training Loss: 750.8559, Valid Loss: 125.5238
Epoch [24201/30000], Step [1/1], Training Loss: 734.1202, Valid Loss: 126.8667
Epoch [24301/30000], Step [1/1], Training Loss: 718.3330, Valid Loss: 127.6190
Epoch [24401/30000], Step [1/1], Training Loss: 703.1741, Valid Loss: 126.8952
Epoch [24501/30000], Step [1/1], Training Loss: 687.5051, Valid Loss: 124.3333
Epoch [24601/30000], Step [1/1], Training Loss: 673.0198, Valid Loss: 122.7429
Epoch [24701/30000], Step [1/1], Training Loss: 657.8658, Valid Loss: 124.5524
Epoch [24801/30000], Step [1/1], Training Loss: 643.4342, Valid Loss: 125.1048
Epoch [24901/30000], Step [1/1], Training Loss: 629.5175, Valid Loss: 126.9905
Epoch [25001/30000], Step [1/1], Training Loss: 615.7892, Valid Loss: 125.5048
Epoch [25101/30000], Step [1/1], Training Loss: 601.9343, Valid Loss: 130.0857
Epoch [25201/30000], Step [1/1], Training Loss: 588.3401, Valid Loss: 128.0381
Epoch [25301/30000], Step [1/1], Training Loss: 575.1522, Valid Loss: 123.3714
Epoch [25401/30000], Step [1/1], Training Loss: 561.8348, Valid Loss: 128.3143
Epoch [25501/30000], Step [1/1], Training Loss: 7212.7021, Valid Loss: 140.0381
Epoch [25601/30000], Step [1/1], Training Loss: 909.9891, Valid Loss: 147.1810
Epoch [25701/30000], Step [1/1], Training Loss: 612.7458, Valid Loss: 159.2286
Epoch [25801/30000], Step [1/1], Training Loss: 554.1290, Valid Loss: 153.6190
Epoch [25901/30000], Step [1/1], Training Loss: 526.8132, Valid Loss: 150.2857
Epoch [26001/30000], Step [1/1], Training Loss: 515.1721, Valid Loss: 148.2857
Epoch [26101/30000], Step [1/1], Training Loss: 502.8358, Valid Loss: 148.5810
Epoch [26201/30000], Step [1/1], Training Loss: 490.2473, Valid Loss: 147.5810
Epoch [26301/30000], Step [1/1], Training Loss: 484.7741, Valid Loss: 145.1619
Epoch [26401/30000], Step [1/1], Training Loss: 473.6778, Valid Loss: 145.4667
Epoch [26501/30000], Step [1/1], Training Loss: 463.1233, Valid Loss: 147.9333
Epoch [26601/30000], Step [1/1], Training Loss: 454.3486, Valid Loss: 152.7619
Epoch [26701/30000], Step [1/1], Training Loss: 445.0937, Valid Loss: 146.3524
Epoch [26801/30000], Step [1/1], Training Loss: 435.0942, Valid Loss: 148.9619
Epoch [26901/30000], Step [1/1], Training Loss: 425.3199, Valid Loss: 141.4572
Epoch [27001/30000], Step [1/1], Training Loss: 417.1318, Valid Loss: 145.5810
Epoch [27101/30000], Step [1/1], Training Loss: 408.2166, Valid Loss: 143.6286
Epoch [27201/30000], Step [1/1], Training Loss: 399.5454, Valid Loss: 142.6000
Epoch [27301/30000], Step [1/1], Training Loss: 391.8164, Valid Loss: 139.2191
Epoch [27401/30000], Step [1/1], Training Loss: 383.8889, Valid Loss: 141.8000
Epoch [27501/30000], Step [1/1], Training Loss: 374.5850, Valid Loss: 139.4476
Epoch [27601/30000], Step [1/1], Training Loss: 367.4384, Valid Loss: 136.8095
Epoch [27701/30000], Step [1/1], Training Loss: 357.2740, Valid Loss: 142.9714
Epoch [27801/30000], Step [1/1], Training Loss: 361.0300, Valid Loss: 134.6476
Epoch [27901/30000], Step [1/1], Training Loss: 341.1151, Valid Loss: 135.3048
Epoch [28001/30000], Step [1/1], Training Loss: 332.3638, Valid Loss: 136.4667
Epoch [28101/30000], Step [1/1], Training Loss: 323.6173, Valid Loss: 137.7048
Epoch [28201/30000], Step [1/1], Training Loss: 314.7967, Valid Loss: 137.2476
Epoch [28301/30000], Step [1/1], Training Loss: 306.6969, Valid Loss: 138.6952
Epoch [28401/30000], Step [1/1], Training Loss: 301.7194, Valid Loss: 140.4952
Epoch [28501/30000], Step [1/1], Training Loss: 289.8128, Valid Loss: 144.5810
Epoch [28601/30000], Step [1/1], Training Loss: 281.7110, Valid Loss: 142.2095
Epoch [28701/30000], Step [1/1], Training Loss: 277.3186, Valid Loss: 130.4286
Epoch [28801/30000], Step [1/1], Training Loss: 265.4767, Valid Loss: 130.6381
Epoch [28901/30000], Step [1/1], Training Loss: 257.0630, Valid Loss: 137.2952
Epoch [29001/30000], Step [1/1], Training Loss: 249.0818, Valid Loss: 136.2000
Epoch [29101/30000], Step [1/1], Training Loss: 241.1539, Valid Loss: 139.7238
Epoch [29201/30000], Step [1/1], Training Loss: 232.9537, Valid Loss: 137.9143
Epoch [29301/30000], Step [1/1], Training Loss: 225.7553, Valid Loss: 137.4667
Epoch [29401/30000], Step [1/1], Training Loss: 218.0705, Valid Loss: 134.6762
Epoch [29501/30000], Step [1/1], Training Loss: 210.7484, Valid Loss: 139.6762
Epoch [29601/30000], Step [1/1], Training Loss: 203.5462, Valid Loss: 141.6667
Epoch [29701/30000], Step [1/1], Training Loss: 196.4369, Valid Loss: 147.1333
Epoch [29801/30000], Step [1/1], Training Loss: 190.1388, Valid Loss: 145.3619
Epoch [29901/30000], Step [1/1], Training Loss: 183.5713, Valid Loss: 150.5524

 End Time: 2021/04/19, 17:11:01




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=512 	layers=2

Start Time = 2021/04/19, 17:11:02
##########################################################


[Epoch 0] Rounded prediction: 
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([13.,  7., 10., 10., 13., 16., 19., 20., 16., 21., 17., 16., 22., 11.,
        14.,  1.,  5.,  7.,  6.,  2.,  5.,  1.,  6.,  5.,  0.,  4.,  7.,  3.,
         4.,  6.,  7.,  0.,  7.,  8.,  2.,  7.,  2.,  7.,  0., 11.,  2., 11.,
         7., 10.,  0., 10.,  4.,  6.,  3.,  5.,  4.,  4.,  5.,  0., 13.,  2.,
         6.,  6.,  5.,  5.,  2.,  9.,  0., 10.,  0., 11.,  0.,  9.,  1.,  2.,
         5.,  4.,  3.,  3.,  5.,  7.,  0., 17., 11., 13.,  8.,  7., 19., 20.,
        12.,  9.,  5., 11.,  7.,  0.,  9., 36., 49., 38., 36., 24., 27., 30.,
        33., 35., 32., 39., 26., 33., 30.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([15.,  9., 12., 13., 11., 15., 19., 17., 18., 25., 15., 21., 28., 20.,
        17., 15.,  2., 10.,  3.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,  0.,
         0.,  0.,  0.,  0.,  0.,  5.,  0.,  3.,  0.,  1.,  0., 12.,  0., 11.,
         0.,  0.,  0.,  5.,  0.,  3.,  0.,  0.,  0.,  0.,  2.,  0.,  9.,  0.,
         0.,  0.,  0.,  4.,  0.,  2.,  0., 10.,  0., 12.,  0.,  4.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  2.,  0., 13.,  0.,  0.,  0.,  0., 12.,  9.,
         4.,  0.,  0.,  1.,  3.,  0., 15., 35., 38., 32., 26., 18., 27., 38.,
        41., 36., 36., 44., 34., 32., 36.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128683.0781, Valid Loss: 231.3048
Epoch [101/30000], Step [1/1], Training Loss: 121381.7422, Valid Loss: 107.8762
Epoch [201/30000], Step [1/1], Training Loss: 118931.3594, Valid Loss: 190.2191
Epoch [301/30000], Step [1/1], Training Loss: 116655.4922, Valid Loss: 320.0191
Epoch [401/30000], Step [1/1], Training Loss: 114479.6016, Valid Loss: 496.4476
Epoch [501/30000], Step [1/1], Training Loss: 112383.2109, Valid Loss: 722.8762
Epoch [601/30000], Step [1/1], Training Loss: 110352.2656, Valid Loss: 999.3048
Epoch [701/30000], Step [1/1], Training Loss: 108387.2969, Valid Loss: 1325.7334
Epoch [801/30000], Step [1/1], Training Loss: 106481.3281, Valid Loss: 1702.1620
Epoch [901/30000], Step [1/1], Training Loss: 104630.6719, Valid Loss: 2124.7239
Epoch [1001/30000], Step [1/1], Training Loss: 102832.0234, Valid Loss: 2505.7334
Epoch [1101/30000], Step [1/1], Training Loss: 101078.9453, Valid Loss: 1921.8381
Epoch [1201/30000], Step [1/1], Training Loss: 99320.6328, Valid Loss: 938.8667
Epoch [1301/30000], Step [1/1], Training Loss: 97400.1094, Valid Loss: 87.0857
Epoch [1401/30000], Step [1/1], Training Loss: 95669.7891, Valid Loss: 45.0476
Epoch [1501/30000], Step [1/1], Training Loss: 93968.0938, Valid Loss: 42.7619
Epoch [1601/30000], Step [1/1], Training Loss: 92309.5078, Valid Loss: 64.2762
Epoch [1701/30000], Step [1/1], Training Loss: 90681.2734, Valid Loss: 84.4381
Epoch [1801/30000], Step [1/1], Training Loss: 89085.7422, Valid Loss: 69.7714
Epoch [1901/30000], Step [1/1], Training Loss: 87510.6875, Valid Loss: 57.1619
Epoch [2001/30000], Step [1/1], Training Loss: 85970.3672, Valid Loss: 52.4667
Epoch [2101/30000], Step [1/1], Training Loss: 84454.4766, Valid Loss: 54.3810
Epoch [2201/30000], Step [1/1], Training Loss: 82969.3203, Valid Loss: 57.2762
Epoch [2301/30000], Step [1/1], Training Loss: 81513.3438, Valid Loss: 54.8381
Epoch [2401/30000], Step [1/1], Training Loss: 80084.2109, Valid Loss: 57.1905
Epoch [2501/30000], Step [1/1], Training Loss: 78681.6484, Valid Loss: 56.2857
Epoch [2601/30000], Step [1/1], Training Loss: 77305.1094, Valid Loss: 57.3429
Epoch [2701/30000], Step [1/1], Training Loss: 75955.0781, Valid Loss: 61.7810
Epoch [2801/30000], Step [1/1], Training Loss: 74630.8047, Valid Loss: 63.9810
Epoch [2901/30000], Step [1/1], Training Loss: 73334.3203, Valid Loss: 61.5143
Epoch [3001/30000], Step [1/1], Training Loss: 72062.2109, Valid Loss: 54.2286
Epoch [3101/30000], Step [1/1], Training Loss: 70815.3828, Valid Loss: 60.9810
Epoch [3201/30000], Step [1/1], Training Loss: 69592.6406, Valid Loss: 63.7333
Epoch [3301/30000], Step [1/1], Training Loss: 68395.2344, Valid Loss: 62.7333
Epoch [3401/30000], Step [1/1], Training Loss: 67220.5391, Valid Loss: 63.6762
Epoch [3501/30000], Step [1/1], Training Loss: 66070.3594, Valid Loss: 68.7429
Epoch [3601/30000], Step [1/1], Training Loss: 64944.1953, Valid Loss: 63.9524
Epoch [3701/30000], Step [1/1], Training Loss: 63841.6133, Valid Loss: 67.5333
Epoch [3801/30000], Step [1/1], Training Loss: 62761.8633, Valid Loss: 71.5810
Epoch [3901/30000], Step [1/1], Training Loss: 61693.2891, Valid Loss: 49.4286
Epoch [4001/30000], Step [1/1], Training Loss: 60577.5391, Valid Loss: 48.6286
Epoch [4101/30000], Step [1/1], Training Loss: 59489.4922, Valid Loss: 52.5524
Epoch [4201/30000], Step [1/1], Training Loss: 58451.6719, Valid Loss: 56.2476
Epoch [4301/30000], Step [1/1], Training Loss: 57411.6328, Valid Loss: 49.0571
Epoch [4401/30000], Step [1/1], Training Loss: 56399.5273, Valid Loss: 53.3905
Epoch [4501/30000], Step [1/1], Training Loss: 55370.3516, Valid Loss: 53.6667
Epoch [4601/30000], Step [1/1], Training Loss: 54398.1133, Valid Loss: 50.8571
Epoch [4701/30000], Step [1/1], Training Loss: 53408.1133, Valid Loss: 59.3619
Epoch [4801/30000], Step [1/1], Training Loss: 52470.4570, Valid Loss: 59.9905
Epoch [4901/30000], Step [1/1], Training Loss: 51523.8164, Valid Loss: 64.3048
Epoch [5001/30000], Step [1/1], Training Loss: 50602.1953, Valid Loss: 68.7810
Epoch [5101/30000], Step [1/1], Training Loss: 49701.3008, Valid Loss: 69.1429
Epoch [5201/30000], Step [1/1], Training Loss: 48821.8867, Valid Loss: 73.0952
Epoch [5301/30000], Step [1/1], Training Loss: 47955.9922, Valid Loss: 73.4857
Epoch [5401/30000], Step [1/1], Training Loss: 47106.2422, Valid Loss: 73.0857
Epoch [5501/30000], Step [1/1], Training Loss: 46283.9023, Valid Loss: 78.4762
Epoch [5601/30000], Step [1/1], Training Loss: 45463.7578, Valid Loss: 79.7905
Epoch [5701/30000], Step [1/1], Training Loss: 44643.0703, Valid Loss: 82.6190
Epoch [5801/30000], Step [1/1], Training Loss: 43867.3008, Valid Loss: 83.2381
Epoch [5901/30000], Step [1/1], Training Loss: 43089.8594, Valid Loss: 83.1524
Epoch [6001/30000], Step [1/1], Training Loss: 42327.2578, Valid Loss: 89.2286
Epoch [6101/30000], Step [1/1], Training Loss: 41595.9922, Valid Loss: 92.2857
Epoch [6201/30000], Step [1/1], Training Loss: 40845.0781, Valid Loss: 91.9429
Epoch [6301/30000], Step [1/1], Training Loss: 40146.1875, Valid Loss: 91.7048
Epoch [6401/30000], Step [1/1], Training Loss: 39439.4219, Valid Loss: 89.2095
Epoch [6501/30000], Step [1/1], Training Loss: 38745.2734, Valid Loss: 96.4095
Epoch [6601/30000], Step [1/1], Training Loss: 38085.6445, Valid Loss: 92.0095
Epoch [6701/30000], Step [1/1], Training Loss: 37412.8867, Valid Loss: 90.1333
Epoch [6801/30000], Step [1/1], Training Loss: 36769.4844, Valid Loss: 98.4762
Epoch [6901/30000], Step [1/1], Training Loss: 36353.0938, Valid Loss: 102.7905
Epoch [7001/30000], Step [1/1], Training Loss: 35498.1523, Valid Loss: 92.9524
Epoch [7101/30000], Step [1/1], Training Loss: 34860.0430, Valid Loss: 94.4286
Epoch [7201/30000], Step [1/1], Training Loss: 34313.3359, Valid Loss: 89.1333
Epoch [7301/30000], Step [1/1], Training Loss: 33483.5742, Valid Loss: 89.4952
Epoch [7401/30000], Step [1/1], Training Loss: 32789.4375, Valid Loss: 87.9048
Epoch [7501/30000], Step [1/1], Training Loss: 32164.3125, Valid Loss: 90.2762
Epoch [7601/30000], Step [1/1], Training Loss: 31499.4883, Valid Loss: 98.2191
Epoch [7701/30000], Step [1/1], Training Loss: 30879.3594, Valid Loss: 100.2857
Epoch [7801/30000], Step [1/1], Training Loss: 30246.9590, Valid Loss: 95.4571
Epoch [7901/30000], Step [1/1], Training Loss: 29676.5098, Valid Loss: 85.7714
Epoch [8001/30000], Step [1/1], Training Loss: 29627.7031, Valid Loss: 103.1905
Epoch [8101/30000], Step [1/1], Training Loss: 28650.9199, Valid Loss: 86.1524
Epoch [8201/30000], Step [1/1], Training Loss: 28038.1211, Valid Loss: 90.8476
Epoch [8301/30000], Step [1/1], Training Loss: 27475.3008, Valid Loss: 91.2381
Epoch [8401/30000], Step [1/1], Training Loss: 26936.3926, Valid Loss: 87.4857
Epoch [8501/30000], Step [1/1], Training Loss: 26426.3398, Valid Loss: 94.3810
Epoch [8601/30000], Step [1/1], Training Loss: 25923.6699, Valid Loss: 99.6667
Epoch [8701/30000], Step [1/1], Training Loss: 25428.8105, Valid Loss: 102.4095
Epoch [8801/30000], Step [1/1], Training Loss: 24935.2109, Valid Loss: 103.5524
Epoch [8901/30000], Step [1/1], Training Loss: 24461.6309, Valid Loss: 109.7238
Epoch [9001/30000], Step [1/1], Training Loss: 23993.3203, Valid Loss: 104.9333
Epoch [9101/30000], Step [1/1], Training Loss: 23550.1387, Valid Loss: 114.4857
Epoch [9201/30000], Step [1/1], Training Loss: 23087.6582, Valid Loss: 107.1333
Epoch [9301/30000], Step [1/1], Training Loss: 22641.1328, Valid Loss: 103.8952
Epoch [9401/30000], Step [1/1], Training Loss: 22210.8496, Valid Loss: 122.9619
Epoch [9501/30000], Step [1/1], Training Loss: 21769.4473, Valid Loss: 114.0952
Epoch [9601/30000], Step [1/1], Training Loss: 21390.0996, Valid Loss: 115.9048
Epoch [9701/30000], Step [1/1], Training Loss: 21094.6992, Valid Loss: 105.1238
Epoch [9801/30000], Step [1/1], Training Loss: 21865.7578, Valid Loss: 107.6286
Epoch [9901/30000], Step [1/1], Training Loss: 20234.3164, Valid Loss: 100.5714
Epoch [10001/30000], Step [1/1], Training Loss: 19855.3320, Valid Loss: 102.5524
Epoch [10101/30000], Step [1/1], Training Loss: 19448.2637, Valid Loss: 110.9714

[Epoch 15000] Rounded prediction: 
tensor([14.,  8., 12., 12., 13., 16., 21., 23., 20., 21., 22., 17., 20., 14.,
        19.,  8.,  0.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  0.,  3.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  2.,
         0.,  0.,  0.,  0.,  0.,  0.,  7., 28., 41., 33., 27., 12., 19., 30.,
        32., 31., 27., 36., 21.,  5., 14.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([14., 10., 12., 14., 12., 18., 22., 27., 26., 26., 28., 20., 27., 19.,
        24.,  5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0., 10.,
         0.,  0.,  0.,  0.,  0.,  0., 17., 39., 56., 45., 34., 12., 17., 37.,
        37., 30., 29., 31., 18.,  8., 13.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [10201/30000], Step [1/1], Training Loss: 19081.2344, Valid Loss: 105.1810
Epoch [10301/30000], Step [1/1], Training Loss: 18720.3184, Valid Loss: 108.1333
Epoch [10401/30000], Step [1/1], Training Loss: 18368.0918, Valid Loss: 109.3905
Epoch [10501/30000], Step [1/1], Training Loss: 18016.6602, Valid Loss: 105.6381
Epoch [10601/30000], Step [1/1], Training Loss: 17511.4844, Valid Loss: 111.2571
Epoch [10701/30000], Step [1/1], Training Loss: 17154.5527, Valid Loss: 107.3714
Epoch [10801/30000], Step [1/1], Training Loss: 16779.5957, Valid Loss: 109.9238
Epoch [10901/30000], Step [1/1], Training Loss: 16420.6328, Valid Loss: 114.9238
Epoch [11001/30000], Step [1/1], Training Loss: 16091.9668, Valid Loss: 113.5524
Epoch [11101/30000], Step [1/1], Training Loss: 15771.7432, Valid Loss: 114.3905
Epoch [11201/30000], Step [1/1], Training Loss: 15459.5703, Valid Loss: 112.6286
Epoch [11301/30000], Step [1/1], Training Loss: 15166.3184, Valid Loss: 114.8762
Epoch [11401/30000], Step [1/1], Training Loss: 14869.2812, Valid Loss: 113.2095
Epoch [11501/30000], Step [1/1], Training Loss: 14584.5410, Valid Loss: 119.6000
Epoch [11601/30000], Step [1/1], Training Loss: 14306.7031, Valid Loss: 122.2667
Epoch [11701/30000], Step [1/1], Training Loss: 14044.2627, Valid Loss: 112.9333
Epoch [11801/30000], Step [1/1], Training Loss: 13918.8584, Valid Loss: 115.9810
Epoch [11901/30000], Step [1/1], Training Loss: 13643.2666, Valid Loss: 120.4095
Epoch [12001/30000], Step [1/1], Training Loss: 13116.6611, Valid Loss: 124.8857
Epoch [12101/30000], Step [1/1], Training Loss: 12846.8936, Valid Loss: 117.6190
Epoch [12201/30000], Step [1/1], Training Loss: 12581.2744, Valid Loss: 121.9810
Epoch [12301/30000], Step [1/1], Training Loss: 12333.3477, Valid Loss: 123.4667
Epoch [12401/30000], Step [1/1], Training Loss: 12093.1934, Valid Loss: 119.8952
Epoch [12501/30000], Step [1/1], Training Loss: 11856.8906, Valid Loss: 116.9048
Epoch [12601/30000], Step [1/1], Training Loss: 11629.5586, Valid Loss: 116.9619
Epoch [12701/30000], Step [1/1], Training Loss: 11405.4375, Valid Loss: 120.2000
Epoch [12801/30000], Step [1/1], Training Loss: 11181.5996, Valid Loss: 123.8857
Epoch [12901/30000], Step [1/1], Training Loss: 10961.1895, Valid Loss: 126.4095
Epoch [13001/30000], Step [1/1], Training Loss: 10765.2061, Valid Loss: 130.8952
Epoch [13101/30000], Step [1/1], Training Loss: 10556.7012, Valid Loss: 123.1810
Epoch [13201/30000], Step [1/1], Training Loss: 11166.8320, Valid Loss: 117.1905
Epoch [13301/30000], Step [1/1], Training Loss: 10074.1074, Valid Loss: 118.4476
Epoch [13401/30000], Step [1/1], Training Loss: 9819.6357, Valid Loss: 125.6572
Epoch [13501/30000], Step [1/1], Training Loss: 9421.2178, Valid Loss: 122.6286
Epoch [13601/30000], Step [1/1], Training Loss: 9191.4424, Valid Loss: 118.2381
Epoch [13701/30000], Step [1/1], Training Loss: 8985.5957, Valid Loss: 118.2857
Epoch [13801/30000], Step [1/1], Training Loss: 8784.6230, Valid Loss: 118.5429
Epoch [13901/30000], Step [1/1], Training Loss: 8583.6611, Valid Loss: 119.1429
Epoch [14001/30000], Step [1/1], Training Loss: 8394.6719, Valid Loss: 118.2571
Epoch [14101/30000], Step [1/1], Training Loss: 8222.5439, Valid Loss: 118.2095
Epoch [14201/30000], Step [1/1], Training Loss: 8043.8398, Valid Loss: 119.2286
Epoch [14301/30000], Step [1/1], Training Loss: 7865.2197, Valid Loss: 120.4191
Epoch [14401/30000], Step [1/1], Training Loss: 7697.5269, Valid Loss: 116.7429
Epoch [14501/30000], Step [1/1], Training Loss: 7537.8413, Valid Loss: 120.3333
Epoch [14601/30000], Step [1/1], Training Loss: 7364.1738, Valid Loss: 122.0571
Epoch [14701/30000], Step [1/1], Training Loss: 7196.5107, Valid Loss: 130.9714
Epoch [14801/30000], Step [1/1], Training Loss: 7030.4277, Valid Loss: 121.0571
Epoch [14901/30000], Step [1/1], Training Loss: 6863.3477, Valid Loss: 127.4095
Epoch [15001/30000], Step [1/1], Training Loss: 6704.7827, Valid Loss: 127.4476
Epoch [15101/30000], Step [1/1], Training Loss: 6560.5308, Valid Loss: 125.1143
Epoch [15201/30000], Step [1/1], Training Loss: 6416.8110, Valid Loss: 125.3810
Epoch [15301/30000], Step [1/1], Training Loss: 6279.8169, Valid Loss: 121.5048
Epoch [15401/30000], Step [1/1], Training Loss: 6144.1450, Valid Loss: 129.3333
Epoch [15501/30000], Step [1/1], Training Loss: 6016.2144, Valid Loss: 126.0571
Epoch [15601/30000], Step [1/1], Training Loss: 5891.1675, Valid Loss: 120.8381
Epoch [15701/30000], Step [1/1], Training Loss: 5765.1675, Valid Loss: 122.5238
Epoch [15801/30000], Step [1/1], Training Loss: 5647.6626, Valid Loss: 127.5048
Epoch [15901/30000], Step [1/1], Training Loss: 7419.4556, Valid Loss: 142.3714
Epoch [16001/30000], Step [1/1], Training Loss: 5677.7559, Valid Loss: 127.2286
Epoch [16101/30000], Step [1/1], Training Loss: 5498.7461, Valid Loss: 127.4286
Epoch [16201/30000], Step [1/1], Training Loss: 5213.2808, Valid Loss: 125.8857
Epoch [16301/30000], Step [1/1], Training Loss: 5091.2007, Valid Loss: 130.0476
Epoch [16401/30000], Step [1/1], Training Loss: 4985.8794, Valid Loss: 136.6476
Epoch [16501/30000], Step [1/1], Training Loss: 4868.8413, Valid Loss: 132.9905
Epoch [16601/30000], Step [1/1], Training Loss: 4673.5234, Valid Loss: 130.9143
Epoch [16701/30000], Step [1/1], Training Loss: 4535.8857, Valid Loss: 129.6857
Epoch [16801/30000], Step [1/1], Training Loss: 4714.7837, Valid Loss: 136.1048
Epoch [16901/30000], Step [1/1], Training Loss: 4487.3599, Valid Loss: 127.9429
Epoch [17001/30000], Step [1/1], Training Loss: 4123.3735, Valid Loss: 132.9238
Epoch [17101/30000], Step [1/1], Training Loss: 4019.5669, Valid Loss: 134.0476
Epoch [17201/30000], Step [1/1], Training Loss: 3915.5696, Valid Loss: 134.6381
Epoch [17301/30000], Step [1/1], Training Loss: 3832.6289, Valid Loss: 129.3238
Epoch [17401/30000], Step [1/1], Training Loss: 3730.0276, Valid Loss: 128.9714
Epoch [17501/30000], Step [1/1], Training Loss: 3640.3721, Valid Loss: 131.6857
Epoch [17601/30000], Step [1/1], Training Loss: 3546.5991, Valid Loss: 131.7238
Epoch [17701/30000], Step [1/1], Training Loss: 3477.6919, Valid Loss: 131.6762
Epoch [17801/30000], Step [1/1], Training Loss: 3376.0859, Valid Loss: 134.0762
Epoch [17901/30000], Step [1/1], Training Loss: 3297.9875, Valid Loss: 130.0191
Epoch [18001/30000], Step [1/1], Training Loss: 4888.0869, Valid Loss: 127.5714
Epoch [18101/30000], Step [1/1], Training Loss: 3532.4707, Valid Loss: 141.1714
Epoch [18201/30000], Step [1/1], Training Loss: 3112.8684, Valid Loss: 133.7143
Epoch [18301/30000], Step [1/1], Training Loss: 3026.3174, Valid Loss: 136.4095
Epoch [18401/30000], Step [1/1], Training Loss: 2937.4595, Valid Loss: 128.7714
Epoch [18501/30000], Step [1/1], Training Loss: 2855.7805, Valid Loss: 129.6095
Epoch [18601/30000], Step [1/1], Training Loss: 2777.2729, Valid Loss: 130.0571
Epoch [18701/30000], Step [1/1], Training Loss: 2712.5803, Valid Loss: 130.1905
Epoch [18801/30000], Step [1/1], Training Loss: 2673.9717, Valid Loss: 133.1524
Epoch [18901/30000], Step [1/1], Training Loss: 2573.5447, Valid Loss: 136.3524
Epoch [19001/30000], Step [1/1], Training Loss: 2509.6736, Valid Loss: 140.9429
Epoch [19101/30000], Step [1/1], Training Loss: 2443.7112, Valid Loss: 143.6190
Epoch [19201/30000], Step [1/1], Training Loss: 2384.8984, Valid Loss: 137.0762
Epoch [19301/30000], Step [1/1], Training Loss: 2317.8936, Valid Loss: 145.2762
Epoch [19401/30000], Step [1/1], Training Loss: 2258.7861, Valid Loss: 146.1048
Epoch [19501/30000], Step [1/1], Training Loss: 2208.3303, Valid Loss: 146.8190
Epoch [19601/30000], Step [1/1], Training Loss: 2147.3350, Valid Loss: 146.2000
Epoch [19701/30000], Step [1/1], Training Loss: 2093.0833, Valid Loss: 141.8952
Epoch [19801/30000], Step [1/1], Training Loss: 2053.4751, Valid Loss: 147.6190
Epoch [19901/30000], Step [1/1], Training Loss: 1986.6012, Valid Loss: 145.2476
Epoch [20001/30000], Step [1/1], Training Loss: 1935.0608, Valid Loss: 142.8571
Epoch [20101/30000], Step [1/1], Training Loss: 1890.3562, Valid Loss: 147.1143
Epoch [20201/30000], Step [1/1], Training Loss: 1842.7924, Valid Loss: 140.8857

[Epoch 25000] Rounded prediction: 
tensor([15., 15., 15., 14., 14., 19., 22., 28., 25., 30., 24., 27., 34., 26.,
        18.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  2., 21., 48., 43., 31., 19., 21., 42.,
        42., 43., 33., 38., 24.,  5.,  0.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [20301/30000], Step [1/1], Training Loss: 1796.2161, Valid Loss: 148.7810
Epoch [20401/30000], Step [1/1], Training Loss: 1756.8737, Valid Loss: 142.9810
Epoch [20501/30000], Step [1/1], Training Loss: 1712.4980, Valid Loss: 151.5048
Epoch [20601/30000], Step [1/1], Training Loss: 1670.3225, Valid Loss: 146.5524
Epoch [20701/30000], Step [1/1], Training Loss: 1636.9713, Valid Loss: 138.6857
Epoch [20801/30000], Step [1/1], Training Loss: 3315.0549, Valid Loss: 145.6667
Epoch [20901/30000], Step [1/1], Training Loss: 1808.7821, Valid Loss: 130.4095
Epoch [21001/30000], Step [1/1], Training Loss: 1575.4653, Valid Loss: 138.2476
Epoch [21101/30000], Step [1/1], Training Loss: 1528.6165, Valid Loss: 150.2476
Epoch [21201/30000], Step [1/1], Training Loss: 1487.4043, Valid Loss: 143.7810
Epoch [21301/30000], Step [1/1], Training Loss: 1460.7673, Valid Loss: 132.5238
Epoch [21401/30000], Step [1/1], Training Loss: 1418.3184, Valid Loss: 140.9714
Epoch [21501/30000], Step [1/1], Training Loss: 1390.1984, Valid Loss: 141.1429
Epoch [21601/30000], Step [1/1], Training Loss: 1352.4380, Valid Loss: 140.5714
Epoch [21701/30000], Step [1/1], Training Loss: 1331.6108, Valid Loss: 139.1238
Epoch [21801/30000], Step [1/1], Training Loss: 1298.5072, Valid Loss: 142.4572
Epoch [21901/30000], Step [1/1], Training Loss: 1268.9896, Valid Loss: 140.0286
Epoch [22001/30000], Step [1/1], Training Loss: 1244.5913, Valid Loss: 144.3333
Epoch [22101/30000], Step [1/1], Training Loss: 1214.5068, Valid Loss: 141.9143
Epoch [22201/30000], Step [1/1], Training Loss: 1188.4379, Valid Loss: 145.0571
Epoch [22301/30000], Step [1/1], Training Loss: 1162.3560, Valid Loss: 142.6476
Epoch [22401/30000], Step [1/1], Training Loss: 1145.2400, Valid Loss: 146.5524
Epoch [22501/30000], Step [1/1], Training Loss: 1119.3947, Valid Loss: 141.1524
Epoch [22601/30000], Step [1/1], Training Loss: 1100.9651, Valid Loss: 147.5238
Epoch [22701/30000], Step [1/1], Training Loss: 1074.2089, Valid Loss: 137.5143
Epoch [22801/30000], Step [1/1], Training Loss: 1053.0415, Valid Loss: 140.1429
Epoch [22901/30000], Step [1/1], Training Loss: 1025.3593, Valid Loss: 136.9714
Epoch [23001/30000], Step [1/1], Training Loss: 1000.5662, Valid Loss: 138.8190
Epoch [23101/30000], Step [1/1], Training Loss: 981.1497, Valid Loss: 144.8476
Epoch [23201/30000], Step [1/1], Training Loss: 961.3289, Valid Loss: 148.3714
Epoch [23301/30000], Step [1/1], Training Loss: 936.7419, Valid Loss: 142.0667
Epoch [23401/30000], Step [1/1], Training Loss: 910.6431, Valid Loss: 138.8952
Epoch [23501/30000], Step [1/1], Training Loss: 887.0060, Valid Loss: 151.2381
Epoch [23601/30000], Step [1/1], Training Loss: 865.2268, Valid Loss: 151.1048
Epoch [23701/30000], Step [1/1], Training Loss: 845.2336, Valid Loss: 148.0571
Epoch [23801/30000], Step [1/1], Training Loss: 827.6107, Valid Loss: 141.5238
Epoch [23901/30000], Step [1/1], Training Loss: 808.2370, Valid Loss: 146.4667
Epoch [24001/30000], Step [1/1], Training Loss: 790.6415, Valid Loss: 149.5524
Epoch [24101/30000], Step [1/1], Training Loss: 774.0176, Valid Loss: 152.5048
Epoch [24201/30000], Step [1/1], Training Loss: 757.0752, Valid Loss: 144.8190
Epoch [24301/30000], Step [1/1], Training Loss: 740.9803, Valid Loss: 149.7810
Epoch [24401/30000], Step [1/1], Training Loss: 723.8173, Valid Loss: 150.0381
Epoch [24501/30000], Step [1/1], Training Loss: 708.7379, Valid Loss: 151.6953
Epoch [24601/30000], Step [1/1], Training Loss: 698.3118, Valid Loss: 162.1429
Epoch [24701/30000], Step [1/1], Training Loss: 679.0801, Valid Loss: 157.2286
Epoch [24801/30000], Step [1/1], Training Loss: 665.1837, Valid Loss: 157.1524
Epoch [24901/30000], Step [1/1], Training Loss: 685.7765, Valid Loss: 190.3714
Epoch [25001/30000], Step [1/1], Training Loss: 639.1410, Valid Loss: 168.8857
Epoch [25101/30000], Step [1/1], Training Loss: 623.4753, Valid Loss: 170.5333
Epoch [25201/30000], Step [1/1], Training Loss: 8372.4287, Valid Loss: 166.0667
Epoch [25301/30000], Step [1/1], Training Loss: 866.7495, Valid Loss: 207.0762
Epoch [25401/30000], Step [1/1], Training Loss: 633.3287, Valid Loss: 188.1905
Epoch [25501/30000], Step [1/1], Training Loss: 595.0193, Valid Loss: 185.3619
Epoch [25601/30000], Step [1/1], Training Loss: 582.8481, Valid Loss: 192.3619
Epoch [25701/30000], Step [1/1], Training Loss: 574.6971, Valid Loss: 187.8667
Epoch [25801/30000], Step [1/1], Training Loss: 557.1360, Valid Loss: 190.6762
Epoch [25901/30000], Step [1/1], Training Loss: 546.4451, Valid Loss: 193.3905
Epoch [26001/30000], Step [1/1], Training Loss: 534.7401, Valid Loss: 193.1048
Epoch [26101/30000], Step [1/1], Training Loss: 523.6327, Valid Loss: 195.6095
Epoch [26201/30000], Step [1/1], Training Loss: 513.8124, Valid Loss: 193.6381
Epoch [26301/30000], Step [1/1], Training Loss: 505.6800, Valid Loss: 193.6476
Epoch [26401/30000], Step [1/1], Training Loss: 493.5645, Valid Loss: 193.5429
Epoch [26501/30000], Step [1/1], Training Loss: 482.7454, Valid Loss: 194.8191
Epoch [26601/30000], Step [1/1], Training Loss: 473.2845, Valid Loss: 195.4952
Epoch [26701/30000], Step [1/1], Training Loss: 465.2222, Valid Loss: 193.9333
Epoch [26801/30000], Step [1/1], Training Loss: 458.0823, Valid Loss: 192.5619
Epoch [26901/30000], Step [1/1], Training Loss: 444.7627, Valid Loss: 193.1714
Epoch [27001/30000], Step [1/1], Training Loss: 435.1986, Valid Loss: 191.2952
Epoch [27101/30000], Step [1/1], Training Loss: 425.1119, Valid Loss: 192.9048
Epoch [27201/30000], Step [1/1], Training Loss: 418.8343, Valid Loss: 192.7333
Epoch [27301/30000], Step [1/1], Training Loss: 407.6425, Valid Loss: 196.0286
Epoch [27401/30000], Step [1/1], Training Loss: 398.9034, Valid Loss: 190.2286
Epoch [27501/30000], Step [1/1], Training Loss: 394.2039, Valid Loss: 182.4000
Epoch [27601/30000], Step [1/1], Training Loss: 382.4632, Valid Loss: 189.7905
Epoch [27701/30000], Step [1/1], Training Loss: 374.0012, Valid Loss: 198.0381
Epoch [27801/30000], Step [1/1], Training Loss: 362.9582, Valid Loss: 187.9524
Epoch [27901/30000], Step [1/1], Training Loss: 354.6701, Valid Loss: 191.5238
Epoch [28001/30000], Step [1/1], Training Loss: 345.3621, Valid Loss: 199.1333
Epoch [28101/30000], Step [1/1], Training Loss: 337.1009, Valid Loss: 197.2857
Epoch [28201/30000], Step [1/1], Training Loss: 327.6155, Valid Loss: 204.2952
Epoch [28301/30000], Step [1/1], Training Loss: 320.3987, Valid Loss: 202.0762
Epoch [28401/30000], Step [1/1], Training Loss: 310.3535, Valid Loss: 198.6572
Epoch [28501/30000], Step [1/1], Training Loss: 301.4398, Valid Loss: 200.0571
Epoch [28601/30000], Step [1/1], Training Loss: 294.7738, Valid Loss: 200.8476
Epoch [28701/30000], Step [1/1], Training Loss: 285.3218, Valid Loss: 209.4857
Epoch [28801/30000], Step [1/1], Training Loss: 276.7715, Valid Loss: 202.0952
Epoch [28901/30000], Step [1/1], Training Loss: 268.3594, Valid Loss: 203.4857
Epoch [29001/30000], Step [1/1], Training Loss: 260.2246, Valid Loss: 201.2000
Epoch [29101/30000], Step [1/1], Training Loss: 253.4229, Valid Loss: 212.1714
Epoch [29201/30000], Step [1/1], Training Loss: 244.8198, Valid Loss: 204.0381
Epoch [29301/30000], Step [1/1], Training Loss: 236.5257, Valid Loss: 195.9714
Epoch [29401/30000], Step [1/1], Training Loss: 228.5613, Valid Loss: 196.8857
Epoch [29501/30000], Step [1/1], Training Loss: 222.6181, Valid Loss: 205.7238
Epoch [29601/30000], Step [1/1], Training Loss: 214.6005, Valid Loss: 199.1238
Epoch [29701/30000], Step [1/1], Training Loss: 206.9728, Valid Loss: 200.8571
Epoch [29801/30000], Step [1/1], Training Loss: 198.7552, Valid Loss: 196.3429
Epoch [29901/30000], Step [1/1], Training Loss: 196.9014, Valid Loss: 200.1333

 End Time: 2021/04/19, 17:17:36




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=1048 	layers=2

Start Time = 2021/04/19, 17:22:34
##########################################################


[Epoch 0] Rounded prediction: 
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([20., 18., 23., 19., 19., 23., 22., 25., 25., 24., 27., 22., 23., 17.,
        17., 19.,  4., 14.,  1.,  9.,  5.,  5., 10., 10.,  8.,  4.,  4.,  2.,
         5.,  6.,  7.,  4.,  1.,  6.,  1.,  8.,  0.,  6.,  0., 11.,  0., 15.,
        20., 13.,  3.,  6.,  0.,  3.,  2.,  2.,  2.,  3.,  6.,  3., 15., 11.,
         5.,  0.,  3.,  2.,  2.,  7.,  0., 11.,  0., 15.,  2., 14., 10.,  9.,
         6.,  5.,  7.,  8.,  8.,  8.,  7., 20., 24., 20., 20., 20., 24., 32.,
        22., 19., 14., 12., 15., 17.,  4., 17., 40., 40., 35., 28., 26., 31.,
        35., 42., 30., 27., 30., 37., 20.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([24., 24., 22., 19., 20., 21., 24., 29., 30., 34., 32., 33., 33., 33.,
        33., 29., 21., 16.,  1.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  3.,  0.,  2.,  0.,  2.,  0.,  8.,  0.,  9.,
         5.,  0.,  0.,  3.,  0.,  1.,  0.,  0.,  0.,  0.,  3.,  0.,  6.,  0.,
         0.,  0.,  1.,  0.,  0.,  0.,  0.,  3.,  0.,  5.,  0.,  6.,  0.,  1.,
         2.,  4.,  5.,  6.,  8., 10.,  1., 15.,  1.,  0.,  9.,  3., 10., 18.,
         5.,  7., 12., 13., 20., 24.,  0., 21., 23., 18., 21., 19., 18., 31.,
        37., 44., 19., 28., 36., 28.,  4.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128658.3281, Valid Loss: 208.8191
Epoch [101/30000], Step [1/1], Training Loss: 116546.6250, Valid Loss: 320.0191
Epoch [201/30000], Step [1/1], Training Loss: 112072.7891, Valid Loss: 774.1619
Epoch [301/30000], Step [1/1], Training Loss: 107946.7734, Valid Loss: 1397.0190
Epoch [401/30000], Step [1/1], Training Loss: 104092.1719, Valid Loss: 2202.3145
Epoch [501/30000], Step [1/1], Training Loss: 100467.3906, Valid Loss: 2384.0286
Epoch [601/30000], Step [1/1], Training Loss: 96710.4766, Valid Loss: 78.6762
Epoch [701/30000], Step [1/1], Training Loss: 93235.9375, Valid Loss: 70.6762
Epoch [801/30000], Step [1/1], Training Loss: 89914.0078, Valid Loss: 112.3810
Epoch [901/30000], Step [1/1], Training Loss: 86731.7734, Valid Loss: 138.0286
Epoch [1001/30000], Step [1/1], Training Loss: 83682.7734, Valid Loss: 153.6381
Epoch [1101/30000], Step [1/1], Training Loss: 80747.0547, Valid Loss: 153.8857
Epoch [1201/30000], Step [1/1], Training Loss: 77945.4141, Valid Loss: 145.6667
Epoch [1301/30000], Step [1/1], Training Loss: 75264.5938, Valid Loss: 133.1238
Epoch [1401/30000], Step [1/1], Training Loss: 72695.0938, Valid Loss: 127.9619
Epoch [1501/30000], Step [1/1], Training Loss: 70238.2109, Valid Loss: 132.7143
Epoch [1601/30000], Step [1/1], Training Loss: 67888.0938, Valid Loss: 161.2667
Epoch [1701/30000], Step [1/1], Training Loss: 65641.4453, Valid Loss: 174.7810
Epoch [1801/30000], Step [1/1], Training Loss: 63498.2695, Valid Loss: 145.8476
Epoch [1901/30000], Step [1/1], Training Loss: 61445.4766, Valid Loss: 98.0095
Epoch [2001/30000], Step [1/1], Training Loss: 59363.5742, Valid Loss: 105.4952
Epoch [2101/30000], Step [1/1], Training Loss: 57469.9219, Valid Loss: 100.0952
Epoch [2201/30000], Step [1/1], Training Loss: 55514.1523, Valid Loss: 91.5810
Epoch [2301/30000], Step [1/1], Training Loss: 53712.0234, Valid Loss: 72.5619
Epoch [2401/30000], Step [1/1], Training Loss: 51910.6211, Valid Loss: 78.8952
Epoch [2501/30000], Step [1/1], Training Loss: 50179.8320, Valid Loss: 79.6762
Epoch [2601/30000], Step [1/1], Training Loss: 48504.7617, Valid Loss: 88.9333
Epoch [2701/30000], Step [1/1], Training Loss: 46934.6992, Valid Loss: 81.3524
Epoch [2801/30000], Step [1/1], Training Loss: 45366.1172, Valid Loss: 85.9810
Epoch [2901/30000], Step [1/1], Training Loss: 43840.3672, Valid Loss: 94.0762
Epoch [3001/30000], Step [1/1], Training Loss: 42414.9492, Valid Loss: 91.7714
Epoch [3101/30000], Step [1/1], Training Loss: 41007.7734, Valid Loss: 89.2571
Epoch [3201/30000], Step [1/1], Training Loss: 39713.2070, Valid Loss: 86.9333
Epoch [3301/30000], Step [1/1], Training Loss: 38338.8828, Valid Loss: 80.2571
Epoch [3401/30000], Step [1/1], Training Loss: 37085.6836, Valid Loss: 83.1619
Epoch [3501/30000], Step [1/1], Training Loss: 35890.1055, Valid Loss: 83.7333
Epoch [3601/30000], Step [1/1], Training Loss: 34891.2070, Valid Loss: 83.0857
Epoch [3701/30000], Step [1/1], Training Loss: 33546.8906, Valid Loss: 78.0857
Epoch [3801/30000], Step [1/1], Training Loss: 32509.5605, Valid Loss: 91.7048
Epoch [3901/30000], Step [1/1], Training Loss: 31361.4316, Valid Loss: 81.6667
Epoch [4001/30000], Step [1/1], Training Loss: 30363.5215, Valid Loss: 86.2952
Epoch [4101/30000], Step [1/1], Training Loss: 29311.8750, Valid Loss: 84.2476
Epoch [4201/30000], Step [1/1], Training Loss: 28350.6250, Valid Loss: 84.1619
Epoch [4301/30000], Step [1/1], Training Loss: 27428.4199, Valid Loss: 86.5524
Epoch [4401/30000], Step [1/1], Training Loss: 26544.6660, Valid Loss: 87.7524
Epoch [4501/30000], Step [1/1], Training Loss: 25700.7363, Valid Loss: 86.3714
Epoch [4601/30000], Step [1/1], Training Loss: 24879.3262, Valid Loss: 95.1905
Epoch [4701/30000], Step [1/1], Training Loss: 24136.0059, Valid Loss: 83.1333
Epoch [4801/30000], Step [1/1], Training Loss: 23217.4258, Valid Loss: 85.1143
Epoch [4901/30000], Step [1/1], Training Loss: 22456.3926, Valid Loss: 96.9429
Epoch [5001/30000], Step [1/1], Training Loss: 21694.5645, Valid Loss: 90.5429
Epoch [5101/30000], Step [1/1], Training Loss: 20984.4023, Valid Loss: 98.0000
Epoch [5201/30000], Step [1/1], Training Loss: 20301.1680, Valid Loss: 99.8095
Epoch [5301/30000], Step [1/1], Training Loss: 19660.8438, Valid Loss: 103.7810
Epoch [5401/30000], Step [1/1], Training Loss: 19050.3125, Valid Loss: 99.9143
Epoch [5501/30000], Step [1/1], Training Loss: 18472.4727, Valid Loss: 98.4286
Epoch [5601/30000], Step [1/1], Training Loss: 17891.9766, Valid Loss: 99.4667
Epoch [5701/30000], Step [1/1], Training Loss: 17364.0352, Valid Loss: 96.3333
Epoch [5801/30000], Step [1/1], Training Loss: 16826.3672, Valid Loss: 97.9524
Epoch [5901/30000], Step [1/1], Training Loss: 16331.0830, Valid Loss: 96.8095
Epoch [6001/30000], Step [1/1], Training Loss: 15848.6025, Valid Loss: 94.7524
Epoch [6101/30000], Step [1/1], Training Loss: 15401.1123, Valid Loss: 104.1810
Epoch [6201/30000], Step [1/1], Training Loss: 14973.8535, Valid Loss: 101.6667
Epoch [6301/30000], Step [1/1], Training Loss: 14567.4219, Valid Loss: 101.4857
Epoch [6401/30000], Step [1/1], Training Loss: 14178.4658, Valid Loss: 101.6286
Epoch [6501/30000], Step [1/1], Training Loss: 14178.6992, Valid Loss: 105.1238
Epoch [6601/30000], Step [1/1], Training Loss: 13469.8613, Valid Loss: 118.8191
Epoch [6701/30000], Step [1/1], Training Loss: 13131.9658, Valid Loss: 116.4286
Epoch [6801/30000], Step [1/1], Training Loss: 12320.5645, Valid Loss: 116.8857
Epoch [6901/30000], Step [1/1], Training Loss: 11796.6064, Valid Loss: 110.9143
Epoch [7001/30000], Step [1/1], Training Loss: 11143.5254, Valid Loss: 112.3429
Epoch [7101/30000], Step [1/1], Training Loss: 11020.8242, Valid Loss: 102.3619
Epoch [7201/30000], Step [1/1], Training Loss: 10277.4277, Valid Loss: 100.2095
Epoch [7301/30000], Step [1/1], Training Loss: 9995.9609, Valid Loss: 105.0476
Epoch [7401/30000], Step [1/1], Training Loss: 9943.2715, Valid Loss: 107.6572
Epoch [7501/30000], Step [1/1], Training Loss: 9122.6133, Valid Loss: 103.7524
Epoch [7601/30000], Step [1/1], Training Loss: 8948.4160, Valid Loss: 107.6952
Epoch [7701/30000], Step [1/1], Training Loss: 8914.3467, Valid Loss: 106.1333
Epoch [7801/30000], Step [1/1], Training Loss: 8171.9365, Valid Loss: 108.1619
Epoch [7901/30000], Step [1/1], Training Loss: 7815.9287, Valid Loss: 112.3714
Epoch [8001/30000], Step [1/1], Training Loss: 7510.5200, Valid Loss: 109.7048
Epoch [8101/30000], Step [1/1], Training Loss: 7223.6299, Valid Loss: 109.7905
Epoch [8201/30000], Step [1/1], Training Loss: 6970.2598, Valid Loss: 110.4857
Epoch [8301/30000], Step [1/1], Training Loss: 6754.2856, Valid Loss: 106.4000
Epoch [8401/30000], Step [1/1], Training Loss: 6485.2744, Valid Loss: 109.0476
Epoch [8501/30000], Step [1/1], Training Loss: 7140.9492, Valid Loss: 119.8191
Epoch [8601/30000], Step [1/1], Training Loss: 6643.1729, Valid Loss: 124.4000
Epoch [8701/30000], Step [1/1], Training Loss: 5957.6650, Valid Loss: 131.2952
Epoch [8801/30000], Step [1/1], Training Loss: 5729.0674, Valid Loss: 126.0857
Epoch [8901/30000], Step [1/1], Training Loss: 5570.1831, Valid Loss: 128.1714
Epoch [9001/30000], Step [1/1], Training Loss: 5360.8833, Valid Loss: 126.4476
Epoch [9101/30000], Step [1/1], Training Loss: 5100.0850, Valid Loss: 125.3429
Epoch [9201/30000], Step [1/1], Training Loss: 5361.3486, Valid Loss: 129.5524
Epoch [9301/30000], Step [1/1], Training Loss: 4816.7344, Valid Loss: 139.5429
Epoch [9401/30000], Step [1/1], Training Loss: 4575.7764, Valid Loss: 160.3143
Epoch [9501/30000], Step [1/1], Training Loss: 4378.8486, Valid Loss: 138.6000
Epoch [9601/30000], Step [1/1], Training Loss: 4172.5151, Valid Loss: 150.5048
Epoch [9701/30000], Step [1/1], Training Loss: 3929.1082, Valid Loss: 156.3143
Epoch [9801/30000], Step [1/1], Training Loss: 3750.2839, Valid Loss: 158.9524
Epoch [9901/30000], Step [1/1], Training Loss: 3614.8086, Valid Loss: 160.3714
Epoch [10001/30000], Step [1/1], Training Loss: 3658.3540, Valid Loss: 167.5524
Epoch [10101/30000], Step [1/1], Training Loss: 3611.4529, Valid Loss: 172.9333
Epoch [10201/30000], Step [1/1], Training Loss: 3539.8787, Valid Loss: 166.9429

[Epoch 15000] Rounded prediction: 
tensor([21., 21., 23., 19., 18., 19., 24., 32., 35., 40., 40., 44., 44., 44.,
        43., 38., 33., 20.,  7.,  2.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  7.,  0.,  4.,
         6.,  0.,  0.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  3.,  0.,  2.,  0.,  0.,
         7.,  5.,  3.,  7., 16., 11.,  0., 11.,  0.,  0.,  2.,  0., 12., 17.,
         3.,  4., 15., 20., 27., 19.,  0., 30., 25., 17., 19., 18., 22., 34.,
        37., 32., 13., 22., 29., 17.,  0.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([21., 26., 29., 25., 26., 31., 30., 40., 41., 50., 48., 62., 61., 60.,
        64., 54., 58., 36., 16.,  8.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,  0.,  6.,
        10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         2.,  0.,  2.,  7., 19., 15.,  4., 10.,  0.,  0.,  8.,  0., 13., 33.,
         5.,  1., 17., 31., 43., 31.,  0., 47., 32., 28., 42., 38., 37., 54.,
        56., 34., 11., 29., 33., 12.,  0.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [10301/30000], Step [1/1], Training Loss: 3106.4287, Valid Loss: 172.7048
Epoch [10401/30000], Step [1/1], Training Loss: 2940.5752, Valid Loss: 176.5619
Epoch [10501/30000], Step [1/1], Training Loss: 2824.9517, Valid Loss: 186.9429
Epoch [10601/30000], Step [1/1], Training Loss: 2714.9111, Valid Loss: 187.3429
Epoch [10701/30000], Step [1/1], Training Loss: 2590.2695, Valid Loss: 185.4857
Epoch [10801/30000], Step [1/1], Training Loss: 2482.1287, Valid Loss: 180.8857
Epoch [10901/30000], Step [1/1], Training Loss: 2380.8389, Valid Loss: 185.4857
Epoch [11001/30000], Step [1/1], Training Loss: 2284.3479, Valid Loss: 189.2952
Epoch [11101/30000], Step [1/1], Training Loss: 2199.8450, Valid Loss: 192.6381
Epoch [11201/30000], Step [1/1], Training Loss: 2100.0952, Valid Loss: 190.5429
Epoch [11301/30000], Step [1/1], Training Loss: 2014.4423, Valid Loss: 192.7524
Epoch [11401/30000], Step [1/1], Training Loss: 1933.5381, Valid Loss: 194.4095
Epoch [11501/30000], Step [1/1], Training Loss: 1873.9487, Valid Loss: 204.5048
Epoch [11601/30000], Step [1/1], Training Loss: 1793.0066, Valid Loss: 197.6286
Epoch [11701/30000], Step [1/1], Training Loss: 1724.3948, Valid Loss: 197.5810
Epoch [11801/30000], Step [1/1], Training Loss: 1655.8453, Valid Loss: 196.7905
Epoch [11901/30000], Step [1/1], Training Loss: 1597.9778, Valid Loss: 195.9048
Epoch [12001/30000], Step [1/1], Training Loss: 1546.5857, Valid Loss: 199.1714
Epoch [12101/30000], Step [1/1], Training Loss: 1493.6388, Valid Loss: 197.2476
Epoch [12201/30000], Step [1/1], Training Loss: 1434.3834, Valid Loss: 199.3524
Epoch [12301/30000], Step [1/1], Training Loss: 1388.4136, Valid Loss: 195.9905
Epoch [12401/30000], Step [1/1], Training Loss: 1342.4359, Valid Loss: 199.6190
Epoch [12501/30000], Step [1/1], Training Loss: 1300.6082, Valid Loss: 200.9714
Epoch [12601/30000], Step [1/1], Training Loss: 1253.1769, Valid Loss: 202.4952
Epoch [12701/30000], Step [1/1], Training Loss: 1214.5316, Valid Loss: 202.3810
Epoch [12801/30000], Step [1/1], Training Loss: 1171.7583, Valid Loss: 198.6857
Epoch [12901/30000], Step [1/1], Training Loss: 1133.8937, Valid Loss: 200.4762
Epoch [13001/30000], Step [1/1], Training Loss: 1098.4034, Valid Loss: 203.1810
Epoch [13101/30000], Step [1/1], Training Loss: 1060.3922, Valid Loss: 207.1619
Epoch [13201/30000], Step [1/1], Training Loss: 1023.4869, Valid Loss: 210.4286
Epoch [13301/30000], Step [1/1], Training Loss: 988.9149, Valid Loss: 209.5714
Epoch [13401/30000], Step [1/1], Training Loss: 955.9486, Valid Loss: 208.6000
Epoch [13501/30000], Step [1/1], Training Loss: 923.7390, Valid Loss: 213.0952
Epoch [13601/30000], Step [1/1], Training Loss: 892.4537, Valid Loss: 212.4762
Epoch [13701/30000], Step [1/1], Training Loss: 859.4730, Valid Loss: 218.7905
Epoch [13801/30000], Step [1/1], Training Loss: 830.9698, Valid Loss: 214.9333
Epoch [13901/30000], Step [1/1], Training Loss: 801.0106, Valid Loss: 214.4762
Epoch [14001/30000], Step [1/1], Training Loss: 781.4224, Valid Loss: 211.5333
Epoch [14101/30000], Step [1/1], Training Loss: 749.2174, Valid Loss: 217.0286
Epoch [14201/30000], Step [1/1], Training Loss: 724.8238, Valid Loss: 214.3143
Epoch [14301/30000], Step [1/1], Training Loss: 700.1888, Valid Loss: 215.2476
Epoch [14401/30000], Step [1/1], Training Loss: 677.2587, Valid Loss: 219.9238
Epoch [14501/30000], Step [1/1], Training Loss: 1249.9928, Valid Loss: 232.2476
Epoch [14601/30000], Step [1/1], Training Loss: 1333.6721, Valid Loss: 227.9333
Epoch [14701/30000], Step [1/1], Training Loss: 864.0311, Valid Loss: 228.5333
Epoch [14801/30000], Step [1/1], Training Loss: 699.9534, Valid Loss: 224.9524
Epoch [14901/30000], Step [1/1], Training Loss: 636.3474, Valid Loss: 224.8381
Epoch [15001/30000], Step [1/1], Training Loss: 601.3498, Valid Loss: 226.5429
Epoch [15101/30000], Step [1/1], Training Loss: 572.2628, Valid Loss: 238.1619
Epoch [15201/30000], Step [1/1], Training Loss: 551.0153, Valid Loss: 233.6286
Epoch [15301/30000], Step [1/1], Training Loss: 535.4431, Valid Loss: 249.9048
Epoch [15401/30000], Step [1/1], Training Loss: 517.3321, Valid Loss: 247.4381
Epoch [15501/30000], Step [1/1], Training Loss: 496.6601, Valid Loss: 251.7810
Epoch [15601/30000], Step [1/1], Training Loss: 480.8830, Valid Loss: 255.1238
Epoch [15701/30000], Step [1/1], Training Loss: 460.6937, Valid Loss: 254.8667
Epoch [15801/30000], Step [1/1], Training Loss: 447.1984, Valid Loss: 254.8476
Epoch [15901/30000], Step [1/1], Training Loss: 431.5527, Valid Loss: 258.6190
Epoch [16001/30000], Step [1/1], Training Loss: 421.5167, Valid Loss: 253.2952
Epoch [16101/30000], Step [1/1], Training Loss: 405.5533, Valid Loss: 257.1048
Epoch [16201/30000], Step [1/1], Training Loss: 388.7076, Valid Loss: 256.7714
Epoch [16301/30000], Step [1/1], Training Loss: 373.8023, Valid Loss: 259.0572
Epoch [16401/30000], Step [1/1], Training Loss: 360.1665, Valid Loss: 257.4476
Epoch [16501/30000], Step [1/1], Training Loss: 344.4268, Valid Loss: 265.1048
Epoch [16601/30000], Step [1/1], Training Loss: 332.5045, Valid Loss: 253.9143
Epoch [16701/30000], Step [1/1], Training Loss: 319.7176, Valid Loss: 261.5524
Epoch [16801/30000], Step [1/1], Training Loss: 305.7044, Valid Loss: 258.6762
Epoch [16901/30000], Step [1/1], Training Loss: 291.1248, Valid Loss: 266.2095
Epoch [17001/30000], Step [1/1], Training Loss: 277.8146, Valid Loss: 264.0952
Epoch [17101/30000], Step [1/1], Training Loss: 264.9981, Valid Loss: 260.2476
Epoch [17201/30000], Step [1/1], Training Loss: 250.8163, Valid Loss: 266.5334
Epoch [17301/30000], Step [1/1], Training Loss: 239.0944, Valid Loss: 260.9429
Epoch [17401/30000], Step [1/1], Training Loss: 227.0343, Valid Loss: 271.3524
Epoch [17501/30000], Step [1/1], Training Loss: 215.6996, Valid Loss: 259.3238
Epoch [17601/30000], Step [1/1], Training Loss: 203.3934, Valid Loss: 271.4857
Epoch [17701/30000], Step [1/1], Training Loss: 193.4418, Valid Loss: 273.6095
Epoch [17801/30000], Step [1/1], Training Loss: 180.9818, Valid Loss: 269.9714
Epoch [17901/30000], Step [1/1], Training Loss: 171.8438, Valid Loss: 273.1143
Epoch [18001/30000], Step [1/1], Training Loss: 157.6090, Valid Loss: 271.5810
Epoch [18101/30000], Step [1/1], Training Loss: 148.3624, Valid Loss: 273.0667
Epoch [18201/30000], Step [1/1], Training Loss: 138.5524, Valid Loss: 276.0000
Epoch [18301/30000], Step [1/1], Training Loss: 203.6019, Valid Loss: 264.1048
Epoch [18401/30000], Step [1/1], Training Loss: 466.2494, Valid Loss: 350.5143
Epoch [18501/30000], Step [1/1], Training Loss: 148.1098, Valid Loss: 344.2286
Epoch [18601/30000], Step [1/1], Training Loss: 138.9038, Valid Loss: 369.2286
Epoch [18701/30000], Step [1/1], Training Loss: 123.8970, Valid Loss: 354.6381
Epoch [18801/30000], Step [1/1], Training Loss: 112.4317, Valid Loss: 358.5810
Epoch [18901/30000], Step [1/1], Training Loss: 107.8322, Valid Loss: 389.1048
Epoch [19001/30000], Step [1/1], Training Loss: 101.3206, Valid Loss: 366.8667
Epoch [19101/30000], Step [1/1], Training Loss: 98.5628, Valid Loss: 369.5810
Epoch [19201/30000], Step [1/1], Training Loss: 90.9321, Valid Loss: 371.7810
Epoch [19301/30000], Step [1/1], Training Loss: 85.8514, Valid Loss: 381.5619
Epoch [19401/30000], Step [1/1], Training Loss: 81.6462, Valid Loss: 376.6286
Epoch [19501/30000], Step [1/1], Training Loss: 75.1003, Valid Loss: 383.1619
Epoch [19601/30000], Step [1/1], Training Loss: 72.5664, Valid Loss: 388.1048
Epoch [19701/30000], Step [1/1], Training Loss: 66.8208, Valid Loss: 385.4762
Epoch [19801/30000], Step [1/1], Training Loss: 65.3778, Valid Loss: 397.1429
Epoch [19901/30000], Step [1/1], Training Loss: 57.4265, Valid Loss: 381.5905
Epoch [20001/30000], Step [1/1], Training Loss: 54.0298, Valid Loss: 396.7715
Epoch [20101/30000], Step [1/1], Training Loss: 50.3416, Valid Loss: 392.8095
Epoch [20201/30000], Step [1/1], Training Loss: 46.6979, Valid Loss: 396.7810
Epoch [20301/30000], Step [1/1], Training Loss: 42.8624, Valid Loss: 396.9714
Epoch [20401/30000], Step [1/1], Training Loss: 38.8636, Valid Loss: 406.7619
Epoch [20501/30000], Step [1/1], Training Loss: 36.6633, Valid Loss: 398.2095

[Epoch 25000] Rounded prediction: 
tensor([21., 28., 30., 24., 28., 32., 31., 40., 42., 49., 49., 63., 64., 63.,
        67., 51., 62., 35., 22.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,  0.,  7.,
         7.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         1.,  0.,  0.,  5., 23.,  6.,  0.,  9.,  0.,  0.,  2.,  0.,  9., 23.,
         0.,  0., 10., 33., 43., 27.,  0., 44., 33., 30., 35., 24., 25., 54.,
        57., 27.,  4., 33., 27.,  7.,  0.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [20601/30000], Step [1/1], Training Loss: 32.8722, Valid Loss: 405.0952
Epoch [20701/30000], Step [1/1], Training Loss: 31.6613, Valid Loss: 409.3905
Epoch [20801/30000], Step [1/1], Training Loss: 27.1686, Valid Loss: 411.4476
Epoch [20901/30000], Step [1/1], Training Loss: 25.6331, Valid Loss: 423.9238
Epoch [21001/30000], Step [1/1], Training Loss: 22.1515, Valid Loss: 409.5714
Epoch [21101/30000], Step [1/1], Training Loss: 20.2020, Valid Loss: 418.3333
Epoch [21201/30000], Step [1/1], Training Loss: 17.9881, Valid Loss: 422.6095
Epoch [21301/30000], Step [1/1], Training Loss: 16.2250, Valid Loss: 404.7333
Epoch [21401/30000], Step [1/1], Training Loss: 14.2431, Valid Loss: 417.8953
Epoch [21501/30000], Step [1/1], Training Loss: 13.1182, Valid Loss: 395.8095
Epoch [21601/30000], Step [1/1], Training Loss: 11.2677, Valid Loss: 408.6095
Epoch [21701/30000], Step [1/1], Training Loss: 9.8375, Valid Loss: 408.6000
Epoch [21801/30000], Step [1/1], Training Loss: 9.0412, Valid Loss: 405.0381
Epoch [21901/30000], Step [1/1], Training Loss: 7.6793, Valid Loss: 405.5619
Epoch [22001/30000], Step [1/1], Training Loss: 6.7698, Valid Loss: 431.7048
Epoch [22101/30000], Step [1/1], Training Loss: 5.7326, Valid Loss: 417.1524
Epoch [22201/30000], Step [1/1], Training Loss: 5.3276, Valid Loss: 405.6095
Epoch [22301/30000], Step [1/1], Training Loss: 4.4152, Valid Loss: 407.8953
Epoch [22401/30000], Step [1/1], Training Loss: 4.2101, Valid Loss: 403.8191
Epoch [22501/30000], Step [1/1], Training Loss: 3.2539, Valid Loss: 414.9238
Epoch [22601/30000], Step [1/1], Training Loss: 3.2701, Valid Loss: 413.4000
Epoch [22701/30000], Step [1/1], Training Loss: 2.8790, Valid Loss: 418.5334
Epoch [22801/30000], Step [1/1], Training Loss: 2.1848, Valid Loss: 417.8191
Epoch [22901/30000], Step [1/1], Training Loss: 2.0134, Valid Loss: 433.4572
Epoch [23001/30000], Step [1/1], Training Loss: 1.6492, Valid Loss: 430.0572
Epoch [23101/30000], Step [1/1], Training Loss: 1.9528, Valid Loss: 424.4191
Epoch [23201/30000], Step [1/1], Training Loss: 1.9875, Valid Loss: 437.8000
Epoch [23301/30000], Step [1/1], Training Loss: 1.2985, Valid Loss: 420.4476
Epoch [23401/30000], Step [1/1], Training Loss: 1.1797, Valid Loss: 417.6953
Epoch [23501/30000], Step [1/1], Training Loss: 1.3857, Valid Loss: 435.6953
Epoch [23601/30000], Step [1/1], Training Loss: 1.1278, Valid Loss: 423.0096
Epoch [23701/30000], Step [1/1], Training Loss: 0.8949, Valid Loss: 437.5524
Epoch [23801/30000], Step [1/1], Training Loss: 2.0308, Valid Loss: 410.6095
Epoch [23901/30000], Step [1/1], Training Loss: 0.9840, Valid Loss: 433.9619
Epoch [24001/30000], Step [1/1], Training Loss: 0.9595, Valid Loss: 436.0096
Epoch [24101/30000], Step [1/1], Training Loss: 0.9921, Valid Loss: 415.2286
Epoch [24201/30000], Step [1/1], Training Loss: 0.7284, Valid Loss: 419.6000
Epoch [24301/30000], Step [1/1], Training Loss: 0.8652, Valid Loss: 410.1143
Epoch [24401/30000], Step [1/1], Training Loss: 0.5117, Valid Loss: 420.9619
Epoch [24501/30000], Step [1/1], Training Loss: 0.6128, Valid Loss: 418.1619
Epoch [24601/30000], Step [1/1], Training Loss: 0.9314, Valid Loss: 416.9238
Epoch [24701/30000], Step [1/1], Training Loss: 0.9503, Valid Loss: 409.6667
Epoch [24801/30000], Step [1/1], Training Loss: 0.8504, Valid Loss: 420.1429
Epoch [24901/30000], Step [1/1], Training Loss: 1.0898, Valid Loss: 430.5334
Epoch [25001/30000], Step [1/1], Training Loss: 0.5005, Valid Loss: 418.4476
Epoch [25101/30000], Step [1/1], Training Loss: 0.4517, Valid Loss: 419.4762
Epoch [25201/30000], Step [1/1], Training Loss: 0.6710, Valid Loss: 419.6953
Epoch [25301/30000], Step [1/1], Training Loss: 1.0420, Valid Loss: 427.9524
Epoch [25401/30000], Step [1/1], Training Loss: 0.5100, Valid Loss: 408.9524
Epoch [25501/30000], Step [1/1], Training Loss: 0.4545, Valid Loss: 410.9143
Epoch [25601/30000], Step [1/1], Training Loss: 0.5002, Valid Loss: 433.3333
Epoch [25701/30000], Step [1/1], Training Loss: 0.4160, Valid Loss: 430.6190
Epoch [25801/30000], Step [1/1], Training Loss: 0.4876, Valid Loss: 426.5334
Epoch [25901/30000], Step [1/1], Training Loss: 0.4877, Valid Loss: 418.9619
Epoch [26001/30000], Step [1/1], Training Loss: 363.4627, Valid Loss: 323.9619
Epoch [26101/30000], Step [1/1], Training Loss: 37.9409, Valid Loss: 373.4191
Epoch [26201/30000], Step [1/1], Training Loss: 18.8642, Valid Loss: 357.6857
Epoch [26301/30000], Step [1/1], Training Loss: 16.1028, Valid Loss: 358.4857
Epoch [26401/30000], Step [1/1], Training Loss: 11.3809, Valid Loss: 363.7810
Epoch [26501/30000], Step [1/1], Training Loss: 8.3100, Valid Loss: 359.1048
Epoch [26601/30000], Step [1/1], Training Loss: 7.9042, Valid Loss: 352.6381
Epoch [26701/30000], Step [1/1], Training Loss: 6.3424, Valid Loss: 356.4286
Epoch [26801/30000], Step [1/1], Training Loss: 6.6456, Valid Loss: 357.4000
Epoch [26901/30000], Step [1/1], Training Loss: 5.4327, Valid Loss: 365.7429
Epoch [27001/30000], Step [1/1], Training Loss: 5.8417, Valid Loss: 367.0000
Epoch [27101/30000], Step [1/1], Training Loss: 4.4947, Valid Loss: 365.9714
Epoch [27201/30000], Step [1/1], Training Loss: 5.9943, Valid Loss: 366.5714
Epoch [27301/30000], Step [1/1], Training Loss: 3.5230, Valid Loss: 368.9429
Epoch [27401/30000], Step [1/1], Training Loss: 4.5794, Valid Loss: 361.0381
Epoch [27501/30000], Step [1/1], Training Loss: 2.3236, Valid Loss: 364.8571
Epoch [27601/30000], Step [1/1], Training Loss: 2.8785, Valid Loss: 383.3619
Epoch [27701/30000], Step [1/1], Training Loss: 2.2570, Valid Loss: 373.7715
Epoch [27801/30000], Step [1/1], Training Loss: 2.2643, Valid Loss: 383.0096
Epoch [27901/30000], Step [1/1], Training Loss: 2.4701, Valid Loss: 382.5714
Epoch [28001/30000], Step [1/1], Training Loss: 1.8732, Valid Loss: 382.1524
Epoch [28101/30000], Step [1/1], Training Loss: 2.3677, Valid Loss: 378.8762
Epoch [28201/30000], Step [1/1], Training Loss: 2.2842, Valid Loss: 378.4381
Epoch [28301/30000], Step [1/1], Training Loss: 2.4765, Valid Loss: 381.6762
Epoch [28401/30000], Step [1/1], Training Loss: 1.4234, Valid Loss: 394.3143
Epoch [28501/30000], Step [1/1], Training Loss: 2.3091, Valid Loss: 378.4000
Epoch [28601/30000], Step [1/1], Training Loss: 2.2713, Valid Loss: 382.7143
Epoch [28701/30000], Step [1/1], Training Loss: 2.0564, Valid Loss: 393.1143
Epoch [28801/30000], Step [1/1], Training Loss: 2.1372, Valid Loss: 387.2953
Epoch [28901/30000], Step [1/1], Training Loss: 1.3058, Valid Loss: 383.5524
Epoch [29001/30000], Step [1/1], Training Loss: 1.0103, Valid Loss: 390.8191
Epoch [29101/30000], Step [1/1], Training Loss: 1.5211, Valid Loss: 382.1238
Epoch [29201/30000], Step [1/1], Training Loss: 1.4084, Valid Loss: 384.6953
Epoch [29301/30000], Step [1/1], Training Loss: 1.3699, Valid Loss: 387.2286
Epoch [29401/30000], Step [1/1], Training Loss: 0.8932, Valid Loss: 384.4000
Epoch [29501/30000], Step [1/1], Training Loss: 2.1290, Valid Loss: 388.4476
Epoch [29601/30000], Step [1/1], Training Loss: 1.3627, Valid Loss: 387.9905
Epoch [29701/30000], Step [1/1], Training Loss: 1.2866, Valid Loss: 390.6286
Epoch [29801/30000], Step [1/1], Training Loss: 0.7850, Valid Loss: 394.6857
Epoch [29901/30000], Step [1/1], Training Loss: 1.5390, Valid Loss: 381.8667

 End Time: 2021/04/19, 17:35:58




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=1048 	layers=2

Start Time = 2021/04/19, 17:35:58
##########################################################


[Epoch 0] Rounded prediction: 
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([17., 13., 17., 16., 16., 20., 24., 23., 24., 22., 19., 17., 21., 14.,
        18., 14.,  7., 11.,  4.,  9., 11., 11., 15., 21., 12.,  7.,  8.,  5.,
         6.,  8., 15.,  8.,  5., 10.,  4.,  9.,  3.,  8.,  0., 12.,  4., 22.,
        27., 26.,  8.,  6.,  3.,  6.,  4.,  4.,  4.,  7., 12.,  5., 26., 18.,
        14.,  5.,  5.,  6.,  4., 11.,  1., 12.,  0., 17.,  4., 14., 19., 13.,
         6.,  7.,  7.,  9.,  9., 14., 18., 37., 29., 42., 36., 27., 50., 41.,
        29., 22., 17.,  5.,  7., 12., 24., 38., 60., 65., 51., 22., 24., 46.,
        53., 48., 33., 32., 34., 18.,  9.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([16., 14., 16., 15., 18., 20., 25., 31., 29., 30., 26., 24., 25., 25.,
        26., 17.,  6.,  3.,  0.,  0.,  0.,  0.,  0.,  6.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 11.,
        24., 12.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 15.,  6.,
         1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0., 31.,  3., 30., 26.,  6., 31., 17.,
         2.,  0.,  0.,  0.,  0.,  7.,  1., 31., 37., 42., 13.,  1., 17., 28.,
        38., 30., 13.,  0., 10.,  0.,  0.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128647.2578, Valid Loss: 208.8952
Epoch [101/30000], Step [1/1], Training Loss: 116565.9219, Valid Loss: 320.0191
Epoch [201/30000], Step [1/1], Training Loss: 112081.2188, Valid Loss: 774.1619
Epoch [301/30000], Step [1/1], Training Loss: 107946.3359, Valid Loss: 1397.0190
Epoch [401/30000], Step [1/1], Training Loss: 104085.4062, Valid Loss: 2214.2573
Epoch [501/30000], Step [1/1], Training Loss: 100459.0703, Valid Loss: 2092.1619
Epoch [601/30000], Step [1/1], Training Loss: 96702.0234, Valid Loss: 73.2381
Epoch [701/30000], Step [1/1], Training Loss: 93229.5391, Valid Loss: 70.7333
Epoch [801/30000], Step [1/1], Training Loss: 89907.4219, Valid Loss: 89.2476
Epoch [901/30000], Step [1/1], Training Loss: 86712.2656, Valid Loss: 138.0667
Epoch [1001/30000], Step [1/1], Training Loss: 83660.9297, Valid Loss: 100.7143
Epoch [1101/30000], Step [1/1], Training Loss: 80735.2344, Valid Loss: 136.5905
Epoch [1201/30000], Step [1/1], Training Loss: 77933.2812, Valid Loss: 132.4952
Epoch [1301/30000], Step [1/1], Training Loss: 75250.5625, Valid Loss: 179.6286
Epoch [1401/30000], Step [1/1], Training Loss: 72682.6797, Valid Loss: 171.5905
Epoch [1501/30000], Step [1/1], Training Loss: 70227.3203, Valid Loss: 190.6000
Epoch [1601/30000], Step [1/1], Training Loss: 67877.1406, Valid Loss: 153.1905
Epoch [1701/30000], Step [1/1], Training Loss: 65633.0469, Valid Loss: 148.0667
Epoch [1801/30000], Step [1/1], Training Loss: 63490.9922, Valid Loss: 146.9619
Epoch [1901/30000], Step [1/1], Training Loss: 61388.7812, Valid Loss: 141.4286
Epoch [2001/30000], Step [1/1], Training Loss: 59395.3164, Valid Loss: 136.7143
Epoch [2101/30000], Step [1/1], Training Loss: 57426.9766, Valid Loss: 113.1810
Epoch [2201/30000], Step [1/1], Training Loss: 55564.8516, Valid Loss: 112.0286
Epoch [2301/30000], Step [1/1], Training Loss: 53761.3555, Valid Loss: 89.3429
Epoch [2401/30000], Step [1/1], Training Loss: 51978.8789, Valid Loss: 114.4000
Epoch [2501/30000], Step [1/1], Training Loss: 50295.6914, Valid Loss: 125.5333
Epoch [2601/30000], Step [1/1], Training Loss: 48602.9531, Valid Loss: 121.9048
Epoch [2701/30000], Step [1/1], Training Loss: 47022.1406, Valid Loss: 120.7810
Epoch [2801/30000], Step [1/1], Training Loss: 45495.3008, Valid Loss: 133.1333
Epoch [2901/30000], Step [1/1], Training Loss: 44026.8984, Valid Loss: 130.9048
Epoch [3001/30000], Step [1/1], Training Loss: 42654.6289, Valid Loss: 117.8286
Epoch [3101/30000], Step [1/1], Training Loss: 41295.6719, Valid Loss: 124.0571
Epoch [3201/30000], Step [1/1], Training Loss: 39961.1523, Valid Loss: 119.3238
Epoch [3301/30000], Step [1/1], Training Loss: 38707.4023, Valid Loss: 138.9048
Epoch [3401/30000], Step [1/1], Training Loss: 37517.5586, Valid Loss: 142.2476
Epoch [3501/30000], Step [1/1], Training Loss: 36251.3906, Valid Loss: 149.4857
Epoch [3601/30000], Step [1/1], Training Loss: 35024.8828, Valid Loss: 129.8667
Epoch [3701/30000], Step [1/1], Training Loss: 33905.7031, Valid Loss: 146.4857
Epoch [3801/30000], Step [1/1], Training Loss: 32767.0898, Valid Loss: 142.7810
Epoch [3901/30000], Step [1/1], Training Loss: 31623.3438, Valid Loss: 151.0857
Epoch [4001/30000], Step [1/1], Training Loss: 30510.2969, Valid Loss: 146.4095
Epoch [4101/30000], Step [1/1], Training Loss: 29711.2344, Valid Loss: 133.6857
Epoch [4201/30000], Step [1/1], Training Loss: 28696.9336, Valid Loss: 129.5429
Epoch [4301/30000], Step [1/1], Training Loss: 27938.1562, Valid Loss: 115.4857
Epoch [4401/30000], Step [1/1], Training Loss: 26861.8105, Valid Loss: 124.9429
Epoch [4501/30000], Step [1/1], Training Loss: 25903.2988, Valid Loss: 128.6572
Epoch [4601/30000], Step [1/1], Training Loss: 24946.9688, Valid Loss: 123.7714
Epoch [4701/30000], Step [1/1], Training Loss: 24338.5879, Valid Loss: 144.4952
Epoch [4801/30000], Step [1/1], Training Loss: 23768.2656, Valid Loss: 127.1048
Epoch [4901/30000], Step [1/1], Training Loss: 22583.5684, Valid Loss: 158.2000
Epoch [5001/30000], Step [1/1], Training Loss: 21777.6895, Valid Loss: 158.3333
Epoch [5101/30000], Step [1/1], Training Loss: 21104.5469, Valid Loss: 151.2667
Epoch [5201/30000], Step [1/1], Training Loss: 20401.6152, Valid Loss: 155.2857
Epoch [5301/30000], Step [1/1], Training Loss: 19756.1445, Valid Loss: 153.5810
Epoch [5401/30000], Step [1/1], Training Loss: 19137.2988, Valid Loss: 137.2095
Epoch [5501/30000], Step [1/1], Training Loss: 18504.9688, Valid Loss: 150.8762
Epoch [5601/30000], Step [1/1], Training Loss: 17950.3223, Valid Loss: 144.4476
Epoch [5701/30000], Step [1/1], Training Loss: 17315.5234, Valid Loss: 144.7048
Epoch [5801/30000], Step [1/1], Training Loss: 16752.9238, Valid Loss: 150.6286
Epoch [5901/30000], Step [1/1], Training Loss: 16623.8203, Valid Loss: 149.5619
Epoch [6001/30000], Step [1/1], Training Loss: 15795.8701, Valid Loss: 169.6286
Epoch [6101/30000], Step [1/1], Training Loss: 15095.1201, Valid Loss: 142.1619
Epoch [6201/30000], Step [1/1], Training Loss: 14429.7803, Valid Loss: 162.2857
Epoch [6301/30000], Step [1/1], Training Loss: 13943.0791, Valid Loss: 160.8095
Epoch [6401/30000], Step [1/1], Training Loss: 13423.4600, Valid Loss: 158.1333
Epoch [6501/30000], Step [1/1], Training Loss: 13022.2939, Valid Loss: 166.7333
Epoch [6601/30000], Step [1/1], Training Loss: 12709.5293, Valid Loss: 157.8000
Epoch [6701/30000], Step [1/1], Training Loss: 12140.9961, Valid Loss: 158.1524
Epoch [6801/30000], Step [1/1], Training Loss: 12239.3330, Valid Loss: 154.1238
Epoch [6901/30000], Step [1/1], Training Loss: 11542.7656, Valid Loss: 137.4095
Epoch [7001/30000], Step [1/1], Training Loss: 11187.3320, Valid Loss: 136.1143
Epoch [7101/30000], Step [1/1], Training Loss: 10709.5791, Valid Loss: 143.2000
Epoch [7201/30000], Step [1/1], Training Loss: 10369.3955, Valid Loss: 148.9524
Epoch [7301/30000], Step [1/1], Training Loss: 10130.6182, Valid Loss: 142.1714
Epoch [7401/30000], Step [1/1], Training Loss: 9747.6143, Valid Loss: 163.3619
Epoch [7501/30000], Step [1/1], Training Loss: 9766.4912, Valid Loss: 133.7524
Epoch [7601/30000], Step [1/1], Training Loss: 9333.0586, Valid Loss: 145.4952
Epoch [7701/30000], Step [1/1], Training Loss: 8943.8760, Valid Loss: 149.4476
Epoch [7801/30000], Step [1/1], Training Loss: 8556.9521, Valid Loss: 149.2857
Epoch [7901/30000], Step [1/1], Training Loss: 7821.1841, Valid Loss: 143.9333
Epoch [8001/30000], Step [1/1], Training Loss: 7509.7837, Valid Loss: 154.8667
Epoch [8101/30000], Step [1/1], Training Loss: 7221.6338, Valid Loss: 146.6667
Epoch [8201/30000], Step [1/1], Training Loss: 7134.1909, Valid Loss: 145.1524
Epoch [8301/30000], Step [1/1], Training Loss: 6730.5220, Valid Loss: 146.6190
Epoch [8401/30000], Step [1/1], Training Loss: 6488.4180, Valid Loss: 147.2857
Epoch [8501/30000], Step [1/1], Training Loss: 6254.7236, Valid Loss: 145.5238
Epoch [8601/30000], Step [1/1], Training Loss: 6035.7998, Valid Loss: 150.9905
Epoch [8701/30000], Step [1/1], Training Loss: 5834.6372, Valid Loss: 147.8667
Epoch [8801/30000], Step [1/1], Training Loss: 5628.0308, Valid Loss: 158.2857
Epoch [8901/30000], Step [1/1], Training Loss: 5443.4707, Valid Loss: 158.2476
Epoch [9001/30000], Step [1/1], Training Loss: 5275.4897, Valid Loss: 159.7810
Epoch [9101/30000], Step [1/1], Training Loss: 5092.4175, Valid Loss: 159.7048
Epoch [9201/30000], Step [1/1], Training Loss: 4928.3965, Valid Loss: 161.1619
Epoch [9301/30000], Step [1/1], Training Loss: 4777.2188, Valid Loss: 168.2286
Epoch [9401/30000], Step [1/1], Training Loss: 4627.2817, Valid Loss: 166.2381
Epoch [9501/30000], Step [1/1], Training Loss: 4640.3501, Valid Loss: 168.1524
Epoch [9601/30000], Step [1/1], Training Loss: 4420.4199, Valid Loss: 179.1238
Epoch [9701/30000], Step [1/1], Training Loss: 4804.1455, Valid Loss: 153.2476
Epoch [9801/30000], Step [1/1], Training Loss: 4739.8345, Valid Loss: 173.6476
Epoch [9901/30000], Step [1/1], Training Loss: 4121.8633, Valid Loss: 174.2762
Epoch [10001/30000], Step [1/1], Training Loss: 6685.5610, Valid Loss: 175.9238
Epoch [10101/30000], Step [1/1], Training Loss: 3978.9155, Valid Loss: 177.7810

[Epoch 15000] Rounded prediction: 
tensor([15., 13., 19., 18., 21., 20., 24., 25., 22., 26., 20., 21., 19., 17.,
        21.,  8., 16.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 10.,
        19.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 12.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0., 38.,  0., 20., 15.,  0., 29.,  8.,
         0.,  0.,  0.,  0.,  1.,  0.,  0., 23., 32., 54., 28.,  7., 23., 29.,
        15., 14.,  0.,  0.,  1.,  0.,  0.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([21., 15., 14., 18., 20., 20., 26., 23., 23., 23., 14., 22., 21., 23.,
        28., 18., 20.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
        13.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  1.,  8., 34., 10.,  0.,  4.,  0.,  8., 14.,
         0.,  0.,  0.,  0.,  0.,  0.,  7., 59., 44., 58., 44., 35., 32., 26.,
        42., 38., 33., 32., 33.,  0.,  0.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [10201/30000], Step [1/1], Training Loss: 3695.6941, Valid Loss: 207.4857
Epoch [10301/30000], Step [1/1], Training Loss: 3240.5000, Valid Loss: 217.3619
Epoch [10401/30000], Step [1/1], Training Loss: 3078.3206, Valid Loss: 217.1714
Epoch [10501/30000], Step [1/1], Training Loss: 2957.8340, Valid Loss: 214.2286
Epoch [10601/30000], Step [1/1], Training Loss: 2840.5330, Valid Loss: 216.9810
Epoch [10701/30000], Step [1/1], Training Loss: 2706.8274, Valid Loss: 229.0381
Epoch [10801/30000], Step [1/1], Training Loss: 2589.8796, Valid Loss: 223.8857
Epoch [10901/30000], Step [1/1], Training Loss: 2474.9639, Valid Loss: 232.0857
Epoch [11001/30000], Step [1/1], Training Loss: 2368.1418, Valid Loss: 232.9333
Epoch [11101/30000], Step [1/1], Training Loss: 2264.4895, Valid Loss: 245.3429
Epoch [11201/30000], Step [1/1], Training Loss: 2161.5029, Valid Loss: 238.0095
Epoch [11301/30000], Step [1/1], Training Loss: 2082.3613, Valid Loss: 244.5238
Epoch [11401/30000], Step [1/1], Training Loss: 1991.1475, Valid Loss: 228.3905
Epoch [11501/30000], Step [1/1], Training Loss: 1908.6511, Valid Loss: 237.0191
Epoch [11601/30000], Step [1/1], Training Loss: 1836.0121, Valid Loss: 223.2000
Epoch [11701/30000], Step [1/1], Training Loss: 1757.3300, Valid Loss: 245.8095
Epoch [11801/30000], Step [1/1], Training Loss: 1696.3887, Valid Loss: 249.3714
Epoch [11901/30000], Step [1/1], Training Loss: 1633.6016, Valid Loss: 223.8000
Epoch [12001/30000], Step [1/1], Training Loss: 1566.8130, Valid Loss: 235.1238
Epoch [12101/30000], Step [1/1], Training Loss: 1512.7231, Valid Loss: 235.3714
Epoch [12201/30000], Step [1/1], Training Loss: 1458.2977, Valid Loss: 254.3619
Epoch [12301/30000], Step [1/1], Training Loss: 1409.5347, Valid Loss: 256.8286
Epoch [12401/30000], Step [1/1], Training Loss: 1355.9194, Valid Loss: 234.4953
Epoch [12501/30000], Step [1/1], Training Loss: 1317.0261, Valid Loss: 243.2286
Epoch [12601/30000], Step [1/1], Training Loss: 1265.6813, Valid Loss: 255.5524
Epoch [12701/30000], Step [1/1], Training Loss: 1226.9048, Valid Loss: 242.7619
Epoch [12801/30000], Step [1/1], Training Loss: 3794.2571, Valid Loss: 225.9905
Epoch [12901/30000], Step [1/1], Training Loss: 1516.7126, Valid Loss: 175.7905
Epoch [13001/30000], Step [1/1], Training Loss: 1264.6650, Valid Loss: 167.1429
Epoch [13101/30000], Step [1/1], Training Loss: 1212.8557, Valid Loss: 168.3143
Epoch [13201/30000], Step [1/1], Training Loss: 1073.5239, Valid Loss: 175.8286
Epoch [13301/30000], Step [1/1], Training Loss: 1029.0195, Valid Loss: 168.7810
Epoch [13401/30000], Step [1/1], Training Loss: 990.1902, Valid Loss: 173.5905
Epoch [13501/30000], Step [1/1], Training Loss: 958.2781, Valid Loss: 173.4286
Epoch [13601/30000], Step [1/1], Training Loss: 923.3652, Valid Loss: 168.8381
Epoch [13701/30000], Step [1/1], Training Loss: 894.8384, Valid Loss: 166.6381
Epoch [13801/30000], Step [1/1], Training Loss: 861.0416, Valid Loss: 169.7619
Epoch [13901/30000], Step [1/1], Training Loss: 834.9060, Valid Loss: 166.0571
Epoch [14001/30000], Step [1/1], Training Loss: 809.3616, Valid Loss: 168.1429
Epoch [14101/30000], Step [1/1], Training Loss: 778.9484, Valid Loss: 169.0286
Epoch [14201/30000], Step [1/1], Training Loss: 753.7431, Valid Loss: 180.3143
Epoch [14301/30000], Step [1/1], Training Loss: 730.0577, Valid Loss: 173.7524
Epoch [14401/30000], Step [1/1], Training Loss: 699.0672, Valid Loss: 171.9714
Epoch [14501/30000], Step [1/1], Training Loss: 679.0264, Valid Loss: 175.4857
Epoch [14601/30000], Step [1/1], Training Loss: 658.8802, Valid Loss: 173.7429
Epoch [14701/30000], Step [1/1], Training Loss: 636.7057, Valid Loss: 170.9333
Epoch [14801/30000], Step [1/1], Training Loss: 616.9229, Valid Loss: 177.7048
Epoch [14901/30000], Step [1/1], Training Loss: 596.8696, Valid Loss: 179.2572
Epoch [15001/30000], Step [1/1], Training Loss: 577.6042, Valid Loss: 176.2952
Epoch [15101/30000], Step [1/1], Training Loss: 557.3882, Valid Loss: 173.1429
Epoch [15201/30000], Step [1/1], Training Loss: 538.0947, Valid Loss: 179.3429
Epoch [15301/30000], Step [1/1], Training Loss: 518.4364, Valid Loss: 175.0191
Epoch [15401/30000], Step [1/1], Training Loss: 501.4723, Valid Loss: 177.0571
Epoch [15501/30000], Step [1/1], Training Loss: 484.5467, Valid Loss: 188.2952
Epoch [15601/30000], Step [1/1], Training Loss: 465.5909, Valid Loss: 183.9810
Epoch [15701/30000], Step [1/1], Training Loss: 450.2704, Valid Loss: 180.6190
Epoch [15801/30000], Step [1/1], Training Loss: 434.5155, Valid Loss: 182.5238
Epoch [15901/30000], Step [1/1], Training Loss: 416.6497, Valid Loss: 184.8667
Epoch [16001/30000], Step [1/1], Training Loss: 417.7708, Valid Loss: 184.4857
Epoch [16101/30000], Step [1/1], Training Loss: 387.8128, Valid Loss: 191.0095
Epoch [16201/30000], Step [1/1], Training Loss: 374.7891, Valid Loss: 206.8952
Epoch [16301/30000], Step [1/1], Training Loss: 357.3181, Valid Loss: 206.1810
Epoch [16401/30000], Step [1/1], Training Loss: 340.0131, Valid Loss: 195.2095
Epoch [16501/30000], Step [1/1], Training Loss: 324.5039, Valid Loss: 203.8762
Epoch [16601/30000], Step [1/1], Training Loss: 310.4347, Valid Loss: 207.3714
Epoch [16701/30000], Step [1/1], Training Loss: 296.4283, Valid Loss: 204.8952
Epoch [16801/30000], Step [1/1], Training Loss: 282.5432, Valid Loss: 202.7619
Epoch [16901/30000], Step [1/1], Training Loss: 268.7177, Valid Loss: 206.6190
Epoch [17001/30000], Step [1/1], Training Loss: 255.5773, Valid Loss: 205.2000
Epoch [17101/30000], Step [1/1], Training Loss: 241.9796, Valid Loss: 208.5714
Epoch [17201/30000], Step [1/1], Training Loss: 229.5712, Valid Loss: 213.8762
Epoch [17301/30000], Step [1/1], Training Loss: 217.6489, Valid Loss: 213.8095
Epoch [17401/30000], Step [1/1], Training Loss: 206.8559, Valid Loss: 206.0667
Epoch [17501/30000], Step [1/1], Training Loss: 193.2613, Valid Loss: 198.4572
Epoch [17601/30000], Step [1/1], Training Loss: 182.8180, Valid Loss: 196.9048
Epoch [17701/30000], Step [1/1], Training Loss: 171.3330, Valid Loss: 202.5238
Epoch [17801/30000], Step [1/1], Training Loss: 160.2607, Valid Loss: 214.1810
Epoch [17901/30000], Step [1/1], Training Loss: 149.9298, Valid Loss: 211.8571
Epoch [18001/30000], Step [1/1], Training Loss: 140.7419, Valid Loss: 209.6762
Epoch [18101/30000], Step [1/1], Training Loss: 130.6075, Valid Loss: 211.8667
Epoch [18201/30000], Step [1/1], Training Loss: 122.1965, Valid Loss: 210.6381
Epoch [18301/30000], Step [1/1], Training Loss: 113.0622, Valid Loss: 217.5524
Epoch [18401/30000], Step [1/1], Training Loss: 104.7975, Valid Loss: 210.8762
Epoch [18501/30000], Step [1/1], Training Loss: 96.8343, Valid Loss: 222.1429
Epoch [18601/30000], Step [1/1], Training Loss: 89.2476, Valid Loss: 217.1333
Epoch [18701/30000], Step [1/1], Training Loss: 81.7646, Valid Loss: 216.1810
Epoch [18801/30000], Step [1/1], Training Loss: 75.2192, Valid Loss: 228.3333
Epoch [18901/30000], Step [1/1], Training Loss: 73.0082, Valid Loss: 224.0857
Epoch [19001/30000], Step [1/1], Training Loss: 63.4116, Valid Loss: 223.6286
Epoch [19101/30000], Step [1/1], Training Loss: 57.6926, Valid Loss: 216.0095
Epoch [19201/30000], Step [1/1], Training Loss: 52.2674, Valid Loss: 221.1714
Epoch [19301/30000], Step [1/1], Training Loss: 2639.6570, Valid Loss: 155.5429
Epoch [19401/30000], Step [1/1], Training Loss: 390.3347, Valid Loss: 156.1333
Epoch [19501/30000], Step [1/1], Training Loss: 146.1122, Valid Loss: 151.5524
Epoch [19601/30000], Step [1/1], Training Loss: 111.1425, Valid Loss: 171.0095
Epoch [19701/30000], Step [1/1], Training Loss: 91.7118, Valid Loss: 161.3048
Epoch [19801/30000], Step [1/1], Training Loss: 79.6223, Valid Loss: 158.7429
Epoch [19901/30000], Step [1/1], Training Loss: 73.2015, Valid Loss: 169.4667
Epoch [20001/30000], Step [1/1], Training Loss: 68.8009, Valid Loss: 168.6572
Epoch [20101/30000], Step [1/1], Training Loss: 65.6025, Valid Loss: 170.3714
Epoch [20201/30000], Step [1/1], Training Loss: 61.4852, Valid Loss: 164.0095
Epoch [20301/30000], Step [1/1], Training Loss: 58.1418, Valid Loss: 162.4667
Epoch [20401/30000], Step [1/1], Training Loss: 52.2176, Valid Loss: 171.2952

[Epoch 25000] Rounded prediction: 
tensor([15., 13., 16., 13., 17., 16., 22., 20., 22., 24., 19., 24., 24., 24.,
        34., 18., 26.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  4., 21.,  6.,  0.,  0.,  0.,  2., 10.,
         0.,  0.,  0.,  0.,  0.,  0.,  2., 66., 40., 49., 38., 25., 15., 31.,
        44., 33., 21., 19., 25.,  0.,  0.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [20501/30000], Step [1/1], Training Loss: 50.7695, Valid Loss: 171.4095
Epoch [20601/30000], Step [1/1], Training Loss: 47.0768, Valid Loss: 172.4095
Epoch [20701/30000], Step [1/1], Training Loss: 46.2415, Valid Loss: 174.6857
Epoch [20801/30000], Step [1/1], Training Loss: 42.0876, Valid Loss: 181.0191
Epoch [20901/30000], Step [1/1], Training Loss: 41.6285, Valid Loss: 174.5619
Epoch [21001/30000], Step [1/1], Training Loss: 38.8199, Valid Loss: 175.0095
Epoch [21101/30000], Step [1/1], Training Loss: 33.1180, Valid Loss: 175.1619
Epoch [21201/30000], Step [1/1], Training Loss: 33.7395, Valid Loss: 178.5524
Epoch [21301/30000], Step [1/1], Training Loss: 30.1887, Valid Loss: 176.6000
Epoch [21401/30000], Step [1/1], Training Loss: 28.5252, Valid Loss: 179.8286
Epoch [21501/30000], Step [1/1], Training Loss: 26.3686, Valid Loss: 175.7238
Epoch [21601/30000], Step [1/1], Training Loss: 25.2189, Valid Loss: 181.1333
Epoch [21701/30000], Step [1/1], Training Loss: 23.2408, Valid Loss: 191.7048
Epoch [21801/30000], Step [1/1], Training Loss: 20.9294, Valid Loss: 183.2286
Epoch [21901/30000], Step [1/1], Training Loss: 19.6981, Valid Loss: 187.9333
Epoch [22001/30000], Step [1/1], Training Loss: 18.4702, Valid Loss: 183.0286
Epoch [22101/30000], Step [1/1], Training Loss: 15.8667, Valid Loss: 192.5333
Epoch [22201/30000], Step [1/1], Training Loss: 15.9501, Valid Loss: 201.3810
Epoch [22301/30000], Step [1/1], Training Loss: 15.1270, Valid Loss: 187.0095
Epoch [22401/30000], Step [1/1], Training Loss: 13.1258, Valid Loss: 200.4952
Epoch [22501/30000], Step [1/1], Training Loss: 11.1892, Valid Loss: 202.8286
Epoch [22601/30000], Step [1/1], Training Loss: 9.8093, Valid Loss: 196.7905
Epoch [22701/30000], Step [1/1], Training Loss: 10.1341, Valid Loss: 192.6667
Epoch [22801/30000], Step [1/1], Training Loss: 8.2315, Valid Loss: 203.4381
Epoch [22901/30000], Step [1/1], Training Loss: 6.7332, Valid Loss: 185.1524
Epoch [23001/30000], Step [1/1], Training Loss: 7.5790, Valid Loss: 202.5619
Epoch [23101/30000], Step [1/1], Training Loss: 5.2125, Valid Loss: 203.6476
Epoch [23201/30000], Step [1/1], Training Loss: 5.9591, Valid Loss: 191.2000
Epoch [23301/30000], Step [1/1], Training Loss: 4.4518, Valid Loss: 202.4762
Epoch [23401/30000], Step [1/1], Training Loss: 3.8910, Valid Loss: 203.2286
Epoch [23501/30000], Step [1/1], Training Loss: 3.3816, Valid Loss: 207.4000
Epoch [23601/30000], Step [1/1], Training Loss: 3.3782, Valid Loss: 206.4762
Epoch [23701/30000], Step [1/1], Training Loss: 3.4477, Valid Loss: 213.2476
Epoch [23801/30000], Step [1/1], Training Loss: 2.5176, Valid Loss: 209.5905
Epoch [23901/30000], Step [1/1], Training Loss: 2.3115, Valid Loss: 217.4095
Epoch [24001/30000], Step [1/1], Training Loss: 1.9103, Valid Loss: 218.5810
Epoch [24101/30000], Step [1/1], Training Loss: 2.3616, Valid Loss: 228.1524
Epoch [24201/30000], Step [1/1], Training Loss: 1.5081, Valid Loss: 211.6953
Epoch [24301/30000], Step [1/1], Training Loss: 1.5760, Valid Loss: 210.1905
Epoch [24401/30000], Step [1/1], Training Loss: 1.7967, Valid Loss: 220.3714
Epoch [24501/30000], Step [1/1], Training Loss: 1.4582, Valid Loss: 222.7048
Epoch [24601/30000], Step [1/1], Training Loss: 4.3038, Valid Loss: 223.2762
Epoch [24701/30000], Step [1/1], Training Loss: 1.1530, Valid Loss: 219.1238
Epoch [24801/30000], Step [1/1], Training Loss: 1.2475, Valid Loss: 219.0000
Epoch [24901/30000], Step [1/1], Training Loss: 0.9882, Valid Loss: 219.7143
Epoch [25001/30000], Step [1/1], Training Loss: 268.2799, Valid Loss: 175.4476
Epoch [25101/30000], Step [1/1], Training Loss: 154.5283, Valid Loss: 233.2667
Epoch [25201/30000], Step [1/1], Training Loss: 45.7002, Valid Loss: 251.7333
Epoch [25301/30000], Step [1/1], Training Loss: 23.8044, Valid Loss: 248.6476
Epoch [25401/30000], Step [1/1], Training Loss: 14.4910, Valid Loss: 247.4191
Epoch [25501/30000], Step [1/1], Training Loss: 15.3096, Valid Loss: 232.0667
Epoch [25601/30000], Step [1/1], Training Loss: 10.5378, Valid Loss: 238.3143
Epoch [25701/30000], Step [1/1], Training Loss: 7.2964, Valid Loss: 236.2952
Epoch [25801/30000], Step [1/1], Training Loss: 5.7938, Valid Loss: 246.5429
Epoch [25901/30000], Step [1/1], Training Loss: 6.1867, Valid Loss: 238.9714
Epoch [26001/30000], Step [1/1], Training Loss: 5.5429, Valid Loss: 238.1429
Epoch [26101/30000], Step [1/1], Training Loss: 4.8618, Valid Loss: 243.7429
Epoch [26201/30000], Step [1/1], Training Loss: 4.3745, Valid Loss: 240.4286
Epoch [26301/30000], Step [1/1], Training Loss: 4.2759, Valid Loss: 240.4381
Epoch [26401/30000], Step [1/1], Training Loss: 3.1080, Valid Loss: 243.5714
Epoch [26501/30000], Step [1/1], Training Loss: 2.9228, Valid Loss: 250.4857
Epoch [26601/30000], Step [1/1], Training Loss: 2.5745, Valid Loss: 241.4572
Epoch [26701/30000], Step [1/1], Training Loss: 2.4057, Valid Loss: 251.1714
Epoch [26801/30000], Step [1/1], Training Loss: 2.1778, Valid Loss: 247.4000
Epoch [26901/30000], Step [1/1], Training Loss: 1.7967, Valid Loss: 251.2572
Epoch [27001/30000], Step [1/1], Training Loss: 1.7643, Valid Loss: 240.3238
Epoch [27101/30000], Step [1/1], Training Loss: 1.8503, Valid Loss: 247.1619
Epoch [27201/30000], Step [1/1], Training Loss: 1.9027, Valid Loss: 242.2000
Epoch [27301/30000], Step [1/1], Training Loss: 2.1311, Valid Loss: 248.4191
Epoch [27401/30000], Step [1/1], Training Loss: 1.4944, Valid Loss: 252.2572
Epoch [27501/30000], Step [1/1], Training Loss: 1.5496, Valid Loss: 245.6572
Epoch [27601/30000], Step [1/1], Training Loss: 1.7801, Valid Loss: 241.0286
Epoch [27701/30000], Step [1/1], Training Loss: 1.4302, Valid Loss: 243.6953
Epoch [27801/30000], Step [1/1], Training Loss: 1.3502, Valid Loss: 247.8762
Epoch [27901/30000], Step [1/1], Training Loss: 1.2614, Valid Loss: 241.9048
Epoch [28001/30000], Step [1/1], Training Loss: 1.1575, Valid Loss: 249.5905
Epoch [28101/30000], Step [1/1], Training Loss: 1.3795, Valid Loss: 243.2952
Epoch [28201/30000], Step [1/1], Training Loss: 0.9295, Valid Loss: 252.1143
Epoch [28301/30000], Step [1/1], Training Loss: 0.8928, Valid Loss: 248.0191
Epoch [28401/30000], Step [1/1], Training Loss: 0.8081, Valid Loss: 240.8286
Epoch [28501/30000], Step [1/1], Training Loss: 0.9142, Valid Loss: 239.9810
Epoch [28601/30000], Step [1/1], Training Loss: 1.7421, Valid Loss: 241.8095
Epoch [28701/30000], Step [1/1], Training Loss: 0.7810, Valid Loss: 243.6667
Epoch [28801/30000], Step [1/1], Training Loss: 0.7012, Valid Loss: 242.0762
Epoch [28901/30000], Step [1/1], Training Loss: 0.5798, Valid Loss: 246.9048
Epoch [29001/30000], Step [1/1], Training Loss: 0.5345, Valid Loss: 249.1333
Epoch [29101/30000], Step [1/1], Training Loss: 0.9251, Valid Loss: 251.5238
Epoch [29201/30000], Step [1/1], Training Loss: 0.6743, Valid Loss: 243.8476
Epoch [29301/30000], Step [1/1], Training Loss: 0.6753, Valid Loss: 241.9048
Epoch [29401/30000], Step [1/1], Training Loss: 0.6988, Valid Loss: 249.4476
Epoch [29501/30000], Step [1/1], Training Loss: 0.6428, Valid Loss: 242.6000
Epoch [29601/30000], Step [1/1], Training Loss: 0.5149, Valid Loss: 248.1333
Epoch [29701/30000], Step [1/1], Training Loss: 0.8016, Valid Loss: 252.5810
Epoch [29801/30000], Step [1/1], Training Loss: 0.5693, Valid Loss: 242.8476
Epoch [29901/30000], Step [1/1], Training Loss: 0.5205, Valid Loss: 249.8667

 End Time: 2021/04/19, 17:49:20




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=1048 	layers=2

Start Time = 2021/04/19, 17:49:20
##########################################################


[Epoch 0] Rounded prediction: 
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128611.0000, Valid Loss: 209.0857




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=2048 	layers=2

Start Time = 2021/04/19, 17:49:39
##########################################################


[Epoch 0] Rounded prediction: 
tensor([3., 3., 3., 2., 2., 2., 3., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
        2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2.,
        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3., 3., 3., 3.],
       device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([26., 20., 27., 22., 18., 24., 21., 21., 23., 16., 23., 13., 20., 17.,
        14., 21.,  4., 21.,  5., 13., 18.,  5., 13., 16.,  0.,  3., 10.,  5.,
         7., 10., 13.,  2.,  0., 15.,  2.,  9.,  2., 11.,  0., 15.,  3., 29.,
        11., 13.,  1.,  4.,  3.,  8.,  4.,  4.,  6.,  7., 18.,  0., 27.,  4.,
         5.,  1.,  7.,  8.,  3., 15.,  0., 16.,  0., 25.,  0., 20., 14.,  8.,
         8., 13., 10., 13., 11., 30., 13., 35., 10., 27., 27., 14., 43., 31.,
        21., 23., 14., 10., 12., 25., 31., 44., 49., 47., 45., 29., 34., 31.,
        39., 31., 38., 42., 27., 31., 42.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([25., 18., 22., 18., 16., 20., 17., 20., 19., 14., 17.,  5., 13.,  8.,
         7., 18.,  0., 14.,  0.,  9., 10.,  4.,  9., 12.,  0.,  4.,  6.,  0.,
         6.,  7.,  9.,  0.,  0., 11.,  0.,  7.,  0.,  8.,  0., 14.,  0., 24.,
        11.,  9.,  0.,  4.,  0.,  2.,  2.,  2.,  4.,  5., 13.,  0., 26.,  1.,
         5.,  0.,  5.,  3.,  2., 11.,  0., 15.,  0., 21.,  0., 18.,  7.,  2.,
         4.,  9.,  4.,  3.,  4., 30.,  6., 32.,  4., 21., 22.,  9., 40., 30.,
        17., 15.,  7.,  3., 10., 20., 30., 49., 52., 51., 48., 33., 35., 33.,
        38., 24., 30., 39., 19., 18., 41.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128618.0000, Valid Loss: 190.7619
Epoch [101/30000], Step [1/1], Training Loss: 110026.1250, Valid Loss: 1060.5906
Epoch [201/30000], Step [1/1], Training Loss: 102318.7578, Valid Loss: 2644.4858
Epoch [301/30000], Step [1/1], Training Loss: 95186.8672, Valid Loss: 77.2571
Epoch [401/30000], Step [1/1], Training Loss: 88605.3047, Valid Loss: 197.8286
Epoch [501/30000], Step [1/1], Training Loss: 82588.9141, Valid Loss: 526.6953
Epoch [601/30000], Step [1/1], Training Loss: 77068.8672, Valid Loss: 888.8191
Epoch [701/30000], Step [1/1], Training Loss: 72028.4375, Valid Loss: 1094.9429
Epoch [801/30000], Step [1/1], Training Loss: 67442.8125, Valid Loss: 992.5715
Epoch [901/30000], Step [1/1], Training Loss: 63275.6289, Valid Loss: 776.8477
Epoch [1001/30000], Step [1/1], Training Loss: 59500.3516, Valid Loss: 514.0953
Epoch [1101/30000], Step [1/1], Training Loss: 55845.3555, Valid Loss: 314.3810
Epoch [1201/30000], Step [1/1], Training Loss: 52452.0000, Valid Loss: 338.0762
Epoch [1301/30000], Step [1/1], Training Loss: 49344.2344, Valid Loss: 300.6572
Epoch [1401/30000], Step [1/1], Training Loss: 46392.1875, Valid Loss: 285.3333
Epoch [1501/30000], Step [1/1], Training Loss: 43711.8281, Valid Loss: 267.7333
Epoch [1601/30000], Step [1/1], Training Loss: 41194.7266, Valid Loss: 270.4857
Epoch [1701/30000], Step [1/1], Training Loss: 38951.9414, Valid Loss: 285.7143
Epoch [1801/30000], Step [1/1], Training Loss: 36851.8398, Valid Loss: 283.8667
Epoch [1901/30000], Step [1/1], Training Loss: 34927.9336, Valid Loss: 289.4762
Epoch [2001/30000], Step [1/1], Training Loss: 33093.6797, Valid Loss: 273.6190
Epoch [2101/30000], Step [1/1], Training Loss: 31342.2305, Valid Loss: 259.4286
Epoch [2201/30000], Step [1/1], Training Loss: 29620.9473, Valid Loss: 235.2857
Epoch [2301/30000], Step [1/1], Training Loss: 27730.7441, Valid Loss: 230.0095
Epoch [2401/30000], Step [1/1], Training Loss: 26110.5234, Valid Loss: 234.4191
Epoch [2501/30000], Step [1/1], Training Loss: 24684.4668, Valid Loss: 202.2857
Epoch [2601/30000], Step [1/1], Training Loss: 23308.7051, Valid Loss: 170.3048
Epoch [2701/30000], Step [1/1], Training Loss: 22087.0000, Valid Loss: 169.7048
Epoch [2801/30000], Step [1/1], Training Loss: 20840.5703, Valid Loss: 174.8095
Epoch [2901/30000], Step [1/1], Training Loss: 19756.8789, Valid Loss: 167.2095
Epoch [3001/30000], Step [1/1], Training Loss: 18766.1523, Valid Loss: 184.0857
Epoch [3101/30000], Step [1/1], Training Loss: 17829.6680, Valid Loss: 166.3143
Epoch [3201/30000], Step [1/1], Training Loss: 16991.3730, Valid Loss: 173.2000
Epoch [3301/30000], Step [1/1], Training Loss: 16198.0615, Valid Loss: 171.7429
Epoch [3401/30000], Step [1/1], Training Loss: 15561.9932, Valid Loss: 172.0667
Epoch [3501/30000], Step [1/1], Training Loss: 14972.9268, Valid Loss: 156.1143
Epoch [3601/30000], Step [1/1], Training Loss: 14186.3652, Valid Loss: 118.7619
Epoch [3701/30000], Step [1/1], Training Loss: 13389.5879, Valid Loss: 111.9143
Epoch [3801/30000], Step [1/1], Training Loss: 12758.1367, Valid Loss: 115.9619
Epoch [3901/30000], Step [1/1], Training Loss: 12205.5947, Valid Loss: 112.7333
Epoch [4001/30000], Step [1/1], Training Loss: 11605.6934, Valid Loss: 117.6381
Epoch [4101/30000], Step [1/1], Training Loss: 11090.2188, Valid Loss: 113.2571
Epoch [4201/30000], Step [1/1], Training Loss: 10387.5723, Valid Loss: 111.4381
Epoch [4301/30000], Step [1/1], Training Loss: 10001.9014, Valid Loss: 121.3429
Epoch [4401/30000], Step [1/1], Training Loss: 9222.2998, Valid Loss: 121.9619
Epoch [4501/30000], Step [1/1], Training Loss: 8685.9482, Valid Loss: 126.3238
Epoch [4601/30000], Step [1/1], Training Loss: 8186.9248, Valid Loss: 121.4286
Epoch [4701/30000], Step [1/1], Training Loss: 7896.5811, Valid Loss: 124.8000
Epoch [4801/30000], Step [1/1], Training Loss: 7410.7881, Valid Loss: 106.4000
Epoch [4901/30000], Step [1/1], Training Loss: 7276.2939, Valid Loss: 118.7905
Epoch [5001/30000], Step [1/1], Training Loss: 6662.3208, Valid Loss: 113.0857
Epoch [5101/30000], Step [1/1], Training Loss: 6309.9688, Valid Loss: 128.5619
Epoch [5201/30000], Step [1/1], Training Loss: 6457.6948, Valid Loss: 144.7810
Epoch [5301/30000], Step [1/1], Training Loss: 5773.3647, Valid Loss: 120.1143
Epoch [5401/30000], Step [1/1], Training Loss: 5603.0859, Valid Loss: 126.2191
Epoch [5501/30000], Step [1/1], Training Loss: 5293.5254, Valid Loss: 150.8190
Epoch [5601/30000], Step [1/1], Training Loss: 4702.5122, Valid Loss: 124.0857
Epoch [5701/30000], Step [1/1], Training Loss: 4517.8901, Valid Loss: 122.9905
Epoch [5801/30000], Step [1/1], Training Loss: 4139.2134, Valid Loss: 122.9143
Epoch [5901/30000], Step [1/1], Training Loss: 4146.6787, Valid Loss: 103.9810
Epoch [6001/30000], Step [1/1], Training Loss: 3798.9473, Valid Loss: 122.4762
Epoch [6101/30000], Step [1/1], Training Loss: 3556.7988, Valid Loss: 131.0857
Epoch [6201/30000], Step [1/1], Training Loss: 3349.2468, Valid Loss: 125.4762
Epoch [6301/30000], Step [1/1], Training Loss: 3165.9133, Valid Loss: 128.9429
Epoch [6401/30000], Step [1/1], Training Loss: 2999.3992, Valid Loss: 128.0762
Epoch [6501/30000], Step [1/1], Training Loss: 2844.0251, Valid Loss: 122.9048
Epoch [6601/30000], Step [1/1], Training Loss: 2687.2393, Valid Loss: 126.1143
Epoch [6701/30000], Step [1/1], Training Loss: 2553.3608, Valid Loss: 118.9524
Epoch [6801/30000], Step [1/1], Training Loss: 2414.1233, Valid Loss: 121.4191
Epoch [6901/30000], Step [1/1], Training Loss: 2285.0356, Valid Loss: 128.3143
Epoch [7001/30000], Step [1/1], Training Loss: 2164.5500, Valid Loss: 141.8381
Epoch [7101/30000], Step [1/1], Training Loss: 2061.6938, Valid Loss: 122.5714
Epoch [7201/30000], Step [1/1], Training Loss: 1958.1931, Valid Loss: 122.0857
Epoch [7301/30000], Step [1/1], Training Loss: 1848.3912, Valid Loss: 128.5143
Epoch [7401/30000], Step [1/1], Training Loss: 1765.8793, Valid Loss: 131.8952
Epoch [7501/30000], Step [1/1], Training Loss: 1681.5476, Valid Loss: 139.6762
Epoch [7601/30000], Step [1/1], Training Loss: 1594.9978, Valid Loss: 115.4191
Epoch [7701/30000], Step [1/1], Training Loss: 1503.4075, Valid Loss: 122.1238
Epoch [7801/30000], Step [1/1], Training Loss: 1438.4333, Valid Loss: 129.0000
Epoch [7901/30000], Step [1/1], Training Loss: 1352.6666, Valid Loss: 135.9333
Epoch [8001/30000], Step [1/1], Training Loss: 1288.5776, Valid Loss: 132.4000
Epoch [8101/30000], Step [1/1], Training Loss: 1236.6226, Valid Loss: 104.0952
Epoch [8201/30000], Step [1/1], Training Loss: 1182.8812, Valid Loss: 94.9238
Epoch [8301/30000], Step [1/1], Training Loss: 1133.8352, Valid Loss: 104.5143
Epoch [8401/30000], Step [1/1], Training Loss: 1079.1210, Valid Loss: 108.6952
Epoch [8501/30000], Step [1/1], Training Loss: 1033.4497, Valid Loss: 102.9524
Epoch [8601/30000], Step [1/1], Training Loss: 988.9207, Valid Loss: 111.9524
Epoch [8701/30000], Step [1/1], Training Loss: 941.6217, Valid Loss: 102.2286
Epoch [8801/30000], Step [1/1], Training Loss: 902.7646, Valid Loss: 98.3429
Epoch [8901/30000], Step [1/1], Training Loss: 862.4924, Valid Loss: 98.2857
Epoch [9001/30000], Step [1/1], Training Loss: 824.8881, Valid Loss: 104.4762
Epoch [9101/30000], Step [1/1], Training Loss: 787.9798, Valid Loss: 106.5810
Epoch [9201/30000], Step [1/1], Training Loss: 754.6387, Valid Loss: 111.7143
Epoch [9301/30000], Step [1/1], Training Loss: 724.2769, Valid Loss: 105.3524
Epoch [9401/30000], Step [1/1], Training Loss: 692.6124, Valid Loss: 110.8571
Epoch [9501/30000], Step [1/1], Training Loss: 664.6830, Valid Loss: 98.7905
Epoch [9601/30000], Step [1/1], Training Loss: 638.3499, Valid Loss: 99.2286
Epoch [9701/30000], Step [1/1], Training Loss: 612.5187, Valid Loss: 108.7619
Epoch [9801/30000], Step [1/1], Training Loss: 585.5417, Valid Loss: 111.5524
Epoch [9901/30000], Step [1/1], Training Loss: 560.0929, Valid Loss: 107.9238
Epoch [10001/30000], Step [1/1], Training Loss: 533.1829, Valid Loss: 98.0571
Epoch [10101/30000], Step [1/1], Training Loss: 510.1306, Valid Loss: 100.5333
Epoch [10201/30000], Step [1/1], Training Loss: 487.4783, Valid Loss: 108.0000

[Epoch 15000] Rounded prediction: 
tensor([25., 24., 28., 22., 25., 26., 26., 28., 30., 30., 31., 30., 30., 24.,
        26., 24., 11., 17.,  0., 12., 14.,  2.,  9., 15.,  0.,  3.,  8.,  2.,
         6.,  9., 11.,  0.,  0., 13.,  0.,  7.,  0.,  9.,  0., 13.,  0., 31.,
         8., 10.,  0.,  5.,  0.,  3.,  2.,  2.,  7.,  7., 17.,  0., 35.,  0.,
         4.,  1.,  5.,  4.,  2., 13.,  0., 15.,  0., 25.,  0., 18.,  4.,  0.,
         7., 14.,  5.,  8.,  9., 36.,  0., 32.,  3., 19., 17.,  4., 42., 20.,
        11.,  9.,  7., 18., 19., 23., 34., 41., 39., 43., 43., 22., 25., 28.,
        30., 23., 27., 34., 21., 20., 24.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([19., 19., 24., 18., 18., 20., 14., 21., 23., 24., 19., 31., 28., 23.,
        30., 25., 24., 11.,  7., 16., 21.,  8., 13., 24.,  2.,  6., 12.,  4.,
        10., 12., 17.,  3.,  2., 18.,  4.,  9.,  4., 16.,  0., 15.,  5., 39.,
        17., 10.,  1.,  8.,  3.,  6.,  6.,  8., 10., 11., 20.,  3., 39.,  7.,
         0.,  8.,  8.,  9.,  5., 15.,  2., 22.,  4., 29.,  4., 23., 19.,  9.,
        28., 24., 25., 20., 25., 31., 26., 37., 13., 23., 36., 14., 45., 34.,
        21., 31., 29., 21., 17., 23., 42., 48., 40., 31., 38., 29., 32., 39.,
        34., 26., 25., 26., 26., 10., 15.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [10301/30000], Step [1/1], Training Loss: 465.3280, Valid Loss: 101.0476
Epoch [10401/30000], Step [1/1], Training Loss: 443.4079, Valid Loss: 101.8476
Epoch [10501/30000], Step [1/1], Training Loss: 421.7015, Valid Loss: 103.0191
Epoch [10601/30000], Step [1/1], Training Loss: 403.5882, Valid Loss: 108.8286
Epoch [10701/30000], Step [1/1], Training Loss: 382.9652, Valid Loss: 106.7238
Epoch [10801/30000], Step [1/1], Training Loss: 362.1196, Valid Loss: 103.4286
Epoch [10901/30000], Step [1/1], Training Loss: 342.7399, Valid Loss: 100.7429
Epoch [11001/30000], Step [1/1], Training Loss: 323.8115, Valid Loss: 104.4952
Epoch [11101/30000], Step [1/1], Training Loss: 305.7907, Valid Loss: 107.5524
Epoch [11201/30000], Step [1/1], Training Loss: 287.3441, Valid Loss: 109.7333
Epoch [11301/30000], Step [1/1], Training Loss: 269.8022, Valid Loss: 107.8952
Epoch [11401/30000], Step [1/1], Training Loss: 252.8543, Valid Loss: 112.7524
Epoch [11501/30000], Step [1/1], Training Loss: 3061.4551, Valid Loss: 117.8000
Epoch [11601/30000], Step [1/1], Training Loss: 898.9660, Valid Loss: 142.9810
Epoch [11701/30000], Step [1/1], Training Loss: 443.9611, Valid Loss: 139.5048
Epoch [11801/30000], Step [1/1], Training Loss: 370.5186, Valid Loss: 140.5143
Epoch [11901/30000], Step [1/1], Training Loss: 333.1978, Valid Loss: 140.0000
Epoch [12001/30000], Step [1/1], Training Loss: 297.2425, Valid Loss: 136.6095
Epoch [12101/30000], Step [1/1], Training Loss: 272.4984, Valid Loss: 141.4000
Epoch [12201/30000], Step [1/1], Training Loss: 266.7919, Valid Loss: 140.4000
Epoch [12301/30000], Step [1/1], Training Loss: 240.9867, Valid Loss: 144.5619
Epoch [12401/30000], Step [1/1], Training Loss: 231.0485, Valid Loss: 136.7429
Epoch [12501/30000], Step [1/1], Training Loss: 215.7993, Valid Loss: 145.1238
Epoch [12601/30000], Step [1/1], Training Loss: 202.8875, Valid Loss: 141.3810
Epoch [12701/30000], Step [1/1], Training Loss: 187.5739, Valid Loss: 141.9810
Epoch [12801/30000], Step [1/1], Training Loss: 175.6874, Valid Loss: 139.0571
Epoch [12901/30000], Step [1/1], Training Loss: 161.0424, Valid Loss: 153.1333
Epoch [13001/30000], Step [1/1], Training Loss: 151.7714, Valid Loss: 148.8190
Epoch [13101/30000], Step [1/1], Training Loss: 138.9840, Valid Loss: 150.6000
Epoch [13201/30000], Step [1/1], Training Loss: 129.5674, Valid Loss: 148.2762
Epoch [13301/30000], Step [1/1], Training Loss: 119.2389, Valid Loss: 142.5143
Epoch [13401/30000], Step [1/1], Training Loss: 110.3800, Valid Loss: 142.5619
Epoch [13501/30000], Step [1/1], Training Loss: 100.4275, Valid Loss: 152.4857
Epoch [13601/30000], Step [1/1], Training Loss: 90.0939, Valid Loss: 149.6667
Epoch [13701/30000], Step [1/1], Training Loss: 82.2259, Valid Loss: 146.8571
Epoch [13801/30000], Step [1/1], Training Loss: 72.9242, Valid Loss: 146.6762
Epoch [13901/30000], Step [1/1], Training Loss: 65.1099, Valid Loss: 154.2286
Epoch [14001/30000], Step [1/1], Training Loss: 58.0442, Valid Loss: 158.6667
Epoch [14101/30000], Step [1/1], Training Loss: 51.8625, Valid Loss: 161.2762
Epoch [14201/30000], Step [1/1], Training Loss: 47.4965, Valid Loss: 148.1048
Epoch [14301/30000], Step [1/1], Training Loss: 40.9632, Valid Loss: 155.7429
Epoch [14401/30000], Step [1/1], Training Loss: 36.3235, Valid Loss: 155.1429
Epoch [14501/30000], Step [1/1], Training Loss: 31.3161, Valid Loss: 161.7238
Epoch [14601/30000], Step [1/1], Training Loss: 26.6833, Valid Loss: 157.2381
Epoch [14701/30000], Step [1/1], Training Loss: 23.4569, Valid Loss: 156.6381
Epoch [14801/30000], Step [1/1], Training Loss: 20.3821, Valid Loss: 166.9714
Epoch [14901/30000], Step [1/1], Training Loss: 17.1460, Valid Loss: 153.9619
Epoch [15001/30000], Step [1/1], Training Loss: 16.6433, Valid Loss: 151.1810
Epoch [15101/30000], Step [1/1], Training Loss: 13.1606, Valid Loss: 158.0476
Epoch [15201/30000], Step [1/1], Training Loss: 11.1715, Valid Loss: 149.7429
Epoch [15301/30000], Step [1/1], Training Loss: 9.4833, Valid Loss: 159.5238
Epoch [15401/30000], Step [1/1], Training Loss: 8.5972, Valid Loss: 152.1810
Epoch [15501/30000], Step [1/1], Training Loss: 7.2935, Valid Loss: 171.1524
Epoch [15601/30000], Step [1/1], Training Loss: 5.5668, Valid Loss: 156.9810
Epoch [15701/30000], Step [1/1], Training Loss: 4.7961, Valid Loss: 166.8952
Epoch [15801/30000], Step [1/1], Training Loss: 4.3211, Valid Loss: 162.8000
Epoch [15901/30000], Step [1/1], Training Loss: 4.1910, Valid Loss: 169.8191
Epoch [16001/30000], Step [1/1], Training Loss: 3.2996, Valid Loss: 174.5048
Epoch [16101/30000], Step [1/1], Training Loss: 3.1274, Valid Loss: 163.0286
Epoch [16201/30000], Step [1/1], Training Loss: 2.4023, Valid Loss: 158.1619
Epoch [16301/30000], Step [1/1], Training Loss: 2.3751, Valid Loss: 163.2381
Epoch [16401/30000], Step [1/1], Training Loss: 2.2517, Valid Loss: 167.5143
Epoch [16501/30000], Step [1/1], Training Loss: 1.7262, Valid Loss: 166.1143
Epoch [16601/30000], Step [1/1], Training Loss: 1.4980, Valid Loss: 179.6381
Epoch [16701/30000], Step [1/1], Training Loss: 1.5074, Valid Loss: 176.7429
Epoch [16801/30000], Step [1/1], Training Loss: 1.8856, Valid Loss: 165.4476
Epoch [16901/30000], Step [1/1], Training Loss: 1.4742, Valid Loss: 176.8476
Epoch [17001/30000], Step [1/1], Training Loss: 1.2058, Valid Loss: 174.0667
Epoch [17101/30000], Step [1/1], Training Loss: 1.2372, Valid Loss: 174.6381
Epoch [17201/30000], Step [1/1], Training Loss: 1.5084, Valid Loss: 181.4286
Epoch [17301/30000], Step [1/1], Training Loss: 0.9770, Valid Loss: 183.5429
Epoch [17401/30000], Step [1/1], Training Loss: 1.1732, Valid Loss: 194.3429
Epoch [17501/30000], Step [1/1], Training Loss: 1.3710, Valid Loss: 183.7810
Epoch [17601/30000], Step [1/1], Training Loss: 0.9560, Valid Loss: 180.6667
Epoch [17701/30000], Step [1/1], Training Loss: 1.4428, Valid Loss: 178.1524
Epoch [17801/30000], Step [1/1], Training Loss: 1.5078, Valid Loss: 183.4286
Epoch [17901/30000], Step [1/1], Training Loss: 1.0871, Valid Loss: 175.8191
Epoch [18001/30000], Step [1/1], Training Loss: 0.8408, Valid Loss: 174.2857
Epoch [18101/30000], Step [1/1], Training Loss: 1.2287, Valid Loss: 200.3429
Epoch [18201/30000], Step [1/1], Training Loss: 0.8752, Valid Loss: 181.6762
Epoch [18301/30000], Step [1/1], Training Loss: 0.6251, Valid Loss: 178.6095
Epoch [18401/30000], Step [1/1], Training Loss: 0.7606, Valid Loss: 180.4857
Epoch [18501/30000], Step [1/1], Training Loss: 0.6659, Valid Loss: 190.6667
Epoch [18601/30000], Step [1/1], Training Loss: 0.7358, Valid Loss: 181.7524
Epoch [18701/30000], Step [1/1], Training Loss: 1.0727, Valid Loss: 177.4000
Epoch [18801/30000], Step [1/1], Training Loss: 0.8925, Valid Loss: 177.5524
Epoch [18901/30000], Step [1/1], Training Loss: 1.2434, Valid Loss: 201.7143
Epoch [19001/30000], Step [1/1], Training Loss: 1.5982, Valid Loss: 200.7905
Epoch [19101/30000], Step [1/1], Training Loss: 0.8318, Valid Loss: 184.5333
Epoch [19201/30000], Step [1/1], Training Loss: 0.8256, Valid Loss: 191.2952
Epoch [19301/30000], Step [1/1], Training Loss: 0.7315, Valid Loss: 184.7810
Epoch [19401/30000], Step [1/1], Training Loss: 0.5453, Valid Loss: 193.1619
Epoch [19501/30000], Step [1/1], Training Loss: 0.4754, Valid Loss: 195.7524
Epoch [19601/30000], Step [1/1], Training Loss: 0.7449, Valid Loss: 188.6857
Epoch [19701/30000], Step [1/1], Training Loss: 6285.3223, Valid Loss: 164.3810
Epoch [19801/30000], Step [1/1], Training Loss: 225.6236, Valid Loss: 181.2476
Epoch [19901/30000], Step [1/1], Training Loss: 129.9981, Valid Loss: 175.5714
Epoch [20001/30000], Step [1/1], Training Loss: 45.3284, Valid Loss: 177.6286
Epoch [20101/30000], Step [1/1], Training Loss: 31.2481, Valid Loss: 173.1429
Epoch [20201/30000], Step [1/1], Training Loss: 24.0146, Valid Loss: 182.3143
Epoch [20301/30000], Step [1/1], Training Loss: 24.1366, Valid Loss: 187.2476
Epoch [20401/30000], Step [1/1], Training Loss: 20.2468, Valid Loss: 194.7905
Epoch [20501/30000], Step [1/1], Training Loss: 18.0139, Valid Loss: 185.7524
Epoch [20601/30000], Step [1/1], Training Loss: 17.5940, Valid Loss: 184.0857

[Epoch 25000] Rounded prediction: 
tensor([20., 19., 26., 21., 19., 22., 18., 22., 24., 21., 22., 28., 30., 25.,
        33., 29., 24., 14.,  1., 12., 19., 11., 13., 20.,  4.,  5., 10.,  5.,
         9., 11., 14.,  3.,  0., 12.,  4., 10.,  1., 11.,  0., 12.,  6., 36.,
        10., 12.,  0.,  6.,  2.,  5.,  4.,  4.,  5.,  8., 19.,  4., 38.,  5.,
         4.,  4.,  6.,  8.,  4., 14.,  0., 19.,  0., 27.,  3., 23., 18., 12.,
        32., 24., 22., 23., 29., 31., 17., 44., 10., 26., 32., 16., 52., 30.,
        19., 35., 31., 26., 22., 21., 39., 47., 42., 33., 40., 28., 29., 42.,
        33., 25., 25., 29., 24., 17., 11.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [20701/30000], Step [1/1], Training Loss: 14.6271, Valid Loss: 185.2191
Epoch [20801/30000], Step [1/1], Training Loss: 11.3144, Valid Loss: 196.9333
Epoch [20901/30000], Step [1/1], Training Loss: 13.0158, Valid Loss: 189.9714
Epoch [21001/30000], Step [1/1], Training Loss: 10.2020, Valid Loss: 189.4191
Epoch [21101/30000], Step [1/1], Training Loss: 9.3682, Valid Loss: 195.1048
Epoch [21201/30000], Step [1/1], Training Loss: 9.9351, Valid Loss: 203.7905
Epoch [21301/30000], Step [1/1], Training Loss: 7.4924, Valid Loss: 199.1048
Epoch [21401/30000], Step [1/1], Training Loss: 6.0102, Valid Loss: 199.5048
Epoch [21501/30000], Step [1/1], Training Loss: 5.2254, Valid Loss: 211.0286
Epoch [21601/30000], Step [1/1], Training Loss: 5.5972, Valid Loss: 195.6857
Epoch [21701/30000], Step [1/1], Training Loss: 5.1091, Valid Loss: 191.0095
Epoch [21801/30000], Step [1/1], Training Loss: 5.7229, Valid Loss: 202.2286
Epoch [21901/30000], Step [1/1], Training Loss: 3.7833, Valid Loss: 197.6667
Epoch [22001/30000], Step [1/1], Training Loss: 4.1696, Valid Loss: 203.0286
Epoch [22101/30000], Step [1/1], Training Loss: 3.0369, Valid Loss: 200.8857
Epoch [22201/30000], Step [1/1], Training Loss: 3.6150, Valid Loss: 201.6095
Epoch [22301/30000], Step [1/1], Training Loss: 3.3529, Valid Loss: 205.1429
Epoch [22401/30000], Step [1/1], Training Loss: 3.3607, Valid Loss: 194.0286
Epoch [22501/30000], Step [1/1], Training Loss: 3.2443, Valid Loss: 187.8191
Epoch [22601/30000], Step [1/1], Training Loss: 2.7662, Valid Loss: 195.8667
Epoch [22701/30000], Step [1/1], Training Loss: 2.6259, Valid Loss: 200.9524
Epoch [22801/30000], Step [1/1], Training Loss: 2.8978, Valid Loss: 193.9524
Epoch [22901/30000], Step [1/1], Training Loss: 2.2941, Valid Loss: 195.7905
Epoch [23001/30000], Step [1/1], Training Loss: 1.6424, Valid Loss: 200.7905
Epoch [23101/30000], Step [1/1], Training Loss: 1.9272, Valid Loss: 196.7429
Epoch [23201/30000], Step [1/1], Training Loss: 2.2221, Valid Loss: 212.7238
Epoch [23301/30000], Step [1/1], Training Loss: 1.4212, Valid Loss: 193.8381
Epoch [23401/30000], Step [1/1], Training Loss: 1.0176, Valid Loss: 192.7905
Epoch [23501/30000], Step [1/1], Training Loss: 1.0522, Valid Loss: 197.6667
Epoch [23601/30000], Step [1/1], Training Loss: 1.4759, Valid Loss: 206.7524
Epoch [23701/30000], Step [1/1], Training Loss: 1.3961, Valid Loss: 187.4381
Epoch [23801/30000], Step [1/1], Training Loss: 1.4556, Valid Loss: 182.5048
Epoch [23901/30000], Step [1/1], Training Loss: 1.5867, Valid Loss: 190.1524
Epoch [24001/30000], Step [1/1], Training Loss: 1.4055, Valid Loss: 190.7429
Epoch [24101/30000], Step [1/1], Training Loss: 1.0106, Valid Loss: 181.4000
Epoch [24201/30000], Step [1/1], Training Loss: 1.0397, Valid Loss: 205.1714
Epoch [24301/30000], Step [1/1], Training Loss: 0.8447, Valid Loss: 192.8381
Epoch [24401/30000], Step [1/1], Training Loss: 1.5001, Valid Loss: 183.5143
Epoch [24501/30000], Step [1/1], Training Loss: 1.3059, Valid Loss: 183.7143
Epoch [24601/30000], Step [1/1], Training Loss: 1.0320, Valid Loss: 198.0000
Epoch [24701/30000], Step [1/1], Training Loss: 1.2076, Valid Loss: 180.8952
Epoch [24801/30000], Step [1/1], Training Loss: 1.0375, Valid Loss: 187.3143
Epoch [24901/30000], Step [1/1], Training Loss: 1.0943, Valid Loss: 197.6762
Epoch [25001/30000], Step [1/1], Training Loss: 0.8626, Valid Loss: 188.6953
Epoch [25101/30000], Step [1/1], Training Loss: 1.1103, Valid Loss: 191.6762
Epoch [25201/30000], Step [1/1], Training Loss: 0.7241, Valid Loss: 202.9048
Epoch [25301/30000], Step [1/1], Training Loss: 1.3997, Valid Loss: 197.5333
Epoch [25401/30000], Step [1/1], Training Loss: 0.8740, Valid Loss: 194.5714
Epoch [25501/30000], Step [1/1], Training Loss: 0.8492, Valid Loss: 211.1619
Epoch [25601/30000], Step [1/1], Training Loss: 0.7508, Valid Loss: 211.7905
Epoch [25701/30000], Step [1/1], Training Loss: 1.2184, Valid Loss: 201.7333
Epoch [25801/30000], Step [1/1], Training Loss: 0.9345, Valid Loss: 201.3333
Epoch [25901/30000], Step [1/1], Training Loss: 1.2119, Valid Loss: 219.7048
Epoch [26001/30000], Step [1/1], Training Loss: 0.6775, Valid Loss: 215.4191
Epoch [26101/30000], Step [1/1], Training Loss: 0.7079, Valid Loss: 190.9619
Epoch [26201/30000], Step [1/1], Training Loss: 0.7703, Valid Loss: 205.6095
Epoch [26301/30000], Step [1/1], Training Loss: 0.7323, Valid Loss: 204.1048
Epoch [26401/30000], Step [1/1], Training Loss: 1.1523, Valid Loss: 197.2952
Epoch [26501/30000], Step [1/1], Training Loss: 1.3524, Valid Loss: 204.2000
Epoch [26601/30000], Step [1/1], Training Loss: 0.5461, Valid Loss: 197.5524
Epoch [26701/30000], Step [1/1], Training Loss: 0.6600, Valid Loss: 205.3143
Epoch [26801/30000], Step [1/1], Training Loss: 0.7170, Valid Loss: 215.0381
Epoch [26901/30000], Step [1/1], Training Loss: 0.6370, Valid Loss: 209.1429
Epoch [27001/30000], Step [1/1], Training Loss: 1.1483, Valid Loss: 231.9810
Epoch [27101/30000], Step [1/1], Training Loss: 0.8448, Valid Loss: 221.1048
Epoch [27201/30000], Step [1/1], Training Loss: 0.5550, Valid Loss: 215.1619
Epoch [27301/30000], Step [1/1], Training Loss: 0.3911, Valid Loss: 211.1333
Epoch [27401/30000], Step [1/1], Training Loss: 0.5329, Valid Loss: 205.3143
Epoch [27501/30000], Step [1/1], Training Loss: 0.5265, Valid Loss: 221.5905
Epoch [27601/30000], Step [1/1], Training Loss: 0.3608, Valid Loss: 221.8286
Epoch [27701/30000], Step [1/1], Training Loss: 0.4945, Valid Loss: 216.6476
Epoch [27801/30000], Step [1/1], Training Loss: 0.5376, Valid Loss: 215.6667
Epoch [27901/30000], Step [1/1], Training Loss: 0.6559, Valid Loss: 214.1143
Epoch [28001/30000], Step [1/1], Training Loss: 0.7416, Valid Loss: 210.1714
Epoch [28101/30000], Step [1/1], Training Loss: 0.4474, Valid Loss: 224.6381
Epoch [28201/30000], Step [1/1], Training Loss: 0.3452, Valid Loss: 225.1429
Epoch [28301/30000], Step [1/1], Training Loss: 0.4663, Valid Loss: 222.9619
Epoch [28401/30000], Step [1/1], Training Loss: 0.5217, Valid Loss: 226.2762
Epoch [28501/30000], Step [1/1], Training Loss: 0.5876, Valid Loss: 227.0857
Epoch [28601/30000], Step [1/1], Training Loss: 0.4078, Valid Loss: 216.9143
Epoch [28701/30000], Step [1/1], Training Loss: 0.3233, Valid Loss: 221.6286
Epoch [28801/30000], Step [1/1], Training Loss: 3.1508, Valid Loss: 229.8286
Epoch [28901/30000], Step [1/1], Training Loss: 1247.7511, Valid Loss: 219.8191
Epoch [29001/30000], Step [1/1], Training Loss: 264.7456, Valid Loss: 236.7333
Epoch [29101/30000], Step [1/1], Training Loss: 58.6915, Valid Loss: 232.4953
Epoch [29201/30000], Step [1/1], Training Loss: 43.0852, Valid Loss: 238.6000
Epoch [29301/30000], Step [1/1], Training Loss: 26.0304, Valid Loss: 247.2000
Epoch [29401/30000], Step [1/1], Training Loss: 25.8746, Valid Loss: 247.6286
Epoch [29501/30000], Step [1/1], Training Loss: 13.0194, Valid Loss: 242.7429
Epoch [29601/30000], Step [1/1], Training Loss: 13.9791, Valid Loss: 245.3429
Epoch [29701/30000], Step [1/1], Training Loss: 10.0350, Valid Loss: 251.5429
Epoch [29801/30000], Step [1/1], Training Loss: 10.8423, Valid Loss: 244.8286
Epoch [29901/30000], Step [1/1], Training Loss: 7.2199, Valid Loss: 253.7619

 End Time: 2021/04/19, 18:23:15




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=2048 	layers=2

Start Time = 2021/04/19, 18:23:15
##########################################################


[Epoch 0] Rounded prediction: 
tensor([3., 2., 2., 3., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
        2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2.,
        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3., 2., 2., 3.],
       device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([26., 27., 28., 20., 20., 25., 21., 27., 26., 27., 28., 26., 25., 27.,
        21., 28., 10., 18.,  8., 14., 17., 12., 15., 19.,  7.,  7., 11.,  9.,
         9., 10., 14.,  6.,  4., 15.,  8., 10.,  5., 11.,  3., 13.,  9., 29.,
        16., 16.,  5.,  8.,  5.,  8.,  7.,  6.,  7.,  8., 17.,  7., 23., 11.,
         9.,  6.,  9., 11.,  8., 14.,  4., 15.,  4., 21.,  6., 22., 18., 13.,
        13., 13., 14., 13., 11., 25., 17., 36., 14., 30., 28., 18., 43., 27.,
        21., 26., 21., 12., 15., 23., 30., 35., 40., 46., 43., 28., 40., 44.,
        41., 31., 48., 43., 32., 42., 43.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([26., 23., 26., 20., 22., 25., 22., 29., 27., 23., 23., 10., 10.,  7.,
         4., 11.,  0.,  8.,  0.,  5., 11.,  9.,  9., 13.,  3.,  0.,  4.,  5.,
         5.,  5., 10.,  3.,  0., 10.,  4.,  5.,  0.,  5.,  0.,  9.,  4., 27.,
        12.,  8.,  0.,  1.,  1.,  4.,  0.,  0.,  0.,  2., 12.,  2., 18.,  7.,
         4.,  0.,  4.,  5.,  2.,  7.,  0.,  9.,  0., 14.,  2., 14., 13.,  4.,
         0.,  3.,  7.,  4.,  0., 18., 14., 36.,  8., 22., 26., 11., 42., 32.,
        15., 17., 11.,  0.,  0., 13., 30., 38., 46., 52., 50., 28., 39., 47.,
        45., 33., 48., 54., 35., 36., 53.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128653.7891, Valid Loss: 191.8000
Epoch [101/30000], Step [1/1], Training Loss: 110061.5078, Valid Loss: 1053.2286
Epoch [201/30000], Step [1/1], Training Loss: 102356.1406, Valid Loss: 2636.9333
Epoch [301/30000], Step [1/1], Training Loss: 95221.6719, Valid Loss: 75.8000
Epoch [401/30000], Step [1/1], Training Loss: 88642.2031, Valid Loss: 181.5429
Epoch [501/30000], Step [1/1], Training Loss: 82620.0625, Valid Loss: 357.4191
Epoch [601/30000], Step [1/1], Training Loss: 77102.7188, Valid Loss: 729.0953
Epoch [701/30000], Step [1/1], Training Loss: 72060.3125, Valid Loss: 808.4952
Epoch [801/30000], Step [1/1], Training Loss: 67469.0312, Valid Loss: 633.7333
Epoch [901/30000], Step [1/1], Training Loss: 63302.2695, Valid Loss: 372.6476
Epoch [1001/30000], Step [1/1], Training Loss: 59515.7891, Valid Loss: 270.2191
Epoch [1101/30000], Step [1/1], Training Loss: 55842.6484, Valid Loss: 264.5810
Epoch [1201/30000], Step [1/1], Training Loss: 52477.2734, Valid Loss: 254.1429
Epoch [1301/30000], Step [1/1], Training Loss: 49302.0977, Valid Loss: 187.0286
Epoch [1401/30000], Step [1/1], Training Loss: 46394.0977, Valid Loss: 168.7714
Epoch [1501/30000], Step [1/1], Training Loss: 43730.7930, Valid Loss: 176.0381
Epoch [1601/30000], Step [1/1], Training Loss: 41268.8398, Valid Loss: 153.6953
Epoch [1701/30000], Step [1/1], Training Loss: 38971.4844, Valid Loss: 178.2952
Epoch [1801/30000], Step [1/1], Training Loss: 36913.0703, Valid Loss: 190.4857
Epoch [1901/30000], Step [1/1], Training Loss: 34982.2305, Valid Loss: 160.5619
Epoch [2001/30000], Step [1/1], Training Loss: 33188.5586, Valid Loss: 158.0476
Epoch [2101/30000], Step [1/1], Training Loss: 31338.3320, Valid Loss: 135.5429
Epoch [2201/30000], Step [1/1], Training Loss: 29669.2422, Valid Loss: 152.6381
Epoch [2301/30000], Step [1/1], Training Loss: 27999.7539, Valid Loss: 138.2286
Epoch [2401/30000], Step [1/1], Training Loss: 26425.4805, Valid Loss: 139.2095
Epoch [2501/30000], Step [1/1], Training Loss: 25415.8848, Valid Loss: 128.5333
Epoch [2601/30000], Step [1/1], Training Loss: 23512.6582, Valid Loss: 151.2095
Epoch [2701/30000], Step [1/1], Training Loss: 22213.4863, Valid Loss: 140.4191
Epoch [2801/30000], Step [1/1], Training Loss: 20990.4121, Valid Loss: 151.3714
Epoch [2901/30000], Step [1/1], Training Loss: 20219.2539, Valid Loss: 133.8667
Epoch [3001/30000], Step [1/1], Training Loss: 18760.7637, Valid Loss: 147.4000
Epoch [3101/30000], Step [1/1], Training Loss: 17764.4121, Valid Loss: 152.9524
Epoch [3201/30000], Step [1/1], Training Loss: 16879.3105, Valid Loss: 144.7238
Epoch [3301/30000], Step [1/1], Training Loss: 16112.2393, Valid Loss: 141.8952
Epoch [3401/30000], Step [1/1], Training Loss: 15619.6016, Valid Loss: 134.5048
Epoch [3501/30000], Step [1/1], Training Loss: 14703.2314, Valid Loss: 124.8571
Epoch [3601/30000], Step [1/1], Training Loss: 14718.4033, Valid Loss: 131.8000
Epoch [3701/30000], Step [1/1], Training Loss: 13420.1182, Valid Loss: 130.8000
Epoch [3801/30000], Step [1/1], Training Loss: 12867.7168, Valid Loss: 142.5714
Epoch [3901/30000], Step [1/1], Training Loss: 12312.9180, Valid Loss: 155.6857
Epoch [4001/30000], Step [1/1], Training Loss: 11761.4990, Valid Loss: 156.7238
Epoch [4101/30000], Step [1/1], Training Loss: 11943.8223, Valid Loss: 134.6000
Epoch [4201/30000], Step [1/1], Training Loss: 10531.5078, Valid Loss: 122.9810
Epoch [4301/30000], Step [1/1], Training Loss: 10002.2881, Valid Loss: 123.6286
Epoch [4401/30000], Step [1/1], Training Loss: 9331.7764, Valid Loss: 154.4952
Epoch [4501/30000], Step [1/1], Training Loss: 8645.7480, Valid Loss: 146.9619
Epoch [4601/30000], Step [1/1], Training Loss: 8295.7217, Valid Loss: 134.7429
Epoch [4701/30000], Step [1/1], Training Loss: 7909.1055, Valid Loss: 122.3619
Epoch [4801/30000], Step [1/1], Training Loss: 7414.9878, Valid Loss: 140.5429
Epoch [4901/30000], Step [1/1], Training Loss: 6920.9258, Valid Loss: 118.0286
Epoch [5001/30000], Step [1/1], Training Loss: 6496.2090, Valid Loss: 127.0857
Epoch [5101/30000], Step [1/1], Training Loss: 6149.3911, Valid Loss: 134.0191
Epoch [5201/30000], Step [1/1], Training Loss: 5961.5420, Valid Loss: 133.8667
Epoch [5301/30000], Step [1/1], Training Loss: 5632.1396, Valid Loss: 135.9619
Epoch [5401/30000], Step [1/1], Training Loss: 5305.3340, Valid Loss: 119.6000
Epoch [5501/30000], Step [1/1], Training Loss: 5055.4302, Valid Loss: 123.1048
Epoch [5601/30000], Step [1/1], Training Loss: 4855.0327, Valid Loss: 101.4667
Epoch [5701/30000], Step [1/1], Training Loss: 4789.8945, Valid Loss: 122.5714
Epoch [5801/30000], Step [1/1], Training Loss: 4626.7432, Valid Loss: 130.9905
Epoch [5901/30000], Step [1/1], Training Loss: 4341.8589, Valid Loss: 105.9143
Epoch [6001/30000], Step [1/1], Training Loss: 4186.5303, Valid Loss: 107.7238
Epoch [6101/30000], Step [1/1], Training Loss: 4001.6543, Valid Loss: 106.3238
Epoch [6201/30000], Step [1/1], Training Loss: 4193.7388, Valid Loss: 103.6190
Epoch [6301/30000], Step [1/1], Training Loss: 4261.5293, Valid Loss: 93.1333
Epoch [6401/30000], Step [1/1], Training Loss: 3547.3645, Valid Loss: 112.7524
Epoch [6501/30000], Step [1/1], Training Loss: 4078.6685, Valid Loss: 100.2286
Epoch [6601/30000], Step [1/1], Training Loss: 3123.3381, Valid Loss: 97.2095
Epoch [6701/30000], Step [1/1], Training Loss: 2937.9890, Valid Loss: 106.3524
Epoch [6801/30000], Step [1/1], Training Loss: 2780.4524, Valid Loss: 118.3714
Epoch [6901/30000], Step [1/1], Training Loss: 2483.4387, Valid Loss: 113.4952
Epoch [7001/30000], Step [1/1], Training Loss: 2319.8335, Valid Loss: 107.3524
Epoch [7101/30000], Step [1/1], Training Loss: 2155.4939, Valid Loss: 104.6190
Epoch [7201/30000], Step [1/1], Training Loss: 1969.7744, Valid Loss: 107.9238
Epoch [7301/30000], Step [1/1], Training Loss: 1843.9446, Valid Loss: 102.6095
Epoch [7401/30000], Step [1/1], Training Loss: 1746.3645, Valid Loss: 98.4191
Epoch [7501/30000], Step [1/1], Training Loss: 1653.5264, Valid Loss: 109.5524
Epoch [7601/30000], Step [1/1], Training Loss: 1560.1832, Valid Loss: 100.7810
Epoch [7701/30000], Step [1/1], Training Loss: 1473.4827, Valid Loss: 101.9524
Epoch [7801/30000], Step [1/1], Training Loss: 1402.4648, Valid Loss: 101.9048
Epoch [7901/30000], Step [1/1], Training Loss: 1341.6232, Valid Loss: 102.6572
Epoch [8001/30000], Step [1/1], Training Loss: 1278.9709, Valid Loss: 100.0571
Epoch [8101/30000], Step [1/1], Training Loss: 1222.0415, Valid Loss: 108.8476
Epoch [8201/30000], Step [1/1], Training Loss: 1167.3716, Valid Loss: 99.4667
Epoch [8301/30000], Step [1/1], Training Loss: 1119.5696, Valid Loss: 106.7810
Epoch [8401/30000], Step [1/1], Training Loss: 1068.6010, Valid Loss: 100.8571
Epoch [8501/30000], Step [1/1], Training Loss: 1022.7769, Valid Loss: 108.9524
Epoch [8601/30000], Step [1/1], Training Loss: 979.1790, Valid Loss: 107.1810
Epoch [8701/30000], Step [1/1], Training Loss: 937.7923, Valid Loss: 109.9619
Epoch [8801/30000], Step [1/1], Training Loss: 891.3956, Valid Loss: 118.9524
Epoch [8901/30000], Step [1/1], Training Loss: 852.4690, Valid Loss: 101.0381
Epoch [9001/30000], Step [1/1], Training Loss: 816.6416, Valid Loss: 114.2667
Epoch [9101/30000], Step [1/1], Training Loss: 780.8171, Valid Loss: 110.9238
Epoch [9201/30000], Step [1/1], Training Loss: 746.7275, Valid Loss: 113.3238
Epoch [9301/30000], Step [1/1], Training Loss: 713.2128, Valid Loss: 107.9143
Epoch [9401/30000], Step [1/1], Training Loss: 683.9501, Valid Loss: 102.4952
Epoch [9501/30000], Step [1/1], Training Loss: 657.0939, Valid Loss: 110.7905
Epoch [9601/30000], Step [1/1], Training Loss: 631.0582, Valid Loss: 102.5619
Epoch [9701/30000], Step [1/1], Training Loss: 603.9337, Valid Loss: 104.5524
Epoch [9801/30000], Step [1/1], Training Loss: 577.1814, Valid Loss: 103.7810
Epoch [9901/30000], Step [1/1], Training Loss: 549.6596, Valid Loss: 106.6667
Epoch [10001/30000], Step [1/1], Training Loss: 525.6859, Valid Loss: 113.3429
Epoch [10101/30000], Step [1/1], Training Loss: 501.0956, Valid Loss: 111.3810
Epoch [10201/30000], Step [1/1], Training Loss: 479.3870, Valid Loss: 109.0762

[Epoch 15000] Rounded prediction: 
tensor([23., 25., 28., 21., 22., 23., 20., 22., 23., 21., 21., 17., 21., 15.,
        15.,  9.,  6.,  6.,  4.,  6.,  8., 11.,  8., 11.,  8.,  2.,  3.,  6.,
         6.,  4., 10.,  6.,  0.,  6.,  6.,  5.,  2.,  5.,  1.,  6.,  3., 26.,
        12., 10.,  2.,  4.,  1.,  5.,  3.,  3.,  5.,  5.,  8.,  6., 16.,  8.,
         3.,  2.,  5.,  4.,  5.,  6.,  5.,  7.,  4., 10., 10.,  9., 15., 14.,
         9.,  7., 13., 13., 13.,  9., 18., 26., 18., 15., 29., 17., 38., 41.,
        18., 25., 22., 21., 13., 13., 25., 44., 49., 53., 57., 41., 35., 41.,
        44., 41., 37., 44., 47., 26., 39.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([22., 22., 29., 23., 25., 25., 23., 24., 18., 21., 17., 22., 17., 13.,
        15.,  4., 13.,  1.,  6.,  6.,  2., 10.,  4.,  5., 17.,  1.,  0.,  1.,
         3.,  0.,  4., 11.,  1.,  2.,  0.,  3.,  1.,  1.,  3.,  3.,  0., 23.,
        11.,  7.,  8.,  1.,  0.,  1.,  2.,  4.,  4.,  3.,  3., 10., 15.,  7.,
         5.,  0.,  2.,  0.,  5.,  2., 12.,  1.,  8.,  6., 12.,  6.,  7., 20.,
         9.,  3., 10., 11., 13.,  1., 13., 26., 15., 15., 15., 15., 32., 21.,
        13., 21., 17., 22., 12.,  6., 25., 30., 38., 46., 44., 28., 36., 36.,
        38., 26., 38., 47., 23., 30., 48.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [10301/30000], Step [1/1], Training Loss: 457.4393, Valid Loss: 110.9905
Epoch [10401/30000], Step [1/1], Training Loss: 435.2235, Valid Loss: 104.2000
Epoch [10501/30000], Step [1/1], Training Loss: 5215.5732, Valid Loss: 92.6095
Epoch [10601/30000], Step [1/1], Training Loss: 1661.6941, Valid Loss: 99.6762
Epoch [10701/30000], Step [1/1], Training Loss: 1246.7249, Valid Loss: 85.1714
Epoch [10801/30000], Step [1/1], Training Loss: 805.9872, Valid Loss: 92.4667
Epoch [10901/30000], Step [1/1], Training Loss: 704.9074, Valid Loss: 101.5524
Epoch [11001/30000], Step [1/1], Training Loss: 582.4101, Valid Loss: 91.7810
Epoch [11101/30000], Step [1/1], Training Loss: 541.0278, Valid Loss: 96.3429
Epoch [11201/30000], Step [1/1], Training Loss: 506.1060, Valid Loss: 97.7048
Epoch [11301/30000], Step [1/1], Training Loss: 475.8904, Valid Loss: 86.0857
Epoch [11401/30000], Step [1/1], Training Loss: 458.1762, Valid Loss: 94.0762
Epoch [11501/30000], Step [1/1], Training Loss: 428.7581, Valid Loss: 90.8571
Epoch [11601/30000], Step [1/1], Training Loss: 409.4356, Valid Loss: 88.2762
Epoch [11701/30000], Step [1/1], Training Loss: 382.6125, Valid Loss: 91.8000
Epoch [11801/30000], Step [1/1], Training Loss: 369.3092, Valid Loss: 92.2667
Epoch [11901/30000], Step [1/1], Training Loss: 345.9262, Valid Loss: 98.0095
Epoch [12001/30000], Step [1/1], Training Loss: 324.5530, Valid Loss: 84.0952
Epoch [12101/30000], Step [1/1], Training Loss: 308.7691, Valid Loss: 96.1619
Epoch [12201/30000], Step [1/1], Training Loss: 288.9029, Valid Loss: 98.9619
Epoch [12301/30000], Step [1/1], Training Loss: 270.1191, Valid Loss: 96.9333
Epoch [12401/30000], Step [1/1], Training Loss: 251.0883, Valid Loss: 94.1429
Epoch [12501/30000], Step [1/1], Training Loss: 233.6140, Valid Loss: 93.1048
Epoch [12601/30000], Step [1/1], Training Loss: 215.9086, Valid Loss: 88.5429
Epoch [12701/30000], Step [1/1], Training Loss: 198.7754, Valid Loss: 93.7238
Epoch [12801/30000], Step [1/1], Training Loss: 183.2519, Valid Loss: 95.7143
Epoch [12901/30000], Step [1/1], Training Loss: 169.8020, Valid Loss: 92.1714
Epoch [13001/30000], Step [1/1], Training Loss: 156.7883, Valid Loss: 100.0381
Epoch [13101/30000], Step [1/1], Training Loss: 143.3125, Valid Loss: 92.5048
Epoch [13201/30000], Step [1/1], Training Loss: 131.4515, Valid Loss: 99.4952
Epoch [13301/30000], Step [1/1], Training Loss: 119.8437, Valid Loss: 108.4286
Epoch [13401/30000], Step [1/1], Training Loss: 106.2701, Valid Loss: 101.1810
Epoch [13501/30000], Step [1/1], Training Loss: 97.8834, Valid Loss: 102.1238
Epoch [13601/30000], Step [1/1], Training Loss: 87.9318, Valid Loss: 112.3048
Epoch [13701/30000], Step [1/1], Training Loss: 79.3112, Valid Loss: 109.1429
Epoch [13801/30000], Step [1/1], Training Loss: 70.9134, Valid Loss: 116.1429
Epoch [13901/30000], Step [1/1], Training Loss: 63.0762, Valid Loss: 107.7619
Epoch [14001/30000], Step [1/1], Training Loss: 54.9412, Valid Loss: 109.1429
Epoch [14101/30000], Step [1/1], Training Loss: 48.6381, Valid Loss: 112.5333
Epoch [14201/30000], Step [1/1], Training Loss: 40.7397, Valid Loss: 102.8191
Epoch [14301/30000], Step [1/1], Training Loss: 36.3332, Valid Loss: 107.8952
Epoch [14401/30000], Step [1/1], Training Loss: 32.2445, Valid Loss: 104.7619
Epoch [14501/30000], Step [1/1], Training Loss: 27.4399, Valid Loss: 113.0000
Epoch [14601/30000], Step [1/1], Training Loss: 23.9005, Valid Loss: 115.2191
Epoch [14701/30000], Step [1/1], Training Loss: 20.2334, Valid Loss: 109.7333
Epoch [14801/30000], Step [1/1], Training Loss: 16.5317, Valid Loss: 115.3905
Epoch [14901/30000], Step [1/1], Training Loss: 14.3778, Valid Loss: 109.5905
Epoch [15001/30000], Step [1/1], Training Loss: 12.5231, Valid Loss: 113.1238
Epoch [15101/30000], Step [1/1], Training Loss: 9.9328, Valid Loss: 113.8476
Epoch [15201/30000], Step [1/1], Training Loss: 8.5765, Valid Loss: 111.9810
Epoch [15301/30000], Step [1/1], Training Loss: 7.5298, Valid Loss: 110.5714
Epoch [15401/30000], Step [1/1], Training Loss: 6.3605, Valid Loss: 106.8952
Epoch [15501/30000], Step [1/1], Training Loss: 5.4384, Valid Loss: 117.4191
Epoch [15601/30000], Step [1/1], Training Loss: 5.0611, Valid Loss: 115.9143
Epoch [15701/30000], Step [1/1], Training Loss: 3.8444, Valid Loss: 103.6667
Epoch [15801/30000], Step [1/1], Training Loss: 3.4800, Valid Loss: 111.7619
Epoch [15901/30000], Step [1/1], Training Loss: 3.1614, Valid Loss: 108.7619
Epoch [16001/30000], Step [1/1], Training Loss: 3.7925, Valid Loss: 115.2000
Epoch [16101/30000], Step [1/1], Training Loss: 2.8452, Valid Loss: 115.5619
Epoch [16201/30000], Step [1/1], Training Loss: 2.0388, Valid Loss: 113.6572
Epoch [16301/30000], Step [1/1], Training Loss: 1.7322, Valid Loss: 117.0381
Epoch [16401/30000], Step [1/1], Training Loss: 2.6846, Valid Loss: 130.4667
Epoch [16501/30000], Step [1/1], Training Loss: 1.5620, Valid Loss: 116.3429
Epoch [16601/30000], Step [1/1], Training Loss: 1.2612, Valid Loss: 111.4286
Epoch [16701/30000], Step [1/1], Training Loss: 1.2542, Valid Loss: 132.0571
Epoch [16801/30000], Step [1/1], Training Loss: 1.5556, Valid Loss: 130.9143
Epoch [16901/30000], Step [1/1], Training Loss: 1.3151, Valid Loss: 114.8857
Epoch [17001/30000], Step [1/1], Training Loss: 15190.2197, Valid Loss: 219.6667
Epoch [17101/30000], Step [1/1], Training Loss: 696.5403, Valid Loss: 56.8000
Epoch [17201/30000], Step [1/1], Training Loss: 189.2238, Valid Loss: 65.4191
Epoch [17301/30000], Step [1/1], Training Loss: 126.6109, Valid Loss: 74.6000
Epoch [17401/30000], Step [1/1], Training Loss: 93.8933, Valid Loss: 80.2476
Epoch [17501/30000], Step [1/1], Training Loss: 84.1646, Valid Loss: 70.7429
Epoch [17601/30000], Step [1/1], Training Loss: 69.7964, Valid Loss: 77.9143
Epoch [17701/30000], Step [1/1], Training Loss: 59.5802, Valid Loss: 79.9524
Epoch [17801/30000], Step [1/1], Training Loss: 53.4690, Valid Loss: 78.5810
Epoch [17901/30000], Step [1/1], Training Loss: 48.2915, Valid Loss: 76.4286
Epoch [18001/30000], Step [1/1], Training Loss: 44.1422, Valid Loss: 69.9619
Epoch [18101/30000], Step [1/1], Training Loss: 40.6767, Valid Loss: 81.6857
Epoch [18201/30000], Step [1/1], Training Loss: 36.7392, Valid Loss: 80.2381
Epoch [18301/30000], Step [1/1], Training Loss: 31.2083, Valid Loss: 78.8952
Epoch [18401/30000], Step [1/1], Training Loss: 27.6974, Valid Loss: 80.0000
Epoch [18501/30000], Step [1/1], Training Loss: 27.3541, Valid Loss: 72.6762
Epoch [18601/30000], Step [1/1], Training Loss: 24.6836, Valid Loss: 76.9619
Epoch [18701/30000], Step [1/1], Training Loss: 23.1213, Valid Loss: 79.8286
Epoch [18801/30000], Step [1/1], Training Loss: 20.6919, Valid Loss: 84.3238
Epoch [18901/30000], Step [1/1], Training Loss: 19.3606, Valid Loss: 80.2476
Epoch [19001/30000], Step [1/1], Training Loss: 18.1367, Valid Loss: 79.0095
Epoch [19101/30000], Step [1/1], Training Loss: 13.7363, Valid Loss: 82.1238
Epoch [19201/30000], Step [1/1], Training Loss: 10.2249, Valid Loss: 77.1905
Epoch [19301/30000], Step [1/1], Training Loss: 11.5558, Valid Loss: 78.2476
Epoch [19401/30000], Step [1/1], Training Loss: 9.2579, Valid Loss: 77.1429
Epoch [19501/30000], Step [1/1], Training Loss: 9.5804, Valid Loss: 85.5429
Epoch [19601/30000], Step [1/1], Training Loss: 7.9520, Valid Loss: 83.1905
Epoch [19701/30000], Step [1/1], Training Loss: 6.4747, Valid Loss: 80.8286
Epoch [19801/30000], Step [1/1], Training Loss: 7.1865, Valid Loss: 85.5333
Epoch [19901/30000], Step [1/1], Training Loss: 4.8768, Valid Loss: 81.9048
Epoch [20001/30000], Step [1/1], Training Loss: 4.2698, Valid Loss: 82.4095
Epoch [20101/30000], Step [1/1], Training Loss: 4.5083, Valid Loss: 85.5048
Epoch [20201/30000], Step [1/1], Training Loss: 4.0808, Valid Loss: 84.2286
Epoch [20301/30000], Step [1/1], Training Loss: 2.8696, Valid Loss: 85.4191
Epoch [20401/30000], Step [1/1], Training Loss: 3.0994, Valid Loss: 81.7429
Epoch [20501/30000], Step [1/1], Training Loss: 2.5960, Valid Loss: 79.3714
Epoch [20601/30000], Step [1/1], Training Loss: 2.3681, Valid Loss: 78.9333
Epoch [20701/30000], Step [1/1], Training Loss: 2.5077, Valid Loss: 84.6476

[Epoch 25000] Rounded prediction: 
tensor([22., 20., 26., 22., 23., 25., 23., 27., 23., 26., 21., 27., 25., 18.,
        23.,  2., 12.,  3.,  4.,  7.,  5.,  8.,  8.,  9., 12.,  4.,  3.,  3.,
         6.,  4.,  8., 11.,  4.,  6.,  2.,  7.,  3.,  5.,  3.,  7.,  2., 24.,
        13., 10.,  7.,  5.,  2.,  4.,  5.,  6.,  5.,  4.,  5.,  9., 22.,  6.,
         6.,  2.,  5.,  2.,  7.,  6.,  8.,  8.,  4., 12.,  7., 14.,  7., 21.,
        11.,  4., 10., 12., 17.,  8., 11., 33., 14., 18., 16., 15., 38., 25.,
        12., 17., 15., 25., 17.,  3., 31., 33., 42., 47., 43., 30., 32., 36.,
        38., 34., 39., 47., 27., 24., 49.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [20801/30000], Step [1/1], Training Loss: 2.9500, Valid Loss: 82.0667
Epoch [20901/30000], Step [1/1], Training Loss: 2.1403, Valid Loss: 84.5905
Epoch [21001/30000], Step [1/1], Training Loss: 1.7212, Valid Loss: 81.2952
Epoch [21101/30000], Step [1/1], Training Loss: 1.6552, Valid Loss: 85.5333
Epoch [21201/30000], Step [1/1], Training Loss: 2.0847, Valid Loss: 85.6381
Epoch [21301/30000], Step [1/1], Training Loss: 1.6655, Valid Loss: 86.2952
Epoch [21401/30000], Step [1/1], Training Loss: 1.8468, Valid Loss: 90.6857
Epoch [21501/30000], Step [1/1], Training Loss: 1.6345, Valid Loss: 85.4762
Epoch [21601/30000], Step [1/1], Training Loss: 2.0954, Valid Loss: 85.5333
Epoch [21701/30000], Step [1/1], Training Loss: 1.9009, Valid Loss: 79.7905
Epoch [21801/30000], Step [1/1], Training Loss: 1.4071, Valid Loss: 90.7905
Epoch [21901/30000], Step [1/1], Training Loss: 1.3047, Valid Loss: 83.3143
Epoch [22001/30000], Step [1/1], Training Loss: 1.7551, Valid Loss: 92.7429
Epoch [22101/30000], Step [1/1], Training Loss: 2.5462, Valid Loss: 84.5810
Epoch [22201/30000], Step [1/1], Training Loss: 2.3911, Valid Loss: 83.2381
Epoch [22301/30000], Step [1/1], Training Loss: 1.6470, Valid Loss: 84.2571
Epoch [22401/30000], Step [1/1], Training Loss: 1.9346, Valid Loss: 87.8381
Epoch [22501/30000], Step [1/1], Training Loss: 1.2525, Valid Loss: 82.2857
Epoch [22601/30000], Step [1/1], Training Loss: 1.1423, Valid Loss: 87.9905
Epoch [22701/30000], Step [1/1], Training Loss: 1.3713, Valid Loss: 90.4762
Epoch [22801/30000], Step [1/1], Training Loss: 1.0211, Valid Loss: 87.4286
Epoch [22901/30000], Step [1/1], Training Loss: 0.8999, Valid Loss: 84.0571
Epoch [23001/30000], Step [1/1], Training Loss: 1.2905, Valid Loss: 79.5238
Epoch [23101/30000], Step [1/1], Training Loss: 1.1250, Valid Loss: 87.2381
Epoch [23201/30000], Step [1/1], Training Loss: 0.7173, Valid Loss: 85.4667
Epoch [23301/30000], Step [1/1], Training Loss: 0.7571, Valid Loss: 85.4286
Epoch [23401/30000], Step [1/1], Training Loss: 1.0146, Valid Loss: 90.0857
Epoch [23501/30000], Step [1/1], Training Loss: 0.8297, Valid Loss: 82.8476
Epoch [23601/30000], Step [1/1], Training Loss: 1.1756, Valid Loss: 86.5714
Epoch [23701/30000], Step [1/1], Training Loss: 1.3409, Valid Loss: 90.0952
Epoch [23801/30000], Step [1/1], Training Loss: 6.8724, Valid Loss: 83.5429
Epoch [23901/30000], Step [1/1], Training Loss: 0.9322, Valid Loss: 90.2571
Epoch [24001/30000], Step [1/1], Training Loss: 0.7042, Valid Loss: 89.2952
Epoch [24101/30000], Step [1/1], Training Loss: 0.9100, Valid Loss: 91.0286
Epoch [24201/30000], Step [1/1], Training Loss: 0.5811, Valid Loss: 90.6095
Epoch [24301/30000], Step [1/1], Training Loss: 0.5755, Valid Loss: 87.5905
Epoch [24401/30000], Step [1/1], Training Loss: 0.7796, Valid Loss: 90.6762
Epoch [24501/30000], Step [1/1], Training Loss: 1.2003, Valid Loss: 93.4095
Epoch [24601/30000], Step [1/1], Training Loss: 1.5145, Valid Loss: 95.4095
Epoch [24701/30000], Step [1/1], Training Loss: 0.3433, Valid Loss: 91.4095
Epoch [24801/30000], Step [1/1], Training Loss: 0.4670, Valid Loss: 94.4000
Epoch [24901/30000], Step [1/1], Training Loss: 0.6729, Valid Loss: 86.6476
Epoch [25001/30000], Step [1/1], Training Loss: 0.5139, Valid Loss: 96.8286
Epoch [25101/30000], Step [1/1], Training Loss: 0.6622, Valid Loss: 83.6476
Epoch [25201/30000], Step [1/1], Training Loss: 0.6627, Valid Loss: 85.5905
Epoch [25301/30000], Step [1/1], Training Loss: 0.4502, Valid Loss: 92.1238
Epoch [25401/30000], Step [1/1], Training Loss: 0.7912, Valid Loss: 89.5524
Epoch [25501/30000], Step [1/1], Training Loss: 0.7617, Valid Loss: 99.4191
Epoch [25601/30000], Step [1/1], Training Loss: 0.8956, Valid Loss: 91.4762
Epoch [25701/30000], Step [1/1], Training Loss: 0.5093, Valid Loss: 98.5048
Epoch [25801/30000], Step [1/1], Training Loss: 0.6070, Valid Loss: 98.2762
Epoch [25901/30000], Step [1/1], Training Loss: 0.3396, Valid Loss: 97.6286
Epoch [26001/30000], Step [1/1], Training Loss: 0.3118, Valid Loss: 99.4857
Epoch [26101/30000], Step [1/1], Training Loss: 0.2652, Valid Loss: 101.0191
Epoch [26201/30000], Step [1/1], Training Loss: 0.3572, Valid Loss: 94.5714
Epoch [26301/30000], Step [1/1], Training Loss: 0.2761, Valid Loss: 101.1143
Epoch [26401/30000], Step [1/1], Training Loss: 1.3267, Valid Loss: 100.4857
Epoch [26501/30000], Step [1/1], Training Loss: 0.7617, Valid Loss: 141.6095
Epoch [26601/30000], Step [1/1], Training Loss: 0.2836, Valid Loss: 129.8476
Epoch [26701/30000], Step [1/1], Training Loss: 0.3028, Valid Loss: 134.9238
Epoch [26801/30000], Step [1/1], Training Loss: 0.2747, Valid Loss: 127.8286
Epoch [26901/30000], Step [1/1], Training Loss: 0.4865, Valid Loss: 136.7714
Epoch [27001/30000], Step [1/1], Training Loss: 0.3767, Valid Loss: 134.2571
Epoch [27101/30000], Step [1/1], Training Loss: 0.2135, Valid Loss: 130.2571
Epoch [27201/30000], Step [1/1], Training Loss: 0.2310, Valid Loss: 133.9905
Epoch [27301/30000], Step [1/1], Training Loss: 0.4145, Valid Loss: 138.9429
Epoch [27401/30000], Step [1/1], Training Loss: 0.2698, Valid Loss: 121.8952
Epoch [27501/30000], Step [1/1], Training Loss: 0.1808, Valid Loss: 131.2381
Epoch [27601/30000], Step [1/1], Training Loss: 0.1861, Valid Loss: 133.6476
Epoch [27701/30000], Step [1/1], Training Loss: 0.2523, Valid Loss: 135.7048
Epoch [27801/30000], Step [1/1], Training Loss: 0.2994, Valid Loss: 145.0191
Epoch [27901/30000], Step [1/1], Training Loss: 0.3674, Valid Loss: 133.1905
Epoch [28001/30000], Step [1/1], Training Loss: 0.3219, Valid Loss: 133.9524
Epoch [28101/30000], Step [1/1], Training Loss: 0.1552, Valid Loss: 136.3238
Epoch [28201/30000], Step [1/1], Training Loss: 0.1883, Valid Loss: 140.8762
Epoch [28301/30000], Step [1/1], Training Loss: 0.8455, Valid Loss: 144.5714
Epoch [28401/30000], Step [1/1], Training Loss: 0.1673, Valid Loss: 141.6952
Epoch [28501/30000], Step [1/1], Training Loss: 0.1775, Valid Loss: 141.2762
Epoch [28601/30000], Step [1/1], Training Loss: 0.3434, Valid Loss: 146.9810
Epoch [28701/30000], Step [1/1], Training Loss: 0.1912, Valid Loss: 146.8190
Epoch [28801/30000], Step [1/1], Training Loss: 0.2913, Valid Loss: 145.2000
Epoch [28901/30000], Step [1/1], Training Loss: 0.1662, Valid Loss: 148.7238
Epoch [29001/30000], Step [1/1], Training Loss: 0.2417, Valid Loss: 136.0286
Epoch [29101/30000], Step [1/1], Training Loss: 0.1619, Valid Loss: 148.7619
Epoch [29201/30000], Step [1/1], Training Loss: 0.1862, Valid Loss: 141.9619
Epoch [29301/30000], Step [1/1], Training Loss: 0.2416, Valid Loss: 157.1048
Epoch [29401/30000], Step [1/1], Training Loss: 0.2325, Valid Loss: 142.9810
Epoch [29501/30000], Step [1/1], Training Loss: 0.1168, Valid Loss: 152.8000
Epoch [29601/30000], Step [1/1], Training Loss: 0.3728, Valid Loss: 166.4952
Epoch [29701/30000], Step [1/1], Training Loss: 0.1173, Valid Loss: 154.8952
Epoch [29801/30000], Step [1/1], Training Loss: 4704.4692, Valid Loss: 82.7905
Epoch [29901/30000], Step [1/1], Training Loss: 973.7737, Valid Loss: 133.8762

 End Time: 2021/04/19, 18:56:35




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=2048 	layers=2

Start Time = 2021/04/19, 18:56:35
##########################################################


[Epoch 0] Rounded prediction: 
tensor([3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 2., 2., 2., 2., 2., 2., 2., 2.,
        2., 2., 2., 1., 1., 2., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2.,
        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
        2., 2., 2., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 3., 3.],
       device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([23., 22., 24., 17., 15., 18., 16., 19., 19., 18., 18., 14., 13., 12.,
         9., 15.,  4., 10.,  3.,  8., 16., 13., 13., 19.,  7.,  1.,  7., 10.,
         9.,  9., 16.,  4.,  0., 13., 11.,  9.,  2.,  8.,  0., 11., 11., 30.,
        14., 16.,  1.,  0.,  4.,  8.,  6.,  5.,  4.,  7., 17.,  6., 24.,  9.,
         4.,  2.,  6., 10.,  6., 13.,  1., 13.,  1., 20.,  8., 19., 18., 12.,
         7., 10., 13., 12.,  8., 23., 18., 37., 15., 26., 30., 19., 41., 33.,
        23., 20., 14.,  8.,  8., 19., 33., 36., 48., 54., 51., 36., 33., 33.,
        36., 35., 42., 39., 33., 29., 32.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([28., 30., 34., 24., 25., 28., 25., 32., 30., 32., 28., 22., 24., 20.,
        15., 11.,  0.,  3.,  3.,  9., 14., 13., 14., 19.,  7.,  4.,  8.,  9.,
         9.,  9., 14.,  4.,  0., 12.,  9.,  6.,  4., 10.,  4.,  9.,  8., 26.,
        12., 10.,  4.,  3.,  5.,  8.,  6.,  7.,  8.,  9., 17.,  6., 26.,  6.,
         2.,  4.,  9., 10.,  6., 12.,  6., 13.,  7., 19., 10., 20., 18., 15.,
        18., 16., 16., 17., 17., 21., 10., 37., 13., 24., 34., 16., 47., 38.,
        16., 20., 22., 20., 18., 15., 27., 37., 47., 52., 53., 33., 28., 37.,
        40., 35., 39., 49., 38., 28., 35.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128620.8516, Valid Loss: 186.3905
Epoch [101/30000], Step [1/1], Training Loss: 110004.9453, Valid Loss: 1059.4857
Epoch [201/30000], Step [1/1], Training Loss: 102301.9453, Valid Loss: 2646.5811
Epoch [301/30000], Step [1/1], Training Loss: 95177.5312, Valid Loss: 74.3048
Epoch [401/30000], Step [1/1], Training Loss: 88598.0391, Valid Loss: 242.0476
Epoch [501/30000], Step [1/1], Training Loss: 82576.0547, Valid Loss: 490.2762
Epoch [601/30000], Step [1/1], Training Loss: 77059.3672, Valid Loss: 839.9048
Epoch [701/30000], Step [1/1], Training Loss: 72020.9297, Valid Loss: 890.5810
Epoch [801/30000], Step [1/1], Training Loss: 67437.5938, Valid Loss: 578.8191
Epoch [901/30000], Step [1/1], Training Loss: 63272.8555, Valid Loss: 449.9524
Epoch [1001/30000], Step [1/1], Training Loss: 59500.3320, Valid Loss: 371.4095
Epoch [1101/30000], Step [1/1], Training Loss: 55803.9609, Valid Loss: 240.2476
Epoch [1201/30000], Step [1/1], Training Loss: 52448.1523, Valid Loss: 201.8571
Epoch [1301/30000], Step [1/1], Training Loss: 49315.4531, Valid Loss: 227.0000
Epoch [1401/30000], Step [1/1], Training Loss: 46371.3125, Valid Loss: 164.4572
Epoch [1501/30000], Step [1/1], Training Loss: 43674.9297, Valid Loss: 166.5524
Epoch [1601/30000], Step [1/1], Training Loss: 41197.7969, Valid Loss: 182.3810
Epoch [1701/30000], Step [1/1], Training Loss: 38970.8281, Valid Loss: 220.3429
Epoch [1801/30000], Step [1/1], Training Loss: 36863.1133, Valid Loss: 202.8381
Epoch [1901/30000], Step [1/1], Training Loss: 34976.3438, Valid Loss: 206.1238
Epoch [2001/30000], Step [1/1], Training Loss: 33240.4219, Valid Loss: 187.1524
Epoch [2101/30000], Step [1/1], Training Loss: 31594.0645, Valid Loss: 177.8095
Epoch [2201/30000], Step [1/1], Training Loss: 29696.6641, Valid Loss: 191.3810
Epoch [2301/30000], Step [1/1], Training Loss: 27874.7637, Valid Loss: 202.9143
Epoch [2401/30000], Step [1/1], Training Loss: 26340.7793, Valid Loss: 136.8000
Epoch [2501/30000], Step [1/1], Training Loss: 24929.9863, Valid Loss: 124.0000
Epoch [2601/30000], Step [1/1], Training Loss: 23407.7852, Valid Loss: 133.7714
Epoch [2701/30000], Step [1/1], Training Loss: 22254.5957, Valid Loss: 136.3714
Epoch [2801/30000], Step [1/1], Training Loss: 20939.5781, Valid Loss: 114.1238
Epoch [2901/30000], Step [1/1], Training Loss: 19800.3828, Valid Loss: 106.1619
Epoch [3001/30000], Step [1/1], Training Loss: 18842.1465, Valid Loss: 121.1143
Epoch [3101/30000], Step [1/1], Training Loss: 17975.6094, Valid Loss: 108.4571
Epoch [3201/30000], Step [1/1], Training Loss: 17100.1504, Valid Loss: 114.0952
Epoch [3301/30000], Step [1/1], Training Loss: 16111.6436, Valid Loss: 106.6095
Epoch [3401/30000], Step [1/1], Training Loss: 15486.9443, Valid Loss: 112.7048
Epoch [3501/30000], Step [1/1], Training Loss: 14701.4131, Valid Loss: 95.8667
Epoch [3601/30000], Step [1/1], Training Loss: 14010.3408, Valid Loss: 128.9429
Epoch [3701/30000], Step [1/1], Training Loss: 13428.1006, Valid Loss: 126.7714
Epoch [3801/30000], Step [1/1], Training Loss: 12806.1709, Valid Loss: 114.7619
Epoch [3901/30000], Step [1/1], Training Loss: 12235.8311, Valid Loss: 111.0762
Epoch [4001/30000], Step [1/1], Training Loss: 11894.7188, Valid Loss: 107.3524
Epoch [4101/30000], Step [1/1], Training Loss: 11033.8545, Valid Loss: 105.2667
Epoch [4201/30000], Step [1/1], Training Loss: 10157.1035, Valid Loss: 103.5429
Epoch [4301/30000], Step [1/1], Training Loss: 9600.3477, Valid Loss: 104.7524
Epoch [4401/30000], Step [1/1], Training Loss: 8933.6807, Valid Loss: 101.0381
Epoch [4501/30000], Step [1/1], Training Loss: 8468.2139, Valid Loss: 101.5333
Epoch [4601/30000], Step [1/1], Training Loss: 8060.5146, Valid Loss: 115.8381
Epoch [4701/30000], Step [1/1], Training Loss: 7627.9971, Valid Loss: 116.5429
Epoch [4801/30000], Step [1/1], Training Loss: 7347.9023, Valid Loss: 106.1905
Epoch [4901/30000], Step [1/1], Training Loss: 6894.4497, Valid Loss: 109.2667
Epoch [5001/30000], Step [1/1], Training Loss: 6580.9692, Valid Loss: 95.2667
Epoch [5101/30000], Step [1/1], Training Loss: 6869.4893, Valid Loss: 147.4381
Epoch [5201/30000], Step [1/1], Training Loss: 6249.4492, Valid Loss: 146.0476
Epoch [5301/30000], Step [1/1], Training Loss: 5803.0205, Valid Loss: 131.3238
Epoch [5401/30000], Step [1/1], Training Loss: 5478.8164, Valid Loss: 114.5333
Epoch [5501/30000], Step [1/1], Training Loss: 5076.1172, Valid Loss: 120.6095
Epoch [5601/30000], Step [1/1], Training Loss: 4926.2637, Valid Loss: 112.5714
Epoch [5701/30000], Step [1/1], Training Loss: 4619.3589, Valid Loss: 117.4000
Epoch [5801/30000], Step [1/1], Training Loss: 4517.8345, Valid Loss: 115.1333
Epoch [5901/30000], Step [1/1], Training Loss: 4464.0229, Valid Loss: 96.0667
Epoch [6001/30000], Step [1/1], Training Loss: 4126.7002, Valid Loss: 112.8571
Epoch [6101/30000], Step [1/1], Training Loss: 3999.9575, Valid Loss: 106.6000
Epoch [6201/30000], Step [1/1], Training Loss: 3932.4243, Valid Loss: 116.9143
Epoch [6301/30000], Step [1/1], Training Loss: 3797.4153, Valid Loss: 106.3524
Epoch [6401/30000], Step [1/1], Training Loss: 3394.9031, Valid Loss: 111.0191
Epoch [6501/30000], Step [1/1], Training Loss: 3381.7871, Valid Loss: 121.2857
Epoch [6601/30000], Step [1/1], Training Loss: 2803.3574, Valid Loss: 125.5714
Epoch [6701/30000], Step [1/1], Training Loss: 2668.1147, Valid Loss: 145.8476
Epoch [6801/30000], Step [1/1], Training Loss: 2566.3918, Valid Loss: 130.0667
Epoch [6901/30000], Step [1/1], Training Loss: 2358.4941, Valid Loss: 113.7905
Epoch [7001/30000], Step [1/1], Training Loss: 2188.0432, Valid Loss: 123.6572
Epoch [7101/30000], Step [1/1], Training Loss: 2036.9211, Valid Loss: 128.6190
Epoch [7201/30000], Step [1/1], Training Loss: 1912.4167, Valid Loss: 119.8381
Epoch [7301/30000], Step [1/1], Training Loss: 1808.9307, Valid Loss: 125.8286
Epoch [7401/30000], Step [1/1], Training Loss: 1705.2562, Valid Loss: 129.7619
Epoch [7501/30000], Step [1/1], Training Loss: 1616.4978, Valid Loss: 137.1333
Epoch [7601/30000], Step [1/1], Training Loss: 1541.5630, Valid Loss: 127.2191
Epoch [7701/30000], Step [1/1], Training Loss: 1462.6948, Valid Loss: 124.9143
Epoch [7801/30000], Step [1/1], Training Loss: 1853.7245, Valid Loss: 172.3143
Epoch [7901/30000], Step [1/1], Training Loss: 1680.1774, Valid Loss: 155.4000
Epoch [8001/30000], Step [1/1], Training Loss: 1291.7911, Valid Loss: 138.8190
Epoch [8101/30000], Step [1/1], Training Loss: 1211.0591, Valid Loss: 135.4000
Epoch [8201/30000], Step [1/1], Training Loss: 1161.2462, Valid Loss: 141.9619
Epoch [8301/30000], Step [1/1], Training Loss: 1109.3988, Valid Loss: 144.5619
Epoch [8401/30000], Step [1/1], Training Loss: 1055.1991, Valid Loss: 135.8476
Epoch [8501/30000], Step [1/1], Training Loss: 1008.8661, Valid Loss: 141.6381
Epoch [8601/30000], Step [1/1], Training Loss: 963.4164, Valid Loss: 140.3905
Epoch [8701/30000], Step [1/1], Training Loss: 922.1251, Valid Loss: 134.4286
Epoch [8801/30000], Step [1/1], Training Loss: 881.9203, Valid Loss: 148.9238
Epoch [8901/30000], Step [1/1], Training Loss: 845.6133, Valid Loss: 141.6952
Epoch [9001/30000], Step [1/1], Training Loss: 810.1798, Valid Loss: 154.8571
Epoch [9101/30000], Step [1/1], Training Loss: 772.5582, Valid Loss: 154.5810
Epoch [9201/30000], Step [1/1], Training Loss: 741.6011, Valid Loss: 156.9333
Epoch [9301/30000], Step [1/1], Training Loss: 711.1579, Valid Loss: 153.1429
Epoch [9401/30000], Step [1/1], Training Loss: 681.5928, Valid Loss: 163.6286
Epoch [9501/30000], Step [1/1], Training Loss: 655.3566, Valid Loss: 163.1905
Epoch [9601/30000], Step [1/1], Training Loss: 630.1113, Valid Loss: 163.6000
Epoch [9701/30000], Step [1/1], Training Loss: 605.8282, Valid Loss: 169.6095
Epoch [9801/30000], Step [1/1], Training Loss: 577.3220, Valid Loss: 154.6572
Epoch [9901/30000], Step [1/1], Training Loss: 551.7296, Valid Loss: 153.3619
Epoch [10001/30000], Step [1/1], Training Loss: 528.9478, Valid Loss: 148.5048
Epoch [10101/30000], Step [1/1], Training Loss: 505.0913, Valid Loss: 156.7524
Epoch [10201/30000], Step [1/1], Training Loss: 715.1858, Valid Loss: 200.3143

[Epoch 15000] Rounded prediction: 
tensor([24., 24., 29., 21., 21., 26., 22., 30., 29., 36., 39., 40., 42., 33.,
        32., 22.,  6.,  7.,  0., 13., 18., 13., 16., 21.,  5.,  6.,  9.,  4.,
         9., 12., 13.,  5.,  0., 14.,  4.,  6.,  4.,  9.,  1., 11.,  4., 30.,
        12., 11.,  0.,  5.,  3.,  4.,  6.,  7.,  8., 10., 19.,  7., 32.,  4.,
         4.,  1., 10.,  7.,  6., 14.,  2., 17.,  5., 24.,  9., 29., 20., 18.,
        28., 22., 23., 28., 28., 26.,  9., 44.,  7., 31., 32., 15., 62., 40.,
        15., 30., 30., 30., 29., 21., 25., 35., 41., 45., 48., 36., 42., 46.,
        48., 36., 37., 44., 31., 22., 25.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([23., 21., 26., 23., 23., 24., 20., 27., 26., 32., 34., 40., 42., 41.,
        39., 40., 17., 17., 10., 18., 22., 16., 28., 21., 12., 17., 10.,  8.,
        16., 14., 14., 10.,  9., 16.,  3., 15.,  8., 15.,  4., 15.,  2., 31.,
        16., 18.,  6., 13.,  5.,  6., 11., 13., 13., 15., 21.,  8., 33.,  8.,
        15.,  7., 12., 11., 11., 18.,  7., 31.,  7., 29., 10., 36., 23., 22.,
        28., 22., 27., 30., 28., 33., 20., 41., 14., 44., 34., 16., 52., 29.,
        17., 35., 33., 28., 27., 33., 38., 27., 37., 45., 46., 38., 38., 38.,
        37., 38., 39., 44., 47., 27., 36.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [10301/30000], Step [1/1], Training Loss: 506.1065, Valid Loss: 181.2476
Epoch [10401/30000], Step [1/1], Training Loss: 462.3800, Valid Loss: 189.8476
Epoch [10501/30000], Step [1/1], Training Loss: 445.3530, Valid Loss: 169.7238
Epoch [10601/30000], Step [1/1], Training Loss: 416.8214, Valid Loss: 183.8095
Epoch [10701/30000], Step [1/1], Training Loss: 393.6379, Valid Loss: 172.1238
Epoch [10801/30000], Step [1/1], Training Loss: 373.1099, Valid Loss: 186.5810
Epoch [10901/30000], Step [1/1], Training Loss: 355.5539, Valid Loss: 180.3143
Epoch [11001/30000], Step [1/1], Training Loss: 336.8164, Valid Loss: 177.9143
Epoch [11101/30000], Step [1/1], Training Loss: 316.8167, Valid Loss: 188.9143
Epoch [11201/30000], Step [1/1], Training Loss: 299.1843, Valid Loss: 183.6190
Epoch [11301/30000], Step [1/1], Training Loss: 284.8583, Valid Loss: 183.7429
Epoch [11401/30000], Step [1/1], Training Loss: 264.2902, Valid Loss: 199.6572
Epoch [11501/30000], Step [1/1], Training Loss: 248.7558, Valid Loss: 198.6953
Epoch [11601/30000], Step [1/1], Training Loss: 231.2361, Valid Loss: 201.2952
Epoch [11701/30000], Step [1/1], Training Loss: 217.1234, Valid Loss: 198.8476
Epoch [11801/30000], Step [1/1], Training Loss: 417.9077, Valid Loss: 268.0286
Epoch [11901/30000], Step [1/1], Training Loss: 710.3994, Valid Loss: 152.8762
Epoch [12001/30000], Step [1/1], Training Loss: 231.3727, Valid Loss: 176.2857
Epoch [12101/30000], Step [1/1], Training Loss: 193.7307, Valid Loss: 192.4762
Epoch [12201/30000], Step [1/1], Training Loss: 169.7500, Valid Loss: 180.5810
Epoch [12301/30000], Step [1/1], Training Loss: 155.5907, Valid Loss: 187.6476
Epoch [12401/30000], Step [1/1], Training Loss: 138.7919, Valid Loss: 191.6667
Epoch [12501/30000], Step [1/1], Training Loss: 127.1306, Valid Loss: 187.6000
Epoch [12601/30000], Step [1/1], Training Loss: 121.4569, Valid Loss: 183.1048
Epoch [12701/30000], Step [1/1], Training Loss: 108.2870, Valid Loss: 188.6572
Epoch [12801/30000], Step [1/1], Training Loss: 105.5261, Valid Loss: 216.4381
Epoch [12901/30000], Step [1/1], Training Loss: 91.7879, Valid Loss: 209.3524
Epoch [13001/30000], Step [1/1], Training Loss: 80.0202, Valid Loss: 200.0667
Epoch [13101/30000], Step [1/1], Training Loss: 70.8572, Valid Loss: 221.4857
Epoch [13201/30000], Step [1/1], Training Loss: 63.8914, Valid Loss: 234.4286
Epoch [13301/30000], Step [1/1], Training Loss: 57.4806, Valid Loss: 217.3429
Epoch [13401/30000], Step [1/1], Training Loss: 50.6972, Valid Loss: 221.6476
Epoch [13501/30000], Step [1/1], Training Loss: 45.7117, Valid Loss: 220.2762
Epoch [13601/30000], Step [1/1], Training Loss: 42.0136, Valid Loss: 232.0857
Epoch [13701/30000], Step [1/1], Training Loss: 34.6425, Valid Loss: 241.1048
Epoch [13801/30000], Step [1/1], Training Loss: 31.1260, Valid Loss: 246.3619
Epoch [13901/30000], Step [1/1], Training Loss: 25.4785, Valid Loss: 236.6095
Epoch [14001/30000], Step [1/1], Training Loss: 22.7995, Valid Loss: 230.0667
Epoch [14101/30000], Step [1/1], Training Loss: 19.0095, Valid Loss: 234.2667
Epoch [14201/30000], Step [1/1], Training Loss: 18.0305, Valid Loss: 250.0762
Epoch [14301/30000], Step [1/1], Training Loss: 156.9682, Valid Loss: 193.2762
Epoch [14401/30000], Step [1/1], Training Loss: 46.6383, Valid Loss: 223.3429
Epoch [14501/30000], Step [1/1], Training Loss: 26.6154, Valid Loss: 202.7333
Epoch [14601/30000], Step [1/1], Training Loss: 24.1593, Valid Loss: 207.4857
Epoch [14701/30000], Step [1/1], Training Loss: 22.7361, Valid Loss: 207.8191
Epoch [14801/30000], Step [1/1], Training Loss: 16.8808, Valid Loss: 225.1333
Epoch [14901/30000], Step [1/1], Training Loss: 15.8486, Valid Loss: 233.7619
Epoch [15001/30000], Step [1/1], Training Loss: 12.3797, Valid Loss: 231.5810
Epoch [15101/30000], Step [1/1], Training Loss: 11.0773, Valid Loss: 227.7524
Epoch [15201/30000], Step [1/1], Training Loss: 10.5263, Valid Loss: 229.8000
Epoch [15301/30000], Step [1/1], Training Loss: 10.7338, Valid Loss: 217.3333
Epoch [15401/30000], Step [1/1], Training Loss: 7.8162, Valid Loss: 224.8571
Epoch [15501/30000], Step [1/1], Training Loss: 7.5052, Valid Loss: 233.6286
Epoch [15601/30000], Step [1/1], Training Loss: 6.4206, Valid Loss: 222.5714
Epoch [15701/30000], Step [1/1], Training Loss: 5.2190, Valid Loss: 235.8286
Epoch [15801/30000], Step [1/1], Training Loss: 4.7045, Valid Loss: 240.2572
Epoch [15901/30000], Step [1/1], Training Loss: 5.8080, Valid Loss: 240.1429
Epoch [16001/30000], Step [1/1], Training Loss: 4.0127, Valid Loss: 234.6953
Epoch [16101/30000], Step [1/1], Training Loss: 3.8512, Valid Loss: 247.7048
Epoch [16201/30000], Step [1/1], Training Loss: 3.4715, Valid Loss: 243.5524
Epoch [16301/30000], Step [1/1], Training Loss: 2.9877, Valid Loss: 249.6857
Epoch [16401/30000], Step [1/1], Training Loss: 2.3736, Valid Loss: 248.6953
Epoch [16501/30000], Step [1/1], Training Loss: 2.8721, Valid Loss: 258.8000
Epoch [16601/30000], Step [1/1], Training Loss: 2.0206, Valid Loss: 252.8476
Epoch [16701/30000], Step [1/1], Training Loss: 2.3493, Valid Loss: 261.9238
Epoch [16801/30000], Step [1/1], Training Loss: 2.7039, Valid Loss: 253.2762
Epoch [16901/30000], Step [1/1], Training Loss: 2.1780, Valid Loss: 260.0190
Epoch [17001/30000], Step [1/1], Training Loss: 2.0933, Valid Loss: 255.1333
Epoch [17101/30000], Step [1/1], Training Loss: 5.3943, Valid Loss: 264.7524
Epoch [17201/30000], Step [1/1], Training Loss: 2.2189, Valid Loss: 267.5429
Epoch [17301/30000], Step [1/1], Training Loss: 1.9324, Valid Loss: 262.0095
Epoch [17401/30000], Step [1/1], Training Loss: 2.1046, Valid Loss: 274.2381
Epoch [17501/30000], Step [1/1], Training Loss: 1.7396, Valid Loss: 276.6381
Epoch [17601/30000], Step [1/1], Training Loss: 1.6998, Valid Loss: 276.9429
Epoch [17701/30000], Step [1/1], Training Loss: 1.4651, Valid Loss: 279.5429
Epoch [17801/30000], Step [1/1], Training Loss: 1.3892, Valid Loss: 277.6667
Epoch [17901/30000], Step [1/1], Training Loss: 1.4419, Valid Loss: 278.2286
Epoch [18001/30000], Step [1/1], Training Loss: 1.3796, Valid Loss: 280.3333
Epoch [18101/30000], Step [1/1], Training Loss: 1.5008, Valid Loss: 281.8571
Epoch [18201/30000], Step [1/1], Training Loss: 1.2402, Valid Loss: 285.9143
Epoch [18301/30000], Step [1/1], Training Loss: 1.1609, Valid Loss: 286.4762
Epoch [18401/30000], Step [1/1], Training Loss: 1.5488, Valid Loss: 274.0952
Epoch [18501/30000], Step [1/1], Training Loss: 0.8926, Valid Loss: 291.0095
Epoch [18601/30000], Step [1/1], Training Loss: 1.1411, Valid Loss: 291.9333
Epoch [18701/30000], Step [1/1], Training Loss: 0.8861, Valid Loss: 297.2476
Epoch [18801/30000], Step [1/1], Training Loss: 1.3559, Valid Loss: 303.7524
Epoch [18901/30000], Step [1/1], Training Loss: 1.0189, Valid Loss: 279.4667
Epoch [19001/30000], Step [1/1], Training Loss: 1.1866, Valid Loss: 289.5334
Epoch [19101/30000], Step [1/1], Training Loss: 0.7893, Valid Loss: 301.5619
Epoch [19201/30000], Step [1/1], Training Loss: 1.1652, Valid Loss: 280.3333
Epoch [19301/30000], Step [1/1], Training Loss: 0.8354, Valid Loss: 297.9524
Epoch [19401/30000], Step [1/1], Training Loss: 1.1223, Valid Loss: 289.9714
Epoch [19501/30000], Step [1/1], Training Loss: 0.9317, Valid Loss: 296.1714
Epoch [19601/30000], Step [1/1], Training Loss: 0.8912, Valid Loss: 274.9048
Epoch [19701/30000], Step [1/1], Training Loss: 0.9867, Valid Loss: 287.7810
Epoch [19801/30000], Step [1/1], Training Loss: 709.1304, Valid Loss: 280.4286
Epoch [19901/30000], Step [1/1], Training Loss: 40.6099, Valid Loss: 279.9619
Epoch [20001/30000], Step [1/1], Training Loss: 25.4620, Valid Loss: 262.2571
Epoch [20101/30000], Step [1/1], Training Loss: 26.3599, Valid Loss: 259.0857
Epoch [20201/30000], Step [1/1], Training Loss: 18.3854, Valid Loss: 271.5334
Epoch [20301/30000], Step [1/1], Training Loss: 14.2004, Valid Loss: 272.9238
Epoch [20401/30000], Step [1/1], Training Loss: 11.5576, Valid Loss: 266.5619
Epoch [20501/30000], Step [1/1], Training Loss: 11.4830, Valid Loss: 280.5714
Epoch [20601/30000], Step [1/1], Training Loss: 10.8598, Valid Loss: 279.4000

[Epoch 25000] Rounded prediction: 
tensor([21., 20., 28., 23., 22., 26., 22., 30., 30., 37., 40., 47., 50., 48.,
        46., 37., 18., 18.,  4., 16., 16., 15., 22., 21., 11., 15.,  9.,  6.,
        15., 13., 13.,  9.,  8., 14.,  3., 12., 10., 12.,  5., 12.,  3., 30.,
        16., 14.,  4., 11.,  6.,  7., 12., 16., 15., 16., 18., 10., 36.,  6.,
        10.,  8., 12.,  9., 10., 17.,  9., 24.,  9., 26., 13., 33., 23., 28.,
        37., 22., 23., 28., 32., 29., 14., 47., 18., 41., 31., 23., 54., 36.,
        22., 38., 36., 39., 34., 39., 41., 33., 44., 54., 56., 46., 46., 46.,
        43., 42., 42., 48., 51., 31., 31.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [20701/30000], Step [1/1], Training Loss: 9.3766, Valid Loss: 281.5810
Epoch [20801/30000], Step [1/1], Training Loss: 7.7565, Valid Loss: 271.2381
Epoch [20901/30000], Step [1/1], Training Loss: 7.1625, Valid Loss: 272.0381
Epoch [21001/30000], Step [1/1], Training Loss: 6.9210, Valid Loss: 272.6190
Epoch [21101/30000], Step [1/1], Training Loss: 6.2961, Valid Loss: 276.9429
Epoch [21201/30000], Step [1/1], Training Loss: 5.2173, Valid Loss: 273.5143
Epoch [21301/30000], Step [1/1], Training Loss: 4.7774, Valid Loss: 280.2191
Epoch [21401/30000], Step [1/1], Training Loss: 5.8559, Valid Loss: 284.1333
Epoch [21501/30000], Step [1/1], Training Loss: 4.4866, Valid Loss: 287.7619
Epoch [21601/30000], Step [1/1], Training Loss: 4.3832, Valid Loss: 286.4000
Epoch [21701/30000], Step [1/1], Training Loss: 3.7073, Valid Loss: 292.4952
Epoch [21801/30000], Step [1/1], Training Loss: 3.0598, Valid Loss: 289.5048
Epoch [21901/30000], Step [1/1], Training Loss: 2.2043, Valid Loss: 292.8667
Epoch [22001/30000], Step [1/1], Training Loss: 2.0525, Valid Loss: 282.3143
Epoch [22101/30000], Step [1/1], Training Loss: 2.0245, Valid Loss: 282.3524
Epoch [22201/30000], Step [1/1], Training Loss: 3.3130, Valid Loss: 281.1524
Epoch [22301/30000], Step [1/1], Training Loss: 2.0859, Valid Loss: 292.7905
Epoch [22401/30000], Step [1/1], Training Loss: 1.5307, Valid Loss: 299.6857
Epoch [22501/30000], Step [1/1], Training Loss: 1.8098, Valid Loss: 301.2476
Epoch [22601/30000], Step [1/1], Training Loss: 1.8784, Valid Loss: 285.6762
Epoch [22701/30000], Step [1/1], Training Loss: 1.3454, Valid Loss: 300.0000
Epoch [22801/30000], Step [1/1], Training Loss: 1.3936, Valid Loss: 305.8667
Epoch [22901/30000], Step [1/1], Training Loss: 1.4307, Valid Loss: 315.3810
Epoch [23001/30000], Step [1/1], Training Loss: 1.5357, Valid Loss: 311.9905
Epoch [23101/30000], Step [1/1], Training Loss: 1.0698, Valid Loss: 314.5714
Epoch [23201/30000], Step [1/1], Training Loss: 1.0474, Valid Loss: 316.0000
Epoch [23301/30000], Step [1/1], Training Loss: 1.3589, Valid Loss: 310.7905
Epoch [23401/30000], Step [1/1], Training Loss: 1.3069, Valid Loss: 318.3905
Epoch [23501/30000], Step [1/1], Training Loss: 1.1277, Valid Loss: 319.6000
Epoch [23601/30000], Step [1/1], Training Loss: 0.9363, Valid Loss: 325.9143
Epoch [23701/30000], Step [1/1], Training Loss: 1.0871, Valid Loss: 311.1048
Epoch [23801/30000], Step [1/1], Training Loss: 1.3605, Valid Loss: 307.9333
Epoch [23901/30000], Step [1/1], Training Loss: 1.1091, Valid Loss: 316.7524
Epoch [24001/30000], Step [1/1], Training Loss: 0.7287, Valid Loss: 320.5238
Epoch [24101/30000], Step [1/1], Training Loss: 1.0440, Valid Loss: 330.2000
Epoch [24201/30000], Step [1/1], Training Loss: 1.1767, Valid Loss: 328.1143
Epoch [24301/30000], Step [1/1], Training Loss: 1.2315, Valid Loss: 328.9524
Epoch [24401/30000], Step [1/1], Training Loss: 0.9940, Valid Loss: 318.1429
Epoch [24501/30000], Step [1/1], Training Loss: 0.6486, Valid Loss: 321.0381
Epoch [24601/30000], Step [1/1], Training Loss: 0.8547, Valid Loss: 335.5905
Epoch [24701/30000], Step [1/1], Training Loss: 1.0237, Valid Loss: 331.0286
Epoch [24801/30000], Step [1/1], Training Loss: 0.9642, Valid Loss: 309.9810
Epoch [24901/30000], Step [1/1], Training Loss: 0.8709, Valid Loss: 319.7143
Epoch [25001/30000], Step [1/1], Training Loss: 1.4942, Valid Loss: 321.0191
Epoch [25101/30000], Step [1/1], Training Loss: 0.6185, Valid Loss: 334.3714
Epoch [25201/30000], Step [1/1], Training Loss: 0.8483, Valid Loss: 344.2857
Epoch [25301/30000], Step [1/1], Training Loss: 1.3675, Valid Loss: 355.7048
Epoch [25401/30000], Step [1/1], Training Loss: 0.6935, Valid Loss: 307.7619
Epoch [25501/30000], Step [1/1], Training Loss: 0.8442, Valid Loss: 378.5619
Epoch [25601/30000], Step [1/1], Training Loss: 0.6172, Valid Loss: 338.7429
Epoch [25701/30000], Step [1/1], Training Loss: 0.7843, Valid Loss: 341.6000
Epoch [25801/30000], Step [1/1], Training Loss: 0.5474, Valid Loss: 340.5334
Epoch [25901/30000], Step [1/1], Training Loss: 0.9510, Valid Loss: 353.1619
Epoch [26001/30000], Step [1/1], Training Loss: 309.0083, Valid Loss: 193.4952
Epoch [26101/30000], Step [1/1], Training Loss: 66.7547, Valid Loss: 205.8000
Epoch [26201/30000], Step [1/1], Training Loss: 31.9943, Valid Loss: 199.7619
Epoch [26301/30000], Step [1/1], Training Loss: 16.3123, Valid Loss: 206.4952
Epoch [26401/30000], Step [1/1], Training Loss: 13.4517, Valid Loss: 187.4095
Epoch [26501/30000], Step [1/1], Training Loss: 9.9721, Valid Loss: 193.2572
Epoch [26601/30000], Step [1/1], Training Loss: 10.4424, Valid Loss: 200.7619
Epoch [26701/30000], Step [1/1], Training Loss: 6.7111, Valid Loss: 193.5143
Epoch [26801/30000], Step [1/1], Training Loss: 10.0551, Valid Loss: 183.5333
Epoch [26901/30000], Step [1/1], Training Loss: 6.6802, Valid Loss: 195.9238
Epoch [27001/30000], Step [1/1], Training Loss: 5.9580, Valid Loss: 190.1714
Epoch [27101/30000], Step [1/1], Training Loss: 5.0900, Valid Loss: 180.8952
Epoch [27201/30000], Step [1/1], Training Loss: 4.1151, Valid Loss: 183.3714
Epoch [27301/30000], Step [1/1], Training Loss: 4.0011, Valid Loss: 181.8095
Epoch [27401/30000], Step [1/1], Training Loss: 3.8512, Valid Loss: 178.0381
Epoch [27501/30000], Step [1/1], Training Loss: 3.3666, Valid Loss: 186.6286
Epoch [27601/30000], Step [1/1], Training Loss: 3.9859, Valid Loss: 174.0667
Epoch [27701/30000], Step [1/1], Training Loss: 3.0951, Valid Loss: 182.2095
Epoch [27801/30000], Step [1/1], Training Loss: 3.1281, Valid Loss: 179.6000
Epoch [27901/30000], Step [1/1], Training Loss: 2.2059, Valid Loss: 186.8476
Epoch [28001/30000], Step [1/1], Training Loss: 2.6796, Valid Loss: 184.3810
Epoch [28101/30000], Step [1/1], Training Loss: 2.5122, Valid Loss: 187.6381
Epoch [28201/30000], Step [1/1], Training Loss: 2.3701, Valid Loss: 189.2952
Epoch [28301/30000], Step [1/1], Training Loss: 2.1391, Valid Loss: 188.9048
Epoch [28401/30000], Step [1/1], Training Loss: 1.7093, Valid Loss: 176.3143
Epoch [28501/30000], Step [1/1], Training Loss: 1.5035, Valid Loss: 184.2952
Epoch [28601/30000], Step [1/1], Training Loss: 2.3897, Valid Loss: 188.0191
Epoch [28701/30000], Step [1/1], Training Loss: 1.6952, Valid Loss: 184.6286
Epoch [28801/30000], Step [1/1], Training Loss: 1.7352, Valid Loss: 183.4381
Epoch [28901/30000], Step [1/1], Training Loss: 1.4416, Valid Loss: 182.2191
Epoch [29001/30000], Step [1/1], Training Loss: 1.9268, Valid Loss: 185.2762
Epoch [29101/30000], Step [1/1], Training Loss: 1.3766, Valid Loss: 184.2000
Epoch [29201/30000], Step [1/1], Training Loss: 1.5825, Valid Loss: 188.8381
Epoch [29301/30000], Step [1/1], Training Loss: 1.6462, Valid Loss: 183.0286
Epoch [29401/30000], Step [1/1], Training Loss: 1.0523, Valid Loss: 187.1714
Epoch [29501/30000], Step [1/1], Training Loss: 1.5033, Valid Loss: 179.6572
Epoch [29601/30000], Step [1/1], Training Loss: 0.9843, Valid Loss: 188.7524
Epoch [29701/30000], Step [1/1], Training Loss: 1.2347, Valid Loss: 177.0857
Epoch [29801/30000], Step [1/1], Training Loss: 0.8837, Valid Loss: 189.0286
Epoch [29901/30000], Step [1/1], Training Loss: 0.9731, Valid Loss: 190.2952

 End Time: 2021/04/19, 19:29:38




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=2048 	layers=3

Start Time = 2021/04/19, 21:12:49
##########################################################


[Epoch 0] Rounded prediction: 
tensor([3., 3., 3., 3., 3., 3., 3., 2., 2., 3., 2., 2., 2., 2., 2., 2., 2., 2.,
        2., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2.,
        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3., 3., 3., 3.],
       device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([19., 19., 21., 18., 14., 20., 29., 29., 26., 31., 27., 30., 33., 32.,
        32., 26., 31., 28.,  7., 23., 23., 38., 10., 18., 32.,  2., 34., 34.,
        22., 34.,  4., 19., 17.,  6., 10., 18.,  0.,  5.,  0., 22.,  7., 22.,
         6., 16.,  8.,  3., 15., 22., 16., 20.,  0., 18.,  8., 13., 16.,  4.,
        40., 17., 31., 18., 24., 25.,  0.,  4.,  4., 18.,  0., 38.,  4., 30.,
         0.,  0.,  6.,  2.,  0., 23., 15., 52., 60., 29., 34., 30., 40., 48.,
        47., 32., 32., 10., 21., 13., 18., 28., 64., 56., 45., 48., 50., 47.,
        48., 50., 53., 52., 51., 52., 42.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128657.2656, Valid Loss: 190.1143
Epoch [101/30000], Step [1/1], Training Loss: 110052.1406, Valid Loss: 1060.5906
Epoch [201/30000], Step [1/1], Training Loss: 102363.1719, Valid Loss: 2676.6096
Epoch [301/30000], Step [1/1], Training Loss: 95276.6641, Valid Loss: 138.2191
Epoch [401/30000], Step [1/1], Training Loss: 88681.6094, Valid Loss: 90.8286
Epoch [501/30000], Step [1/1], Training Loss: 82666.3281, Valid Loss: 133.5905
Epoch [601/30000], Step [1/1], Training Loss: 77166.5781, Valid Loss: 187.8952
Epoch [701/30000], Step [1/1], Training Loss: 72132.1875, Valid Loss: 278.7143
Epoch [801/30000], Step [1/1], Training Loss: 67424.1172, Valid Loss: 177.2191
Epoch [901/30000], Step [1/1], Training Loss: 63214.9883, Valid Loss: 161.5048
Epoch [1001/30000], Step [1/1], Training Loss: 59395.4688, Valid Loss: 219.9429
Epoch [1101/30000], Step [1/1], Training Loss: 55789.9414, Valid Loss: 159.7905
Epoch [1201/30000], Step [1/1], Training Loss: 52477.7773, Valid Loss: 159.4000
Epoch [1301/30000], Step [1/1], Training Loss: 49333.5508, Valid Loss: 176.9048
Epoch [1401/30000], Step [1/1], Training Loss: 46430.9883, Valid Loss: 149.5333
Epoch [1501/30000], Step [1/1], Training Loss: 43644.9883, Valid Loss: 152.4572
Epoch [1601/30000], Step [1/1], Training Loss: 41152.7930, Valid Loss: 139.7524
Epoch [1701/30000], Step [1/1], Training Loss: 38837.3320, Valid Loss: 177.5810
Epoch [1801/30000], Step [1/1], Training Loss: 36807.8906, Valid Loss: 146.9810
Epoch [1901/30000], Step [1/1], Training Loss: 35195.6406, Valid Loss: 151.7333
Epoch [2001/30000], Step [1/1], Training Loss: 32710.2148, Valid Loss: 191.4857
Epoch [2101/30000], Step [1/1], Training Loss: 30866.8105, Valid Loss: 273.6476
Epoch [2201/30000], Step [1/1], Training Loss: 28886.5586, Valid Loss: 215.3619
Epoch [2301/30000], Step [1/1], Training Loss: 27251.7617, Valid Loss: 329.8953
Epoch [2401/30000], Step [1/1], Training Loss: 25741.6602, Valid Loss: 329.7238
Epoch [2501/30000], Step [1/1], Training Loss: 24348.1836, Valid Loss: 289.0476
Epoch [2601/30000], Step [1/1], Training Loss: 23065.4336, Valid Loss: 361.5810
Epoch [2701/30000], Step [1/1], Training Loss: 21817.2070, Valid Loss: 285.6095
Epoch [2801/30000], Step [1/1], Training Loss: 20690.9766, Valid Loss: 325.5048
Epoch [2901/30000], Step [1/1], Training Loss: 19798.9766, Valid Loss: 369.4095
Epoch [3001/30000], Step [1/1], Training Loss: 18584.3496, Valid Loss: 318.5619
Epoch [3101/30000], Step [1/1], Training Loss: 17792.6270, Valid Loss: 295.1238
Epoch [3201/30000], Step [1/1], Training Loss: 16637.7051, Valid Loss: 249.7524
Epoch [3301/30000], Step [1/1], Training Loss: 15712.2246, Valid Loss: 299.2191
Epoch [3401/30000], Step [1/1], Training Loss: 14835.9922, Valid Loss: 328.9810
Epoch [3501/30000], Step [1/1], Training Loss: 14175.4932, Valid Loss: 317.1238
Epoch [3601/30000], Step [1/1], Training Loss: 13415.4141, Valid Loss: 234.1143
Epoch [3701/30000], Step [1/1], Training Loss: 12993.4629, Valid Loss: 306.0191
Epoch [3801/30000], Step [1/1], Training Loss: 12176.9346, Valid Loss: 327.2571
Epoch [3901/30000], Step [1/1], Training Loss: 11507.6719, Valid Loss: 339.6190
Epoch [4001/30000], Step [1/1], Training Loss: 10952.7646, Valid Loss: 348.5334
Epoch [4101/30000], Step [1/1], Training Loss: 10427.5791, Valid Loss: 373.0191
Epoch [4201/30000], Step [1/1], Training Loss: 9868.4590, Valid Loss: 391.1143
Epoch [4301/30000], Step [1/1], Training Loss: 9592.9121, Valid Loss: 320.7524
Epoch [4401/30000], Step [1/1], Training Loss: 9692.0244, Valid Loss: 446.5905
Epoch [4501/30000], Step [1/1], Training Loss: 8180.8564, Valid Loss: 398.1143
Epoch [4601/30000], Step [1/1], Training Loss: 7736.3154, Valid Loss: 355.7905
Epoch [4701/30000], Step [1/1], Training Loss: 7352.8252, Valid Loss: 332.9905
Epoch [4801/30000], Step [1/1], Training Loss: 7038.3467, Valid Loss: 436.1810
Epoch [4901/30000], Step [1/1], Training Loss: 6534.8354, Valid Loss: 325.3905
Epoch [5001/30000], Step [1/1], Training Loss: 6174.7290, Valid Loss: 323.1333
Epoch [5101/30000], Step [1/1], Training Loss: 5856.5542, Valid Loss: 354.9810
Epoch [5201/30000], Step [1/1], Training Loss: 5562.1001, Valid Loss: 329.8953
Epoch [5301/30000], Step [1/1], Training Loss: 5369.8726, Valid Loss: 397.8762
Epoch [5401/30000], Step [1/1], Training Loss: 5050.3491, Valid Loss: 370.9333
Epoch [5501/30000], Step [1/1], Training Loss: 4638.7319, Valid Loss: 314.4000
Epoch [5601/30000], Step [1/1], Training Loss: 4353.0063, Valid Loss: 370.3048
Epoch [5701/30000], Step [1/1], Training Loss: 4103.2568, Valid Loss: 323.2000
Epoch [5801/30000], Step [1/1], Training Loss: 3871.1504, Valid Loss: 276.8762
Epoch [5901/30000], Step [1/1], Training Loss: 3657.3083, Valid Loss: 319.4286
Epoch [6001/30000], Step [1/1], Training Loss: 3455.8618, Valid Loss: 315.2095
Epoch [6101/30000], Step [1/1], Training Loss: 3264.8596, Valid Loss: 298.1333
Epoch [6201/30000], Step [1/1], Training Loss: 3085.0203, Valid Loss: 331.4000
Epoch [6301/30000], Step [1/1], Training Loss: 2916.9697, Valid Loss: 326.6572
Epoch [6401/30000], Step [1/1], Training Loss: 2796.0806, Valid Loss: 335.0095
Epoch [6501/30000], Step [1/1], Training Loss: 2611.4570, Valid Loss: 312.6953
Epoch [6601/30000], Step [1/1], Training Loss: 2467.2537, Valid Loss: 294.1619
Epoch [6701/30000], Step [1/1], Training Loss: 2332.0017, Valid Loss: 329.6857
Epoch [6801/30000], Step [1/1], Training Loss: 2204.4641, Valid Loss: 333.5429




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=2048 	layers=2

Start Time = 2021/04/19, 21:28:12
##########################################################


[Epoch 0] Rounded prediction: 
tensor([2., 2., 2., 2., 2., 3., 2., 3., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2.,
        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],
       device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128654.1562, Valid Loss: 193.2952
Epoch [101/30000], Step [1/1], Training Loss: 110202.1328, Valid Loss: 1025.7524
Epoch [201/30000], Step [1/1], Training Loss: 102483.6172, Valid Loss: 2598.2859




##########################################################

Epochs=30000 	batch=245 	lr=6e-05
window=2 	seq_len=7 	hidden_size=1024 	layers=2

Start Time = 2021/04/20, 00:57:21
##########################################################


[Epoch 0] Rounded prediction: 
tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],
       device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([18., 17., 25., 22., 24., 29., 26., 35., 30., 32., 30., 28., 32., 28.,
        27., 18., 14., 18., 11., 15., 14., 13., 12., 19., 13.,  7., 10., 11.,
        11., 11., 14., 10.,  6., 13., 11.,  9.,  7., 10.,  5., 11., 11., 20.,
        25., 19., 10.,  9.,  9.,  8.,  8.,  8., 10.,  9., 13., 10., 19., 19.,
        10.,  8.,  9., 11.,  8., 13.,  8., 12.,  7., 14., 10., 13., 18., 12.,
         8.,  8.,  8.,  7.,  7., 20., 17., 29., 28., 26., 25., 17., 29., 28.,
        20., 12.,  9.,  6.,  6., 12., 21., 37., 53., 55., 47., 32., 22., 22.,
        23., 27., 27., 27., 26., 30., 26.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([21., 20., 24., 21., 22., 25., 22., 30., 25., 27., 30., 31., 34., 29.,
        27., 20., 22., 28., 12., 16.,  9.,  7., 11.,  9.,  4.,  5.,  4.,  3.,
         7.,  9.,  6.,  3.,  2.,  6.,  1.,  9.,  3.,  7.,  0., 15.,  1., 18.,
        18., 15.,  0., 10.,  0.,  9.,  4.,  7.,  6.,  6.,  7.,  3., 21.,  8.,
        10.,  0.,  9.,  4.,  4., 11.,  0., 11.,  0., 11.,  0., 11.,  6.,  5.,
         3.,  2.,  4.,  5.,  9., 17.,  8., 28., 17., 23., 14.,  9., 16., 12.,
        12.,  9.,  7., 11., 16., 15., 15., 31., 52., 50., 39., 24., 16., 16.,
        20., 30., 35., 33., 33., 34., 35.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128648.4531, Valid Loss: 230.1619
Epoch [101/30000], Step [1/1], Training Loss: 118656.4688, Valid Loss: 193.5905
Epoch [201/30000], Step [1/1], Training Loss: 115843.0000, Valid Loss: 384.5905
Epoch [301/30000], Step [1/1], Training Loss: 113219.4922, Valid Loss: 626.3048
Epoch [401/30000], Step [1/1], Training Loss: 110725.4375, Valid Loss: 940.0191
Epoch [501/30000], Step [1/1], Training Loss: 108337.2656, Valid Loss: 1325.7334
Epoch [601/30000], Step [1/1], Training Loss: 106031.9375, Valid Loss: 1783.4476
Epoch [701/30000], Step [1/1], Training Loss: 103813.9375, Valid Loss: 2307.4097
Epoch [801/30000], Step [1/1], Training Loss: 101671.6484, Valid Loss: 2757.0571
Epoch [901/30000], Step [1/1], Training Loss: 99604.5156, Valid Loss: 1559.8762
Epoch [1001/30000], Step [1/1], Training Loss: 97310.3984, Valid Loss: 56.5905
Epoch [1101/30000], Step [1/1], Training Loss: 95225.5312, Valid Loss: 58.2286
Epoch [1201/30000], Step [1/1], Training Loss: 93199.8750, Valid Loss: 62.4667
Epoch [1301/30000], Step [1/1], Training Loss: 91219.5391, Valid Loss: 72.2000
Epoch [1401/30000], Step [1/1], Training Loss: 89290.7031, Valid Loss: 89.1905
Epoch [1501/30000], Step [1/1], Training Loss: 87399.0625, Valid Loss: 146.9524
Epoch [1601/30000], Step [1/1], Training Loss: 85552.3125, Valid Loss: 142.5810
Epoch [1701/30000], Step [1/1], Training Loss: 83752.5234, Valid Loss: 192.5143
Epoch [1801/30000], Step [1/1], Training Loss: 81994.6641, Valid Loss: 191.2857
Epoch [1901/30000], Step [1/1], Training Loss: 80280.8750, Valid Loss: 195.1143
Epoch [2001/30000], Step [1/1], Training Loss: 78606.4219, Valid Loss: 247.6000
Epoch [2101/30000], Step [1/1], Training Loss: 76972.5234, Valid Loss: 306.7238
Epoch [2201/30000], Step [1/1], Training Loss: 75375.2422, Valid Loss: 297.3333
Epoch [2301/30000], Step [1/1], Training Loss: 73817.0469, Valid Loss: 344.4857
Epoch [2401/30000], Step [1/1], Training Loss: 72296.1094, Valid Loss: 341.6190
Epoch [2501/30000], Step [1/1], Training Loss: 70811.4453, Valid Loss: 323.3238
Epoch [2601/30000], Step [1/1], Training Loss: 69366.8906, Valid Loss: 370.2857
Epoch [2701/30000], Step [1/1], Training Loss: 67952.6875, Valid Loss: 340.8857
Epoch [2801/30000], Step [1/1], Training Loss: 66567.2656, Valid Loss: 197.0571
Epoch [2901/30000], Step [1/1], Training Loss: 65170.3945, Valid Loss: 203.3429
Epoch [3001/30000], Step [1/1], Training Loss: 63843.1641, Valid Loss: 223.5524
Epoch [3101/30000], Step [1/1], Training Loss: 62553.0664, Valid Loss: 228.4381
Epoch [3201/30000], Step [1/1], Training Loss: 61296.6172, Valid Loss: 246.1810
Epoch [3301/30000], Step [1/1], Training Loss: 60072.8633, Valid Loss: 217.6095
Epoch [3401/30000], Step [1/1], Training Loss: 58844.5781, Valid Loss: 266.9714
Epoch [3501/30000], Step [1/1], Training Loss: 57627.9453, Valid Loss: 231.8667
Epoch [3601/30000], Step [1/1], Training Loss: 56445.0273, Valid Loss: 222.6667
Epoch [3701/30000], Step [1/1], Training Loss: 55261.6406, Valid Loss: 197.0762
Epoch [3801/30000], Step [1/1], Training Loss: 54106.8906, Valid Loss: 184.6095
Epoch [3901/30000], Step [1/1], Training Loss: 52991.9922, Valid Loss: 199.7143
Epoch [4001/30000], Step [1/1], Training Loss: 51890.7461, Valid Loss: 186.5810
Epoch [4101/30000], Step [1/1], Training Loss: 50830.1484, Valid Loss: 181.7143
Epoch [4201/30000], Step [1/1], Training Loss: 49746.6367, Valid Loss: 156.8571
Epoch [4301/30000], Step [1/1], Training Loss: 48713.3281, Valid Loss: 162.0667
Epoch [4401/30000], Step [1/1], Training Loss: 47706.0117, Valid Loss: 140.3048
Epoch [4501/30000], Step [1/1], Training Loss: 46717.8945, Valid Loss: 157.6762
Epoch [4601/30000], Step [1/1], Training Loss: 45774.9883, Valid Loss: 137.8667
Epoch [4701/30000], Step [1/1], Training Loss: 44826.2070, Valid Loss: 145.3905
Epoch [4801/30000], Step [1/1], Training Loss: 43901.2812, Valid Loss: 153.9810
Epoch [4901/30000], Step [1/1], Training Loss: 42987.9531, Valid Loss: 140.6095
Epoch [5001/30000], Step [1/1], Training Loss: 42122.4062, Valid Loss: 125.5238
Epoch [5101/30000], Step [1/1], Training Loss: 41241.7188, Valid Loss: 119.3238
Epoch [5201/30000], Step [1/1], Training Loss: 40358.2734, Valid Loss: 102.1238
Epoch [5301/30000], Step [1/1], Training Loss: 39541.5430, Valid Loss: 100.9714
Epoch [5401/30000], Step [1/1], Training Loss: 38800.6680, Valid Loss: 117.2095
Epoch [5501/30000], Step [1/1], Training Loss: 37928.7656, Valid Loss: 103.2857
Epoch [5601/30000], Step [1/1], Training Loss: 37134.5156, Valid Loss: 101.3619
Epoch [5701/30000], Step [1/1], Training Loss: 36328.7500, Valid Loss: 100.9238
Epoch [5801/30000], Step [1/1], Training Loss: 35610.6055, Valid Loss: 97.6572
Epoch [5901/30000], Step [1/1], Training Loss: 34788.1367, Valid Loss: 100.7143
Epoch [6001/30000], Step [1/1], Training Loss: 33958.1055, Valid Loss: 117.3143
Epoch [6101/30000], Step [1/1], Training Loss: 33182.0703, Valid Loss: 106.8571
Epoch [6201/30000], Step [1/1], Training Loss: 32369.2637, Valid Loss: 110.3333
Epoch [6301/30000], Step [1/1], Training Loss: 31604.7988, Valid Loss: 109.2952
Epoch [6401/30000], Step [1/1], Training Loss: 30913.5332, Valid Loss: 103.5429
Epoch [6501/30000], Step [1/1], Training Loss: 30235.5898, Valid Loss: 100.4667
Epoch [6601/30000], Step [1/1], Training Loss: 29557.1055, Valid Loss: 106.2381
Epoch [6701/30000], Step [1/1], Training Loss: 28876.6016, Valid Loss: 113.8286
Epoch [6801/30000], Step [1/1], Training Loss: 28231.3730, Valid Loss: 106.0857
Epoch [6901/30000], Step [1/1], Training Loss: 27671.1641, Valid Loss: 103.2286
Epoch [7001/30000], Step [1/1], Training Loss: 26998.9609, Valid Loss: 101.6190
Epoch [7101/30000], Step [1/1], Training Loss: 26387.7734, Valid Loss: 107.1714
Epoch [7201/30000], Step [1/1], Training Loss: 25751.2051, Valid Loss: 105.8762
Epoch [7301/30000], Step [1/1], Training Loss: 25442.6973, Valid Loss: 107.5810
Epoch [7401/30000], Step [1/1], Training Loss: 24683.7578, Valid Loss: 109.8476
Epoch [7501/30000], Step [1/1], Training Loss: 24069.0449, Valid Loss: 99.2286
Epoch [7601/30000], Step [1/1], Training Loss: 23498.0938, Valid Loss: 102.7333
Epoch [7701/30000], Step [1/1], Training Loss: 22975.8555, Valid Loss: 106.1810
Epoch [7801/30000], Step [1/1], Training Loss: 22451.7207, Valid Loss: 99.7524
Epoch [7901/30000], Step [1/1], Training Loss: 21935.4160, Valid Loss: 104.2571
Epoch [8001/30000], Step [1/1], Training Loss: 21448.9707, Valid Loss: 101.5238
Epoch [8101/30000], Step [1/1], Training Loss: 20966.2051, Valid Loss: 98.8191
Epoch [8201/30000], Step [1/1], Training Loss: 20497.5996, Valid Loss: 104.8191
Epoch [8301/30000], Step [1/1], Training Loss: 20043.7578, Valid Loss: 101.9810
Epoch [8401/30000], Step [1/1], Training Loss: 19601.7285, Valid Loss: 109.3429
Epoch [8501/30000], Step [1/1], Training Loss: 19165.3457, Valid Loss: 113.5619
Epoch [8601/30000], Step [1/1], Training Loss: 18743.7754, Valid Loss: 108.6572
Epoch [8701/30000], Step [1/1], Training Loss: 18338.4160, Valid Loss: 113.9143
Epoch [8801/30000], Step [1/1], Training Loss: 17940.1973, Valid Loss: 115.1143
Epoch [8901/30000], Step [1/1], Training Loss: 17602.0840, Valid Loss: 100.1619
Epoch [9001/30000], Step [1/1], Training Loss: 17180.9277, Valid Loss: 108.0857
Epoch [9101/30000], Step [1/1], Training Loss: 16762.5410, Valid Loss: 108.6190
Epoch [9201/30000], Step [1/1], Training Loss: 16371.3096, Valid Loss: 111.0476
Epoch [9301/30000], Step [1/1], Training Loss: 16015.3613, Valid Loss: 108.7429
Epoch [9401/30000], Step [1/1], Training Loss: 15665.8232, Valid Loss: 107.8381
Epoch [9501/30000], Step [1/1], Training Loss: 15303.4131, Valid Loss: 107.0381
Epoch [9601/30000], Step [1/1], Training Loss: 14967.3770, Valid Loss: 114.2381
Epoch [9701/30000], Step [1/1], Training Loss: 14625.7969, Valid Loss: 117.9714
Epoch [9801/30000], Step [1/1], Training Loss: 14311.8535, Valid Loss: 107.5524
Epoch [9901/30000], Step [1/1], Training Loss: 13998.9912, Valid Loss: 111.7143
Epoch [10001/30000], Step [1/1], Training Loss: 13693.6045, Valid Loss: 116.8381
Epoch [10101/30000], Step [1/1], Training Loss: 13400.6172, Valid Loss: 106.6952

[Epoch 15000] Rounded prediction: 
tensor([23., 22., 25., 21., 24., 25., 23., 28., 27., 32., 32., 36., 38., 33.,
        33., 34., 38., 43., 21., 29., 14., 14., 18., 16., 12., 12.,  5.,  6.,
        13., 10.,  7.,  9.,  8.,  9.,  3., 14.,  7., 10.,  5., 17.,  1., 24.,
        21., 16.,  4., 12.,  1., 13., 11., 13., 15., 14., 14., 11., 28., 12.,
        11.,  2., 12.,  8., 10., 11.,  7., 15.,  8., 20.,  8., 21., 13., 19.,
        20., 19., 21., 26., 28., 32., 18., 40., 18., 28., 19., 17., 26., 15.,
        17., 20., 24., 29., 30., 27., 28., 43., 55., 50., 39., 26., 19., 23.,
        36., 45., 46., 42., 45., 38., 38.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([26., 28., 30., 23., 26., 26., 25., 32., 31., 37., 35., 41., 41., 37.,
        40., 37., 38., 41., 15., 22., 10.,  8., 11., 14.,  9.,  7.,  1.,  1.,
         6.,  4.,  3.,  6.,  4.,  3.,  0.,  6.,  3.,  4.,  3.,  9.,  0., 20.,
        20.,  9.,  3.,  7.,  0.,  7.,  5.,  7.,  9., 10., 10.,  6., 20., 10.,
         5.,  0.,  6.,  3.,  5.,  4.,  4.,  8.,  5., 13.,  4., 14.,  8., 14.,
        18., 19., 20., 23., 26., 32., 15., 39., 13., 17., 15., 10., 24., 12.,
        10., 16., 22., 30., 36., 32., 24., 48., 59., 60., 49., 24., 18., 24.,
        34., 34., 44., 43., 40., 32., 41.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [10201/30000], Step [1/1], Training Loss: 13118.1914, Valid Loss: 112.7048
Epoch [10301/30000], Step [1/1], Training Loss: 12842.4990, Valid Loss: 111.9429
Epoch [10401/30000], Step [1/1], Training Loss: 12570.4014, Valid Loss: 118.2857
Epoch [10501/30000], Step [1/1], Training Loss: 13972.2588, Valid Loss: 116.8095
Epoch [10601/30000], Step [1/1], Training Loss: 11956.3389, Valid Loss: 118.1714
Epoch [10701/30000], Step [1/1], Training Loss: 11785.2900, Valid Loss: 125.6667
Epoch [10801/30000], Step [1/1], Training Loss: 11369.4717, Valid Loss: 117.0952
Epoch [10901/30000], Step [1/1], Training Loss: 11077.5615, Valid Loss: 121.3333
Epoch [11001/30000], Step [1/1], Training Loss: 10814.1367, Valid Loss: 127.4857
Epoch [11101/30000], Step [1/1], Training Loss: 10485.0361, Valid Loss: 125.5429
Epoch [11201/30000], Step [1/1], Training Loss: 10445.0811, Valid Loss: 114.6476
Epoch [11301/30000], Step [1/1], Training Loss: 10083.6836, Valid Loss: 116.9524
Epoch [11401/30000], Step [1/1], Training Loss: 9558.8760, Valid Loss: 117.0286
Epoch [11501/30000], Step [1/1], Training Loss: 9330.5352, Valid Loss: 122.7810
Epoch [11601/30000], Step [1/1], Training Loss: 9111.3311, Valid Loss: 114.9048
Epoch [11701/30000], Step [1/1], Training Loss: 8792.6533, Valid Loss: 113.8667
Epoch [11801/30000], Step [1/1], Training Loss: 8599.8057, Valid Loss: 121.6952
Epoch [11901/30000], Step [1/1], Training Loss: 8349.5234, Valid Loss: 123.3429
Epoch [12001/30000], Step [1/1], Training Loss: 8132.1689, Valid Loss: 124.6667
Epoch [12101/30000], Step [1/1], Training Loss: 7924.6416, Valid Loss: 126.4286
Epoch [12201/30000], Step [1/1], Training Loss: 7766.3418, Valid Loss: 132.4667
Epoch [12301/30000], Step [1/1], Training Loss: 7551.8081, Valid Loss: 132.2857
Epoch [12401/30000], Step [1/1], Training Loss: 7383.9858, Valid Loss: 148.4381
Epoch [12501/30000], Step [1/1], Training Loss: 7166.7412, Valid Loss: 144.6190
Epoch [12601/30000], Step [1/1], Training Loss: 6992.7720, Valid Loss: 141.9905
Epoch [12701/30000], Step [1/1], Training Loss: 6810.1094, Valid Loss: 149.0191
Epoch [12801/30000], Step [1/1], Training Loss: 6646.5981, Valid Loss: 143.1048
Epoch [12901/30000], Step [1/1], Training Loss: 6558.2134, Valid Loss: 165.1524
Epoch [13001/30000], Step [1/1], Training Loss: 6422.6768, Valid Loss: 136.8476
Epoch [13101/30000], Step [1/1], Training Loss: 6180.2515, Valid Loss: 148.4762
Epoch [13201/30000], Step [1/1], Training Loss: 6026.1890, Valid Loss: 154.5333
Epoch [13301/30000], Step [1/1], Training Loss: 5875.3950, Valid Loss: 165.3048
Epoch [13401/30000], Step [1/1], Training Loss: 5729.0874, Valid Loss: 160.7905
Epoch [13501/30000], Step [1/1], Training Loss: 5436.7339, Valid Loss: 172.2381
Epoch [13601/30000], Step [1/1], Training Loss: 5308.7427, Valid Loss: 171.0286
Epoch [13701/30000], Step [1/1], Training Loss: 5159.7437, Valid Loss: 171.2952
Epoch [13801/30000], Step [1/1], Training Loss: 5016.9795, Valid Loss: 174.4000
Epoch [13901/30000], Step [1/1], Training Loss: 4883.2021, Valid Loss: 183.8667
Epoch [14001/30000], Step [1/1], Training Loss: 4767.5640, Valid Loss: 202.8095
Epoch [14101/30000], Step [1/1], Training Loss: 4651.4810, Valid Loss: 176.7619
Epoch [14201/30000], Step [1/1], Training Loss: 4505.1729, Valid Loss: 173.8762
Epoch [14301/30000], Step [1/1], Training Loss: 4381.2114, Valid Loss: 180.9143
Epoch [14401/30000], Step [1/1], Training Loss: 4238.3188, Valid Loss: 177.0476
Epoch [14501/30000], Step [1/1], Training Loss: 4103.8008, Valid Loss: 190.8476
Epoch [14601/30000], Step [1/1], Training Loss: 3988.3787, Valid Loss: 198.1429
Epoch [14701/30000], Step [1/1], Training Loss: 3878.7947, Valid Loss: 195.9333
Epoch [14801/30000], Step [1/1], Training Loss: 3771.4397, Valid Loss: 201.1048
Epoch [14901/30000], Step [1/1], Training Loss: 3664.5542, Valid Loss: 220.0381
Epoch [15001/30000], Step [1/1], Training Loss: 3560.8801, Valid Loss: 203.1714
Epoch [15101/30000], Step [1/1], Training Loss: 3462.3721, Valid Loss: 211.0952
Epoch [15201/30000], Step [1/1], Training Loss: 3366.8977, Valid Loss: 225.8762
Epoch [15301/30000], Step [1/1], Training Loss: 3273.0261, Valid Loss: 209.2095
Epoch [15401/30000], Step [1/1], Training Loss: 3181.7480, Valid Loss: 221.3238
Epoch [15501/30000], Step [1/1], Training Loss: 3100.2014, Valid Loss: 211.7524
Epoch [15601/30000], Step [1/1], Training Loss: 3017.4868, Valid Loss: 229.4476
Epoch [15701/30000], Step [1/1], Training Loss: 2932.1104, Valid Loss: 218.6572
Epoch [15801/30000], Step [1/1], Training Loss: 3196.1782, Valid Loss: 227.0762
Epoch [15901/30000], Step [1/1], Training Loss: 2812.6238, Valid Loss: 225.3714
Epoch [16001/30000], Step [1/1], Training Loss: 2722.0757, Valid Loss: 218.1714
Epoch [16101/30000], Step [1/1], Training Loss: 2635.6741, Valid Loss: 218.9333
Epoch [16201/30000], Step [1/1], Training Loss: 2565.7046, Valid Loss: 216.6381
Epoch [16301/30000], Step [1/1], Training Loss: 2494.6233, Valid Loss: 227.8476
Epoch [16401/30000], Step [1/1], Training Loss: 2423.3650, Valid Loss: 225.4191
Epoch [16501/30000], Step [1/1], Training Loss: 2359.8655, Valid Loss: 232.6190
Epoch [16601/30000], Step [1/1], Training Loss: 2295.6658, Valid Loss: 216.3238
Epoch [16701/30000], Step [1/1], Training Loss: 2234.6880, Valid Loss: 213.8667
Epoch [16801/30000], Step [1/1], Training Loss: 2175.0457, Valid Loss: 216.3429
Epoch [16901/30000], Step [1/1], Training Loss: 2125.3037, Valid Loss: 220.1619
Epoch [17001/30000], Step [1/1], Training Loss: 2061.2163, Valid Loss: 222.7429
Epoch [17101/30000], Step [1/1], Training Loss: 2007.0782, Valid Loss: 214.7524
Epoch [17201/30000], Step [1/1], Training Loss: 1955.8994, Valid Loss: 214.9333
Epoch [17301/30000], Step [1/1], Training Loss: 1907.6436, Valid Loss: 214.4667
Epoch [17401/30000], Step [1/1], Training Loss: 1859.5414, Valid Loss: 230.0571
Epoch [17501/30000], Step [1/1], Training Loss: 1818.2170, Valid Loss: 211.8286
Epoch [17601/30000], Step [1/1], Training Loss: 1769.6796, Valid Loss: 207.8191
Epoch [17701/30000], Step [1/1], Training Loss: 1726.6597, Valid Loss: 206.3048
Epoch [17801/30000], Step [1/1], Training Loss: 1684.3738, Valid Loss: 220.0191
Epoch [17901/30000], Step [1/1], Training Loss: 1645.4921, Valid Loss: 213.1810
Epoch [18001/30000], Step [1/1], Training Loss: 1609.8669, Valid Loss: 215.1714
Epoch [18101/30000], Step [1/1], Training Loss: 1570.6667, Valid Loss: 206.2476
Epoch [18201/30000], Step [1/1], Training Loss: 1537.5104, Valid Loss: 217.8095
Epoch [18301/30000], Step [1/1], Training Loss: 1503.9209, Valid Loss: 211.2000
Epoch [18401/30000], Step [1/1], Training Loss: 1470.5250, Valid Loss: 209.3810
Epoch [18501/30000], Step [1/1], Training Loss: 1441.8147, Valid Loss: 204.7905
Epoch [18601/30000], Step [1/1], Training Loss: 1408.4939, Valid Loss: 215.4000
Epoch [18701/30000], Step [1/1], Training Loss: 1377.0337, Valid Loss: 205.2191
Epoch [18801/30000], Step [1/1], Training Loss: 1348.9797, Valid Loss: 211.6953
Epoch [18901/30000], Step [1/1], Training Loss: 1320.5638, Valid Loss: 226.7905
Epoch [19001/30000], Step [1/1], Training Loss: 1290.2485, Valid Loss: 224.3429
Epoch [19101/30000], Step [1/1], Training Loss: 1258.6758, Valid Loss: 215.7714
Epoch [19201/30000], Step [1/1], Training Loss: 1229.0432, Valid Loss: 213.5714
Epoch [19301/30000], Step [1/1], Training Loss: 1202.6846, Valid Loss: 203.1238
Epoch [19401/30000], Step [1/1], Training Loss: 1170.1486, Valid Loss: 217.8000
Epoch [19501/30000], Step [1/1], Training Loss: 1142.3403, Valid Loss: 218.6572
Epoch [19601/30000], Step [1/1], Training Loss: 1115.7783, Valid Loss: 224.5714
Epoch [19701/30000], Step [1/1], Training Loss: 1086.1903, Valid Loss: 235.1429
Epoch [19801/30000], Step [1/1], Training Loss: 5061.6265, Valid Loss: 152.2762
Epoch [19901/30000], Step [1/1], Training Loss: 1148.5884, Valid Loss: 220.5619
Epoch [20001/30000], Step [1/1], Training Loss: 1033.1792, Valid Loss: 218.2381
Epoch [20101/30000], Step [1/1], Training Loss: 996.4484, Valid Loss: 223.0286
Epoch [20201/30000], Step [1/1], Training Loss: 962.7491, Valid Loss: 224.4667
Epoch [20301/30000], Step [1/1], Training Loss: 939.5201, Valid Loss: 230.6476

[Epoch 25000] Rounded prediction: 
tensor([26., 29., 33., 25., 30., 30., 28., 36., 35., 42., 43., 49., 48., 46.,
        48., 47., 45., 45., 15., 24.,  9.,  7.,  8., 12.,  8.,  6.,  0.,  0.,
         5.,  3.,  0.,  5.,  4.,  0.,  0.,  5.,  1.,  1.,  2.,  5.,  0., 18.,
        20.,  7.,  3.,  6.,  0.,  6.,  5.,  7., 10., 11., 10.,  5., 15.,  9.,
         3.,  0.,  5.,  0.,  4.,  1.,  4.,  5.,  7., 10.,  5., 14.,  8., 19.,
        26., 25., 26., 30., 34., 37., 15., 42., 15., 19., 14., 12., 25., 13.,
        12., 25., 32., 41., 45., 40., 26., 48., 62., 68., 59., 28., 19., 24.,
        32., 35., 48., 46., 42., 33., 47.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [20401/30000], Step [1/1], Training Loss: 919.5091, Valid Loss: 219.5333
Epoch [20501/30000], Step [1/1], Training Loss: 894.7049, Valid Loss: 235.2857
Epoch [20601/30000], Step [1/1], Training Loss: 872.2431, Valid Loss: 237.2667
Epoch [20701/30000], Step [1/1], Training Loss: 854.4299, Valid Loss: 241.5905
Epoch [20801/30000], Step [1/1], Training Loss: 833.1489, Valid Loss: 245.6476
Epoch [20901/30000], Step [1/1], Training Loss: 814.5458, Valid Loss: 253.4286
Epoch [21001/30000], Step [1/1], Training Loss: 792.3257, Valid Loss: 253.7714
Epoch [21101/30000], Step [1/1], Training Loss: 772.5350, Valid Loss: 257.8667
Epoch [21201/30000], Step [1/1], Training Loss: 759.7540, Valid Loss: 247.5810
Epoch [21301/30000], Step [1/1], Training Loss: 739.7029, Valid Loss: 252.2095
Epoch [21401/30000], Step [1/1], Training Loss: 722.3890, Valid Loss: 264.8476
Epoch [21501/30000], Step [1/1], Training Loss: 708.4298, Valid Loss: 257.9333
Epoch [21601/30000], Step [1/1], Training Loss: 694.7117, Valid Loss: 256.1048
Epoch [21701/30000], Step [1/1], Training Loss: 672.6310, Valid Loss: 261.8857
Epoch [21801/30000], Step [1/1], Training Loss: 652.1277, Valid Loss: 262.1143
Epoch [21901/30000], Step [1/1], Training Loss: 639.1342, Valid Loss: 258.8381
Epoch [22001/30000], Step [1/1], Training Loss: 621.9306, Valid Loss: 270.2857
Epoch [22101/30000], Step [1/1], Training Loss: 604.5635, Valid Loss: 269.5238
Epoch [22201/30000], Step [1/1], Training Loss: 591.1063, Valid Loss: 277.2762
Epoch [22301/30000], Step [1/1], Training Loss: 581.2407, Valid Loss: 279.2000
Epoch [22401/30000], Step [1/1], Training Loss: 562.0905, Valid Loss: 282.3143
Epoch [22501/30000], Step [1/1], Training Loss: 547.8883, Valid Loss: 286.2762
Epoch [22601/30000], Step [1/1], Training Loss: 534.4539, Valid Loss: 296.4667
Epoch [22701/30000], Step [1/1], Training Loss: 521.5856, Valid Loss: 295.3524
Epoch [22801/30000], Step [1/1], Training Loss: 507.4289, Valid Loss: 292.6286
Epoch [22901/30000], Step [1/1], Training Loss: 494.7091, Valid Loss: 296.7333
Epoch [23001/30000], Step [1/1], Training Loss: 480.7281, Valid Loss: 294.1619
Epoch [23101/30000], Step [1/1], Training Loss: 469.6783, Valid Loss: 292.7048
Epoch [23201/30000], Step [1/1], Training Loss: 458.8600, Valid Loss: 303.9143
Epoch [23301/30000], Step [1/1], Training Loss: 446.8260, Valid Loss: 300.3333
Epoch [23401/30000], Step [1/1], Training Loss: 435.7618, Valid Loss: 302.4286
Epoch [23501/30000], Step [1/1], Training Loss: 423.9619, Valid Loss: 293.7715
Epoch [23601/30000], Step [1/1], Training Loss: 412.4382, Valid Loss: 303.7810
Epoch [23701/30000], Step [1/1], Training Loss: 401.2630, Valid Loss: 300.2667
Epoch [23801/30000], Step [1/1], Training Loss: 391.3510, Valid Loss: 312.3429
Epoch [23901/30000], Step [1/1], Training Loss: 379.7819, Valid Loss: 295.9238
Epoch [24001/30000], Step [1/1], Training Loss: 370.3386, Valid Loss: 306.6095
Epoch [24101/30000], Step [1/1], Training Loss: 358.4212, Valid Loss: 293.3524
Epoch [24201/30000], Step [1/1], Training Loss: 347.4126, Valid Loss: 287.8857
Epoch [24301/30000], Step [1/1], Training Loss: 338.9350, Valid Loss: 300.4095
Epoch [24401/30000], Step [1/1], Training Loss: 327.4604, Valid Loss: 293.7810
Epoch [24501/30000], Step [1/1], Training Loss: 315.2839, Valid Loss: 298.5429
Epoch [24601/30000], Step [1/1], Training Loss: 305.1520, Valid Loss: 308.7715
Epoch [24701/30000], Step [1/1], Training Loss: 295.9192, Valid Loss: 314.5524
Epoch [24801/30000], Step [1/1], Training Loss: 285.1694, Valid Loss: 314.4572
Epoch [24901/30000], Step [1/1], Training Loss: 275.3768, Valid Loss: 310.1143
Epoch [25001/30000], Step [1/1], Training Loss: 264.0443, Valid Loss: 320.0952
Epoch [25101/30000], Step [1/1], Training Loss: 254.2478, Valid Loss: 319.8953
Epoch [25201/30000], Step [1/1], Training Loss: 243.6240, Valid Loss: 310.5714
Epoch [25301/30000], Step [1/1], Training Loss: 233.7340, Valid Loss: 290.3619
Epoch [25401/30000], Step [1/1], Training Loss: 225.2321, Valid Loss: 324.5143
Epoch [25501/30000], Step [1/1], Training Loss: 215.4582, Valid Loss: 314.7238
Epoch [25601/30000], Step [1/1], Training Loss: 206.9282, Valid Loss: 325.7619
Epoch [25701/30000], Step [1/1], Training Loss: 198.1962, Valid Loss: 325.3048
Epoch [25801/30000], Step [1/1], Training Loss: 190.1022, Valid Loss: 335.8000
Epoch [25901/30000], Step [1/1], Training Loss: 182.1152, Valid Loss: 332.0381
Epoch [26001/30000], Step [1/1], Training Loss: 174.2503, Valid Loss: 336.6762
Epoch [26101/30000], Step [1/1], Training Loss: 165.7236, Valid Loss: 317.4667
Epoch [26201/30000], Step [1/1], Training Loss: 158.3167, Valid Loss: 329.6286
Epoch [26301/30000], Step [1/1], Training Loss: 151.0972, Valid Loss: 345.3238
Epoch [26401/30000], Step [1/1], Training Loss: 144.1041, Valid Loss: 325.4381
Epoch [26501/30000], Step [1/1], Training Loss: 136.7158, Valid Loss: 336.0667
Epoch [26601/30000], Step [1/1], Training Loss: 129.1243, Valid Loss: 345.7429
Epoch [26701/30000], Step [1/1], Training Loss: 122.1846, Valid Loss: 346.3714
Epoch [26801/30000], Step [1/1], Training Loss: 116.4025, Valid Loss: 342.8000
Epoch [26901/30000], Step [1/1], Training Loss: 110.0657, Valid Loss: 342.1048
Epoch [27001/30000], Step [1/1], Training Loss: 104.2231, Valid Loss: 355.4095
Epoch [27101/30000], Step [1/1], Training Loss: 98.1113, Valid Loss: 350.9048
Epoch [27201/30000], Step [1/1], Training Loss: 92.6851, Valid Loss: 354.6000
Epoch [27301/30000], Step [1/1], Training Loss: 87.0493, Valid Loss: 349.2286
Epoch [27401/30000], Step [1/1], Training Loss: 82.0383, Valid Loss: 355.9524
Epoch [27501/30000], Step [1/1], Training Loss: 77.4893, Valid Loss: 337.6857
Epoch [27601/30000], Step [1/1], Training Loss: 72.3676, Valid Loss: 344.7905
Epoch [27701/30000], Step [1/1], Training Loss: 68.0374, Valid Loss: 353.3714
Epoch [27801/30000], Step [1/1], Training Loss: 63.6967, Valid Loss: 354.9429
Epoch [27901/30000], Step [1/1], Training Loss: 59.7970, Valid Loss: 340.9048
Epoch [28001/30000], Step [1/1], Training Loss: 56.4583, Valid Loss: 355.9048
Epoch [28101/30000], Step [1/1], Training Loss: 53.1843, Valid Loss: 379.6667
Epoch [28201/30000], Step [1/1], Training Loss: 48.2368, Valid Loss: 358.2667
Epoch [28301/30000], Step [1/1], Training Loss: 44.9247, Valid Loss: 364.7333
Epoch [28401/30000], Step [1/1], Training Loss: 42.3465, Valid Loss: 359.9714
Epoch [28501/30000], Step [1/1], Training Loss: 39.0371, Valid Loss: 355.3905
Epoch [28601/30000], Step [1/1], Training Loss: 36.2419, Valid Loss: 366.4476
Epoch [28701/30000], Step [1/1], Training Loss: 33.3053, Valid Loss: 368.7524
Epoch [28801/30000], Step [1/1], Training Loss: 30.7268, Valid Loss: 375.9333
Epoch [28901/30000], Step [1/1], Training Loss: 28.3207, Valid Loss: 358.1048
Epoch [29001/30000], Step [1/1], Training Loss: 25.9878, Valid Loss: 356.2476
Epoch [29101/30000], Step [1/1], Training Loss: 23.7308, Valid Loss: 365.7238
Epoch [29201/30000], Step [1/1], Training Loss: 21.6826, Valid Loss: 355.8381
Epoch [29301/30000], Step [1/1], Training Loss: 20.0818, Valid Loss: 351.3905
Epoch [29401/30000], Step [1/1], Training Loss: 18.0678, Valid Loss: 370.6095
Epoch [29501/30000], Step [1/1], Training Loss: 16.4559, Valid Loss: 355.4572
Epoch [29601/30000], Step [1/1], Training Loss: 14.9629, Valid Loss: 361.0381
Epoch [29701/30000], Step [1/1], Training Loss: 13.5360, Valid Loss: 365.5429
Epoch [29801/30000], Step [1/1], Training Loss: 12.1400, Valid Loss: 372.0667
Epoch [29901/30000], Step [1/1], Training Loss: 11.0338, Valid Loss: 375.6572

 End Time: 2021/04/20, 01:10:25




##########################################################

Epochs=30000 	batch=245 	lr=6e-05
window=2 	seq_len=7 	hidden_size=1024 	layers=2

Start Time = 2021/04/20, 01:10:25
##########################################################


[Epoch 0] Rounded prediction: 
tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.],
       device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([18., 14., 20., 17., 14., 16., 21., 20., 21., 21., 23., 21., 30., 26.,
        21., 19., 11., 12., 14., 16., 18., 16., 16., 19., 15., 11., 13., 12.,
        11., 12., 17., 11., 10., 16., 11., 11., 10., 13.,  7., 12., 11., 22.,
        20., 21., 10., 12., 10., 10., 10., 11., 12., 12., 15., 10., 22., 17.,
        14., 13., 11., 11.,  9., 16., 10., 18.,  9., 18., 14., 18., 19., 15.,
        16., 13., 12., 13., 14., 16., 14., 30., 24., 29., 25., 20., 32., 32.,
        22., 20., 16., 12., 16., 16., 10., 20., 41., 49., 48., 37., 27., 29.,
        35., 41., 33., 28., 32., 33., 25.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([21., 17., 25., 19., 18., 20., 21., 26., 24., 25., 26., 26., 29., 25.,
        25., 17., 10., 14.,  2., 13., 10.,  9., 17., 13.,  9.,  9.,  8.,  6.,
        11.,  9., 13.,  6.,  8.,  9.,  3., 15.,  3., 13.,  1., 13.,  4., 25.,
        18., 19.,  4.,  9.,  3.,  7.,  8.,  7.,  7.,  8., 11.,  4., 25.,  7.,
        14.,  7.,  6.,  8.,  7., 14.,  0., 17.,  0., 18.,  2., 20.,  7., 11.,
         9.,  7.,  7.,  9., 10., 13.,  5., 30., 10., 25., 17., 14., 27., 22.,
        16., 13.,  7., 11., 15.,  9.,  4., 21., 42., 49., 44., 31., 24., 29.,
        35., 38., 29., 22., 21., 27., 17.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128665.7109, Valid Loss: 227.9524
Epoch [101/30000], Step [1/1], Training Loss: 118466.3984, Valid Loss: 211.7429
Epoch [201/30000], Step [1/1], Training Loss: 115645.4844, Valid Loss: 384.5905
Epoch [301/30000], Step [1/1], Training Loss: 113026.8359, Valid Loss: 640.7524
Epoch [401/30000], Step [1/1], Training Loss: 110534.3359, Valid Loss: 985.8572
Epoch [501/30000], Step [1/1], Training Loss: 108144.0938, Valid Loss: 1372.8572
Epoch [601/30000], Step [1/1], Training Loss: 105845.5469, Valid Loss: 1820.0953
Epoch [701/30000], Step [1/1], Training Loss: 103629.6094, Valid Loss: 2313.1621
Epoch [801/30000], Step [1/1], Training Loss: 101490.9688, Valid Loss: 2763.1621
Epoch [901/30000], Step [1/1], Training Loss: 99413.2188, Valid Loss: 1739.1525
Epoch [1001/30000], Step [1/1], Training Loss: 97121.3281, Valid Loss: 53.1429
Epoch [1101/30000], Step [1/1], Training Loss: 95038.8828, Valid Loss: 60.4381
Epoch [1201/30000], Step [1/1], Training Loss: 93015.7109, Valid Loss: 53.2000
Epoch [1301/30000], Step [1/1], Training Loss: 91040.9453, Valid Loss: 62.6381
Epoch [1401/30000], Step [1/1], Training Loss: 89115.1016, Valid Loss: 77.6857
Epoch [1501/30000], Step [1/1], Training Loss: 87234.7344, Valid Loss: 127.0571
Epoch [1601/30000], Step [1/1], Training Loss: 85381.2344, Valid Loss: 176.6762
Epoch [1701/30000], Step [1/1], Training Loss: 83585.8359, Valid Loss: 272.8953
Epoch [1801/30000], Step [1/1], Training Loss: 81834.7344, Valid Loss: 283.0000
Epoch [1901/30000], Step [1/1], Training Loss: 80123.7031, Valid Loss: 351.2095
Epoch [2001/30000], Step [1/1], Training Loss: 78452.4297, Valid Loss: 394.5905
Epoch [2101/30000], Step [1/1], Training Loss: 76818.3203, Valid Loss: 325.7238
Epoch [2201/30000], Step [1/1], Training Loss: 75223.4531, Valid Loss: 235.8191
Epoch [2301/30000], Step [1/1], Training Loss: 73669.5234, Valid Loss: 225.1238
Epoch [2401/30000], Step [1/1], Training Loss: 72151.7109, Valid Loss: 217.0571
Epoch [2501/30000], Step [1/1], Training Loss: 70670.1641, Valid Loss: 229.7714
Epoch [2601/30000], Step [1/1], Training Loss: 69226.4141, Valid Loss: 204.5048
Epoch [2701/30000], Step [1/1], Training Loss: 67817.8359, Valid Loss: 198.7524
Epoch [2801/30000], Step [1/1], Training Loss: 66445.3203, Valid Loss: 175.7714
Epoch [2901/30000], Step [1/1], Training Loss: 65106.2539, Valid Loss: 173.5333
Epoch [3001/30000], Step [1/1], Training Loss: 63801.9727, Valid Loss: 196.4381
Epoch [3101/30000], Step [1/1], Training Loss: 62530.8477, Valid Loss: 204.0571
Epoch [3201/30000], Step [1/1], Training Loss: 61217.2305, Valid Loss: 140.1714
Epoch [3301/30000], Step [1/1], Training Loss: 59956.3047, Valid Loss: 155.8857
Epoch [3401/30000], Step [1/1], Training Loss: 58729.4023, Valid Loss: 104.4191
Epoch [3501/30000], Step [1/1], Training Loss: 57522.9023, Valid Loss: 122.1524
Epoch [3601/30000], Step [1/1], Training Loss: 56351.0742, Valid Loss: 124.3238
Epoch [3701/30000], Step [1/1], Training Loss: 55193.8984, Valid Loss: 99.8000
Epoch [3801/30000], Step [1/1], Training Loss: 54071.7539, Valid Loss: 112.7143
Epoch [3901/30000], Step [1/1], Training Loss: 52947.6680, Valid Loss: 110.2476
Epoch [4001/30000], Step [1/1], Training Loss: 51837.2383, Valid Loss: 118.1429
Epoch [4101/30000], Step [1/1], Training Loss: 50776.4883, Valid Loss: 115.8762
Epoch [4201/30000], Step [1/1], Training Loss: 49679.8008, Valid Loss: 101.8286
Epoch [4301/30000], Step [1/1], Training Loss: 48643.0977, Valid Loss: 92.8571
Epoch [4401/30000], Step [1/1], Training Loss: 47654.3047, Valid Loss: 93.7714
Epoch [4501/30000], Step [1/1], Training Loss: 46643.7031, Valid Loss: 89.6571
Epoch [4601/30000], Step [1/1], Training Loss: 45687.1992, Valid Loss: 94.0476
Epoch [4701/30000], Step [1/1], Training Loss: 44744.5195, Valid Loss: 92.1905
Epoch [4801/30000], Step [1/1], Training Loss: 43797.8594, Valid Loss: 89.8381
Epoch [4901/30000], Step [1/1], Training Loss: 42915.5625, Valid Loss: 97.2095
Epoch [5001/30000], Step [1/1], Training Loss: 42017.5742, Valid Loss: 109.6476
Epoch [5101/30000], Step [1/1], Training Loss: 41178.2969, Valid Loss: 81.7048
Epoch [5201/30000], Step [1/1], Training Loss: 40271.5078, Valid Loss: 78.3810
Epoch [5301/30000], Step [1/1], Training Loss: 39445.4570, Valid Loss: 88.3714
Epoch [5401/30000], Step [1/1], Training Loss: 38496.4023, Valid Loss: 85.1048
Epoch [5501/30000], Step [1/1], Training Loss: 37619.7852, Valid Loss: 84.8762
Epoch [5601/30000], Step [1/1], Training Loss: 36820.7383, Valid Loss: 88.2667
Epoch [5701/30000], Step [1/1], Training Loss: 36061.0664, Valid Loss: 83.7905
Epoch [5801/30000], Step [1/1], Training Loss: 35274.0273, Valid Loss: 80.2476
Epoch [5901/30000], Step [1/1], Training Loss: 34369.6484, Valid Loss: 85.3238
Epoch [6001/30000], Step [1/1], Training Loss: 33609.1016, Valid Loss: 83.7714
Epoch [6101/30000], Step [1/1], Training Loss: 32861.1719, Valid Loss: 89.0571
Epoch [6201/30000], Step [1/1], Training Loss: 32134.6504, Valid Loss: 93.2286
Epoch [6301/30000], Step [1/1], Training Loss: 31434.8086, Valid Loss: 82.7714
Epoch [6401/30000], Step [1/1], Training Loss: 30729.2168, Valid Loss: 79.3143
Epoch [6501/30000], Step [1/1], Training Loss: 30048.1328, Valid Loss: 89.6952
Epoch [6601/30000], Step [1/1], Training Loss: 29379.6914, Valid Loss: 90.9429
Epoch [6701/30000], Step [1/1], Training Loss: 28748.0801, Valid Loss: 90.8381
Epoch [6801/30000], Step [1/1], Training Loss: 28102.4414, Valid Loss: 103.0191
Epoch [6901/30000], Step [1/1], Training Loss: 27481.8906, Valid Loss: 102.1143
Epoch [7001/30000], Step [1/1], Training Loss: 26891.4219, Valid Loss: 104.8857
Epoch [7101/30000], Step [1/1], Training Loss: 26297.4648, Valid Loss: 101.8381
Epoch [7201/30000], Step [1/1], Training Loss: 25716.5918, Valid Loss: 112.7048
Epoch [7301/30000], Step [1/1], Training Loss: 25222.1035, Valid Loss: 110.4476
Epoch [7401/30000], Step [1/1], Training Loss: 24622.6660, Valid Loss: 120.0286
Epoch [7501/30000], Step [1/1], Training Loss: 24167.8105, Valid Loss: 114.9143
Epoch [7601/30000], Step [1/1], Training Loss: 23566.0039, Valid Loss: 103.4191
Epoch [7701/30000], Step [1/1], Training Loss: 23047.9180, Valid Loss: 109.0286
Epoch [7801/30000], Step [1/1], Training Loss: 22549.5273, Valid Loss: 113.6000
Epoch [7901/30000], Step [1/1], Training Loss: 22066.6641, Valid Loss: 112.5619
Epoch [8001/30000], Step [1/1], Training Loss: 21597.6230, Valid Loss: 118.6381
Epoch [8101/30000], Step [1/1], Training Loss: 21140.8398, Valid Loss: 117.4000
Epoch [8201/30000], Step [1/1], Training Loss: 20695.9863, Valid Loss: 119.7619
Epoch [8301/30000], Step [1/1], Training Loss: 20257.9863, Valid Loss: 122.4571
Epoch [8401/30000], Step [1/1], Training Loss: 19846.2031, Valid Loss: 123.2762
Epoch [8501/30000], Step [1/1], Training Loss: 19407.2559, Valid Loss: 115.0381
Epoch [8601/30000], Step [1/1], Training Loss: 18987.8555, Valid Loss: 120.5905
Epoch [8701/30000], Step [1/1], Training Loss: 18566.4746, Valid Loss: 118.0476
Epoch [8801/30000], Step [1/1], Training Loss: 18220.3672, Valid Loss: 117.5524
Epoch [8901/30000], Step [1/1], Training Loss: 17789.0488, Valid Loss: 112.0000
Epoch [9001/30000], Step [1/1], Training Loss: 17435.5879, Valid Loss: 118.3524
Epoch [9101/30000], Step [1/1], Training Loss: 17058.7402, Valid Loss: 118.3238
Epoch [9201/30000], Step [1/1], Training Loss: 16820.6367, Valid Loss: 118.1905
Epoch [9301/30000], Step [1/1], Training Loss: 16373.5518, Valid Loss: 114.7524
Epoch [9401/30000], Step [1/1], Training Loss: 16046.2510, Valid Loss: 117.2857
Epoch [9501/30000], Step [1/1], Training Loss: 15512.6484, Valid Loss: 106.8000
Epoch [9601/30000], Step [1/1], Training Loss: 15193.5645, Valid Loss: 102.9048
Epoch [9701/30000], Step [1/1], Training Loss: 14682.0811, Valid Loss: 109.5714
Epoch [9801/30000], Step [1/1], Training Loss: 14260.0508, Valid Loss: 112.0762
Epoch [9901/30000], Step [1/1], Training Loss: 13903.4834, Valid Loss: 107.7905
Epoch [10001/30000], Step [1/1], Training Loss: 13564.9062, Valid Loss: 112.2762
Epoch [10101/30000], Step [1/1], Training Loss: 13232.3818, Valid Loss: 110.1048

[Epoch 15000] Rounded prediction: 
tensor([20., 19., 27., 19., 20., 22., 22., 30., 26., 32., 28., 33., 33., 33.,
        31., 24., 16., 17.,  4., 12.,  9.,  8., 15., 13.,  6.,  3.,  6.,  6.,
        10.,  9., 11.,  4.,  4.,  5.,  3., 15.,  1.,  8.,  2., 10.,  5., 23.,
        17., 12.,  1.,  5.,  1.,  8.,  6.,  6.,  7.,  8., 12.,  4., 22.,  7.,
         9.,  4.,  7.,  6.,  6., 12.,  1., 11.,  0., 17.,  1., 18.,  7.,  9.,
         9., 10., 10., 11., 14., 16.,  2., 30.,  7., 22., 15.,  7., 22., 15.,
         7.,  8.,  8., 18., 31., 17., 12., 28., 40., 43., 38., 20., 12., 15.,
        23., 33., 31., 29., 28., 28., 21.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([19., 20., 29., 21., 25., 24., 23., 32., 26., 33., 31., 40., 42., 39.,
        40., 30., 17., 20.,  3., 12.,  9.,  8., 11., 11.,  4.,  2.,  5.,  4.,
         8.,  7.,  9.,  3.,  1.,  5.,  2., 11.,  0.,  6.,  1.,  9.,  3., 21.,
        15.,  8.,  0.,  4.,  1.,  7.,  5.,  3.,  7.,  7., 11.,  5., 19.,  4.,
         4.,  0.,  6.,  6.,  4.,  8.,  0.,  8.,  1., 15.,  0., 17.,  5.,  8.,
        11., 13., 12., 13., 17., 22.,  0., 29.,  7., 17., 13.,  5., 24., 20.,
         8.,  8., 13., 23., 37., 19., 13., 29., 40., 43., 41., 24., 18., 25.,
        32., 35., 33., 36., 30., 31., 24.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [10201/30000], Step [1/1], Training Loss: 13030.8096, Valid Loss: 100.8952
Epoch [10301/30000], Step [1/1], Training Loss: 12412.0781, Valid Loss: 115.4857
Epoch [10401/30000], Step [1/1], Training Loss: 12097.1455, Valid Loss: 111.0000
Epoch [10501/30000], Step [1/1], Training Loss: 11802.5068, Valid Loss: 120.5429
Epoch [10601/30000], Step [1/1], Training Loss: 11508.1689, Valid Loss: 112.6095
Epoch [10701/30000], Step [1/1], Training Loss: 11214.8193, Valid Loss: 119.1714
Epoch [10801/30000], Step [1/1], Training Loss: 10939.4229, Valid Loss: 118.4667
Epoch [10901/30000], Step [1/1], Training Loss: 10670.2246, Valid Loss: 107.7429
Epoch [11001/30000], Step [1/1], Training Loss: 10408.0049, Valid Loss: 114.5619
Epoch [11101/30000], Step [1/1], Training Loss: 10146.6064, Valid Loss: 119.4762
Epoch [11201/30000], Step [1/1], Training Loss: 9897.3809, Valid Loss: 114.1333
Epoch [11301/30000], Step [1/1], Training Loss: 9654.8662, Valid Loss: 126.0857
Epoch [11401/30000], Step [1/1], Training Loss: 9419.7803, Valid Loss: 124.1429
Epoch [11501/30000], Step [1/1], Training Loss: 9189.5293, Valid Loss: 121.6857
Epoch [11601/30000], Step [1/1], Training Loss: 8970.4131, Valid Loss: 115.1619
Epoch [11701/30000], Step [1/1], Training Loss: 8755.8535, Valid Loss: 119.3143
Epoch [11801/30000], Step [1/1], Training Loss: 8548.0977, Valid Loss: 122.2286
Epoch [11901/30000], Step [1/1], Training Loss: 8363.8018, Valid Loss: 124.6095
Epoch [12001/30000], Step [1/1], Training Loss: 8157.5679, Valid Loss: 126.6000
Epoch [12101/30000], Step [1/1], Training Loss: 7962.2817, Valid Loss: 133.1048
Epoch [12201/30000], Step [1/1], Training Loss: 7776.5005, Valid Loss: 139.0571
Epoch [12301/30000], Step [1/1], Training Loss: 7598.2031, Valid Loss: 133.8095
Epoch [12401/30000], Step [1/1], Training Loss: 7424.5352, Valid Loss: 129.1143
Epoch [12501/30000], Step [1/1], Training Loss: 7248.2168, Valid Loss: 122.7524
Epoch [12601/30000], Step [1/1], Training Loss: 7083.2573, Valid Loss: 124.3619
Epoch [12701/30000], Step [1/1], Training Loss: 6919.3550, Valid Loss: 131.1238
Epoch [12801/30000], Step [1/1], Training Loss: 6861.4097, Valid Loss: 133.2762
Epoch [12901/30000], Step [1/1], Training Loss: 6882.1528, Valid Loss: 120.8286
Epoch [13001/30000], Step [1/1], Training Loss: 6401.0073, Valid Loss: 128.0952
Epoch [13101/30000], Step [1/1], Training Loss: 6232.3423, Valid Loss: 119.5333
Epoch [13201/30000], Step [1/1], Training Loss: 6026.8848, Valid Loss: 130.1619
Epoch [13301/30000], Step [1/1], Training Loss: 5856.6255, Valid Loss: 120.3429
Epoch [13401/30000], Step [1/1], Training Loss: 5717.3843, Valid Loss: 124.3619
Epoch [13501/30000], Step [1/1], Training Loss: 5559.1548, Valid Loss: 131.8381
Epoch [13601/30000], Step [1/1], Training Loss: 5421.5996, Valid Loss: 121.3905
Epoch [13701/30000], Step [1/1], Training Loss: 5292.8320, Valid Loss: 127.3333
Epoch [13801/30000], Step [1/1], Training Loss: 5154.8481, Valid Loss: 121.6000
Epoch [13901/30000], Step [1/1], Training Loss: 5034.3232, Valid Loss: 121.4571
Epoch [14001/30000], Step [1/1], Training Loss: 4905.5664, Valid Loss: 122.1810
Epoch [14101/30000], Step [1/1], Training Loss: 4789.7188, Valid Loss: 120.6381
Epoch [14201/30000], Step [1/1], Training Loss: 4671.6812, Valid Loss: 122.0667
Epoch [14301/30000], Step [1/1], Training Loss: 4564.2754, Valid Loss: 127.0762
Epoch [14401/30000], Step [1/1], Training Loss: 4473.4849, Valid Loss: 125.7714
Epoch [14501/30000], Step [1/1], Training Loss: 4352.1504, Valid Loss: 135.3048
Epoch [14601/30000], Step [1/1], Training Loss: 4249.9883, Valid Loss: 137.8571
Epoch [14701/30000], Step [1/1], Training Loss: 4178.0269, Valid Loss: 134.8381
Epoch [14801/30000], Step [1/1], Training Loss: 4096.2930, Valid Loss: 144.9429
Epoch [14901/30000], Step [1/1], Training Loss: 3977.6689, Valid Loss: 145.9810
Epoch [15001/30000], Step [1/1], Training Loss: 3769.4695, Valid Loss: 127.5714
Epoch [15101/30000], Step [1/1], Training Loss: 4082.3159, Valid Loss: 150.1810
Epoch [15201/30000], Step [1/1], Training Loss: 3441.6252, Valid Loss: 132.5810
Epoch [15301/30000], Step [1/1], Training Loss: 3279.2842, Valid Loss: 136.3143
Epoch [15401/30000], Step [1/1], Training Loss: 3184.0398, Valid Loss: 134.4857
Epoch [15501/30000], Step [1/1], Training Loss: 3091.0173, Valid Loss: 129.3143
Epoch [15601/30000], Step [1/1], Training Loss: 2998.8311, Valid Loss: 130.9143
Epoch [15701/30000], Step [1/1], Training Loss: 2912.1311, Valid Loss: 131.0571
Epoch [15801/30000], Step [1/1], Training Loss: 2828.2666, Valid Loss: 132.6572
Epoch [15901/30000], Step [1/1], Training Loss: 2745.1863, Valid Loss: 134.8190
Epoch [16001/30000], Step [1/1], Training Loss: 2665.9502, Valid Loss: 131.7905
Epoch [16101/30000], Step [1/1], Training Loss: 2588.4929, Valid Loss: 127.9619
Epoch [16201/30000], Step [1/1], Training Loss: 2514.7859, Valid Loss: 133.1619
Epoch [16301/30000], Step [1/1], Training Loss: 2440.9988, Valid Loss: 131.2286
Epoch [16401/30000], Step [1/1], Training Loss: 2370.2288, Valid Loss: 132.0857
Epoch [16501/30000], Step [1/1], Training Loss: 2301.3142, Valid Loss: 133.7238
Epoch [16601/30000], Step [1/1], Training Loss: 2232.1245, Valid Loss: 131.9714
Epoch [16701/30000], Step [1/1], Training Loss: 2167.9016, Valid Loss: 139.5524
Epoch [16801/30000], Step [1/1], Training Loss: 2103.9504, Valid Loss: 141.9048
Epoch [16901/30000], Step [1/1], Training Loss: 2044.4199, Valid Loss: 137.5238
Epoch [17001/30000], Step [1/1], Training Loss: 1985.7313, Valid Loss: 141.5143
Epoch [17101/30000], Step [1/1], Training Loss: 1928.3020, Valid Loss: 141.2762
Epoch [17201/30000], Step [1/1], Training Loss: 1873.9852, Valid Loss: 147.4952
Epoch [17301/30000], Step [1/1], Training Loss: 2354.2686, Valid Loss: 138.7333
Epoch [17401/30000], Step [1/1], Training Loss: 1826.9889, Valid Loss: 134.1048
Epoch [17501/30000], Step [1/1], Training Loss: 1740.8597, Valid Loss: 137.8476
Epoch [17601/30000], Step [1/1], Training Loss: 1689.0227, Valid Loss: 141.5238
Epoch [17701/30000], Step [1/1], Training Loss: 1643.4102, Valid Loss: 144.2667
Epoch [17801/30000], Step [1/1], Training Loss: 1598.5120, Valid Loss: 144.0286
Epoch [17901/30000], Step [1/1], Training Loss: 1556.3204, Valid Loss: 136.2667
Epoch [18001/30000], Step [1/1], Training Loss: 1516.9260, Valid Loss: 144.0762
Epoch [18101/30000], Step [1/1], Training Loss: 1478.4532, Valid Loss: 144.5524
Epoch [18201/30000], Step [1/1], Training Loss: 1440.7433, Valid Loss: 146.7905
Epoch [18301/30000], Step [1/1], Training Loss: 1403.8497, Valid Loss: 148.3714
Epoch [18401/30000], Step [1/1], Training Loss: 1369.9521, Valid Loss: 151.7619
Epoch [18501/30000], Step [1/1], Training Loss: 1337.2103, Valid Loss: 145.2095
Epoch [18601/30000], Step [1/1], Training Loss: 1304.7601, Valid Loss: 144.1048
Epoch [18701/30000], Step [1/1], Training Loss: 1274.7151, Valid Loss: 144.6857
Epoch [18801/30000], Step [1/1], Training Loss: 1241.2334, Valid Loss: 149.1714
Epoch [18901/30000], Step [1/1], Training Loss: 1211.4563, Valid Loss: 153.2476
Epoch [19001/30000], Step [1/1], Training Loss: 1183.0923, Valid Loss: 151.1429
Epoch [19101/30000], Step [1/1], Training Loss: 1154.1097, Valid Loss: 157.1524
Epoch [19201/30000], Step [1/1], Training Loss: 1127.5203, Valid Loss: 148.4476
Epoch [19301/30000], Step [1/1], Training Loss: 1100.8749, Valid Loss: 152.1810
Epoch [19401/30000], Step [1/1], Training Loss: 1073.3926, Valid Loss: 150.4286
Epoch [19501/30000], Step [1/1], Training Loss: 1046.8751, Valid Loss: 148.2857
Epoch [19601/30000], Step [1/1], Training Loss: 1020.6922, Valid Loss: 149.5524
Epoch [19701/30000], Step [1/1], Training Loss: 993.9669, Valid Loss: 151.3619
Epoch [19801/30000], Step [1/1], Training Loss: 970.6324, Valid Loss: 147.5905
Epoch [19901/30000], Step [1/1], Training Loss: 946.4141, Valid Loss: 152.5524
Epoch [20001/30000], Step [1/1], Training Loss: 920.6582, Valid Loss: 155.5238
Epoch [20101/30000], Step [1/1], Training Loss: 897.6230, Valid Loss: 154.2095
Epoch [20201/30000], Step [1/1], Training Loss: 875.8593, Valid Loss: 153.1524
Epoch [20301/30000], Step [1/1], Training Loss: 852.2412, Valid Loss: 154.4286

[Epoch 25000] Rounded prediction: 
tensor([19., 22., 32., 22., 28., 29., 27., 35., 27., 39., 33., 48., 48., 47.,
        49., 37., 26., 22.,  0.,  8.,  6.,  8.,  7.,  8.,  2.,  0.,  1.,  0.,
         5.,  5.,  5.,  1.,  0.,  2.,  1.,  6.,  0.,  2.,  0.,  5.,  3., 16.,
        14.,  2.,  0.,  2.,  0.,  3.,  2.,  1.,  4.,  6.,  9.,  3., 15.,  3.,
         1.,  0.,  3.,  2.,  2.,  4.,  0.,  4.,  1., 12.,  0., 14.,  4.,  9.,
        14., 16., 15., 16., 26., 26.,  0., 27.,  7., 11.,  8.,  5., 29., 31.,
         9., 11., 21., 33., 48., 26., 19., 46., 43., 47., 48., 36., 26., 33.,
        40., 39., 44., 43., 32., 37., 33.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [20401/30000], Step [1/1], Training Loss: 830.2926, Valid Loss: 151.7619
Epoch [20501/30000], Step [1/1], Training Loss: 809.9636, Valid Loss: 148.3429
Epoch [20601/30000], Step [1/1], Training Loss: 788.5974, Valid Loss: 155.2667
Epoch [20701/30000], Step [1/1], Training Loss: 769.1450, Valid Loss: 146.2952
Epoch [20801/30000], Step [1/1], Training Loss: 750.3169, Valid Loss: 157.7524
Epoch [20901/30000], Step [1/1], Training Loss: 731.4862, Valid Loss: 161.1905
Epoch [21001/30000], Step [1/1], Training Loss: 714.0836, Valid Loss: 161.5810
Epoch [21101/30000], Step [1/1], Training Loss: 697.2496, Valid Loss: 160.6000
Epoch [21201/30000], Step [1/1], Training Loss: 680.3592, Valid Loss: 160.1048
Epoch [21301/30000], Step [1/1], Training Loss: 664.1985, Valid Loss: 157.3429
Epoch [21401/30000], Step [1/1], Training Loss: 653.0426, Valid Loss: 159.8286
Epoch [21501/30000], Step [1/1], Training Loss: 632.7100, Valid Loss: 154.3333
Epoch [21601/30000], Step [1/1], Training Loss: 616.2224, Valid Loss: 157.0191
Epoch [21701/30000], Step [1/1], Training Loss: 600.7849, Valid Loss: 160.2000
Epoch [21801/30000], Step [1/1], Training Loss: 585.6586, Valid Loss: 157.9810
Epoch [21901/30000], Step [1/1], Training Loss: 570.2914, Valid Loss: 165.9524
Epoch [22001/30000], Step [1/1], Training Loss: 555.4267, Valid Loss: 162.5238
Epoch [22101/30000], Step [1/1], Training Loss: 541.5455, Valid Loss: 162.0381
Epoch [22201/30000], Step [1/1], Training Loss: 526.1475, Valid Loss: 164.9238
Epoch [22301/30000], Step [1/1], Training Loss: 512.0858, Valid Loss: 163.7048
Epoch [22401/30000], Step [1/1], Training Loss: 498.1946, Valid Loss: 162.4762
Epoch [22501/30000], Step [1/1], Training Loss: 485.6197, Valid Loss: 174.2857
Epoch [22601/30000], Step [1/1], Training Loss: 471.6368, Valid Loss: 171.9429
Epoch [22701/30000], Step [1/1], Training Loss: 458.5594, Valid Loss: 173.6381
Epoch [22801/30000], Step [1/1], Training Loss: 446.2055, Valid Loss: 174.9429
Epoch [22901/30000], Step [1/1], Training Loss: 433.8580, Valid Loss: 173.1619
Epoch [23001/30000], Step [1/1], Training Loss: 421.7164, Valid Loss: 172.4572
Epoch [23101/30000], Step [1/1], Training Loss: 410.6268, Valid Loss: 172.0952
Epoch [23201/30000], Step [1/1], Training Loss: 400.3982, Valid Loss: 174.3143
Epoch [23301/30000], Step [1/1], Training Loss: 388.1097, Valid Loss: 173.5905
Epoch [23401/30000], Step [1/1], Training Loss: 377.2112, Valid Loss: 177.5238
Epoch [23501/30000], Step [1/1], Training Loss: 366.3127, Valid Loss: 173.1143
Epoch [23601/30000], Step [1/1], Training Loss: 355.3100, Valid Loss: 178.1143
Epoch [23701/30000], Step [1/1], Training Loss: 344.1661, Valid Loss: 177.1238
Epoch [23801/30000], Step [1/1], Training Loss: 333.6513, Valid Loss: 175.7429
Epoch [23901/30000], Step [1/1], Training Loss: 323.2684, Valid Loss: 180.1333
Epoch [24001/30000], Step [1/1], Training Loss: 312.2830, Valid Loss: 178.8000
Epoch [24101/30000], Step [1/1], Training Loss: 302.3965, Valid Loss: 181.5048
Epoch [24201/30000], Step [1/1], Training Loss: 292.5228, Valid Loss: 184.4381
Epoch [24301/30000], Step [1/1], Training Loss: 281.9868, Valid Loss: 184.2381
Epoch [24401/30000], Step [1/1], Training Loss: 360.8633, Valid Loss: 229.0381
Epoch [24501/30000], Step [1/1], Training Loss: 313.9807, Valid Loss: 219.8286
Epoch [24601/30000], Step [1/1], Training Loss: 296.0192, Valid Loss: 226.7333
Epoch [24701/30000], Step [1/1], Training Loss: 285.0787, Valid Loss: 213.9810
Epoch [24801/30000], Step [1/1], Training Loss: 276.8896, Valid Loss: 225.9333
Epoch [24901/30000], Step [1/1], Training Loss: 271.6339, Valid Loss: 219.5619
Epoch [25001/30000], Step [1/1], Training Loss: 265.1919, Valid Loss: 219.7429
Epoch [25101/30000], Step [1/1], Training Loss: 258.0936, Valid Loss: 221.8381
Epoch [25201/30000], Step [1/1], Training Loss: 250.2890, Valid Loss: 222.4095
Epoch [25301/30000], Step [1/1], Training Loss: 246.9927, Valid Loss: 223.1143
Epoch [25401/30000], Step [1/1], Training Loss: 237.7428, Valid Loss: 228.3619
Epoch [25501/30000], Step [1/1], Training Loss: 231.2612, Valid Loss: 223.6476
Epoch [25601/30000], Step [1/1], Training Loss: 225.6449, Valid Loss: 230.6476
Epoch [25701/30000], Step [1/1], Training Loss: 218.9091, Valid Loss: 226.2572
Epoch [25801/30000], Step [1/1], Training Loss: 212.9065, Valid Loss: 223.3810
Epoch [25901/30000], Step [1/1], Training Loss: 206.8890, Valid Loss: 226.0476
Epoch [26001/30000], Step [1/1], Training Loss: 199.2942, Valid Loss: 228.2572
Epoch [26101/30000], Step [1/1], Training Loss: 193.1424, Valid Loss: 228.8095
Epoch [26201/30000], Step [1/1], Training Loss: 186.9699, Valid Loss: 233.8286
Epoch [26301/30000], Step [1/1], Training Loss: 180.5132, Valid Loss: 230.6953
Epoch [26401/30000], Step [1/1], Training Loss: 174.6167, Valid Loss: 236.0762
Epoch [26501/30000], Step [1/1], Training Loss: 168.2944, Valid Loss: 232.9810
Epoch [26601/30000], Step [1/1], Training Loss: 162.0330, Valid Loss: 235.4000
Epoch [26701/30000], Step [1/1], Training Loss: 152.7971, Valid Loss: 224.6381
Epoch [26801/30000], Step [1/1], Training Loss: 147.3887, Valid Loss: 235.4286
Epoch [26901/30000], Step [1/1], Training Loss: 140.8067, Valid Loss: 231.1714
Epoch [27001/30000], Step [1/1], Training Loss: 134.8996, Valid Loss: 236.5714
Epoch [27101/30000], Step [1/1], Training Loss: 129.1059, Valid Loss: 237.0095
Epoch [27201/30000], Step [1/1], Training Loss: 123.8622, Valid Loss: 230.6476
Epoch [27301/30000], Step [1/1], Training Loss: 118.3578, Valid Loss: 231.5810
Epoch [27401/30000], Step [1/1], Training Loss: 113.2983, Valid Loss: 216.7905
Epoch [27501/30000], Step [1/1], Training Loss: 107.2817, Valid Loss: 229.1810
Epoch [27601/30000], Step [1/1], Training Loss: 102.0499, Valid Loss: 232.4953
Epoch [27701/30000], Step [1/1], Training Loss: 97.2217, Valid Loss: 236.3524
Epoch [27801/30000], Step [1/1], Training Loss: 92.4948, Valid Loss: 222.9429
Epoch [27901/30000], Step [1/1], Training Loss: 87.4770, Valid Loss: 229.7429
Epoch [28001/30000], Step [1/1], Training Loss: 83.0044, Valid Loss: 232.6762
Epoch [28101/30000], Step [1/1], Training Loss: 78.4808, Valid Loss: 239.3524
Epoch [28201/30000], Step [1/1], Training Loss: 73.9818, Valid Loss: 230.9905
Epoch [28301/30000], Step [1/1], Training Loss: 69.5065, Valid Loss: 229.4857
Epoch [28401/30000], Step [1/1], Training Loss: 68.5657, Valid Loss: 249.2572
Epoch [28501/30000], Step [1/1], Training Loss: 61.8425, Valid Loss: 238.3048
Epoch [28601/30000], Step [1/1], Training Loss: 57.6539, Valid Loss: 240.9714
Epoch [28701/30000], Step [1/1], Training Loss: 54.1951, Valid Loss: 239.3905
Epoch [28801/30000], Step [1/1], Training Loss: 51.1261, Valid Loss: 247.4191
Epoch [28901/30000], Step [1/1], Training Loss: 47.0844, Valid Loss: 247.8667
Epoch [29001/30000], Step [1/1], Training Loss: 43.9601, Valid Loss: 240.3619
Epoch [29101/30000], Step [1/1], Training Loss: 41.7648, Valid Loss: 239.6095
Epoch [29201/30000], Step [1/1], Training Loss: 38.1883, Valid Loss: 236.7619
Epoch [29301/30000], Step [1/1], Training Loss: 35.4619, Valid Loss: 238.0952
Epoch [29401/30000], Step [1/1], Training Loss: 32.8813, Valid Loss: 237.5333
Epoch [29501/30000], Step [1/1], Training Loss: 30.2174, Valid Loss: 226.6953
Epoch [29601/30000], Step [1/1], Training Loss: 27.8142, Valid Loss: 246.4667
Epoch [29701/30000], Step [1/1], Training Loss: 25.9072, Valid Loss: 243.0667
Epoch [29801/30000], Step [1/1], Training Loss: 23.7214, Valid Loss: 245.0191
Epoch [29901/30000], Step [1/1], Training Loss: 21.4439, Valid Loss: 241.1524

 End Time: 2021/04/20, 01:23:23




##########################################################

Epochs=30000 	batch=245 	lr=6e-05
window=2 	seq_len=7 	hidden_size=1024 	layers=2

Start Time = 2021/04/20, 01:23:23
##########################################################


[Epoch 0] Rounded prediction: 
tensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.],
       device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([19., 18., 29., 24., 24., 29., 31., 42., 40., 44., 47., 49., 50., 52.,
        63., 54., 46., 44., 33., 31., 20., 13., 16., 17., 10.,  9., 13., 11.,
        11., 11., 13.,  8.,  8., 15., 10., 10.,  8., 12.,  6., 14., 11., 18.,
        17., 15.,  8., 10., 10., 10.,  9., 10., 12., 12., 15.,  9., 19., 13.,
         9., 10., 10., 12.,  9., 14.,  8., 15.,  9., 17., 11., 17., 16., 13.,
        13., 14., 14., 13., 19., 23., 18., 27., 24., 22., 22., 18., 24., 25.,
        22., 15., 11., 13., 32., 33., 25., 33., 47., 53., 43., 34., 26., 26.,
        32., 33., 23., 25., 26., 23., 21.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([17., 18., 26., 25., 24., 27., 29., 37., 32., 34., 36., 36., 42., 38.,
        41., 34., 33., 30., 23., 19., 15., 13., 13., 11.,  4.,  4., 12.,  6.,
        10., 10., 11.,  1.,  4., 15.,  2., 11.,  3., 12.,  0., 20.,  3., 23.,
        10., 13.,  1.,  5.,  5., 11.,  6.,  8.,  7.,  9., 14.,  6., 22.,  1.,
         8.,  4.,  9., 10.,  6., 13.,  0., 15.,  0., 19.,  3., 17.,  7.,  8.,
         7., 10., 12., 16., 21., 24., 12., 28., 12., 21., 10., 12., 22., 14.,
        16.,  8.,  7., 14., 28., 25., 18., 29., 44., 50., 40., 26., 22., 25.,
        31., 24., 20., 21., 19., 18., 16.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128663.6016, Valid Loss: 228.8476
Epoch [101/30000], Step [1/1], Training Loss: 118908.2109, Valid Loss: 192.7333
Epoch [201/30000], Step [1/1], Training Loss: 116081.4297, Valid Loss: 351.3048
Epoch [301/30000], Step [1/1], Training Loss: 113453.5000, Valid Loss: 581.0190
Epoch [401/30000], Step [1/1], Training Loss: 110950.4609, Valid Loss: 916.5620
Epoch [501/30000], Step [1/1], Training Loss: 108554.5078, Valid Loss: 1293.4191
Epoch [601/30000], Step [1/1], Training Loss: 106244.1797, Valid Loss: 1702.1620
Epoch [701/30000], Step [1/1], Training Loss: 104022.2188, Valid Loss: 2219.8762
Epoch [801/30000], Step [1/1], Training Loss: 101876.6875, Valid Loss: 2744.2668
Epoch [901/30000], Step [1/1], Training Loss: 99793.1641, Valid Loss: 1563.9714
Epoch [1001/30000], Step [1/1], Training Loss: 97497.7812, Valid Loss: 71.8381
Epoch [1101/30000], Step [1/1], Training Loss: 95410.7344, Valid Loss: 68.0762
Epoch [1201/30000], Step [1/1], Training Loss: 93380.6875, Valid Loss: 77.9238
Epoch [1301/30000], Step [1/1], Training Loss: 91403.2578, Valid Loss: 83.0667
Epoch [1401/30000], Step [1/1], Training Loss: 89470.8672, Valid Loss: 141.1429
Epoch [1501/30000], Step [1/1], Training Loss: 87580.1406, Valid Loss: 186.6000
Epoch [1601/30000], Step [1/1], Training Loss: 85733.8438, Valid Loss: 308.5714
Epoch [1701/30000], Step [1/1], Training Loss: 83929.9688, Valid Loss: 502.9619
Epoch [1801/30000], Step [1/1], Training Loss: 82171.7422, Valid Loss: 476.4191
Epoch [1901/30000], Step [1/1], Training Loss: 80453.2422, Valid Loss: 577.5620
Epoch [2001/30000], Step [1/1], Training Loss: 78775.7656, Valid Loss: 777.6381
Epoch [2101/30000], Step [1/1], Training Loss: 77137.2266, Valid Loss: 768.6096
Epoch [2201/30000], Step [1/1], Training Loss: 75538.0391, Valid Loss: 938.9238
Epoch [2301/30000], Step [1/1], Training Loss: 73977.4766, Valid Loss: 970.1048
Epoch [2401/30000], Step [1/1], Training Loss: 72454.5078, Valid Loss: 1028.4857
Epoch [2501/30000], Step [1/1], Training Loss: 70965.6328, Valid Loss: 971.9048
Epoch [2601/30000], Step [1/1], Training Loss: 69515.6875, Valid Loss: 1063.2858
Epoch [2701/30000], Step [1/1], Training Loss: 68100.9922, Valid Loss: 967.2477
Epoch [2801/30000], Step [1/1], Training Loss: 66721.0938, Valid Loss: 856.9619
Epoch [2901/30000], Step [1/1], Training Loss: 65374.7773, Valid Loss: 1013.3429
Epoch [3001/30000], Step [1/1], Training Loss: 64063.7500, Valid Loss: 1118.0953
Epoch [3101/30000], Step [1/1], Training Loss: 62786.5000, Valid Loss: 1268.9619
Epoch [3201/30000], Step [1/1], Training Loss: 61523.0078, Valid Loss: 1011.9810
Epoch [3301/30000], Step [1/1], Training Loss: 60215.6758, Valid Loss: 489.3810
Epoch [3401/30000], Step [1/1], Training Loss: 58969.0547, Valid Loss: 411.7048
Epoch [3501/30000], Step [1/1], Training Loss: 57761.7891, Valid Loss: 484.3715
Epoch [3601/30000], Step [1/1], Training Loss: 56568.5977, Valid Loss: 544.6476
Epoch [3701/30000], Step [1/1], Training Loss: 55409.6562, Valid Loss: 445.0762
Epoch [3801/30000], Step [1/1], Training Loss: 54279.2773, Valid Loss: 411.1810
Epoch [3901/30000], Step [1/1], Training Loss: 53149.3828, Valid Loss: 398.7238
Epoch [4001/30000], Step [1/1], Training Loss: 52044.3828, Valid Loss: 429.9429
Epoch [4101/30000], Step [1/1], Training Loss: 50976.3242, Valid Loss: 360.5429
Epoch [4201/30000], Step [1/1], Training Loss: 49863.8828, Valid Loss: 363.6857
Epoch [4301/30000], Step [1/1], Training Loss: 48808.6133, Valid Loss: 342.9714
Epoch [4401/30000], Step [1/1], Training Loss: 47803.6133, Valid Loss: 365.6762
Epoch [4501/30000], Step [1/1], Training Loss: 46813.4570, Valid Loss: 274.9143
Epoch [4601/30000], Step [1/1], Training Loss: 45839.7148, Valid Loss: 298.9619
Epoch [4701/30000], Step [1/1], Training Loss: 44887.2344, Valid Loss: 321.8381
Epoch [4801/30000], Step [1/1], Training Loss: 43968.9453, Valid Loss: 347.6572
Epoch [4901/30000], Step [1/1], Training Loss: 43068.1211, Valid Loss: 312.9429
Epoch [5001/30000], Step [1/1], Training Loss: 42202.3555, Valid Loss: 281.8953
Epoch [5101/30000], Step [1/1], Training Loss: 41359.8789, Valid Loss: 248.3333
Epoch [5201/30000], Step [1/1], Training Loss: 40507.7188, Valid Loss: 255.9143
Epoch [5301/30000], Step [1/1], Training Loss: 39679.4297, Valid Loss: 234.9619
Epoch [5401/30000], Step [1/1], Training Loss: 38719.1602, Valid Loss: 256.0000
Epoch [5501/30000], Step [1/1], Training Loss: 37958.4102, Valid Loss: 153.1143
Epoch [5601/30000], Step [1/1], Training Loss: 37032.4258, Valid Loss: 168.7048
Epoch [5701/30000], Step [1/1], Training Loss: 36227.4414, Valid Loss: 181.6095
Epoch [5801/30000], Step [1/1], Training Loss: 35462.0586, Valid Loss: 182.0000
Epoch [5901/30000], Step [1/1], Training Loss: 34723.0820, Valid Loss: 171.7048
Epoch [6001/30000], Step [1/1], Training Loss: 33973.5859, Valid Loss: 171.8571
Epoch [6101/30000], Step [1/1], Training Loss: 33265.7852, Valid Loss: 205.0000
Epoch [6201/30000], Step [1/1], Training Loss: 32559.9453, Valid Loss: 199.7238
Epoch [6301/30000], Step [1/1], Training Loss: 31952.5000, Valid Loss: 167.2667
Epoch [6401/30000], Step [1/1], Training Loss: 31214.9648, Valid Loss: 137.8000
Epoch [6501/30000], Step [1/1], Training Loss: 30464.8594, Valid Loss: 147.0667
Epoch [6601/30000], Step [1/1], Training Loss: 29815.4688, Valid Loss: 144.4952
Epoch [6701/30000], Step [1/1], Training Loss: 29168.2637, Valid Loss: 157.6953
Epoch [6801/30000], Step [1/1], Training Loss: 28559.6172, Valid Loss: 169.3619
Epoch [6901/30000], Step [1/1], Training Loss: 27949.0508, Valid Loss: 168.1143
Epoch [7001/30000], Step [1/1], Training Loss: 27356.4297, Valid Loss: 168.8762
Epoch [7101/30000], Step [1/1], Training Loss: 26779.6895, Valid Loss: 181.2286
Epoch [7201/30000], Step [1/1], Training Loss: 26221.1738, Valid Loss: 173.1619
Epoch [7301/30000], Step [1/1], Training Loss: 25665.9414, Valid Loss: 193.5905
Epoch [7401/30000], Step [1/1], Training Loss: 25110.9141, Valid Loss: 180.9905
Epoch [7501/30000], Step [1/1], Training Loss: 24771.2207, Valid Loss: 168.7810
Epoch [7601/30000], Step [1/1], Training Loss: 24091.8848, Valid Loss: 145.2857
Epoch [7701/30000], Step [1/1], Training Loss: 23567.0117, Valid Loss: 162.0191
Epoch [7801/30000], Step [1/1], Training Loss: 23060.1934, Valid Loss: 169.5905
Epoch [7901/30000], Step [1/1], Training Loss: 22882.7695, Valid Loss: 138.6667
Epoch [8001/30000], Step [1/1], Training Loss: 21877.4453, Valid Loss: 146.2571
Epoch [8101/30000], Step [1/1], Training Loss: 21299.9219, Valid Loss: 170.6667
Epoch [8201/30000], Step [1/1], Training Loss: 20819.9102, Valid Loss: 169.6857
Epoch [8301/30000], Step [1/1], Training Loss: 20376.6738, Valid Loss: 169.4572
Epoch [8401/30000], Step [1/1], Training Loss: 19906.9824, Valid Loss: 166.0095
Epoch [8501/30000], Step [1/1], Training Loss: 19463.5000, Valid Loss: 175.6572
Epoch [8601/30000], Step [1/1], Training Loss: 19040.9023, Valid Loss: 171.8762
Epoch [8701/30000], Step [1/1], Training Loss: 18625.5215, Valid Loss: 167.2286
Epoch [8801/30000], Step [1/1], Training Loss: 18224.3496, Valid Loss: 180.0286
Epoch [8901/30000], Step [1/1], Training Loss: 17821.1406, Valid Loss: 180.9619
Epoch [9001/30000], Step [1/1], Training Loss: 17438.2480, Valid Loss: 183.7238
Epoch [9101/30000], Step [1/1], Training Loss: 17075.5391, Valid Loss: 185.5238
Epoch [9201/30000], Step [1/1], Training Loss: 16714.5996, Valid Loss: 186.1238
Epoch [9301/30000], Step [1/1], Training Loss: 16358.2695, Valid Loss: 192.6190
Epoch [9401/30000], Step [1/1], Training Loss: 16014.8184, Valid Loss: 183.2762
Epoch [9501/30000], Step [1/1], Training Loss: 15681.9893, Valid Loss: 199.3619
Epoch [9601/30000], Step [1/1], Training Loss: 15364.3857, Valid Loss: 193.9905
Epoch [9701/30000], Step [1/1], Training Loss: 15052.9775, Valid Loss: 190.3238
Epoch [9801/30000], Step [1/1], Training Loss: 14750.2744, Valid Loss: 178.3238
Epoch [9901/30000], Step [1/1], Training Loss: 14459.3701, Valid Loss: 188.2095
Epoch [10001/30000], Step [1/1], Training Loss: 14179.4961, Valid Loss: 177.0095
Epoch [10101/30000], Step [1/1], Training Loss: 13901.0371, Valid Loss: 175.3810

[Epoch 15000] Rounded prediction: 
tensor([16., 19., 26., 26., 22., 27., 27., 36., 32., 35., 33., 35., 35., 37.,
        35., 32., 28., 33., 24., 23., 17., 13., 12.,  8.,  6.,  8., 13.,  7.,
        11.,  7.,  7.,  3.,  4., 14.,  3., 12.,  3., 11.,  3., 20.,  4., 18.,
        10., 10.,  1.,  7.,  4., 11.,  8., 11., 13., 13., 16.,  9., 18.,  2.,
         9.,  5., 12.,  9.,  8., 11.,  3., 17.,  2., 20.,  4., 18.,  6., 13.,
        15., 17., 18., 20., 20., 28., 15., 32., 11., 19., 10., 13., 22., 19.,
        18., 12., 14., 16., 27., 23., 20., 41., 44., 53., 46., 31., 29., 35.,
        37., 17., 10., 17., 13., 13.,  3.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([16., 20., 22., 25., 23., 28., 28., 36., 32., 34., 32., 34., 39., 39.,
        38., 35., 34., 36., 20., 18., 12.,  9.,  9.,  6.,  5.,  6., 10.,  4.,
         8.,  6.,  4.,  3.,  3., 13.,  0.,  9.,  2.,  9.,  0., 17.,  1., 13.,
        11.,  7.,  0.,  8.,  4.,  8.,  5.,  7., 10., 11., 13.,  7., 14.,  2.,
         8.,  1., 11.,  5.,  5.,  8.,  2., 14.,  2., 17.,  4., 13.,  5., 10.,
        11., 14., 15., 17., 20., 28., 12., 32., 11., 12., 12., 12., 24., 24.,
        15.,  9.,  7., 18., 32., 27., 22., 48., 51., 62., 50., 28., 27., 40.,
        40., 27., 16., 22., 14., 13.,  0.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [10201/30000], Step [1/1], Training Loss: 13637.2676, Valid Loss: 193.2000
Epoch [10301/30000], Step [1/1], Training Loss: 13372.8701, Valid Loss: 186.2476
Epoch [10401/30000], Step [1/1], Training Loss: 13088.1553, Valid Loss: 164.5429
Epoch [10501/30000], Step [1/1], Training Loss: 12653.0908, Valid Loss: 149.8190
Epoch [10601/30000], Step [1/1], Training Loss: 12251.4824, Valid Loss: 158.3048
Epoch [10701/30000], Step [1/1], Training Loss: 11944.6025, Valid Loss: 165.0000
Epoch [10801/30000], Step [1/1], Training Loss: 11687.5947, Valid Loss: 173.0857
Epoch [10901/30000], Step [1/1], Training Loss: 11426.9355, Valid Loss: 169.1714
Epoch [11001/30000], Step [1/1], Training Loss: 11206.2305, Valid Loss: 176.3524
Epoch [11101/30000], Step [1/1], Training Loss: 10962.8818, Valid Loss: 182.1810
Epoch [11201/30000], Step [1/1], Training Loss: 10742.7578, Valid Loss: 178.2191
Epoch [11301/30000], Step [1/1], Training Loss: 10541.9688, Valid Loss: 175.7333
Epoch [11401/30000], Step [1/1], Training Loss: 10364.6162, Valid Loss: 160.2857
Epoch [11501/30000], Step [1/1], Training Loss: 9472.1240, Valid Loss: 157.3810
Epoch [11601/30000], Step [1/1], Training Loss: 9206.6162, Valid Loss: 166.3048
Epoch [11701/30000], Step [1/1], Training Loss: 8931.9512, Valid Loss: 167.0952
Epoch [11801/30000], Step [1/1], Training Loss: 8671.8232, Valid Loss: 174.3333
Epoch [11901/30000], Step [1/1], Training Loss: 8443.8799, Valid Loss: 168.0762
Epoch [12001/30000], Step [1/1], Training Loss: 8181.4502, Valid Loss: 173.6667
Epoch [12101/30000], Step [1/1], Training Loss: 7952.7300, Valid Loss: 181.6667
Epoch [12201/30000], Step [1/1], Training Loss: 7735.2812, Valid Loss: 182.0000
Epoch [12301/30000], Step [1/1], Training Loss: 7532.7578, Valid Loss: 183.4952
Epoch [12401/30000], Step [1/1], Training Loss: 7328.0781, Valid Loss: 175.9810
Epoch [12501/30000], Step [1/1], Training Loss: 7132.3232, Valid Loss: 177.0571
Epoch [12601/30000], Step [1/1], Training Loss: 6934.3965, Valid Loss: 176.8762
Epoch [12701/30000], Step [1/1], Training Loss: 6742.0571, Valid Loss: 185.8286
Epoch [12801/30000], Step [1/1], Training Loss: 6550.6631, Valid Loss: 175.5905
Epoch [12901/30000], Step [1/1], Training Loss: 6384.8457, Valid Loss: 173.5238
Epoch [13001/30000], Step [1/1], Training Loss: 6199.7266, Valid Loss: 175.0381
Epoch [13101/30000], Step [1/1], Training Loss: 6028.0381, Valid Loss: 171.0000
Epoch [13201/30000], Step [1/1], Training Loss: 5863.9443, Valid Loss: 177.0857
Epoch [13301/30000], Step [1/1], Training Loss: 5699.6387, Valid Loss: 178.7143
Epoch [13401/30000], Step [1/1], Training Loss: 5793.6797, Valid Loss: 185.8952
Epoch [13501/30000], Step [1/1], Training Loss: 5404.0288, Valid Loss: 181.0571
Epoch [13601/30000], Step [1/1], Training Loss: 5250.2964, Valid Loss: 185.6381
Epoch [13701/30000], Step [1/1], Training Loss: 5115.1943, Valid Loss: 172.2000
Epoch [13801/30000], Step [1/1], Training Loss: 4968.4971, Valid Loss: 179.6000
Epoch [13901/30000], Step [1/1], Training Loss: 4829.5703, Valid Loss: 186.3905
Epoch [14001/30000], Step [1/1], Training Loss: 4698.2393, Valid Loss: 177.9333
Epoch [14101/30000], Step [1/1], Training Loss: 4573.3013, Valid Loss: 178.5429
Epoch [14201/30000], Step [1/1], Training Loss: 4443.1509, Valid Loss: 179.0952
Epoch [14301/30000], Step [1/1], Training Loss: 4323.8398, Valid Loss: 183.5524
Epoch [14401/30000], Step [1/1], Training Loss: 4205.6753, Valid Loss: 182.9714
Epoch [14501/30000], Step [1/1], Training Loss: 4089.7361, Valid Loss: 188.5905
Epoch [14601/30000], Step [1/1], Training Loss: 3975.0854, Valid Loss: 192.7429
Epoch [14701/30000], Step [1/1], Training Loss: 3867.4973, Valid Loss: 186.7905
Epoch [14801/30000], Step [1/1], Training Loss: 3772.2122, Valid Loss: 191.4381
Epoch [14901/30000], Step [1/1], Training Loss: 3664.6382, Valid Loss: 198.1143
Epoch [15001/30000], Step [1/1], Training Loss: 3563.9963, Valid Loss: 189.5619
Epoch [15101/30000], Step [1/1], Training Loss: 3469.6357, Valid Loss: 185.8571
Epoch [15201/30000], Step [1/1], Training Loss: 3376.7485, Valid Loss: 189.0095
Epoch [15301/30000], Step [1/1], Training Loss: 3286.0779, Valid Loss: 190.0762
Epoch [15401/30000], Step [1/1], Training Loss: 3199.4170, Valid Loss: 187.2572
Epoch [15501/30000], Step [1/1], Training Loss: 3111.7942, Valid Loss: 191.0762
Epoch [15601/30000], Step [1/1], Training Loss: 3031.9116, Valid Loss: 187.9714
Epoch [15701/30000], Step [1/1], Training Loss: 2951.6587, Valid Loss: 195.3524
Epoch [15801/30000], Step [1/1], Training Loss: 2872.9448, Valid Loss: 195.7810
Epoch [15901/30000], Step [1/1], Training Loss: 2795.4529, Valid Loss: 199.5048
Epoch [16001/30000], Step [1/1], Training Loss: 2719.1838, Valid Loss: 195.5619
Epoch [16101/30000], Step [1/1], Training Loss: 2650.3933, Valid Loss: 198.0857
Epoch [16201/30000], Step [1/1], Training Loss: 2581.7798, Valid Loss: 191.2286
Epoch [16301/30000], Step [1/1], Training Loss: 6026.2065, Valid Loss: 148.7619
Epoch [16401/30000], Step [1/1], Training Loss: 3262.1973, Valid Loss: 196.9810
Epoch [16501/30000], Step [1/1], Training Loss: 2518.7224, Valid Loss: 197.9810
Epoch [16601/30000], Step [1/1], Training Loss: 2370.6230, Valid Loss: 191.1524
Epoch [16701/30000], Step [1/1], Training Loss: 2283.7419, Valid Loss: 187.7810
Epoch [16801/30000], Step [1/1], Training Loss: 2207.1484, Valid Loss: 184.0762
Epoch [16901/30000], Step [1/1], Training Loss: 2138.6731, Valid Loss: 189.0952
Epoch [17001/30000], Step [1/1], Training Loss: 2073.1682, Valid Loss: 192.1238
Epoch [17101/30000], Step [1/1], Training Loss: 2018.6617, Valid Loss: 190.9810
Epoch [17201/30000], Step [1/1], Training Loss: 1962.6958, Valid Loss: 191.6381
Epoch [17301/30000], Step [1/1], Training Loss: 1904.4714, Valid Loss: 198.3238
Epoch [17401/30000], Step [1/1], Training Loss: 1851.3931, Valid Loss: 193.0000
Epoch [17501/30000], Step [1/1], Training Loss: 1798.2665, Valid Loss: 195.8000
Epoch [17601/30000], Step [1/1], Training Loss: 1748.3035, Valid Loss: 195.3429
Epoch [17701/30000], Step [1/1], Training Loss: 1701.4794, Valid Loss: 196.5905
Epoch [17801/30000], Step [1/1], Training Loss: 1664.6669, Valid Loss: 195.4572
Epoch [17901/30000], Step [1/1], Training Loss: 1612.2534, Valid Loss: 197.5238
Epoch [18001/30000], Step [1/1], Training Loss: 1575.3868, Valid Loss: 196.2095
Epoch [18101/30000], Step [1/1], Training Loss: 1532.9242, Valid Loss: 199.7714
Epoch [18201/30000], Step [1/1], Training Loss: 1500.7346, Valid Loss: 194.1429
Epoch [18301/30000], Step [1/1], Training Loss: 1460.0247, Valid Loss: 193.0857
Epoch [18401/30000], Step [1/1], Training Loss: 1423.6091, Valid Loss: 193.8095
Epoch [18501/30000], Step [1/1], Training Loss: 1390.4475, Valid Loss: 201.5048
Epoch [18601/30000], Step [1/1], Training Loss: 1357.4064, Valid Loss: 201.6857
Epoch [18701/30000], Step [1/1], Training Loss: 1327.5115, Valid Loss: 195.4286
Epoch [18801/30000], Step [1/1], Training Loss: 1290.8984, Valid Loss: 198.1143
Epoch [18901/30000], Step [1/1], Training Loss: 1259.8082, Valid Loss: 200.7048
Epoch [19001/30000], Step [1/1], Training Loss: 1228.4666, Valid Loss: 199.4381
Epoch [19101/30000], Step [1/1], Training Loss: 1202.0543, Valid Loss: 198.7143
Epoch [19201/30000], Step [1/1], Training Loss: 1173.5898, Valid Loss: 199.9524
Epoch [19301/30000], Step [1/1], Training Loss: 1149.6177, Valid Loss: 203.7333
Epoch [19401/30000], Step [1/1], Training Loss: 1121.2046, Valid Loss: 199.8952
Epoch [19501/30000], Step [1/1], Training Loss: 1096.0677, Valid Loss: 199.8857
Epoch [19601/30000], Step [1/1], Training Loss: 1069.6121, Valid Loss: 201.3048
Epoch [19701/30000], Step [1/1], Training Loss: 1042.6936, Valid Loss: 207.1524
Epoch [19801/30000], Step [1/1], Training Loss: 1018.7463, Valid Loss: 200.3524
Epoch [19901/30000], Step [1/1], Training Loss: 998.5489, Valid Loss: 201.4286
Epoch [20001/30000], Step [1/1], Training Loss: 968.8354, Valid Loss: 201.2286
Epoch [20101/30000], Step [1/1], Training Loss: 944.9185, Valid Loss: 224.7238
Epoch [20201/30000], Step [1/1], Training Loss: 917.4528, Valid Loss: 218.1524
Epoch [20301/30000], Step [1/1], Training Loss: 894.4814, Valid Loss: 214.9524

[Epoch 25000] Rounded prediction: 
tensor([19., 21., 24., 26., 27., 30., 29., 41., 36., 38., 38., 38., 43., 45.,
        43., 41., 37., 38., 12., 16.,  5.,  6.,  6.,  5.,  4.,  6.,  9.,  2.,
         7.,  6.,  3.,  3.,  2., 12.,  0.,  8.,  2.,  8.,  0., 16.,  0.,  9.,
        10.,  5.,  0.,  8.,  3.,  7.,  4.,  6.,  9.,  9.,  9.,  6., 11.,  2.,
         7.,  0., 10.,  5.,  5.,  8.,  2., 13.,  1., 15.,  1., 10.,  4.,  9.,
         9., 13., 12., 13., 16., 27.,  7., 29.,  6.,  9., 12., 10., 23., 22.,
         9.,  6.,  6., 18., 33., 32., 25., 56., 55., 65., 57., 28., 26., 42.,
        47., 18., 20., 22., 14., 15.,  2.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [20401/30000], Step [1/1], Training Loss: 873.4097, Valid Loss: 213.1619
Epoch [20501/30000], Step [1/1], Training Loss: 852.1276, Valid Loss: 214.5048
Epoch [20601/30000], Step [1/1], Training Loss: 831.2917, Valid Loss: 218.6476
Epoch [20701/30000], Step [1/1], Training Loss: 808.8135, Valid Loss: 205.8381
Epoch [20801/30000], Step [1/1], Training Loss: 787.1669, Valid Loss: 208.4667
Epoch [20901/30000], Step [1/1], Training Loss: 767.0748, Valid Loss: 217.4857
Epoch [21001/30000], Step [1/1], Training Loss: 747.1592, Valid Loss: 213.5048
Epoch [21101/30000], Step [1/1], Training Loss: 729.6733, Valid Loss: 215.1429
Epoch [21201/30000], Step [1/1], Training Loss: 713.3112, Valid Loss: 223.4857
Epoch [21301/30000], Step [1/1], Training Loss: 695.0646, Valid Loss: 217.2476
Epoch [21401/30000], Step [1/1], Training Loss: 678.5722, Valid Loss: 214.0667
Epoch [21501/30000], Step [1/1], Training Loss: 664.7856, Valid Loss: 218.0286
Epoch [21601/30000], Step [1/1], Training Loss: 647.8665, Valid Loss: 222.7619
Epoch [21701/30000], Step [1/1], Training Loss: 632.0380, Valid Loss: 221.9048
Epoch [21801/30000], Step [1/1], Training Loss: 618.8264, Valid Loss: 221.1524
Epoch [21901/30000], Step [1/1], Training Loss: 603.2382, Valid Loss: 222.6286
Epoch [22001/30000], Step [1/1], Training Loss: 586.2674, Valid Loss: 230.5429
Epoch [22101/30000], Step [1/1], Training Loss: 570.2618, Valid Loss: 220.4952
Epoch [22201/30000], Step [1/1], Training Loss: 555.9024, Valid Loss: 221.6762
Epoch [22301/30000], Step [1/1], Training Loss: 541.6653, Valid Loss: 223.0286
Epoch [22401/30000], Step [1/1], Training Loss: 528.0693, Valid Loss: 231.3905
Epoch [22501/30000], Step [1/1], Training Loss: 515.0986, Valid Loss: 220.0000
Epoch [22601/30000], Step [1/1], Training Loss: 498.8705, Valid Loss: 233.0000
Epoch [22701/30000], Step [1/1], Training Loss: 485.0954, Valid Loss: 227.6286
Epoch [22801/30000], Step [1/1], Training Loss: 471.8777, Valid Loss: 234.6190
Epoch [22901/30000], Step [1/1], Training Loss: 458.4236, Valid Loss: 225.9810
Epoch [23001/30000], Step [1/1], Training Loss: 445.3214, Valid Loss: 231.2667
Epoch [23101/30000], Step [1/1], Training Loss: 432.5716, Valid Loss: 230.4667
Epoch [23201/30000], Step [1/1], Training Loss: 421.4021, Valid Loss: 232.5810
Epoch [23301/30000], Step [1/1], Training Loss: 407.3582, Valid Loss: 223.8476
Epoch [23401/30000], Step [1/1], Training Loss: 395.4211, Valid Loss: 230.9429
Epoch [23501/30000], Step [1/1], Training Loss: 384.6348, Valid Loss: 236.6381
Epoch [23601/30000], Step [1/1], Training Loss: 372.5945, Valid Loss: 230.6381
Epoch [23701/30000], Step [1/1], Training Loss: 361.0841, Valid Loss: 232.0000
Epoch [23801/30000], Step [1/1], Training Loss: 350.4355, Valid Loss: 230.6381
Epoch [23901/30000], Step [1/1], Training Loss: 340.0230, Valid Loss: 237.2572
Epoch [24001/30000], Step [1/1], Training Loss: 328.4878, Valid Loss: 234.3238
Epoch [24101/30000], Step [1/1], Training Loss: 318.8069, Valid Loss: 230.8857
Epoch [24201/30000], Step [1/1], Training Loss: 307.0094, Valid Loss: 232.0571
Epoch [24301/30000], Step [1/1], Training Loss: 296.4959, Valid Loss: 231.6381
Epoch [24401/30000], Step [1/1], Training Loss: 286.3746, Valid Loss: 230.6095
Epoch [24501/30000], Step [1/1], Training Loss: 276.5807, Valid Loss: 237.8000
Epoch [24601/30000], Step [1/1], Training Loss: 266.9606, Valid Loss: 243.4572
Epoch [24701/30000], Step [1/1], Training Loss: 256.9877, Valid Loss: 235.6286
Epoch [24801/30000], Step [1/1], Training Loss: 247.0904, Valid Loss: 229.1810
Epoch [24901/30000], Step [1/1], Training Loss: 237.5414, Valid Loss: 237.9714
Epoch [25001/30000], Step [1/1], Training Loss: 227.7791, Valid Loss: 243.7429
Epoch [25101/30000], Step [1/1], Training Loss: 218.7488, Valid Loss: 236.8762
Epoch [25201/30000], Step [1/1], Training Loss: 209.7907, Valid Loss: 234.1333
Epoch [25301/30000], Step [1/1], Training Loss: 200.8783, Valid Loss: 244.0667
Epoch [25401/30000], Step [1/1], Training Loss: 192.5524, Valid Loss: 231.8286
Epoch [25501/30000], Step [1/1], Training Loss: 184.4968, Valid Loss: 236.0952
Epoch [25601/30000], Step [1/1], Training Loss: 176.5560, Valid Loss: 241.6286
Epoch [25701/30000], Step [1/1], Training Loss: 168.2755, Valid Loss: 240.6476
Epoch [25801/30000], Step [1/1], Training Loss: 161.1552, Valid Loss: 239.5619
Epoch [25901/30000], Step [1/1], Training Loss: 153.3949, Valid Loss: 249.0191
Epoch [26001/30000], Step [1/1], Training Loss: 145.9852, Valid Loss: 252.5048
Epoch [26101/30000], Step [1/1], Training Loss: 138.8953, Valid Loss: 243.2000
Epoch [26201/30000], Step [1/1], Training Loss: 131.6683, Valid Loss: 239.0857
Epoch [26301/30000], Step [1/1], Training Loss: 125.2119, Valid Loss: 241.6953
Epoch [26401/30000], Step [1/1], Training Loss: 118.6395, Valid Loss: 235.1048
Epoch [26501/30000], Step [1/1], Training Loss: 112.0718, Valid Loss: 248.7429
Epoch [26601/30000], Step [1/1], Training Loss: 107.5696, Valid Loss: 244.3619
Epoch [26701/30000], Step [1/1], Training Loss: 100.5818, Valid Loss: 248.6953
Epoch [26801/30000], Step [1/1], Training Loss: 95.3213, Valid Loss: 247.5429
Epoch [26901/30000], Step [1/1], Training Loss: 121.8807, Valid Loss: 249.1238
Epoch [27001/30000], Step [1/1], Training Loss: 114.0201, Valid Loss: 241.2000
Epoch [27101/30000], Step [1/1], Training Loss: 101.4865, Valid Loss: 246.6191
Epoch [27201/30000], Step [1/1], Training Loss: 97.9439, Valid Loss: 250.0762
Epoch [27301/30000], Step [1/1], Training Loss: 94.2763, Valid Loss: 246.7429
Epoch [27401/30000], Step [1/1], Training Loss: 91.7857, Valid Loss: 247.0476
Epoch [27501/30000], Step [1/1], Training Loss: 87.9096, Valid Loss: 243.2476
Epoch [27601/30000], Step [1/1], Training Loss: 84.4766, Valid Loss: 237.5333
Epoch [27701/30000], Step [1/1], Training Loss: 82.3369, Valid Loss: 241.0191
Epoch [27801/30000], Step [1/1], Training Loss: 79.0356, Valid Loss: 246.0476
Epoch [27901/30000], Step [1/1], Training Loss: 76.1421, Valid Loss: 242.8000
Epoch [28001/30000], Step [1/1], Training Loss: 74.8639, Valid Loss: 247.1048
Epoch [28101/30000], Step [1/1], Training Loss: 70.8961, Valid Loss: 245.3429
Epoch [28201/30000], Step [1/1], Training Loss: 69.0776, Valid Loss: 245.2476
Epoch [28301/30000], Step [1/1], Training Loss: 65.7815, Valid Loss: 252.6762
Epoch [28401/30000], Step [1/1], Training Loss: 63.1646, Valid Loss: 246.8476
Epoch [28501/30000], Step [1/1], Training Loss: 60.5064, Valid Loss: 249.8571
Epoch [28601/30000], Step [1/1], Training Loss: 57.9884, Valid Loss: 240.6381
Epoch [28701/30000], Step [1/1], Training Loss: 55.1077, Valid Loss: 242.3619
Epoch [28801/30000], Step [1/1], Training Loss: 53.2019, Valid Loss: 248.1238
Epoch [28901/30000], Step [1/1], Training Loss: 50.2984, Valid Loss: 245.0476
Epoch [29001/30000], Step [1/1], Training Loss: 47.3035, Valid Loss: 244.3810
Epoch [29101/30000], Step [1/1], Training Loss: 45.3407, Valid Loss: 241.5714
Epoch [29201/30000], Step [1/1], Training Loss: 43.2620, Valid Loss: 243.3333
Epoch [29301/30000], Step [1/1], Training Loss: 40.1721, Valid Loss: 247.6286
Epoch [29401/30000], Step [1/1], Training Loss: 38.1517, Valid Loss: 239.9524
Epoch [29501/30000], Step [1/1], Training Loss: 36.2289, Valid Loss: 249.9429
Epoch [29601/30000], Step [1/1], Training Loss: 33.5377, Valid Loss: 246.2762
Epoch [29701/30000], Step [1/1], Training Loss: 31.5673, Valid Loss: 247.2667
Epoch [29801/30000], Step [1/1], Training Loss: 29.8510, Valid Loss: 246.5619
Epoch [29901/30000], Step [1/1], Training Loss: 27.3694, Valid Loss: 245.3905

 End Time: 2021/04/20, 01:36:25




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=2048 	layers=2

Start Time = 2021/04/20, 01:46:00
##########################################################


[Epoch 0] Rounded prediction: 
tensor([3., 3., 3., 3., 3., 3., 3., 3., 3., 2., 3., 2., 2., 2., 2., 2., 2., 2.,
        2., 2., 2., 2., 2., 2., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2.,
        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
        2., 2., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],
       device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([23., 24., 28., 19., 20., 27., 22., 29., 26., 26., 31., 29., 33., 26.,
        28., 29., 15., 23.,  8., 20., 21., 24., 23., 26., 17.,  7., 13., 11.,
        19., 14., 20., 11.,  4., 17., 10., 17.,  7., 14.,  3., 17.,  8., 37.,
        26., 21.,  7.,  7.,  6., 10., 14., 10., 10., 11., 25., 17., 33., 18.,
        10.,  9., 11., 14., 13., 19.,  9., 22.,  7., 29., 16., 30., 27., 24.,
        19., 20., 20., 21., 19., 29., 30., 44., 29., 37., 42., 32., 47., 43.,
        34., 33., 28., 24., 21., 29., 35., 48., 59., 61., 56., 41., 36., 41.,
        43., 47., 56., 57., 51., 55., 54.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([29., 30., 38., 25., 31., 33., 30., 39., 35., 42., 42., 46., 36., 26.,
        16., 16.,  8., 12.,  2., 14., 11., 17., 17., 19., 11.,  6., 12.,  5.,
        12., 12., 14., 11.,  6., 15.,  1., 10.,  7., 12.,  5., 15.,  3., 30.,
        22., 12.,  4., 11.,  3.,  5.,  7.,  8.,  7.,  9., 17., 12., 28., 13.,
         6.,  7., 10.,  8.,  9., 14.,  7., 17.,  3., 23., 12., 22., 22., 24.,
        17., 12., 16., 19., 17., 26., 23., 45., 23., 32., 35., 29., 50., 42.,
        34., 28., 22., 17., 19., 20., 23., 46., 56., 62., 52., 46., 41., 41.,
        48., 52., 59., 58., 51., 54., 37.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128596.8438, Valid Loss: 185.6190
Epoch [101/30000], Step [1/1], Training Loss: 110213.4141, Valid Loss: 1023.8191
Epoch [201/30000], Step [1/1], Training Loss: 102489.5938, Valid Loss: 2585.6096
Epoch [301/30000], Step [1/1], Training Loss: 95356.6328, Valid Loss: 79.6000
Epoch [401/30000], Step [1/1], Training Loss: 88767.4922, Valid Loss: 177.8191
Epoch [501/30000], Step [1/1], Training Loss: 82746.1328, Valid Loss: 443.3715
Epoch [601/30000], Step [1/1], Training Loss: 77211.5312, Valid Loss: 885.2953
Epoch [701/30000], Step [1/1], Training Loss: 72168.5547, Valid Loss: 1116.6477
Epoch [801/30000], Step [1/1], Training Loss: 67569.7109, Valid Loss: 706.6000
Epoch [901/30000], Step [1/1], Training Loss: 63395.6953, Valid Loss: 594.5715
Epoch [1001/30000], Step [1/1], Training Loss: 59616.1328, Valid Loss: 513.3905
Epoch [1101/30000], Step [1/1], Training Loss: 55920.2695, Valid Loss: 423.1905
Epoch [1201/30000], Step [1/1], Training Loss: 52563.6328, Valid Loss: 318.7905
Epoch [1301/30000], Step [1/1], Training Loss: 49514.4453, Valid Loss: 283.4857
Epoch [1401/30000], Step [1/1], Training Loss: 46485.4844, Valid Loss: 282.0095
Epoch [1501/30000], Step [1/1], Training Loss: 43810.0234, Valid Loss: 235.2667
Epoch [1601/30000], Step [1/1], Training Loss: 41320.7188, Valid Loss: 258.6381
Epoch [1701/30000], Step [1/1], Training Loss: 39058.5664, Valid Loss: 278.1619
Epoch [1801/30000], Step [1/1], Training Loss: 36952.0898, Valid Loss: 280.7429
Epoch [1901/30000], Step [1/1], Training Loss: 35064.5039, Valid Loss: 296.9905
Epoch [2001/30000], Step [1/1], Training Loss: 33235.8789, Valid Loss: 273.2191
Epoch [2101/30000], Step [1/1], Training Loss: 31608.7871, Valid Loss: 245.3619
Epoch [2201/30000], Step [1/1], Training Loss: 29829.2285, Valid Loss: 278.2095
Epoch [2301/30000], Step [1/1], Training Loss: 28246.8945, Valid Loss: 231.7238
Epoch [2401/30000], Step [1/1], Training Loss: 26695.1641, Valid Loss: 208.2857
Epoch [2501/30000], Step [1/1], Training Loss: 25761.2480, Valid Loss: 208.3333
Epoch [2601/30000], Step [1/1], Training Loss: 23862.3965, Valid Loss: 217.4476
Epoch [2701/30000], Step [1/1], Training Loss: 22833.1445, Valid Loss: 215.0952
Epoch [2801/30000], Step [1/1], Training Loss: 21394.9238, Valid Loss: 224.8952
Epoch [2901/30000], Step [1/1], Training Loss: 20391.6855, Valid Loss: 223.0476
Epoch [3001/30000], Step [1/1], Training Loss: 19192.9375, Valid Loss: 250.3810
Epoch [3101/30000], Step [1/1], Training Loss: 18127.8379, Valid Loss: 270.6381
Epoch [3201/30000], Step [1/1], Training Loss: 17178.1992, Valid Loss: 250.7810
Epoch [3301/30000], Step [1/1], Training Loss: 16444.6152, Valid Loss: 243.7333
Epoch [3401/30000], Step [1/1], Training Loss: 15846.2344, Valid Loss: 233.7143
Epoch [3501/30000], Step [1/1], Training Loss: 15064.0811, Valid Loss: 248.8476
Epoch [3601/30000], Step [1/1], Training Loss: 14293.2695, Valid Loss: 275.7810
Epoch [3701/30000], Step [1/1], Training Loss: 13625.3301, Valid Loss: 281.3810
Epoch [3801/30000], Step [1/1], Training Loss: 13031.3906, Valid Loss: 246.1905
Epoch [3901/30000], Step [1/1], Training Loss: 12569.5527, Valid Loss: 259.0095
Epoch [4001/30000], Step [1/1], Training Loss: 11906.3467, Valid Loss: 294.9810
Epoch [4101/30000], Step [1/1], Training Loss: 11507.9697, Valid Loss: 269.4857
Epoch [4201/30000], Step [1/1], Training Loss: 10789.7598, Valid Loss: 280.8953
Epoch [4301/30000], Step [1/1], Training Loss: 10604.7217, Valid Loss: 290.0857
Epoch [4401/30000], Step [1/1], Training Loss: 9620.4727, Valid Loss: 314.2762
Epoch [4501/30000], Step [1/1], Training Loss: 9084.8213, Valid Loss: 267.0572
Epoch [4601/30000], Step [1/1], Training Loss: 8747.1602, Valid Loss: 287.6000
Epoch [4701/30000], Step [1/1], Training Loss: 8065.2354, Valid Loss: 252.4095
Epoch [4801/30000], Step [1/1], Training Loss: 7908.3013, Valid Loss: 305.3333
Epoch [4901/30000], Step [1/1], Training Loss: 7171.7480, Valid Loss: 261.9048
Epoch [5001/30000], Step [1/1], Training Loss: 6766.6362, Valid Loss: 265.6667
Epoch [5101/30000], Step [1/1], Training Loss: 6365.0410, Valid Loss: 281.0286
Epoch [5201/30000], Step [1/1], Training Loss: 6273.9468, Valid Loss: 293.8762
Epoch [5301/30000], Step [1/1], Training Loss: 5811.3691, Valid Loss: 279.6190
Epoch [5401/30000], Step [1/1], Training Loss: 5523.4385, Valid Loss: 261.4286
Epoch [5501/30000], Step [1/1], Training Loss: 5225.0020, Valid Loss: 284.6857
Epoch [5601/30000], Step [1/1], Training Loss: 5005.1411, Valid Loss: 327.2286
Epoch [5701/30000], Step [1/1], Training Loss: 4736.7285, Valid Loss: 316.1524
Epoch [5801/30000], Step [1/1], Training Loss: 4533.0986, Valid Loss: 349.1048
Epoch [5901/30000], Step [1/1], Training Loss: 4316.5708, Valid Loss: 335.0095
Epoch [6001/30000], Step [1/1], Training Loss: 4122.2148, Valid Loss: 300.3619
Epoch [6101/30000], Step [1/1], Training Loss: 3941.5479, Valid Loss: 304.6095
Epoch [6201/30000], Step [1/1], Training Loss: 3759.0701, Valid Loss: 318.9429
Epoch [6301/30000], Step [1/1], Training Loss: 3584.1294, Valid Loss: 316.8571
Epoch [6401/30000], Step [1/1], Training Loss: 3465.2200, Valid Loss: 305.3524
Epoch [6501/30000], Step [1/1], Training Loss: 4035.9521, Valid Loss: 304.3714
Epoch [6601/30000], Step [1/1], Training Loss: 3454.1890, Valid Loss: 313.9429
Epoch [6701/30000], Step [1/1], Training Loss: 3154.1655, Valid Loss: 283.1524
Epoch [6801/30000], Step [1/1], Training Loss: 2793.4312, Valid Loss: 340.5619
Epoch [6901/30000], Step [1/1], Training Loss: 2690.6458, Valid Loss: 332.5810
Epoch [7001/30000], Step [1/1], Training Loss: 2422.5647, Valid Loss: 302.5619
Epoch [7101/30000], Step [1/1], Training Loss: 2202.9060, Valid Loss: 316.3524
Epoch [7201/30000], Step [1/1], Training Loss: 2757.8418, Valid Loss: 290.4572
Epoch [7301/30000], Step [1/1], Training Loss: 2156.2268, Valid Loss: 296.5619
Epoch [7401/30000], Step [1/1], Training Loss: 2071.8489, Valid Loss: 310.8762
Epoch [7501/30000], Step [1/1], Training Loss: 2062.2073, Valid Loss: 310.3429
Epoch [7601/30000], Step [1/1], Training Loss: 1684.6726, Valid Loss: 320.1810
Epoch [7701/30000], Step [1/1], Training Loss: 1598.5156, Valid Loss: 293.8476
Epoch [7801/30000], Step [1/1], Training Loss: 1463.3312, Valid Loss: 320.2762
Epoch [7901/30000], Step [1/1], Training Loss: 1365.4197, Valid Loss: 284.2476
Epoch [8001/30000], Step [1/1], Training Loss: 1291.3945, Valid Loss: 300.8762
Epoch [8101/30000], Step [1/1], Training Loss: 1235.9927, Valid Loss: 283.3905
Epoch [8201/30000], Step [1/1], Training Loss: 1174.4979, Valid Loss: 303.1143
Epoch [8301/30000], Step [1/1], Training Loss: 1183.3400, Valid Loss: 256.4000
Epoch [8401/30000], Step [1/1], Training Loss: 1080.4316, Valid Loss: 285.8667
Epoch [8501/30000], Step [1/1], Training Loss: 1032.5624, Valid Loss: 283.4476
Epoch [8601/30000], Step [1/1], Training Loss: 1587.2157, Valid Loss: 315.3905
Epoch [8701/30000], Step [1/1], Training Loss: 1749.7640, Valid Loss: 323.7429
Epoch [8801/30000], Step [1/1], Training Loss: 1478.4033, Valid Loss: 248.4762
Epoch [8901/30000], Step [1/1], Training Loss: 981.0004, Valid Loss: 220.4476
Epoch [9001/30000], Step [1/1], Training Loss: 887.7065, Valid Loss: 228.9429
Epoch [9101/30000], Step [1/1], Training Loss: 874.9058, Valid Loss: 284.0572
Epoch [9201/30000], Step [1/1], Training Loss: 773.9932, Valid Loss: 263.3048
Epoch [9301/30000], Step [1/1], Training Loss: 1287.8251, Valid Loss: 316.6762
Epoch [9401/30000], Step [1/1], Training Loss: 715.5549, Valid Loss: 250.8381
Epoch [9501/30000], Step [1/1], Training Loss: 727.8126, Valid Loss: 284.9619
Epoch [9601/30000], Step [1/1], Training Loss: 671.3306, Valid Loss: 281.3524
Epoch [9701/30000], Step [1/1], Training Loss: 634.3975, Valid Loss: 285.2381
Epoch [9801/30000], Step [1/1], Training Loss: 595.8058, Valid Loss: 267.5238
Epoch [9901/30000], Step [1/1], Training Loss: 576.2087, Valid Loss: 258.4762
Epoch [10001/30000], Step [1/1], Training Loss: 548.8058, Valid Loss: 261.9810
Epoch [10101/30000], Step [1/1], Training Loss: 525.2411, Valid Loss: 254.5333
Epoch [10201/30000], Step [1/1], Training Loss: 501.6292, Valid Loss: 261.8667

[Epoch 15000] Rounded prediction: 
tensor([24., 29., 32., 27., 31., 30., 31., 41., 38., 52., 44., 54., 40., 27.,
        33., 21., 13., 13.,  4., 15., 18., 18., 17., 17., 14., 10.,  8.,  7.,
        13., 15., 13., 12.,  8., 13.,  5., 12., 10., 10.,  8., 13.,  7., 31.,
        25., 10.,  7., 11.,  1.,  7.,  9., 12., 10., 12., 17., 15., 26., 15.,
        11.,  3., 12., 10., 12., 15., 11., 18.,  6., 19., 16., 26., 27., 22.,
        20., 14., 18., 21., 23., 30., 28., 47., 26., 40., 37., 34., 55., 45.,
        40., 33., 27., 27., 21., 26., 31., 52., 55., 59., 56., 43., 43., 43.,
        38., 40., 48., 47., 33., 45., 38.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([20., 24., 30., 24., 28., 27., 25., 37., 32., 44., 40., 57., 42., 33.,
        35., 17., 15.,  5.,  2., 10.,  9., 19., 18., 14., 17., 13.,  1.,  2.,
        12., 13., 10., 15.,  7.,  8.,  3., 13.,  8.,  6.,  3., 13.,  3., 27.,
        29., 12.,  8., 12.,  0.,  2.,  9.,  8.,  9.,  4., 10., 17., 22., 16.,
        14.,  0.,  7.,  4., 12., 10.,  8., 13.,  6., 17., 11., 23., 23., 32.,
        14.,  9., 14., 23., 18., 11., 29., 51., 27., 42., 34., 36., 50., 52.,
        35., 37., 26., 26., 22., 13., 41., 58., 62., 64., 61., 45., 41., 44.,
        45., 44., 51., 48., 48., 41., 30.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [10301/30000], Step [1/1], Training Loss: 477.5880, Valid Loss: 270.4095
Epoch [10401/30000], Step [1/1], Training Loss: 455.8020, Valid Loss: 278.3048
Epoch [10501/30000], Step [1/1], Training Loss: 432.6033, Valid Loss: 247.5714
Epoch [10601/30000], Step [1/1], Training Loss: 415.4076, Valid Loss: 260.2476
Epoch [10701/30000], Step [1/1], Training Loss: 397.7034, Valid Loss: 281.4572
Epoch [10801/30000], Step [1/1], Training Loss: 378.7448, Valid Loss: 273.6857
Epoch [10901/30000], Step [1/1], Training Loss: 363.8699, Valid Loss: 269.2857
Epoch [11001/30000], Step [1/1], Training Loss: 340.3996, Valid Loss: 288.9810
Epoch [11101/30000], Step [1/1], Training Loss: 324.0536, Valid Loss: 280.1619
Epoch [11201/30000], Step [1/1], Training Loss: 305.3932, Valid Loss: 278.1619
Epoch [11301/30000], Step [1/1], Training Loss: 287.7595, Valid Loss: 277.4857
Epoch [11401/30000], Step [1/1], Training Loss: 269.8582, Valid Loss: 285.0381
Epoch [11501/30000], Step [1/1], Training Loss: 252.5251, Valid Loss: 278.0381
Epoch [11601/30000], Step [1/1], Training Loss: 236.5943, Valid Loss: 278.1524
Epoch [11701/30000], Step [1/1], Training Loss: 220.1064, Valid Loss: 284.7905
Epoch [11801/30000], Step [1/1], Training Loss: 203.9595, Valid Loss: 288.7429
Epoch [11901/30000], Step [1/1], Training Loss: 189.0827, Valid Loss: 292.0667
Epoch [12001/30000], Step [1/1], Training Loss: 174.8118, Valid Loss: 281.9143
Epoch [12101/30000], Step [1/1], Training Loss: 163.2164, Valid Loss: 293.7429
Epoch [12201/30000], Step [1/1], Training Loss: 148.1291, Valid Loss: 273.0000
Epoch [12301/30000], Step [1/1], Training Loss: 136.3910, Valid Loss: 285.1429
Epoch [12401/30000], Step [1/1], Training Loss: 123.5980, Valid Loss: 283.2857
Epoch [12501/30000], Step [1/1], Training Loss: 111.9971, Valid Loss: 278.2953
Epoch [12601/30000], Step [1/1], Training Loss: 102.4344, Valid Loss: 298.6381
Epoch [12701/30000], Step [1/1], Training Loss: 92.4176, Valid Loss: 298.1429
Epoch [12801/30000], Step [1/1], Training Loss: 83.4989, Valid Loss: 296.0381
Epoch [12901/30000], Step [1/1], Training Loss: 74.4557, Valid Loss: 320.4095
Epoch [13001/30000], Step [1/1], Training Loss: 66.3934, Valid Loss: 317.6381
Epoch [13101/30000], Step [1/1], Training Loss: 59.7317, Valid Loss: 287.4857
Epoch [13201/30000], Step [1/1], Training Loss: 52.3094, Valid Loss: 307.4381
Epoch [13301/30000], Step [1/1], Training Loss: 45.6477, Valid Loss: 320.9714
Epoch [13401/30000], Step [1/1], Training Loss: 40.9800, Valid Loss: 318.1238
Epoch [13501/30000], Step [1/1], Training Loss: 39.8736, Valid Loss: 341.6381
Epoch [13601/30000], Step [1/1], Training Loss: 29.9187, Valid Loss: 327.1429
Epoch [13701/30000], Step [1/1], Training Loss: 25.8793, Valid Loss: 308.9714
Epoch [13801/30000], Step [1/1], Training Loss: 22.5290, Valid Loss: 330.7810
Epoch [13901/30000], Step [1/1], Training Loss: 19.9481, Valid Loss: 332.2191
Epoch [14001/30000], Step [1/1], Training Loss: 15.9091, Valid Loss: 320.7333
Epoch [14101/30000], Step [1/1], Training Loss: 14.7400, Valid Loss: 320.7524
Epoch [14201/30000], Step [1/1], Training Loss: 12.0399, Valid Loss: 341.6857
Epoch [14301/30000], Step [1/1], Training Loss: 11.9850, Valid Loss: 340.2095
Epoch [14401/30000], Step [1/1], Training Loss: 8.9924, Valid Loss: 345.6190
Epoch [14501/30000], Step [1/1], Training Loss: 7.1510, Valid Loss: 327.4952
Epoch [14601/30000], Step [1/1], Training Loss: 6512.1631, Valid Loss: 114.9810
Epoch [14701/30000], Step [1/1], Training Loss: 1010.9510, Valid Loss: 289.8191
Epoch [14801/30000], Step [1/1], Training Loss: 157.6933, Valid Loss: 317.6667
Epoch [14901/30000], Step [1/1], Training Loss: 378.6587, Valid Loss: 256.4000
Epoch [15001/30000], Step [1/1], Training Loss: 56.1114, Valid Loss: 285.6095
Epoch [15101/30000], Step [1/1], Training Loss: 39.5728, Valid Loss: 287.4476
Epoch [15201/30000], Step [1/1], Training Loss: 36.0021, Valid Loss: 285.9619
Epoch [15301/30000], Step [1/1], Training Loss: 31.4442, Valid Loss: 301.7905
Epoch [15401/30000], Step [1/1], Training Loss: 30.9519, Valid Loss: 310.7333
Epoch [15501/30000], Step [1/1], Training Loss: 32.3784, Valid Loss: 314.1810
Epoch [15601/30000], Step [1/1], Training Loss: 24.3072, Valid Loss: 285.1714
Epoch [15701/30000], Step [1/1], Training Loss: 22.8042, Valid Loss: 310.4000
Epoch [15801/30000], Step [1/1], Training Loss: 19.6268, Valid Loss: 320.1238
Epoch [15901/30000], Step [1/1], Training Loss: 19.4130, Valid Loss: 291.6095
Epoch [16001/30000], Step [1/1], Training Loss: 17.6032, Valid Loss: 320.6381
Epoch [16101/30000], Step [1/1], Training Loss: 15.3583, Valid Loss: 329.3619
Epoch [16201/30000], Step [1/1], Training Loss: 19.9550, Valid Loss: 314.3905
Epoch [16301/30000], Step [1/1], Training Loss: 14.9740, Valid Loss: 325.4667
Epoch [16401/30000], Step [1/1], Training Loss: 12.9186, Valid Loss: 333.6095
Epoch [16501/30000], Step [1/1], Training Loss: 11.2788, Valid Loss: 326.0381
Epoch [16601/30000], Step [1/1], Training Loss: 13.2570, Valid Loss: 310.7905
Epoch [16701/30000], Step [1/1], Training Loss: 9.3483, Valid Loss: 326.9714
Epoch [16801/30000], Step [1/1], Training Loss: 10.3280, Valid Loss: 340.1333
Epoch [16901/30000], Step [1/1], Training Loss: 7.3309, Valid Loss: 331.7619
Epoch [17001/30000], Step [1/1], Training Loss: 6.9159, Valid Loss: 338.3619
Epoch [17101/30000], Step [1/1], Training Loss: 7.0111, Valid Loss: 335.4572
Epoch [17201/30000], Step [1/1], Training Loss: 6.2482, Valid Loss: 318.6000
Epoch [17301/30000], Step [1/1], Training Loss: 5.2621, Valid Loss: 339.7333
Epoch [17401/30000], Step [1/1], Training Loss: 1237.3718, Valid Loss: 203.6381
Epoch [17501/30000], Step [1/1], Training Loss: 79.4138, Valid Loss: 273.1714
Epoch [17601/30000], Step [1/1], Training Loss: 21.4084, Valid Loss: 297.4952
Epoch [17701/30000], Step [1/1], Training Loss: 21.3840, Valid Loss: 277.4381
Epoch [17801/30000], Step [1/1], Training Loss: 21.6184, Valid Loss: 286.2953
Epoch [17901/30000], Step [1/1], Training Loss: 10.7535, Valid Loss: 284.2000
Epoch [18001/30000], Step [1/1], Training Loss: 9.4886, Valid Loss: 275.7524
Epoch [18101/30000], Step [1/1], Training Loss: 7.1758, Valid Loss: 279.1714
Epoch [18201/30000], Step [1/1], Training Loss: 4.9216, Valid Loss: 297.8191
Epoch [18301/30000], Step [1/1], Training Loss: 8.4647, Valid Loss: 291.1429
Epoch [18401/30000], Step [1/1], Training Loss: 4.8918, Valid Loss: 293.0762
Epoch [18501/30000], Step [1/1], Training Loss: 5.1380, Valid Loss: 291.3619
Epoch [18601/30000], Step [1/1], Training Loss: 6.3165, Valid Loss: 294.9714
Epoch [18701/30000], Step [1/1], Training Loss: 4.8080, Valid Loss: 299.7333
Epoch [18801/30000], Step [1/1], Training Loss: 4.7972, Valid Loss: 293.2095
Epoch [18901/30000], Step [1/1], Training Loss: 3.5964, Valid Loss: 298.7143
Epoch [19001/30000], Step [1/1], Training Loss: 3.8146, Valid Loss: 303.3810
Epoch [19101/30000], Step [1/1], Training Loss: 3.0276, Valid Loss: 300.2381
Epoch [19201/30000], Step [1/1], Training Loss: 3.7900, Valid Loss: 300.8953
Epoch [19301/30000], Step [1/1], Training Loss: 3.3860, Valid Loss: 295.6095
Epoch [19401/30000], Step [1/1], Training Loss: 3.0858, Valid Loss: 284.4572
Epoch [19501/30000], Step [1/1], Training Loss: 2.2509, Valid Loss: 292.6095
Epoch [19601/30000], Step [1/1], Training Loss: 2.5382, Valid Loss: 292.7333
Epoch [19701/30000], Step [1/1], Training Loss: 3.2651, Valid Loss: 287.2286
Epoch [19801/30000], Step [1/1], Training Loss: 1.9681, Valid Loss: 293.5143
Epoch [19901/30000], Step [1/1], Training Loss: 2.8753, Valid Loss: 289.6476
Epoch [20001/30000], Step [1/1], Training Loss: 2.3363, Valid Loss: 294.6095
Epoch [20101/30000], Step [1/1], Training Loss: 1.7411, Valid Loss: 289.2667
Epoch [20201/30000], Step [1/1], Training Loss: 1.9704, Valid Loss: 306.4952
Epoch [20301/30000], Step [1/1], Training Loss: 1.8875, Valid Loss: 311.9429
Epoch [20401/30000], Step [1/1], Training Loss: 924.3311, Valid Loss: 270.6286
Epoch [20501/30000], Step [1/1], Training Loss: 271.7609, Valid Loss: 201.4381
Epoch [20601/30000], Step [1/1], Training Loss: 389.9742, Valid Loss: 242.3429

[Epoch 25000] Rounded prediction: 
tensor([23., 27., 34., 23., 26., 28., 23., 35., 27., 34., 32., 47., 49., 31.,
        24.,  8., 10.,  8.,  0., 10.,  8., 19., 14., 15., 17., 10.,  4.,  2.,
        12., 13., 14., 16.,  6.,  7.,  1., 12.,  7., 11.,  5., 12.,  3., 30.,
        26.,  9.,  9., 10.,  2.,  4.,  8.,  6.,  7.,  5.,  9., 14., 23., 20.,
         9.,  0., 10.,  7., 10., 13., 10., 12.,  5., 16., 17., 16., 22., 26.,
        12.,  3., 11., 16., 21., 12., 28., 59., 34., 33., 42., 38., 52., 43.,
        42., 34., 36., 32., 15., 12., 28., 64., 71., 62., 51., 44., 44., 46.,
        49., 41., 44., 54., 56., 37., 14.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [20701/30000], Step [1/1], Training Loss: 22.4335, Valid Loss: 294.2953
Epoch [20801/30000], Step [1/1], Training Loss: 15.8440, Valid Loss: 291.3619
Epoch [20901/30000], Step [1/1], Training Loss: 14.1970, Valid Loss: 280.8381
Epoch [21001/30000], Step [1/1], Training Loss: 10.6611, Valid Loss: 282.4381
Epoch [21101/30000], Step [1/1], Training Loss: 9.7890, Valid Loss: 281.8191
Epoch [21201/30000], Step [1/1], Training Loss: 10.6788, Valid Loss: 272.8857
Epoch [21301/30000], Step [1/1], Training Loss: 5.7213, Valid Loss: 286.1048
Epoch [21401/30000], Step [1/1], Training Loss: 5.0011, Valid Loss: 296.5810
Epoch [21501/30000], Step [1/1], Training Loss: 4.5148, Valid Loss: 287.8095
Epoch [21601/30000], Step [1/1], Training Loss: 5.8588, Valid Loss: 285.7333
Epoch [21701/30000], Step [1/1], Training Loss: 6.1574, Valid Loss: 282.8667
Epoch [21801/30000], Step [1/1], Training Loss: 3.6476, Valid Loss: 284.2667
Epoch [21901/30000], Step [1/1], Training Loss: 7.9784, Valid Loss: 272.2476
Epoch [22001/30000], Step [1/1], Training Loss: 3.9011, Valid Loss: 284.1333
Epoch [22101/30000], Step [1/1], Training Loss: 3.9338, Valid Loss: 267.8286
Epoch [22201/30000], Step [1/1], Training Loss: 3.1744, Valid Loss: 292.4381
Epoch [22301/30000], Step [1/1], Training Loss: 4.4081, Valid Loss: 277.4000
Epoch [22401/30000], Step [1/1], Training Loss: 3.2380, Valid Loss: 270.8857
Epoch [22501/30000], Step [1/1], Training Loss: 3.4417, Valid Loss: 296.1905
Epoch [22601/30000], Step [1/1], Training Loss: 3.0023, Valid Loss: 296.5238
Epoch [22701/30000], Step [1/1], Training Loss: 1.9754, Valid Loss: 281.9619
Epoch [22801/30000], Step [1/1], Training Loss: 2.2952, Valid Loss: 288.7048
Epoch [22901/30000], Step [1/1], Training Loss: 4.1553, Valid Loss: 297.5810
Epoch [23001/30000], Step [1/1], Training Loss: 2.6343, Valid Loss: 283.8667
Epoch [23101/30000], Step [1/1], Training Loss: 1.7936, Valid Loss: 297.9048
Epoch [23201/30000], Step [1/1], Training Loss: 374.9949, Valid Loss: 283.0667
Epoch [23301/30000], Step [1/1], Training Loss: 220.2408, Valid Loss: 279.9810
Epoch [23401/30000], Step [1/1], Training Loss: 41.7347, Valid Loss: 274.9429
Epoch [23501/30000], Step [1/1], Training Loss: 32.4564, Valid Loss: 262.6953
Epoch [23601/30000], Step [1/1], Training Loss: 9.8088, Valid Loss: 300.9905
Epoch [23701/30000], Step [1/1], Training Loss: 14.8271, Valid Loss: 294.7524
Epoch [23801/30000], Step [1/1], Training Loss: 6.3251, Valid Loss: 291.6667
Epoch [23901/30000], Step [1/1], Training Loss: 6.7210, Valid Loss: 274.5619
Epoch [24001/30000], Step [1/1], Training Loss: 5.4675, Valid Loss: 300.8000
Epoch [24101/30000], Step [1/1], Training Loss: 4.0230, Valid Loss: 280.3905
Epoch [24201/30000], Step [1/1], Training Loss: 4.2289, Valid Loss: 276.6286
Epoch [24301/30000], Step [1/1], Training Loss: 4.0421, Valid Loss: 281.6476
Epoch [24401/30000], Step [1/1], Training Loss: 2.8221, Valid Loss: 287.9143
Epoch [24501/30000], Step [1/1], Training Loss: 2.9128, Valid Loss: 300.0952
Epoch [24601/30000], Step [1/1], Training Loss: 3.1368, Valid Loss: 302.9048
Epoch [24701/30000], Step [1/1], Training Loss: 4.2686, Valid Loss: 292.0857
Epoch [24801/30000], Step [1/1], Training Loss: 3.3197, Valid Loss: 281.2667
Epoch [24901/30000], Step [1/1], Training Loss: 2.8216, Valid Loss: 297.2762
Epoch [25001/30000], Step [1/1], Training Loss: 3.1828, Valid Loss: 299.0762
Epoch [25101/30000], Step [1/1], Training Loss: 2.4262, Valid Loss: 302.8857
Epoch [25201/30000], Step [1/1], Training Loss: 2.2936, Valid Loss: 293.2000
Epoch [25301/30000], Step [1/1], Training Loss: 3.4926, Valid Loss: 294.0000
Epoch [25401/30000], Step [1/1], Training Loss: 1.9328, Valid Loss: 301.0476
Epoch [25501/30000], Step [1/1], Training Loss: 2.0716, Valid Loss: 277.5905
Epoch [25601/30000], Step [1/1], Training Loss: 1.9981, Valid Loss: 289.1714
Epoch [25701/30000], Step [1/1], Training Loss: 2.7146, Valid Loss: 292.1524
Epoch [25801/30000], Step [1/1], Training Loss: 1.5208, Valid Loss: 306.2953
Epoch [25901/30000], Step [1/1], Training Loss: 2.1180, Valid Loss: 280.7048
Epoch [26001/30000], Step [1/1], Training Loss: 2.3672, Valid Loss: 285.4952
Epoch [26101/30000], Step [1/1], Training Loss: 1.0517, Valid Loss: 282.8762
Epoch [26201/30000], Step [1/1], Training Loss: 1.5034, Valid Loss: 295.6953
Epoch [26301/30000], Step [1/1], Training Loss: 1.6656, Valid Loss: 276.6286
Epoch [26401/30000], Step [1/1], Training Loss: 1.6583, Valid Loss: 274.2000
Epoch [26501/30000], Step [1/1], Training Loss: 1.5030, Valid Loss: 277.4286
Epoch [26601/30000], Step [1/1], Training Loss: 1.4801, Valid Loss: 285.4476
Epoch [26701/30000], Step [1/1], Training Loss: 1.3745, Valid Loss: 283.7905
Epoch [26801/30000], Step [1/1], Training Loss: 1.5713, Valid Loss: 280.0191
Epoch [26901/30000], Step [1/1], Training Loss: 0.9689, Valid Loss: 282.8571
Epoch [27001/30000], Step [1/1], Training Loss: 1.3575, Valid Loss: 286.5334
Epoch [27101/30000], Step [1/1], Training Loss: 0.9889, Valid Loss: 275.8286
Epoch [27201/30000], Step [1/1], Training Loss: 1.0866, Valid Loss: 283.2571
Epoch [27301/30000], Step [1/1], Training Loss: 1.3433, Valid Loss: 278.6572
Epoch [27401/30000], Step [1/1], Training Loss: 0.9347, Valid Loss: 271.9524
Epoch [27501/30000], Step [1/1], Training Loss: 1.2100, Valid Loss: 282.0476
Epoch [27601/30000], Step [1/1], Training Loss: 1.1133, Valid Loss: 278.1524
Epoch [27701/30000], Step [1/1], Training Loss: 1.2007, Valid Loss: 290.3905
Epoch [27801/30000], Step [1/1], Training Loss: 1.0896, Valid Loss: 290.4572
Epoch [27901/30000], Step [1/1], Training Loss: 0.9886, Valid Loss: 264.4572
Epoch [28001/30000], Step [1/1], Training Loss: 1.0132, Valid Loss: 266.3048
Epoch [28101/30000], Step [1/1], Training Loss: 1.1613, Valid Loss: 279.0572
Epoch [28201/30000], Step [1/1], Training Loss: 0.7539, Valid Loss: 270.8571
Epoch [28301/30000], Step [1/1], Training Loss: 0.8020, Valid Loss: 258.1429
Epoch [28401/30000], Step [1/1], Training Loss: 0.8348, Valid Loss: 273.8191
Epoch [28501/30000], Step [1/1], Training Loss: 0.6980, Valid Loss: 285.7810
Epoch [28601/30000], Step [1/1], Training Loss: 0.7747, Valid Loss: 300.6190
Epoch [28701/30000], Step [1/1], Training Loss: 0.9273, Valid Loss: 275.2191
Epoch [28801/30000], Step [1/1], Training Loss: 1.0963, Valid Loss: 268.8000
Epoch [28901/30000], Step [1/1], Training Loss: 0.7408, Valid Loss: 285.1429
Epoch [29001/30000], Step [1/1], Training Loss: 0.7163, Valid Loss: 274.5429
Epoch [29101/30000], Step [1/1], Training Loss: 0.5744, Valid Loss: 243.8000
Epoch [29201/30000], Step [1/1], Training Loss: 0.8164, Valid Loss: 237.4762
Epoch [29301/30000], Step [1/1], Training Loss: 1.0435, Valid Loss: 266.4667
Epoch [29401/30000], Step [1/1], Training Loss: 0.5087, Valid Loss: 271.4381
Epoch [29501/30000], Step [1/1], Training Loss: 0.8025, Valid Loss: 258.7524
Epoch [29601/30000], Step [1/1], Training Loss: 0.6871, Valid Loss: 242.3619
Epoch [29701/30000], Step [1/1], Training Loss: 0.9448, Valid Loss: 275.4857
Epoch [29801/30000], Step [1/1], Training Loss: 0.4469, Valid Loss: 272.8571
Epoch [29901/30000], Step [1/1], Training Loss: 0.6114, Valid Loss: 256.6190

 End Time: 2021/04/20, 02:20:47




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=2048 	layers=2

Start Time = 2021/04/20, 02:20:47
##########################################################


[Epoch 0] Rounded prediction: 
tensor([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
        2., 2., 2., 2., 2., 2., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2.,
        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],
       device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([22., 20., 24., 19., 17., 22., 19., 22., 20., 16., 22., 11., 14., 13.,
        10., 16.,  3., 13.,  3., 10., 13.,  8., 10., 14.,  3.,  2., 10.,  9.,
         9.,  9., 11.,  3.,  0., 15.,  9.,  8.,  1.,  8.,  0., 12.,  8., 23.,
        10., 11.,  0.,  4.,  8.,  9.,  4.,  4.,  4.,  5., 15.,  3., 21.,  2.,
         8.,  3.,  9., 11.,  4., 11.,  0., 14.,  0., 21.,  1., 19.,  9.,  8.,
         4., 10., 10.,  7.,  6., 23., 10., 33.,  2., 23., 24., 10., 40., 22.,
        12., 19., 11.,  3.,  9., 21., 30., 24., 31., 42., 44., 27., 30., 40.,
        36., 30., 34., 37., 25., 24., 32.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([27., 20., 25., 21., 19., 24., 20., 24., 22., 12., 14.,  3.,  9., 11.,
         5.,  9.,  0.,  6.,  0.,  8., 13.,  6.,  5., 12.,  0.,  0.,  5.,  3.,
         3.,  6., 10.,  0.,  0.,  9.,  2.,  4.,  0.,  5.,  0.,  9.,  4., 23.,
         9.,  8.,  0.,  0.,  1.,  4.,  0.,  0.,  3.,  4., 13.,  0., 23.,  0.,
         1.,  0.,  2.,  6.,  0.,  8.,  0., 13.,  0., 20.,  0., 17., 12.,  2.,
         4.,  9., 11.,  6.,  7., 26., 12., 32.,  0., 15., 26.,  6., 38., 23.,
         6.,  9., 10.,  0.,  7., 23., 33., 21., 28., 39., 44., 24., 31., 39.,
        40., 26., 30., 45., 23., 19., 32.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128684.4453, Valid Loss: 192.1048
Epoch [101/30000], Step [1/1], Training Loss: 110174.5156, Valid Loss: 1029.4476
Epoch [201/30000], Step [1/1], Training Loss: 102448.2969, Valid Loss: 2609.0095
Epoch [301/30000], Step [1/1], Training Loss: 95305.3906, Valid Loss: 73.2571
Epoch [401/30000], Step [1/1], Training Loss: 88719.1484, Valid Loss: 205.8381
Epoch [501/30000], Step [1/1], Training Loss: 82689.6953, Valid Loss: 461.9714
Epoch [601/30000], Step [1/1], Training Loss: 77166.1094, Valid Loss: 625.2286
Epoch [701/30000], Step [1/1], Training Loss: 72119.2422, Valid Loss: 916.1810
Epoch [801/30000], Step [1/1], Training Loss: 67528.4297, Valid Loss: 1081.2572
Epoch [901/30000], Step [1/1], Training Loss: 63357.3711, Valid Loss: 660.5524
Epoch [1001/30000], Step [1/1], Training Loss: 59574.6992, Valid Loss: 473.8381
Epoch [1101/30000], Step [1/1], Training Loss: 55939.3008, Valid Loss: 300.5334
Epoch [1201/30000], Step [1/1], Training Loss: 52536.8594, Valid Loss: 268.8476
Epoch [1301/30000], Step [1/1], Training Loss: 49367.6797, Valid Loss: 249.9810
Epoch [1401/30000], Step [1/1], Training Loss: 46499.5312, Valid Loss: 229.2095
Epoch [1501/30000], Step [1/1], Training Loss: 43727.7305, Valid Loss: 197.8476
Epoch [1601/30000], Step [1/1], Training Loss: 41230.7773, Valid Loss: 182.6476
Epoch [1701/30000], Step [1/1], Training Loss: 38936.1406, Valid Loss: 196.5333
Epoch [1801/30000], Step [1/1], Training Loss: 36851.4492, Valid Loss: 189.4572
Epoch [1901/30000], Step [1/1], Training Loss: 34944.2227, Valid Loss: 205.0857
Epoch [2001/30000], Step [1/1], Training Loss: 32950.8398, Valid Loss: 171.7524
Epoch [2101/30000], Step [1/1], Training Loss: 31118.2402, Valid Loss: 157.0000
Epoch [2201/30000], Step [1/1], Training Loss: 29255.7637, Valid Loss: 153.9810
Epoch [2301/30000], Step [1/1], Training Loss: 27622.0312, Valid Loss: 144.7714
Epoch [2401/30000], Step [1/1], Training Loss: 26099.4414, Valid Loss: 124.2857
Epoch [2501/30000], Step [1/1], Training Loss: 25019.2852, Valid Loss: 126.4191
Epoch [2601/30000], Step [1/1], Training Loss: 23181.9668, Valid Loss: 142.0095
Epoch [2701/30000], Step [1/1], Training Loss: 21983.5234, Valid Loss: 115.2857
Epoch [2801/30000], Step [1/1], Training Loss: 20876.7480, Valid Loss: 109.9048
Epoch [2901/30000], Step [1/1], Training Loss: 20477.4707, Valid Loss: 113.5048
Epoch [3001/30000], Step [1/1], Training Loss: 18674.2832, Valid Loss: 119.3333
Epoch [3101/30000], Step [1/1], Training Loss: 17887.0059, Valid Loss: 85.2190
Epoch [3201/30000], Step [1/1], Training Loss: 16909.1211, Valid Loss: 96.8857
Epoch [3301/30000], Step [1/1], Training Loss: 16183.9971, Valid Loss: 88.8762
Epoch [3401/30000], Step [1/1], Training Loss: 15385.4961, Valid Loss: 90.3905
Epoch [3501/30000], Step [1/1], Training Loss: 14619.8125, Valid Loss: 98.5810
Epoch [3601/30000], Step [1/1], Training Loss: 13942.1963, Valid Loss: 100.8191
Epoch [3701/30000], Step [1/1], Training Loss: 13452.6875, Valid Loss: 98.5524
Epoch [3801/30000], Step [1/1], Training Loss: 12887.5801, Valid Loss: 104.7238
Epoch [3901/30000], Step [1/1], Training Loss: 12455.5068, Valid Loss: 103.0476
Epoch [4001/30000], Step [1/1], Training Loss: 11835.5996, Valid Loss: 91.8952
Epoch [4101/30000], Step [1/1], Training Loss: 11121.4160, Valid Loss: 105.6190
Epoch [4201/30000], Step [1/1], Training Loss: 11074.8691, Valid Loss: 86.3619
Epoch [4301/30000], Step [1/1], Training Loss: 10074.9648, Valid Loss: 101.2476
Epoch [4401/30000], Step [1/1], Training Loss: 9737.9941, Valid Loss: 75.4476
Epoch [4501/30000], Step [1/1], Training Loss: 9219.9414, Valid Loss: 87.2857
Epoch [4601/30000], Step [1/1], Training Loss: 8602.2402, Valid Loss: 87.2952
Epoch [4701/30000], Step [1/1], Training Loss: 8053.0889, Valid Loss: 90.8762
Epoch [4801/30000], Step [1/1], Training Loss: 7682.3857, Valid Loss: 97.9143
Epoch [4901/30000], Step [1/1], Training Loss: 7179.5303, Valid Loss: 84.0857
Epoch [5001/30000], Step [1/1], Training Loss: 6793.5269, Valid Loss: 80.4667
Epoch [5101/30000], Step [1/1], Training Loss: 6503.1294, Valid Loss: 85.6571
Epoch [5201/30000], Step [1/1], Training Loss: 6201.0518, Valid Loss: 80.9143
Epoch [5301/30000], Step [1/1], Training Loss: 5933.0493, Valid Loss: 89.6381
Epoch [5401/30000], Step [1/1], Training Loss: 5650.8550, Valid Loss: 84.9333
Epoch [5501/30000], Step [1/1], Training Loss: 5416.1074, Valid Loss: 85.0191
Epoch [5601/30000], Step [1/1], Training Loss: 5346.6074, Valid Loss: 80.2286
Epoch [5701/30000], Step [1/1], Training Loss: 5197.8320, Valid Loss: 82.0191
Epoch [5801/30000], Step [1/1], Training Loss: 4830.2520, Valid Loss: 71.9810
Epoch [5901/30000], Step [1/1], Training Loss: 4595.6030, Valid Loss: 79.9619
Epoch [6001/30000], Step [1/1], Training Loss: 4607.2002, Valid Loss: 91.6571
Epoch [6101/30000], Step [1/1], Training Loss: 3967.9695, Valid Loss: 79.4667
Epoch [6201/30000], Step [1/1], Training Loss: 3944.1545, Valid Loss: 80.7429
Epoch [6301/30000], Step [1/1], Training Loss: 3539.2346, Valid Loss: 75.5429
Epoch [6401/30000], Step [1/1], Training Loss: 3175.8967, Valid Loss: 74.8476
Epoch [6501/30000], Step [1/1], Training Loss: 3775.7583, Valid Loss: 75.5714
Epoch [6601/30000], Step [1/1], Training Loss: 2861.1819, Valid Loss: 68.3810
Epoch [6701/30000], Step [1/1], Training Loss: 2603.8701, Valid Loss: 71.3810
Epoch [6801/30000], Step [1/1], Training Loss: 2430.0522, Valid Loss: 79.2381
Epoch [6901/30000], Step [1/1], Training Loss: 2290.1001, Valid Loss: 71.9810
Epoch [7001/30000], Step [1/1], Training Loss: 2140.5974, Valid Loss: 76.3714
Epoch [7101/30000], Step [1/1], Training Loss: 2022.1627, Valid Loss: 77.2667
Epoch [7201/30000], Step [1/1], Training Loss: 1907.2451, Valid Loss: 78.6190
Epoch [7301/30000], Step [1/1], Training Loss: 1806.0098, Valid Loss: 78.9714
Epoch [7401/30000], Step [1/1], Training Loss: 1702.6791, Valid Loss: 77.2000
Epoch [7501/30000], Step [1/1], Training Loss: 1619.5431, Valid Loss: 75.9143
Epoch [7601/30000], Step [1/1], Training Loss: 1534.5588, Valid Loss: 75.4571
Epoch [7701/30000], Step [1/1], Training Loss: 1460.8387, Valid Loss: 79.9238
Epoch [7801/30000], Step [1/1], Training Loss: 1388.4177, Valid Loss: 77.4191
Epoch [7901/30000], Step [1/1], Training Loss: 1325.1869, Valid Loss: 84.6000
Epoch [8001/30000], Step [1/1], Training Loss: 1267.9363, Valid Loss: 81.8667
Epoch [8101/30000], Step [1/1], Training Loss: 1211.7419, Valid Loss: 80.2571
Epoch [8201/30000], Step [1/1], Training Loss: 1158.9602, Valid Loss: 79.3905
Epoch [8301/30000], Step [1/1], Training Loss: 1105.9871, Valid Loss: 84.6381
Epoch [8401/30000], Step [1/1], Training Loss: 1056.8153, Valid Loss: 82.0667
Epoch [8501/30000], Step [1/1], Training Loss: 1012.5283, Valid Loss: 83.7619
Epoch [8601/30000], Step [1/1], Training Loss: 968.0757, Valid Loss: 82.5905
Epoch [8701/30000], Step [1/1], Training Loss: 925.0583, Valid Loss: 90.3619
Epoch [8801/30000], Step [1/1], Training Loss: 885.0245, Valid Loss: 86.9905
Epoch [8901/30000], Step [1/1], Training Loss: 845.7030, Valid Loss: 87.1619
Epoch [9001/30000], Step [1/1], Training Loss: 810.6418, Valid Loss: 88.0000
Epoch [9101/30000], Step [1/1], Training Loss: 774.3314, Valid Loss: 90.6476
Epoch [9201/30000], Step [1/1], Training Loss: 741.7027, Valid Loss: 89.1238
Epoch [9301/30000], Step [1/1], Training Loss: 711.7446, Valid Loss: 87.2381
Epoch [9401/30000], Step [1/1], Training Loss: 682.7485, Valid Loss: 91.4571
Epoch [9501/30000], Step [1/1], Training Loss: 654.5292, Valid Loss: 87.0191
Epoch [9601/30000], Step [1/1], Training Loss: 629.6854, Valid Loss: 84.1048
Epoch [9701/30000], Step [1/1], Training Loss: 602.0466, Valid Loss: 90.5048
Epoch [9801/30000], Step [1/1], Training Loss: 575.9461, Valid Loss: 90.2000
Epoch [9901/30000], Step [1/1], Training Loss: 552.2933, Valid Loss: 89.6095
Epoch [10001/30000], Step [1/1], Training Loss: 524.8899, Valid Loss: 91.3048
Epoch [10101/30000], Step [1/1], Training Loss: 502.1304, Valid Loss: 91.4191
Epoch [10201/30000], Step [1/1], Training Loss: 478.3731, Valid Loss: 96.3524

[Epoch 15000] Rounded prediction: 
tensor([21., 18., 25., 21., 16., 19., 17., 21., 20., 18., 24., 13., 23., 22.,
        15., 31.,  0., 17.,  4., 23., 37., 10., 20., 35.,  0., 10., 20.,  8.,
        13., 18., 20.,  0.,  5., 26.,  6.,  9.,  5., 17.,  1., 20.,  8., 38.,
         6.,  8.,  0., 14., 11., 10.,  8.,  9., 17., 17., 33.,  0., 44.,  0.,
         8.,  9., 18., 16.,  5., 24.,  0., 37.,  0., 43.,  0., 44., 30.,  7.,
        25., 34., 24., 18., 17., 52., 18., 56.,  0., 47., 55.,  3., 82., 35.,
         4., 36., 20.,  5., 22., 41., 54., 45., 40., 52., 55., 33., 55., 57.,
        49., 26., 46., 49., 18., 26., 49.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([22., 15., 20., 23., 14., 19., 18., 14., 20., 13., 25., 20., 24., 27.,
        25., 33.,  5., 24., 11., 25., 34., 16., 29., 35.,  2., 15., 20., 13.,
        16., 20., 21.,  7.,  7., 24.,  9., 17., 10., 19.,  8., 17., 11., 37.,
         8., 14.,  0., 15., 13., 12., 12., 14., 21., 22., 30.,  6., 42.,  0.,
        18., 12., 19., 21.,  9., 24.,  5., 35.,  9., 39.,  4., 44., 28., 13.,
        30., 36., 31., 28., 21., 47., 19., 51.,  0., 47., 43.,  9., 74., 22.,
         1., 34., 25.,  6., 21., 50., 53., 32., 41., 47., 44.,  5., 24., 43.,
        39., 25., 45., 36.,  7., 32., 56.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [10301/30000], Step [1/1], Training Loss: 457.6430, Valid Loss: 89.3429
Epoch [10401/30000], Step [1/1], Training Loss: 434.6589, Valid Loss: 93.4095
Epoch [10501/30000], Step [1/1], Training Loss: 413.9943, Valid Loss: 97.1905
Epoch [10601/30000], Step [1/1], Training Loss: 398.6624, Valid Loss: 97.0667
Epoch [10701/30000], Step [1/1], Training Loss: 375.1471, Valid Loss: 104.1238
Epoch [10801/30000], Step [1/1], Training Loss: 356.2479, Valid Loss: 101.0476
Epoch [10901/30000], Step [1/1], Training Loss: 17383.4336, Valid Loss: 207.3238
Epoch [11001/30000], Step [1/1], Training Loss: 1425.2762, Valid Loss: 183.2762
Epoch [11101/30000], Step [1/1], Training Loss: 861.9702, Valid Loss: 254.1905
Epoch [11201/30000], Step [1/1], Training Loss: 564.7140, Valid Loss: 224.2286
Epoch [11301/30000], Step [1/1], Training Loss: 353.0467, Valid Loss: 203.1714
Epoch [11401/30000], Step [1/1], Training Loss: 304.5551, Valid Loss: 207.7143
Epoch [11501/30000], Step [1/1], Training Loss: 293.0065, Valid Loss: 198.0857
Epoch [11601/30000], Step [1/1], Training Loss: 268.7822, Valid Loss: 208.8000
Epoch [11701/30000], Step [1/1], Training Loss: 265.1026, Valid Loss: 201.8762
Epoch [11801/30000], Step [1/1], Training Loss: 243.0354, Valid Loss: 214.2286
Epoch [11901/30000], Step [1/1], Training Loss: 270.0303, Valid Loss: 196.3333
Epoch [12001/30000], Step [1/1], Training Loss: 233.7084, Valid Loss: 219.1714
Epoch [12101/30000], Step [1/1], Training Loss: 205.6911, Valid Loss: 238.1333
Epoch [12201/30000], Step [1/1], Training Loss: 192.6562, Valid Loss: 234.8476
Epoch [12301/30000], Step [1/1], Training Loss: 173.0294, Valid Loss: 242.6286
Epoch [12401/30000], Step [1/1], Training Loss: 163.0718, Valid Loss: 242.4381
Epoch [12501/30000], Step [1/1], Training Loss: 150.6072, Valid Loss: 250.1333
Epoch [12601/30000], Step [1/1], Training Loss: 140.4839, Valid Loss: 255.3429
Epoch [12701/30000], Step [1/1], Training Loss: 132.3733, Valid Loss: 259.3810
Epoch [12801/30000], Step [1/1], Training Loss: 118.9332, Valid Loss: 260.7429
Epoch [12901/30000], Step [1/1], Training Loss: 110.6230, Valid Loss: 280.4667
Epoch [13001/30000], Step [1/1], Training Loss: 101.8559, Valid Loss: 271.6953
Epoch [13101/30000], Step [1/1], Training Loss: 92.1773, Valid Loss: 266.8286
Epoch [13201/30000], Step [1/1], Training Loss: 83.4345, Valid Loss: 273.5143
Epoch [13301/30000], Step [1/1], Training Loss: 75.1280, Valid Loss: 282.7619
Epoch [13401/30000], Step [1/1], Training Loss: 69.3457, Valid Loss: 304.8571
Epoch [13501/30000], Step [1/1], Training Loss: 62.2081, Valid Loss: 300.6381
Epoch [13601/30000], Step [1/1], Training Loss: 54.4509, Valid Loss: 310.0095
Epoch [13701/30000], Step [1/1], Training Loss: 48.7869, Valid Loss: 301.6190
Epoch [13801/30000], Step [1/1], Training Loss: 42.4386, Valid Loss: 299.9524
Epoch [13901/30000], Step [1/1], Training Loss: 37.7443, Valid Loss: 302.1238
Epoch [14001/30000], Step [1/1], Training Loss: 32.4654, Valid Loss: 283.2762
Epoch [14101/30000], Step [1/1], Training Loss: 29.5990, Valid Loss: 292.4381
Epoch [14201/30000], Step [1/1], Training Loss: 26.4686, Valid Loss: 308.5143
Epoch [14301/30000], Step [1/1], Training Loss: 23.7201, Valid Loss: 328.5619
Epoch [14401/30000], Step [1/1], Training Loss: 19.3537, Valid Loss: 319.1524
Epoch [14501/30000], Step [1/1], Training Loss: 17.1146, Valid Loss: 329.3905
Epoch [14601/30000], Step [1/1], Training Loss: 18.1678, Valid Loss: 340.8953
Epoch [14701/30000], Step [1/1], Training Loss: 13.3314, Valid Loss: 323.8191
Epoch [14801/30000], Step [1/1], Training Loss: 10.7233, Valid Loss: 358.4667
Epoch [14901/30000], Step [1/1], Training Loss: 9.3571, Valid Loss: 332.6476
Epoch [15001/30000], Step [1/1], Training Loss: 8.4446, Valid Loss: 334.1048
Epoch [15101/30000], Step [1/1], Training Loss: 7.3967, Valid Loss: 349.4000
Epoch [15201/30000], Step [1/1], Training Loss: 7.4584, Valid Loss: 368.2667
Epoch [15301/30000], Step [1/1], Training Loss: 4.6133, Valid Loss: 348.6572
Epoch [15401/30000], Step [1/1], Training Loss: 4.6460, Valid Loss: 351.4476
Epoch [15501/30000], Step [1/1], Training Loss: 3.6479, Valid Loss: 329.2762
Epoch [15601/30000], Step [1/1], Training Loss: 3.0587, Valid Loss: 344.6667
Epoch [15701/30000], Step [1/1], Training Loss: 3.0154, Valid Loss: 347.6572
Epoch [15801/30000], Step [1/1], Training Loss: 2.0301, Valid Loss: 351.7143
Epoch [15901/30000], Step [1/1], Training Loss: 3.3032, Valid Loss: 330.1524
Epoch [16001/30000], Step [1/1], Training Loss: 2.1772, Valid Loss: 326.2191
Epoch [16101/30000], Step [1/1], Training Loss: 1.9697, Valid Loss: 373.0857
Epoch [16201/30000], Step [1/1], Training Loss: 1.9265, Valid Loss: 359.3143
Epoch [16301/30000], Step [1/1], Training Loss: 1.4488, Valid Loss: 361.0667
Epoch [16401/30000], Step [1/1], Training Loss: 1.3696, Valid Loss: 353.2667
Epoch [16501/30000], Step [1/1], Training Loss: 1.3950, Valid Loss: 374.0952
Epoch [16601/30000], Step [1/1], Training Loss: 1.5465, Valid Loss: 373.8476
Epoch [16701/30000], Step [1/1], Training Loss: 1.4037, Valid Loss: 378.1905
Epoch [16801/30000], Step [1/1], Training Loss: 0.7995, Valid Loss: 368.8667
Epoch [16901/30000], Step [1/1], Training Loss: 1.0950, Valid Loss: 350.0857
Epoch [17001/30000], Step [1/1], Training Loss: 1.3283, Valid Loss: 388.6857
Epoch [17101/30000], Step [1/1], Training Loss: 1.3862, Valid Loss: 372.8953
Epoch [17201/30000], Step [1/1], Training Loss: 0.9308, Valid Loss: 338.9810
Epoch [17301/30000], Step [1/1], Training Loss: 1.2509, Valid Loss: 361.0191
Epoch [17401/30000], Step [1/1], Training Loss: 0.8326, Valid Loss: 413.6095
Epoch [17501/30000], Step [1/1], Training Loss: 1.4030, Valid Loss: 397.7905
Epoch [17601/30000], Step [1/1], Training Loss: 0.8608, Valid Loss: 331.5619
Epoch [17701/30000], Step [1/1], Training Loss: 0.7586, Valid Loss: 333.8667
Epoch [17801/30000], Step [1/1], Training Loss: 1.1218, Valid Loss: 342.6000
Epoch [17901/30000], Step [1/1], Training Loss: 1.0135, Valid Loss: 354.4381
Epoch [18001/30000], Step [1/1], Training Loss: 3802.9004, Valid Loss: 208.1810
Epoch [18101/30000], Step [1/1], Training Loss: 1377.0356, Valid Loss: 235.6095
Epoch [18201/30000], Step [1/1], Training Loss: 786.7004, Valid Loss: 196.4762
Epoch [18301/30000], Step [1/1], Training Loss: 446.8550, Valid Loss: 215.8857
Epoch [18401/30000], Step [1/1], Training Loss: 316.6388, Valid Loss: 216.2191
Epoch [18501/30000], Step [1/1], Training Loss: 260.4062, Valid Loss: 217.3524
Epoch [18601/30000], Step [1/1], Training Loss: 218.9116, Valid Loss: 219.9905
Epoch [18701/30000], Step [1/1], Training Loss: 173.9243, Valid Loss: 223.5714
Epoch [18801/30000], Step [1/1], Training Loss: 148.5868, Valid Loss: 250.6191
Epoch [18901/30000], Step [1/1], Training Loss: 136.1572, Valid Loss: 252.2667
Epoch [19001/30000], Step [1/1], Training Loss: 127.6687, Valid Loss: 258.3905
Epoch [19101/30000], Step [1/1], Training Loss: 114.2980, Valid Loss: 238.6953
Epoch [19201/30000], Step [1/1], Training Loss: 123.2282, Valid Loss: 256.3333
Epoch [19301/30000], Step [1/1], Training Loss: 120.5600, Valid Loss: 308.3905
Epoch [19401/30000], Step [1/1], Training Loss: 77.9647, Valid Loss: 289.4000
Epoch [19501/30000], Step [1/1], Training Loss: 70.3265, Valid Loss: 270.5334
Epoch [19601/30000], Step [1/1], Training Loss: 57.1634, Valid Loss: 255.3810
Epoch [19701/30000], Step [1/1], Training Loss: 53.3636, Valid Loss: 280.4952
Epoch [19801/30000], Step [1/1], Training Loss: 51.0639, Valid Loss: 309.6000
Epoch [19901/30000], Step [1/1], Training Loss: 46.5861, Valid Loss: 302.7143
Epoch [20001/30000], Step [1/1], Training Loss: 41.7496, Valid Loss: 299.0667
Epoch [20101/30000], Step [1/1], Training Loss: 36.8466, Valid Loss: 299.7810
Epoch [20201/30000], Step [1/1], Training Loss: 33.3057, Valid Loss: 290.4572
Epoch [20301/30000], Step [1/1], Training Loss: 28.4902, Valid Loss: 316.5143
Epoch [20401/30000], Step [1/1], Training Loss: 26.4651, Valid Loss: 340.4857
Epoch [20501/30000], Step [1/1], Training Loss: 20.4360, Valid Loss: 335.8667
Epoch [20601/30000], Step [1/1], Training Loss: 19.6016, Valid Loss: 313.2667

[Epoch 25000] Rounded prediction: 
tensor([24., 20., 25., 23., 17., 25., 19., 26., 30., 11., 20., 10., 21., 18.,
        15., 31.,  2., 22.,  0., 29., 27.,  3., 26., 28.,  0., 20., 21.,  5.,
        10., 20., 20.,  0.,  7., 28.,  0., 12.,  5., 21.,  3., 22.,  9., 34.,
         2., 17.,  0., 19., 14.,  9.,  7., 11., 17., 16., 28.,  0., 45.,  0.,
        17.,  8., 21., 14.,  4., 23.,  0., 34.,  0., 41.,  0., 46., 14.,  0.,
        22., 25., 21., 15.,  7., 54.,  8., 62.,  0., 47., 38.,  0., 70., 26.,
         0., 13.,  4.,  4., 18., 20., 41., 54., 50., 53., 43., 15., 22., 43.,
        43., 29., 28., 39., 12., 14., 20.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [20701/30000], Step [1/1], Training Loss: 16.1335, Valid Loss: 371.4000
Epoch [20801/30000], Step [1/1], Training Loss: 12.5846, Valid Loss: 329.1238
Epoch [20901/30000], Step [1/1], Training Loss: 15.9434, Valid Loss: 338.7333
Epoch [21001/30000], Step [1/1], Training Loss: 10.3736, Valid Loss: 362.6762
Epoch [21101/30000], Step [1/1], Training Loss: 10.3133, Valid Loss: 337.4191
Epoch [21201/30000], Step [1/1], Training Loss: 9.5358, Valid Loss: 333.4095
Epoch [21301/30000], Step [1/1], Training Loss: 8.9626, Valid Loss: 334.3810
Epoch [21401/30000], Step [1/1], Training Loss: 8.1854, Valid Loss: 343.5238
Epoch [21501/30000], Step [1/1], Training Loss: 5.4397, Valid Loss: 353.9143
Epoch [21601/30000], Step [1/1], Training Loss: 6.6264, Valid Loss: 387.9619
Epoch [21701/30000], Step [1/1], Training Loss: 5.8681, Valid Loss: 372.1905
Epoch [21801/30000], Step [1/1], Training Loss: 3.7001, Valid Loss: 362.2762
Epoch [21901/30000], Step [1/1], Training Loss: 4.1588, Valid Loss: 351.9238
Epoch [22001/30000], Step [1/1], Training Loss: 4.1012, Valid Loss: 353.5238
Epoch [22101/30000], Step [1/1], Training Loss: 2315.8113, Valid Loss: 168.2952
Epoch [22201/30000], Step [1/1], Training Loss: 772.9111, Valid Loss: 262.9524
Epoch [22301/30000], Step [1/1], Training Loss: 410.4102, Valid Loss: 258.7714
Epoch [22401/30000], Step [1/1], Training Loss: 125.6155, Valid Loss: 262.3143
Epoch [22501/30000], Step [1/1], Training Loss: 64.4179, Valid Loss: 279.4286
Epoch [22601/30000], Step [1/1], Training Loss: 31.2832, Valid Loss: 277.9810
Epoch [22701/30000], Step [1/1], Training Loss: 27.3300, Valid Loss: 294.3333
Epoch [22801/30000], Step [1/1], Training Loss: 16.5323, Valid Loss: 292.1429
Epoch [22901/30000], Step [1/1], Training Loss: 13.6703, Valid Loss: 319.9524
Epoch [23001/30000], Step [1/1], Training Loss: 10.9450, Valid Loss: 309.7524
Epoch [23101/30000], Step [1/1], Training Loss: 12.0743, Valid Loss: 328.1714
Epoch [23201/30000], Step [1/1], Training Loss: 8.6815, Valid Loss: 301.0381
Epoch [23301/30000], Step [1/1], Training Loss: 11.0117, Valid Loss: 313.9714
Epoch [23401/30000], Step [1/1], Training Loss: 7.2807, Valid Loss: 317.7429
Epoch [23501/30000], Step [1/1], Training Loss: 6.8575, Valid Loss: 311.3714
Epoch [23601/30000], Step [1/1], Training Loss: 7.8178, Valid Loss: 328.2667
Epoch [23701/30000], Step [1/1], Training Loss: 5.6791, Valid Loss: 322.9524
Epoch [23801/30000], Step [1/1], Training Loss: 5.3945, Valid Loss: 300.7429
Epoch [23901/30000], Step [1/1], Training Loss: 4.4580, Valid Loss: 328.0381
Epoch [24001/30000], Step [1/1], Training Loss: 5.7353, Valid Loss: 320.9143
Epoch [24101/30000], Step [1/1], Training Loss: 4.2923, Valid Loss: 327.9238
Epoch [24201/30000], Step [1/1], Training Loss: 3.9051, Valid Loss: 353.8000
Epoch [24301/30000], Step [1/1], Training Loss: 296.3466, Valid Loss: 194.1048
Epoch [24401/30000], Step [1/1], Training Loss: 96.2126, Valid Loss: 312.0286
Epoch [24501/30000], Step [1/1], Training Loss: 83.5642, Valid Loss: 264.8095
Epoch [24601/30000], Step [1/1], Training Loss: 37.1100, Valid Loss: 316.7143
Epoch [24701/30000], Step [1/1], Training Loss: 38.7609, Valid Loss: 290.4286
Epoch [24801/30000], Step [1/1], Training Loss: 8.8422, Valid Loss: 296.1333
Epoch [24901/30000], Step [1/1], Training Loss: 10.9945, Valid Loss: 299.1905
Epoch [25001/30000], Step [1/1], Training Loss: 8.7280, Valid Loss: 296.1429
Epoch [25101/30000], Step [1/1], Training Loss: 8.5851, Valid Loss: 294.5334
Epoch [25201/30000], Step [1/1], Training Loss: 11.2005, Valid Loss: 320.7905
Epoch [25301/30000], Step [1/1], Training Loss: 7.4092, Valid Loss: 302.2762
Epoch [25401/30000], Step [1/1], Training Loss: 5.8802, Valid Loss: 306.3429
Epoch [25501/30000], Step [1/1], Training Loss: 3.5754, Valid Loss: 304.1429
Epoch [25601/30000], Step [1/1], Training Loss: 5.9561, Valid Loss: 318.6190
Epoch [25701/30000], Step [1/1], Training Loss: 5.3956, Valid Loss: 313.0381
Epoch [25801/30000], Step [1/1], Training Loss: 5.5450, Valid Loss: 297.4000
Epoch [25901/30000], Step [1/1], Training Loss: 4.4234, Valid Loss: 313.2286
Epoch [26001/30000], Step [1/1], Training Loss: 3.1811, Valid Loss: 303.0762
Epoch [26101/30000], Step [1/1], Training Loss: 3.3763, Valid Loss: 305.4572
Epoch [26201/30000], Step [1/1], Training Loss: 3.8494, Valid Loss: 317.9714
Epoch [26301/30000], Step [1/1], Training Loss: 3.6151, Valid Loss: 329.2571
Epoch [26401/30000], Step [1/1], Training Loss: 3.3620, Valid Loss: 326.2667
Epoch [26501/30000], Step [1/1], Training Loss: 3.1719, Valid Loss: 335.8571
Epoch [26601/30000], Step [1/1], Training Loss: 3.4611, Valid Loss: 322.0095
Epoch [26701/30000], Step [1/1], Training Loss: 1.8776, Valid Loss: 338.7905
Epoch [26801/30000], Step [1/1], Training Loss: 320.4297, Valid Loss: 322.3619
Epoch [26901/30000], Step [1/1], Training Loss: 135.8573, Valid Loss: 355.7905
Epoch [27001/30000], Step [1/1], Training Loss: 20.9588, Valid Loss: 305.7143
Epoch [27101/30000], Step [1/1], Training Loss: 15.5345, Valid Loss: 375.9619
Epoch [27201/30000], Step [1/1], Training Loss: 9.1564, Valid Loss: 367.9714
Epoch [27301/30000], Step [1/1], Training Loss: 8.6838, Valid Loss: 382.9333
Epoch [27401/30000], Step [1/1], Training Loss: 7.5651, Valid Loss: 376.9333
Epoch [27501/30000], Step [1/1], Training Loss: 5.1551, Valid Loss: 391.8667
Epoch [27601/30000], Step [1/1], Training Loss: 3.6655, Valid Loss: 404.6572
Epoch [27701/30000], Step [1/1], Training Loss: 6.1695, Valid Loss: 371.3429
Epoch [27801/30000], Step [1/1], Training Loss: 3.6893, Valid Loss: 404.5238
Epoch [27901/30000], Step [1/1], Training Loss: 4.5234, Valid Loss: 416.7619
Epoch [28001/30000], Step [1/1], Training Loss: 3.6121, Valid Loss: 400.4095
Epoch [28101/30000], Step [1/1], Training Loss: 3.8271, Valid Loss: 406.9524
Epoch [28201/30000], Step [1/1], Training Loss: 3.2115, Valid Loss: 398.4476
Epoch [28301/30000], Step [1/1], Training Loss: 3.5576, Valid Loss: 407.1905
Epoch [28401/30000], Step [1/1], Training Loss: 4.2994, Valid Loss: 427.2000
Epoch [28501/30000], Step [1/1], Training Loss: 2.3262, Valid Loss: 388.7429
Epoch [28601/30000], Step [1/1], Training Loss: 1.9161, Valid Loss: 399.1429
Epoch [28701/30000], Step [1/1], Training Loss: 1.9060, Valid Loss: 403.6095
Epoch [28801/30000], Step [1/1], Training Loss: 2.3676, Valid Loss: 396.8476
Epoch [28901/30000], Step [1/1], Training Loss: 2.0589, Valid Loss: 422.5524
Epoch [29001/30000], Step [1/1], Training Loss: 2.0077, Valid Loss: 443.1905
Epoch [29101/30000], Step [1/1], Training Loss: 1.9212, Valid Loss: 389.3333
Epoch [29201/30000], Step [1/1], Training Loss: 1.9903, Valid Loss: 405.0572
Epoch [29301/30000], Step [1/1], Training Loss: 1.5418, Valid Loss: 414.3238
Epoch [29401/30000], Step [1/1], Training Loss: 1.4348, Valid Loss: 379.3333
Epoch [29501/30000], Step [1/1], Training Loss: 1.7905, Valid Loss: 394.8000
Epoch [29601/30000], Step [1/1], Training Loss: 1.4732, Valid Loss: 419.4000
Epoch [29701/30000], Step [1/1], Training Loss: 1.6050, Valid Loss: 387.5714
Epoch [29801/30000], Step [1/1], Training Loss: 1.2190, Valid Loss: 382.1905
Epoch [29901/30000], Step [1/1], Training Loss: 0.7724, Valid Loss: 399.4191

 End Time: 2021/04/20, 02:55:12




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=2048 	layers=2

Start Time = 2021/04/20, 02:55:12
##########################################################


[Epoch 0] Rounded prediction: 
tensor([3., 3., 3., 2., 3., 2., 3., 3., 3., 3., 3., 3., 3., 2., 2., 2., 2., 2.,
        2., 2., 2., 2., 2., 2., 2., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2.,
        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
        2., 2., 2., 2., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 2.],
       device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([29., 26., 27., 20., 18., 21., 21., 28., 26., 27., 29., 24., 26., 24.,
        20., 24., 16., 21., 15., 16., 25., 22., 22., 26., 14.,  6., 14., 17.,
        17., 14., 21.,  9.,  3., 13., 17., 17., 11., 11.,  7., 15., 16., 32.,
        21., 20.,  9.,  4., 11., 13., 12., 10., 12., 15., 22., 18., 24., 21.,
        11., 11., 13., 16., 14., 17.,  9., 19., 13., 26., 19., 27., 33., 24.,
        21., 22., 24., 25., 23., 32., 32., 41., 27., 39., 45., 30., 45., 48.,
        34., 34., 30., 24., 20., 30., 39., 42., 51., 58., 54., 43., 43., 45.,
        47., 46., 52., 54., 49., 45., 52.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([27., 26., 28., 20., 20., 25., 22., 35., 28., 32., 33., 30., 28., 25.,
        21., 24., 15., 13., 12., 14., 20., 20., 19., 22., 17.,  6., 12., 12.,
        14., 13., 18., 12.,  3., 13., 12., 13., 10., 12.,  7., 10., 11., 26.,
        19., 17., 10.,  6., 10.,  9., 11., 10., 10., 13., 18., 13., 23., 20.,
        10., 11., 11., 13., 12., 14., 12., 14., 12., 19., 18., 23., 30., 23.,
        21., 20., 22., 22., 21., 25., 30., 41., 28., 33., 41., 30., 43., 50.,
        32., 33., 27., 20., 18., 27., 37., 43., 49., 64., 60., 45., 42., 47.,
        45., 40., 50., 50., 42., 37., 48.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128676.7422, Valid Loss: 187.3619
Epoch [101/30000], Step [1/1], Training Loss: 110031.8516, Valid Loss: 1060.5906
Epoch [201/30000], Step [1/1], Training Loss: 102320.4531, Valid Loss: 2659.7905
Epoch [301/30000], Step [1/1], Training Loss: 95210.9766, Valid Loss: 82.5905
Epoch [401/30000], Step [1/1], Training Loss: 88614.1562, Valid Loss: 167.8476
Epoch [501/30000], Step [1/1], Training Loss: 82590.3125, Valid Loss: 418.7143
Epoch [601/30000], Step [1/1], Training Loss: 77072.9297, Valid Loss: 446.8095
Epoch [701/30000], Step [1/1], Training Loss: 72029.3359, Valid Loss: 813.3524
Epoch [801/30000], Step [1/1], Training Loss: 67438.0938, Valid Loss: 621.3524
Epoch [901/30000], Step [1/1], Training Loss: 63269.5664, Valid Loss: 436.3333
Epoch [1001/30000], Step [1/1], Training Loss: 59520.6914, Valid Loss: 304.8191
Epoch [1101/30000], Step [1/1], Training Loss: 55796.0039, Valid Loss: 248.3619
Epoch [1201/30000], Step [1/1], Training Loss: 52461.8633, Valid Loss: 200.7714
Epoch [1301/30000], Step [1/1], Training Loss: 49333.7734, Valid Loss: 180.4762
Epoch [1401/30000], Step [1/1], Training Loss: 46512.6719, Valid Loss: 178.3905
Epoch [1501/30000], Step [1/1], Training Loss: 43697.4688, Valid Loss: 213.9238
Epoch [1601/30000], Step [1/1], Training Loss: 41218.9180, Valid Loss: 208.4095
Epoch [1701/30000], Step [1/1], Training Loss: 38973.9570, Valid Loss: 235.7143
Epoch [1801/30000], Step [1/1], Training Loss: 36895.2969, Valid Loss: 193.8857
Epoch [1901/30000], Step [1/1], Training Loss: 34906.9766, Valid Loss: 211.0667
Epoch [2001/30000], Step [1/1], Training Loss: 33093.7344, Valid Loss: 214.5048
Epoch [2101/30000], Step [1/1], Training Loss: 31320.5957, Valid Loss: 228.2286
Epoch [2201/30000], Step [1/1], Training Loss: 29853.9766, Valid Loss: 178.2000
Epoch [2301/30000], Step [1/1], Training Loss: 27976.3379, Valid Loss: 196.4476
Epoch [2401/30000], Step [1/1], Training Loss: 26466.5742, Valid Loss: 126.3810
Epoch [2501/30000], Step [1/1], Training Loss: 25062.7520, Valid Loss: 172.9238
Epoch [2601/30000], Step [1/1], Training Loss: 23719.9219, Valid Loss: 230.3143
Epoch [2701/30000], Step [1/1], Training Loss: 22566.4023, Valid Loss: 240.1143
Epoch [2801/30000], Step [1/1], Training Loss: 21323.1992, Valid Loss: 196.8476
Epoch [2901/30000], Step [1/1], Training Loss: 20167.8477, Valid Loss: 212.0095
Epoch [3001/30000], Step [1/1], Training Loss: 18996.3477, Valid Loss: 201.5810
Epoch [3101/30000], Step [1/1], Training Loss: 17929.1797, Valid Loss: 203.9238
Epoch [3201/30000], Step [1/1], Training Loss: 17000.5195, Valid Loss: 174.2381
Epoch [3301/30000], Step [1/1], Training Loss: 16244.8105, Valid Loss: 183.2191
Epoch [3401/30000], Step [1/1], Training Loss: 15715.7002, Valid Loss: 184.6762
Epoch [3501/30000], Step [1/1], Training Loss: 14734.7900, Valid Loss: 172.4762
Epoch [3601/30000], Step [1/1], Training Loss: 14031.2578, Valid Loss: 197.6095
Epoch [3701/30000], Step [1/1], Training Loss: 13506.5996, Valid Loss: 161.2000
Epoch [3801/30000], Step [1/1], Training Loss: 12908.4619, Valid Loss: 176.4381
Epoch [3901/30000], Step [1/1], Training Loss: 12255.2227, Valid Loss: 191.0476
Epoch [4001/30000], Step [1/1], Training Loss: 11336.1699, Valid Loss: 217.5905
Epoch [4101/30000], Step [1/1], Training Loss: 10764.8428, Valid Loss: 221.7619
Epoch [4201/30000], Step [1/1], Training Loss: 10316.2383, Valid Loss: 226.3143
Epoch [4301/30000], Step [1/1], Training Loss: 9660.9375, Valid Loss: 202.7524
Epoch [4401/30000], Step [1/1], Training Loss: 9156.6953, Valid Loss: 167.2952
Epoch [4501/30000], Step [1/1], Training Loss: 8649.4072, Valid Loss: 211.7905
Epoch [4601/30000], Step [1/1], Training Loss: 8199.9775, Valid Loss: 219.0095
Epoch [4701/30000], Step [1/1], Training Loss: 7924.1147, Valid Loss: 223.5619
Epoch [4801/30000], Step [1/1], Training Loss: 7666.7837, Valid Loss: 217.4572
Epoch [4901/30000], Step [1/1], Training Loss: 7060.6699, Valid Loss: 285.8857
Epoch [5001/30000], Step [1/1], Training Loss: 6508.3208, Valid Loss: 244.4191
Epoch [5101/30000], Step [1/1], Training Loss: 6186.2217, Valid Loss: 258.8095
Epoch [5201/30000], Step [1/1], Training Loss: 5868.1548, Valid Loss: 267.7429
Epoch [5301/30000], Step [1/1], Training Loss: 5509.2705, Valid Loss: 265.2476
Epoch [5401/30000], Step [1/1], Training Loss: 5231.0659, Valid Loss: 266.6762
Epoch [5501/30000], Step [1/1], Training Loss: 4990.0181, Valid Loss: 256.2191
Epoch [5601/30000], Step [1/1], Training Loss: 4758.7290, Valid Loss: 258.1429
Epoch [5701/30000], Step [1/1], Training Loss: 4542.0234, Valid Loss: 250.2381
Epoch [5801/30000], Step [1/1], Training Loss: 4336.4736, Valid Loss: 273.8000
Epoch [5901/30000], Step [1/1], Training Loss: 4210.2915, Valid Loss: 202.4381
Epoch [6001/30000], Step [1/1], Training Loss: 4215.1685, Valid Loss: 278.4952
Epoch [6101/30000], Step [1/1], Training Loss: 3940.9119, Valid Loss: 241.6095
Epoch [6201/30000], Step [1/1], Training Loss: 3725.7837, Valid Loss: 276.5429
Epoch [6301/30000], Step [1/1], Training Loss: 3699.1975, Valid Loss: 244.5238
Epoch [6401/30000], Step [1/1], Training Loss: 3256.9165, Valid Loss: 235.6095
Epoch [6501/30000], Step [1/1], Training Loss: 2907.9331, Valid Loss: 239.6381
Epoch [6601/30000], Step [1/1], Training Loss: 2759.1174, Valid Loss: 228.9238
Epoch [6701/30000], Step [1/1], Training Loss: 2566.0959, Valid Loss: 243.6000
Epoch [6801/30000], Step [1/1], Training Loss: 2401.1157, Valid Loss: 253.3429
Epoch [6901/30000], Step [1/1], Training Loss: 2277.6692, Valid Loss: 257.7619
Epoch [7001/30000], Step [1/1], Training Loss: 2149.8030, Valid Loss: 260.3810
Epoch [7101/30000], Step [1/1], Training Loss: 2026.7965, Valid Loss: 267.0381
Epoch [7201/30000], Step [1/1], Training Loss: 1936.4348, Valid Loss: 259.3143
Epoch [7301/30000], Step [1/1], Training Loss: 1815.8346, Valid Loss: 283.5619
Epoch [7401/30000], Step [1/1], Training Loss: 1703.4380, Valid Loss: 260.6953
Epoch [7501/30000], Step [1/1], Training Loss: 1610.3492, Valid Loss: 259.7905
Epoch [7601/30000], Step [1/1], Training Loss: 1538.1766, Valid Loss: 280.8667
Epoch [7701/30000], Step [1/1], Training Loss: 1453.1697, Valid Loss: 277.2191
Epoch [7801/30000], Step [1/1], Training Loss: 1387.7490, Valid Loss: 278.0286
Epoch [7901/30000], Step [1/1], Training Loss: 1326.2037, Valid Loss: 290.1714
Epoch [8001/30000], Step [1/1], Training Loss: 1579.7344, Valid Loss: 250.1714
Epoch [8101/30000], Step [1/1], Training Loss: 2053.9619, Valid Loss: 160.6857
Epoch [8201/30000], Step [1/1], Training Loss: 1224.9125, Valid Loss: 247.8000
Epoch [8301/30000], Step [1/1], Training Loss: 1121.6857, Valid Loss: 240.2000
Epoch [8401/30000], Step [1/1], Training Loss: 1060.9161, Valid Loss: 234.2762
Epoch [8501/30000], Step [1/1], Training Loss: 1007.5137, Valid Loss: 227.7048
Epoch [8601/30000], Step [1/1], Training Loss: 966.0179, Valid Loss: 218.2286
Epoch [8701/30000], Step [1/1], Training Loss: 926.2660, Valid Loss: 227.9905
Epoch [8801/30000], Step [1/1], Training Loss: 879.6376, Valid Loss: 219.0095
Epoch [8901/30000], Step [1/1], Training Loss: 842.5005, Valid Loss: 206.7524
Epoch [9001/30000], Step [1/1], Training Loss: 812.5133, Valid Loss: 209.3429
Epoch [9101/30000], Step [1/1], Training Loss: 774.6166, Valid Loss: 186.6095
Epoch [9201/30000], Step [1/1], Training Loss: 741.8325, Valid Loss: 197.1524
Epoch [9301/30000], Step [1/1], Training Loss: 712.0674, Valid Loss: 197.8952
Epoch [9401/30000], Step [1/1], Training Loss: 679.8123, Valid Loss: 206.9238
Epoch [9501/30000], Step [1/1], Training Loss: 654.3354, Valid Loss: 214.3238
Epoch [9601/30000], Step [1/1], Training Loss: 629.2509, Valid Loss: 220.8857
Epoch [9701/30000], Step [1/1], Training Loss: 604.3992, Valid Loss: 202.8667
Epoch [9801/30000], Step [1/1], Training Loss: 577.9062, Valid Loss: 242.1429
Epoch [9901/30000], Step [1/1], Training Loss: 553.6317, Valid Loss: 229.1905
Epoch [10001/30000], Step [1/1], Training Loss: 529.6990, Valid Loss: 219.2095
Epoch [10101/30000], Step [1/1], Training Loss: 505.2756, Valid Loss: 233.9429
Epoch [10201/30000], Step [1/1], Training Loss: 481.9805, Valid Loss: 206.1048

[Epoch 15000] Rounded prediction: 
tensor([29., 28., 30., 20., 24., 25., 25., 37., 34., 39., 37., 39., 32., 32.,
        28., 24., 18.,  8., 13., 11., 21., 20., 18., 24., 17.,  5.,  9., 11.,
        12., 12., 15., 13.,  2.,  8.,  9., 10.,  9., 10.,  9.,  7., 10., 28.,
        20., 14.,  8.,  3.,  6.,  7., 10., 11., 10., 12., 19., 14., 25., 17.,
         7.,  8., 10., 11., 12., 13., 15., 10., 17., 18., 21., 22., 36., 22.,
        20., 22., 25., 23., 23., 27., 35., 49., 26., 32., 50., 26., 49., 58.,
        25., 28., 28., 18., 20., 30., 48., 52., 56., 68., 65., 44., 35., 42.,
        44., 35., 45., 56., 43., 28., 56.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([22., 18., 23., 18., 17., 22., 21., 34., 33., 45., 46., 56., 40., 39.,
        34., 33., 16., 10.,  8., 13., 19., 19., 17., 23., 14.,  5., 10.,  8.,
        11., 13., 16., 11.,  3., 10.,  7., 10.,  8., 10.,  6.,  8.,  8., 26.,
        15., 11.,  8.,  4.,  6.,  6.,  9., 11., 10., 12., 16., 13., 24., 15.,
         7.,  8.,  9., 10., 10., 12., 12., 11., 14., 19., 20., 22., 33., 23.,
        21., 24., 27., 25., 25., 34., 33., 50., 28., 35., 47., 27., 55., 60.,
        25., 31., 30., 20., 26., 40., 56., 56., 58., 65., 59., 45., 40., 45.,
        45., 36., 48., 57., 42., 24., 58.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [10301/30000], Step [1/1], Training Loss: 459.3138, Valid Loss: 227.9524
Epoch [10401/30000], Step [1/1], Training Loss: 437.7378, Valid Loss: 243.3048
Epoch [10501/30000], Step [1/1], Training Loss: 418.6345, Valid Loss: 235.3143
Epoch [10601/30000], Step [1/1], Training Loss: 398.0868, Valid Loss: 232.2572
Epoch [10701/30000], Step [1/1], Training Loss: 378.5753, Valid Loss: 218.5524
Epoch [10801/30000], Step [1/1], Training Loss: 361.4516, Valid Loss: 222.2572
Epoch [10901/30000], Step [1/1], Training Loss: 341.4486, Valid Loss: 251.2095
Epoch [11001/30000], Step [1/1], Training Loss: 322.0463, Valid Loss: 227.2762
Epoch [11101/30000], Step [1/1], Training Loss: 304.7369, Valid Loss: 228.3238
Epoch [11201/30000], Step [1/1], Training Loss: 286.6051, Valid Loss: 226.0952
Epoch [11301/30000], Step [1/1], Training Loss: 269.8530, Valid Loss: 211.7524
Epoch [11401/30000], Step [1/1], Training Loss: 251.5295, Valid Loss: 251.0572
Epoch [11501/30000], Step [1/1], Training Loss: 234.3088, Valid Loss: 244.5714
Epoch [11601/30000], Step [1/1], Training Loss: 218.4350, Valid Loss: 273.1619
Epoch [11701/30000], Step [1/1], Training Loss: 202.4180, Valid Loss: 263.6762
Epoch [11801/30000], Step [1/1], Training Loss: 187.2976, Valid Loss: 255.0667
Epoch [11901/30000], Step [1/1], Training Loss: 173.5812, Valid Loss: 280.6000
Epoch [12001/30000], Step [1/1], Training Loss: 164.3492, Valid Loss: 233.0571
Epoch [12101/30000], Step [1/1], Training Loss: 148.4424, Valid Loss: 239.2762
Epoch [12201/30000], Step [1/1], Training Loss: 133.1708, Valid Loss: 213.7333
Epoch [12301/30000], Step [1/1], Training Loss: 120.8684, Valid Loss: 216.1905
Epoch [12401/30000], Step [1/1], Training Loss: 110.2709, Valid Loss: 222.2667
Epoch [12501/30000], Step [1/1], Training Loss: 98.8552, Valid Loss: 222.3810
Epoch [12601/30000], Step [1/1], Training Loss: 88.7595, Valid Loss: 228.5905
Epoch [12701/30000], Step [1/1], Training Loss: 80.1263, Valid Loss: 246.9143
Epoch [12801/30000], Step [1/1], Training Loss: 70.5076, Valid Loss: 241.0667
Epoch [12901/30000], Step [1/1], Training Loss: 63.9269, Valid Loss: 256.6762
Epoch [13001/30000], Step [1/1], Training Loss: 56.7312, Valid Loss: 245.6762
Epoch [13101/30000], Step [1/1], Training Loss: 49.3314, Valid Loss: 214.3429
Epoch [13201/30000], Step [1/1], Training Loss: 42.5534, Valid Loss: 235.1524
Epoch [13301/30000], Step [1/1], Training Loss: 37.1400, Valid Loss: 252.5524
Epoch [13401/30000], Step [1/1], Training Loss: 31.8238, Valid Loss: 249.4381
Epoch [13501/30000], Step [1/1], Training Loss: 28.5869, Valid Loss: 252.0191
Epoch [13601/30000], Step [1/1], Training Loss: 23.9816, Valid Loss: 266.2476
Epoch [13701/30000], Step [1/1], Training Loss: 20.1569, Valid Loss: 231.7429
Epoch [13801/30000], Step [1/1], Training Loss: 27.2161, Valid Loss: 193.2572
Epoch [13901/30000], Step [1/1], Training Loss: 17.2645, Valid Loss: 236.6286
Epoch [14001/30000], Step [1/1], Training Loss: 13.9836, Valid Loss: 242.8191
Epoch [14101/30000], Step [1/1], Training Loss: 10.2193, Valid Loss: 253.9810
Epoch [14201/30000], Step [1/1], Training Loss: 8.2943, Valid Loss: 258.1524
Epoch [14301/30000], Step [1/1], Training Loss: 7.0836, Valid Loss: 272.2095
Epoch [14401/30000], Step [1/1], Training Loss: 6.0322, Valid Loss: 263.2476
Epoch [14501/30000], Step [1/1], Training Loss: 4.7150, Valid Loss: 266.0476
Epoch [14601/30000], Step [1/1], Training Loss: 3.9651, Valid Loss: 282.5524
Epoch [14701/30000], Step [1/1], Training Loss: 3.4301, Valid Loss: 280.2381
Epoch [14801/30000], Step [1/1], Training Loss: 2.5627, Valid Loss: 294.5714
Epoch [14901/30000], Step [1/1], Training Loss: 2.0929, Valid Loss: 291.5810
Epoch [15001/30000], Step [1/1], Training Loss: 1.6258, Valid Loss: 280.6286
Epoch [15101/30000], Step [1/1], Training Loss: 1.6530, Valid Loss: 281.0857
Epoch [15201/30000], Step [1/1], Training Loss: 1.2760, Valid Loss: 306.6000
Epoch [15301/30000], Step [1/1], Training Loss: 1.3697, Valid Loss: 319.8000
Epoch [15401/30000], Step [1/1], Training Loss: 1.0831, Valid Loss: 249.3714
Epoch [15501/30000], Step [1/1], Training Loss: 0.7076, Valid Loss: 295.7524
Epoch [15601/30000], Step [1/1], Training Loss: 0.9682, Valid Loss: 261.7714
Epoch [15701/30000], Step [1/1], Training Loss: 0.6813, Valid Loss: 302.5524
Epoch [15801/30000], Step [1/1], Training Loss: 0.5051, Valid Loss: 294.3810
Epoch [15901/30000], Step [1/1], Training Loss: 0.6745, Valid Loss: 313.0476
Epoch [16001/30000], Step [1/1], Training Loss: 0.5659, Valid Loss: 294.3238
Epoch [16101/30000], Step [1/1], Training Loss: 0.7198, Valid Loss: 315.4762
Epoch [16201/30000], Step [1/1], Training Loss: 0.4194, Valid Loss: 282.5714
Epoch [16301/30000], Step [1/1], Training Loss: 0.5240, Valid Loss: 296.2286
Epoch [16401/30000], Step [1/1], Training Loss: 0.4097, Valid Loss: 305.4476
Epoch [16501/30000], Step [1/1], Training Loss: 0.5266, Valid Loss: 318.0381
Epoch [16601/30000], Step [1/1], Training Loss: 0.4259, Valid Loss: 294.1714
Epoch [16701/30000], Step [1/1], Training Loss: 0.4198, Valid Loss: 301.7810
Epoch [16801/30000], Step [1/1], Training Loss: 0.3748, Valid Loss: 317.8953
Epoch [16901/30000], Step [1/1], Training Loss: 0.3865, Valid Loss: 311.5238
Epoch [17001/30000], Step [1/1], Training Loss: 0.4463, Valid Loss: 337.4095
Epoch [17101/30000], Step [1/1], Training Loss: 0.6174, Valid Loss: 304.0762
Epoch [17201/30000], Step [1/1], Training Loss: 0.4250, Valid Loss: 301.7048
Epoch [17301/30000], Step [1/1], Training Loss: 0.3964, Valid Loss: 323.0952
Epoch [17401/30000], Step [1/1], Training Loss: 0.3643, Valid Loss: 326.5619
Epoch [17501/30000], Step [1/1], Training Loss: 0.4564, Valid Loss: 303.0381
Epoch [17601/30000], Step [1/1], Training Loss: 0.2283, Valid Loss: 298.0381
Epoch [17701/30000], Step [1/1], Training Loss: 0.3765, Valid Loss: 294.9238
Epoch [17801/30000], Step [1/1], Training Loss: 0.2659, Valid Loss: 303.4952
Epoch [17901/30000], Step [1/1], Training Loss: 0.2584, Valid Loss: 314.9048
Epoch [18001/30000], Step [1/1], Training Loss: 0.2389, Valid Loss: 298.1238
Epoch [18101/30000], Step [1/1], Training Loss: 0.2764, Valid Loss: 304.5524
Epoch [18201/30000], Step [1/1], Training Loss: 0.2280, Valid Loss: 290.4286
Epoch [18301/30000], Step [1/1], Training Loss: 0.3215, Valid Loss: 314.8857
Epoch [18401/30000], Step [1/1], Training Loss: 0.2874, Valid Loss: 296.4286
Epoch [18501/30000], Step [1/1], Training Loss: 0.2015, Valid Loss: 330.1810
Epoch [18601/30000], Step [1/1], Training Loss: 0.2991, Valid Loss: 293.3238
Epoch [18701/30000], Step [1/1], Training Loss: 0.2769, Valid Loss: 340.8857
Epoch [18801/30000], Step [1/1], Training Loss: 0.3119, Valid Loss: 301.8000
Epoch [18901/30000], Step [1/1], Training Loss: 0.2667, Valid Loss: 298.1048
Epoch [19001/30000], Step [1/1], Training Loss: 0.1539, Valid Loss: 330.9524
Epoch [19101/30000], Step [1/1], Training Loss: 0.1936, Valid Loss: 312.7429
Epoch [19201/30000], Step [1/1], Training Loss: 0.1212, Valid Loss: 322.5143
Epoch [19301/30000], Step [1/1], Training Loss: 0.1526, Valid Loss: 336.2286
Epoch [19401/30000], Step [1/1], Training Loss: 0.1425, Valid Loss: 345.4572
Epoch [19501/30000], Step [1/1], Training Loss: 0.1896, Valid Loss: 352.1143
Epoch [19601/30000], Step [1/1], Training Loss: 0.3658, Valid Loss: 345.0000
Epoch [19701/30000], Step [1/1], Training Loss: 0.1579, Valid Loss: 348.2571
Epoch [19801/30000], Step [1/1], Training Loss: 0.1893, Valid Loss: 311.7905
Epoch [19901/30000], Step [1/1], Training Loss: 0.5214, Valid Loss: 307.3524
Epoch [20001/30000], Step [1/1], Training Loss: 0.1136, Valid Loss: 319.1048
Epoch [20101/30000], Step [1/1], Training Loss: 0.1962, Valid Loss: 335.1143
Epoch [20201/30000], Step [1/1], Training Loss: 0.1150, Valid Loss: 311.9905
Epoch [20301/30000], Step [1/1], Training Loss: 0.1394, Valid Loss: 313.9524
Epoch [20401/30000], Step [1/1], Training Loss: 0.0739, Valid Loss: 334.1143
Epoch [20501/30000], Step [1/1], Training Loss: 0.3308, Valid Loss: 311.2762
Epoch [20601/30000], Step [1/1], Training Loss: 0.1237, Valid Loss: 327.2381
Epoch [20701/30000], Step [1/1], Training Loss: 0.1181, Valid Loss: 341.9048

[Epoch 25000] Rounded prediction: 
tensor([25., 23., 29., 18., 17., 22., 18., 26., 20., 20., 18., 17.,  8.,  8.,
        10.,  8., 10.,  8.,  9.,  8., 16., 18., 10., 17., 14.,  2.,  9.,  7.,
         6., 10., 15.,  8.,  0.,  9.,  7.,  4.,  5.,  9.,  7.,  5.,  9., 22.,
        16.,  9.,  5.,  1.,  6.,  3.,  4.,  6.,  7.,  7., 13., 12., 19., 13.,
         3.,  6.,  7.,  8.,  7.,  8., 11.,  7., 10., 10., 16., 13., 22., 18.,
         7.,  9., 16., 15., 13., 23., 24., 39., 25., 22., 38., 24., 41., 43.,
        26., 19., 16.,  6.,  3.,  8., 40., 38., 44., 55., 48., 43., 37., 37.,
        40., 30., 35., 48., 34., 23., 36.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [20801/30000], Step [1/1], Training Loss: 0.0876, Valid Loss: 344.7143
Epoch [20901/30000], Step [1/1], Training Loss: 0.1421, Valid Loss: 344.2571
Epoch [21001/30000], Step [1/1], Training Loss: 4830.5078, Valid Loss: 91.0857
Epoch [21101/30000], Step [1/1], Training Loss: 637.1427, Valid Loss: 80.8095
Epoch [21201/30000], Step [1/1], Training Loss: 203.6892, Valid Loss: 93.1048
Epoch [21301/30000], Step [1/1], Training Loss: 133.3454, Valid Loss: 96.3333
Epoch [21401/30000], Step [1/1], Training Loss: 107.2777, Valid Loss: 98.8381
Epoch [21501/30000], Step [1/1], Training Loss: 86.5177, Valid Loss: 104.4476
Epoch [21601/30000], Step [1/1], Training Loss: 73.0657, Valid Loss: 100.5429
Epoch [21701/30000], Step [1/1], Training Loss: 59.6234, Valid Loss: 96.4095
Epoch [21801/30000], Step [1/1], Training Loss: 54.2818, Valid Loss: 99.8286
Epoch [21901/30000], Step [1/1], Training Loss: 44.2616, Valid Loss: 92.3524
Epoch [22001/30000], Step [1/1], Training Loss: 40.6557, Valid Loss: 97.2667
Epoch [22101/30000], Step [1/1], Training Loss: 35.8741, Valid Loss: 94.3238
Epoch [22201/30000], Step [1/1], Training Loss: 29.8589, Valid Loss: 90.6000
Epoch [22301/30000], Step [1/1], Training Loss: 24.9655, Valid Loss: 94.2952
Epoch [22401/30000], Step [1/1], Training Loss: 23.3185, Valid Loss: 93.7429
Epoch [22501/30000], Step [1/1], Training Loss: 20.5862, Valid Loss: 91.8571
Epoch [22601/30000], Step [1/1], Training Loss: 25.2947, Valid Loss: 91.8381
Epoch [22701/30000], Step [1/1], Training Loss: 16.5107, Valid Loss: 92.3143
Epoch [22801/30000], Step [1/1], Training Loss: 13.8887, Valid Loss: 92.4857
Epoch [22901/30000], Step [1/1], Training Loss: 11.5459, Valid Loss: 103.9714
Epoch [23001/30000], Step [1/1], Training Loss: 11.8854, Valid Loss: 107.2095
Epoch [23101/30000], Step [1/1], Training Loss: 6.7154, Valid Loss: 94.2571
Epoch [23201/30000], Step [1/1], Training Loss: 7.6497, Valid Loss: 105.5524
Epoch [23301/30000], Step [1/1], Training Loss: 6.6740, Valid Loss: 101.1048
Epoch [23401/30000], Step [1/1], Training Loss: 5.5709, Valid Loss: 105.2476
Epoch [23501/30000], Step [1/1], Training Loss: 5.0251, Valid Loss: 107.4095
Epoch [23601/30000], Step [1/1], Training Loss: 4.4751, Valid Loss: 101.3524
Epoch [23701/30000], Step [1/1], Training Loss: 4.7320, Valid Loss: 106.1238
Epoch [23801/30000], Step [1/1], Training Loss: 3.5473, Valid Loss: 111.3048
Epoch [23901/30000], Step [1/1], Training Loss: 3.0095, Valid Loss: 106.6000
Epoch [24001/30000], Step [1/1], Training Loss: 3.8166, Valid Loss: 109.2571
Epoch [24101/30000], Step [1/1], Training Loss: 2.7086, Valid Loss: 104.8857
Epoch [24201/30000], Step [1/1], Training Loss: 2.3215, Valid Loss: 109.6857
Epoch [24301/30000], Step [1/1], Training Loss: 2.0249, Valid Loss: 107.6381
Epoch [24401/30000], Step [1/1], Training Loss: 1.5321, Valid Loss: 111.3619
Epoch [24501/30000], Step [1/1], Training Loss: 1.5265, Valid Loss: 108.6952
Epoch [24601/30000], Step [1/1], Training Loss: 1.7680, Valid Loss: 103.0857
Epoch [24701/30000], Step [1/1], Training Loss: 1.7925, Valid Loss: 110.2571
Epoch [24801/30000], Step [1/1], Training Loss: 1.4221, Valid Loss: 106.2286
Epoch [24901/30000], Step [1/1], Training Loss: 0.8577, Valid Loss: 111.2095
Epoch [25001/30000], Step [1/1], Training Loss: 1.0850, Valid Loss: 109.1810
Epoch [25101/30000], Step [1/1], Training Loss: 1.2680, Valid Loss: 104.9714
Epoch [25201/30000], Step [1/1], Training Loss: 1.2748, Valid Loss: 107.7333
Epoch [25301/30000], Step [1/1], Training Loss: 1.3990, Valid Loss: 113.2667
Epoch [25401/30000], Step [1/1], Training Loss: 1.5556, Valid Loss: 117.0191
Epoch [25501/30000], Step [1/1], Training Loss: 1.2281, Valid Loss: 122.1238
Epoch [25601/30000], Step [1/1], Training Loss: 1.3052, Valid Loss: 120.2762
Epoch [25701/30000], Step [1/1], Training Loss: 0.8949, Valid Loss: 115.9524
Epoch [25801/30000], Step [1/1], Training Loss: 0.9017, Valid Loss: 101.0000
Epoch [25901/30000], Step [1/1], Training Loss: 1.2996, Valid Loss: 124.4571
Epoch [26001/30000], Step [1/1], Training Loss: 1.1087, Valid Loss: 120.6286
Epoch [26101/30000], Step [1/1], Training Loss: 0.6082, Valid Loss: 123.3619
Epoch [26201/30000], Step [1/1], Training Loss: 1.0090, Valid Loss: 109.6952
Epoch [26301/30000], Step [1/1], Training Loss: 0.7666, Valid Loss: 116.6286
Epoch [26401/30000], Step [1/1], Training Loss: 1.0485, Valid Loss: 122.9143
Epoch [26501/30000], Step [1/1], Training Loss: 0.8435, Valid Loss: 119.0667
Epoch [26601/30000], Step [1/1], Training Loss: 0.7241, Valid Loss: 125.6952
Epoch [26701/30000], Step [1/1], Training Loss: 1.2397, Valid Loss: 124.2667
Epoch [26801/30000], Step [1/1], Training Loss: 0.6912, Valid Loss: 123.7048
Epoch [26901/30000], Step [1/1], Training Loss: 0.7806, Valid Loss: 124.6572
Epoch [27001/30000], Step [1/1], Training Loss: 0.5923, Valid Loss: 119.9143
Epoch [27101/30000], Step [1/1], Training Loss: 1.7182, Valid Loss: 139.7810
Epoch [27201/30000], Step [1/1], Training Loss: 1.2272, Valid Loss: 117.1333
Epoch [27301/30000], Step [1/1], Training Loss: 1.1508, Valid Loss: 119.4000
Epoch [27401/30000], Step [1/1], Training Loss: 0.5792, Valid Loss: 133.6667
Epoch [27501/30000], Step [1/1], Training Loss: 0.6757, Valid Loss: 119.2667
Epoch [27601/30000], Step [1/1], Training Loss: 0.8850, Valid Loss: 113.9048
Epoch [27701/30000], Step [1/1], Training Loss: 0.6819, Valid Loss: 121.7048
Epoch [27801/30000], Step [1/1], Training Loss: 0.7935, Valid Loss: 122.7238
Epoch [27901/30000], Step [1/1], Training Loss: 0.6134, Valid Loss: 125.4000
Epoch [28001/30000], Step [1/1], Training Loss: 0.5403, Valid Loss: 132.9048
Epoch [28101/30000], Step [1/1], Training Loss: 1.2900, Valid Loss: 120.2476
Epoch [28201/30000], Step [1/1], Training Loss: 0.8571, Valid Loss: 131.6476
Epoch [28301/30000], Step [1/1], Training Loss: 0.6635, Valid Loss: 130.5905
Epoch [28401/30000], Step [1/1], Training Loss: 0.5427, Valid Loss: 132.2857
Epoch [28501/30000], Step [1/1], Training Loss: 0.9777, Valid Loss: 141.4381
Epoch [28601/30000], Step [1/1], Training Loss: 0.4605, Valid Loss: 131.5238
Epoch [28701/30000], Step [1/1], Training Loss: 0.5583, Valid Loss: 134.2952
Epoch [28801/30000], Step [1/1], Training Loss: 0.6527, Valid Loss: 134.8762
Epoch [28901/30000], Step [1/1], Training Loss: 0.6167, Valid Loss: 123.2571
Epoch [29001/30000], Step [1/1], Training Loss: 0.3989, Valid Loss: 138.1524
Epoch [29101/30000], Step [1/1], Training Loss: 0.4982, Valid Loss: 132.5905
Epoch [29201/30000], Step [1/1], Training Loss: 0.4903, Valid Loss: 131.1333
Epoch [29301/30000], Step [1/1], Training Loss: 0.3881, Valid Loss: 129.5714
Epoch [29401/30000], Step [1/1], Training Loss: 0.4519, Valid Loss: 136.3333
Epoch [29501/30000], Step [1/1], Training Loss: 4627.9067, Valid Loss: 93.0857
Epoch [29601/30000], Step [1/1], Training Loss: 490.5443, Valid Loss: 139.2476
Epoch [29701/30000], Step [1/1], Training Loss: 226.4009, Valid Loss: 130.0476
Epoch [29801/30000], Step [1/1], Training Loss: 113.9286, Valid Loss: 140.6857
Epoch [29901/30000], Step [1/1], Training Loss: 70.1608, Valid Loss: 154.0095

 End Time: 2021/04/20, 03:28:50
