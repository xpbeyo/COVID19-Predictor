



##########################################################

Epochs=30000 	batch=245 	lr=0.0003
window=2 	seq_len=7 	hidden_size=512 	layers=3

Start Time = 2021/04/19, 02:06:01
##########################################################


[Epoch 0] Rounded prediction: 
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([ 7., 15., 15., 16., 16., 16., 15., 14., 14., 14., 17., 17., 12., 16.,
        19., 15., 12.,  2., 17., 18.,  0., 19., 24., 17.,  0.,  0.,  7., 28.,
        24., 32., 34.,  6.,  0., 20.,  9.,  0., 22., 11.,  6., 30.,  0., 60.,
        36., 30.,  0., 11., 18., 25.,  0., 10.,  0.,  6., 18., 18., 41.,  0.,
        16., 15.,  0., 17., 26., 27.,  0., 18., 18., 18., 16., 29.,  0., 24.,
         2., 15.,  0., 18., 18., 24., 25., 60.,  7.,  0., 36., 28., 64., 60.,
        24., 10., 19., 11., 20., 19., 41., 80., 80., 63., 63., 60., 62., 50.,
        48., 47., 47., 44., 33., 34., 50.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([ 13.,  23.,  19.,  22.,  21.,  25.,  20.,  18.,  18.,  20.,  24.,  22.,
         16.,  16.,  24.,  22.,  36.,   0.,   1.,  34.,   4.,  54.,   9.,  18.,
         46.,  42.,  45.,  61.,  54.,  65.,  73.,   0.,  40.,  70.,  53.,   0.,
         48.,   4.,  43.,  60.,  14.,  70.,   0.,  51.,   0.,  37.,   0.,  52.,
          0.,   0.,   0.,  34.,  51.,  41.,  78.,  42.,  49.,  31.,  38.,  57.,
          5.,  60.,  39.,  48.,  37.,   0.,  40.,  45.,  51.,   0.,   0.,  31.,
         34.,  36.,  32.,  38.,  44.,  73.,  48.,  51.,  63.,  40.,  73.,  60.,
         36.,  36.,  24.,  12.,  23.,  31.,  48.,  94., 106.,  93.,  77.,  59.,
         42.,  39.,  47.,  40.,  53.,  64.,  28.,  24.,  42.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128582.2969, Valid Loss: 215.8286
Epoch [101/30000], Step [1/1], Training Loss: 116603.4531, Valid Loss: 317.3524
Epoch [201/30000], Step [1/1], Training Loss: 110283.6875, Valid Loss: 990.9238
Epoch [301/30000], Step [1/1], Training Loss: 104570.2734, Valid Loss: 2114.4954
Epoch [401/30000], Step [1/1], Training Loss: 99347.2578, Valid Loss: 876.0953
Epoch [501/30000], Step [1/1], Training Loss: 94052.5312, Valid Loss: 120.3238
Epoch [601/30000], Step [1/1], Training Loss: 89248.3359, Valid Loss: 113.6095
Epoch [701/30000], Step [1/1], Training Loss: 84782.0156, Valid Loss: 121.4286
Epoch [801/30000], Step [1/1], Training Loss: 80499.4297, Valid Loss: 115.9048
Epoch [901/30000], Step [1/1], Training Loss: 76500.3281, Valid Loss: 108.7714
Epoch [1001/30000], Step [1/1], Training Loss: 72719.8125, Valid Loss: 93.0667
Epoch [1101/30000], Step [1/1], Training Loss: 69316.0391, Valid Loss: 95.0286
Epoch [1201/30000], Step [1/1], Training Loss: 66053.5312, Valid Loss: 96.5524
Epoch [1301/30000], Step [1/1], Training Loss: 62997.5664, Valid Loss: 103.2667
Epoch [1401/30000], Step [1/1], Training Loss: 60171.9570, Valid Loss: 96.1905
Epoch [1501/30000], Step [1/1], Training Loss: 57496.3203, Valid Loss: 106.0095
Epoch [1601/30000], Step [1/1], Training Loss: 55410.5039, Valid Loss: 100.3714
Epoch [1701/30000], Step [1/1], Training Loss: 52487.7305, Valid Loss: 102.2667
Epoch [1801/30000], Step [1/1], Training Loss: 50016.2188, Valid Loss: 89.2190
Epoch [1901/30000], Step [1/1], Training Loss: 47860.4414, Valid Loss: 83.5524
Epoch [2001/30000], Step [1/1], Training Loss: 45709.6836, Valid Loss: 87.3238
Epoch [2101/30000], Step [1/1], Training Loss: 43859.9180, Valid Loss: 85.7048
Epoch [2201/30000], Step [1/1], Training Loss: 41906.7266, Valid Loss: 97.9810
Epoch [2301/30000], Step [1/1], Training Loss: 40152.5508, Valid Loss: 97.0762
Epoch [2401/30000], Step [1/1], Training Loss: 38502.3203, Valid Loss: 95.8571
Epoch [2501/30000], Step [1/1], Training Loss: 36953.0586, Valid Loss: 85.8857
Epoch [2601/30000], Step [1/1], Training Loss: 35484.5117, Valid Loss: 101.1905
Epoch [2701/30000], Step [1/1], Training Loss: 33891.0273, Valid Loss: 98.2762
Epoch [2801/30000], Step [1/1], Training Loss: 32558.2285, Valid Loss: 96.8952
Epoch [2901/30000], Step [1/1], Training Loss: 30935.8242, Valid Loss: 91.6286
Epoch [3001/30000], Step [1/1], Training Loss: 30115.0723, Valid Loss: 134.7905
Epoch [3101/30000], Step [1/1], Training Loss: 28393.7598, Valid Loss: 125.9333
Epoch [3201/30000], Step [1/1], Training Loss: 27033.7715, Valid Loss: 118.9048
Epoch [3301/30000], Step [1/1], Training Loss: 25643.1621, Valid Loss: 118.6000
Epoch [3401/30000], Step [1/1], Training Loss: 24539.1445, Valid Loss: 139.4286
Epoch [3501/30000], Step [1/1], Training Loss: 23317.7949, Valid Loss: 158.1810
Epoch [3601/30000], Step [1/1], Training Loss: 22241.4355, Valid Loss: 120.5238
Epoch [3701/30000], Step [1/1], Training Loss: 21230.3027, Valid Loss: 150.7619
Epoch [3801/30000], Step [1/1], Training Loss: 20309.3770, Valid Loss: 120.7238
Epoch [3901/30000], Step [1/1], Training Loss: 19395.8125, Valid Loss: 139.8190
Epoch [4001/30000], Step [1/1], Training Loss: 18602.2461, Valid Loss: 166.7429
Epoch [4101/30000], Step [1/1], Training Loss: 17820.7812, Valid Loss: 170.3524
Epoch [4201/30000], Step [1/1], Training Loss: 17107.6660, Valid Loss: 179.6667
Epoch [4301/30000], Step [1/1], Training Loss: 16621.1582, Valid Loss: 138.4381
Epoch [4401/30000], Step [1/1], Training Loss: 17030.6797, Valid Loss: 244.2000
Epoch [4501/30000], Step [1/1], Training Loss: 15328.7441, Valid Loss: 192.6000
Epoch [4601/30000], Step [1/1], Training Loss: 14524.1611, Valid Loss: 244.5143
Epoch [4701/30000], Step [1/1], Training Loss: 13929.0146, Valid Loss: 307.9048
Epoch [4801/30000], Step [1/1], Training Loss: 12962.8252, Valid Loss: 300.4476
Epoch [4901/30000], Step [1/1], Training Loss: 12386.9883, Valid Loss: 234.2476
Epoch [5001/30000], Step [1/1], Training Loss: 11837.7041, Valid Loss: 322.4572
Epoch [5101/30000], Step [1/1], Training Loss: 11366.5527, Valid Loss: 357.1810
Epoch [5201/30000], Step [1/1], Training Loss: 10894.7812, Valid Loss: 335.1905
Epoch [5301/30000], Step [1/1], Training Loss: 10587.0449, Valid Loss: 283.8857
Epoch [5401/30000], Step [1/1], Training Loss: 9961.7676, Valid Loss: 344.4095
Epoch [5501/30000], Step [1/1], Training Loss: 9543.5596, Valid Loss: 354.2572
Epoch [5601/30000], Step [1/1], Training Loss: 9124.6777, Valid Loss: 341.8095
Epoch [5701/30000], Step [1/1], Training Loss: 8748.3516, Valid Loss: 437.6762
Epoch [5801/30000], Step [1/1], Training Loss: 8484.1260, Valid Loss: 391.7333
Epoch [5901/30000], Step [1/1], Training Loss: 8125.1123, Valid Loss: 425.8000
Epoch [6001/30000], Step [1/1], Training Loss: 7808.7822, Valid Loss: 356.1810
Epoch [6101/30000], Step [1/1], Training Loss: 7552.8931, Valid Loss: 380.9238
Epoch [6201/30000], Step [1/1], Training Loss: 7241.9956, Valid Loss: 437.1334
Epoch [6301/30000], Step [1/1], Training Loss: 7101.8037, Valid Loss: 442.8667
Epoch [6401/30000], Step [1/1], Training Loss: 6757.5703, Valid Loss: 475.3429
Epoch [6501/30000], Step [1/1], Training Loss: 6536.3286, Valid Loss: 486.0857
Epoch [6601/30000], Step [1/1], Training Loss: 10791.8340, Valid Loss: 693.8000
Epoch [6701/30000], Step [1/1], Training Loss: 5813.2944, Valid Loss: 179.6572
Epoch [6801/30000], Step [1/1], Training Loss: 6715.9253, Valid Loss: 297.1619
Epoch [6901/30000], Step [1/1], Training Loss: 5421.2510, Valid Loss: 461.0191
Epoch [7001/30000], Step [1/1], Training Loss: 4754.5234, Valid Loss: 523.3429
Epoch [7101/30000], Step [1/1], Training Loss: 4515.0498, Valid Loss: 387.7524
Epoch [7201/30000], Step [1/1], Training Loss: 4452.3662, Valid Loss: 501.6000
Epoch [7301/30000], Step [1/1], Training Loss: 4525.5918, Valid Loss: 352.0572
Epoch [7401/30000], Step [1/1], Training Loss: 4294.1069, Valid Loss: 484.2667
Epoch [7501/30000], Step [1/1], Training Loss: 5063.2007, Valid Loss: 565.9714
Epoch [7601/30000], Step [1/1], Training Loss: 4855.4702, Valid Loss: 391.2953
Epoch [7701/30000], Step [1/1], Training Loss: 4749.7900, Valid Loss: 421.6095
Epoch [7801/30000], Step [1/1], Training Loss: 4386.4927, Valid Loss: 564.6286
Epoch [7901/30000], Step [1/1], Training Loss: 3975.2947, Valid Loss: 481.0476
Epoch [8001/30000], Step [1/1], Training Loss: 3439.8198, Valid Loss: 552.4381
Epoch [8101/30000], Step [1/1], Training Loss: 3306.2820, Valid Loss: 575.7238
Epoch [8201/30000], Step [1/1], Training Loss: 4385.2427, Valid Loss: 635.0286
Epoch [8301/30000], Step [1/1], Training Loss: 2726.9055, Valid Loss: 509.8095
Epoch [8401/30000], Step [1/1], Training Loss: 2589.2847, Valid Loss: 567.6857
Epoch [8501/30000], Step [1/1], Training Loss: 3028.8787, Valid Loss: 517.5048
Epoch [8601/30000], Step [1/1], Training Loss: 2574.0935, Valid Loss: 838.2477
Epoch [8701/30000], Step [1/1], Training Loss: 2437.5876, Valid Loss: 779.5143
Epoch [8801/30000], Step [1/1], Training Loss: 2194.3635, Valid Loss: 664.9143
Epoch [8901/30000], Step [1/1], Training Loss: 2082.9963, Valid Loss: 770.7238
Epoch [9001/30000], Step [1/1], Training Loss: 1993.6848, Valid Loss: 801.7429
Epoch [9101/30000], Step [1/1], Training Loss: 1892.8567, Valid Loss: 882.7810
Epoch [9201/30000], Step [1/1], Training Loss: 1651.1842, Valid Loss: 1080.7715
Epoch [9301/30000], Step [1/1], Training Loss: 1570.9080, Valid Loss: 980.0096
Epoch [9401/30000], Step [1/1], Training Loss: 1506.7120, Valid Loss: 986.3143
Epoch [9501/30000], Step [1/1], Training Loss: 1440.5873, Valid Loss: 918.2572
Epoch [9601/30000], Step [1/1], Training Loss: 1383.0825, Valid Loss: 1005.1524
Epoch [9701/30000], Step [1/1], Training Loss: 1325.1777, Valid Loss: 1109.0095
Epoch [9801/30000], Step [1/1], Training Loss: 1268.6128, Valid Loss: 1042.4191
Epoch [9901/30000], Step [1/1], Training Loss: 1220.1381, Valid Loss: 1188.5715
Epoch [10001/30000], Step [1/1], Training Loss: 1172.4404, Valid Loss: 1071.0381
Epoch [10101/30000], Step [1/1], Training Loss: 1127.7068, Valid Loss: 1195.2858

[Epoch 15000] Rounded prediction: 
tensor([18., 23., 17., 20., 19., 19., 21., 15., 19., 17., 16., 20., 21., 23.,
        21., 21., 22., 28., 26., 30., 43., 42.,  0., 19., 27., 28.,  7., 41.,
        34., 40., 64., 21., 28., 48., 39., 43., 35., 41., 27., 34., 63., 70.,
        65., 42.,  2., 15.,  0., 20., 35., 23., 31., 20., 47.,  4., 66., 42.,
        10., 38., 40., 37., 16., 45., 10., 34.,  0., 43., 42.,  0., 26., 33.,
         0., 26., 31., 31., 27.,  0., 47., 59., 50., 35., 33., 38., 42., 65.,
        33., 21., 15.,  7., 10., 22., 43., 88., 61., 77., 71., 32., 49., 54.,
        49., 45., 27., 52., 44., 35., 32.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([ 12.,  17.,  10.,  15.,  13.,  12.,  16.,  10.,  11.,   0.,   5.,  13.,
         12.,  15.,  10.,  21.,  14.,  14.,  21.,  20.,  32.,  39.,  36.,  48.,
         36.,  27.,  33.,  47.,   0.,  40.,  71.,  29.,  28.,  46.,  42.,  46.,
         38.,  14.,  32.,  46.,  73., 112.,  56.,  57.,  36.,  29.,   0.,  39.,
         31.,  29.,   0.,   0.,  28.,  21.,  63.,  38.,   0.,  34.,  36.,  37.,
         36.,  25.,   0.,   0.,   0.,  39.,   0.,   2.,  17.,  10.,   9.,  29.,
         18.,  28.,  17.,  32.,  31.,  28.,  37.,  39.,  34.,  37.,  72.,  55.,
         39.,  33.,   7.,   9.,  12.,   6.,  35.,  91., 120., 118.,  92.,  24.,
         35.,  47.,  69.,  47.,  46.,  80.,  42.,  25.,  49.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [10201/30000], Step [1/1], Training Loss: 1081.0583, Valid Loss: 1022.8857
Epoch [10301/30000], Step [1/1], Training Loss: 1041.6423, Valid Loss: 1058.1049
Epoch [10401/30000], Step [1/1], Training Loss: 996.3972, Valid Loss: 1008.0286
Epoch [10501/30000], Step [1/1], Training Loss: 957.5484, Valid Loss: 1140.8191
Epoch [10601/30000], Step [1/1], Training Loss: 920.3116, Valid Loss: 1055.6477
Epoch [10701/30000], Step [1/1], Training Loss: 880.7097, Valid Loss: 1253.9524
Epoch [10801/30000], Step [1/1], Training Loss: 843.8553, Valid Loss: 1063.5048
Epoch [10901/30000], Step [1/1], Training Loss: 804.6219, Valid Loss: 1116.6001
Epoch [11001/30000], Step [1/1], Training Loss: 774.1055, Valid Loss: 937.2953
Epoch [11101/30000], Step [1/1], Training Loss: 741.5476, Valid Loss: 1176.5048
Epoch [11201/30000], Step [1/1], Training Loss: 712.0038, Valid Loss: 1215.6477
Epoch [11301/30000], Step [1/1], Training Loss: 701.4996, Valid Loss: 1194.6191
Epoch [11401/30000], Step [1/1], Training Loss: 2775.8735, Valid Loss: 875.1714
Epoch [11501/30000], Step [1/1], Training Loss: 1440.1748, Valid Loss: 659.6476
Epoch [11601/30000], Step [1/1], Training Loss: 5256.0767, Valid Loss: 769.5239
Epoch [11701/30000], Step [1/1], Training Loss: 790.5438, Valid Loss: 714.9048
Epoch [11801/30000], Step [1/1], Training Loss: 676.0711, Valid Loss: 842.3619
Epoch [11901/30000], Step [1/1], Training Loss: 1703.9033, Valid Loss: 672.6953
Epoch [12001/30000], Step [1/1], Training Loss: 564.7034, Valid Loss: 685.7429
Epoch [12101/30000], Step [1/1], Training Loss: 522.5136, Valid Loss: 595.7809
Epoch [12201/30000], Step [1/1], Training Loss: 495.9408, Valid Loss: 762.3810
Epoch [12301/30000], Step [1/1], Training Loss: 471.3671, Valid Loss: 778.8572
Epoch [12401/30000], Step [1/1], Training Loss: 451.4133, Valid Loss: 866.8762
Epoch [12501/30000], Step [1/1], Training Loss: 430.9172, Valid Loss: 788.9905
Epoch [12601/30000], Step [1/1], Training Loss: 414.7592, Valid Loss: 757.3619
Epoch [12701/30000], Step [1/1], Training Loss: 399.9916, Valid Loss: 758.7238
Epoch [12801/30000], Step [1/1], Training Loss: 385.0274, Valid Loss: 681.5620
Epoch [12901/30000], Step [1/1], Training Loss: 366.8028, Valid Loss: 794.9714
Epoch [13001/30000], Step [1/1], Training Loss: 355.4116, Valid Loss: 901.1048
Epoch [13101/30000], Step [1/1], Training Loss: 334.1502, Valid Loss: 746.7333
Epoch [13201/30000], Step [1/1], Training Loss: 377.3219, Valid Loss: 902.9238
Epoch [13301/30000], Step [1/1], Training Loss: 307.5648, Valid Loss: 1008.4858
Epoch [13401/30000], Step [1/1], Training Loss: 290.9725, Valid Loss: 1125.6001
Epoch [13501/30000], Step [1/1], Training Loss: 274.1169, Valid Loss: 1231.6858
Epoch [13601/30000], Step [1/1], Training Loss: 258.4258, Valid Loss: 890.7238
Epoch [13701/30000], Step [1/1], Training Loss: 245.3564, Valid Loss: 1149.4095
Epoch [13801/30000], Step [1/1], Training Loss: 229.5021, Valid Loss: 1022.5715
Epoch [13901/30000], Step [1/1], Training Loss: 214.5450, Valid Loss: 998.4858
Epoch [14001/30000], Step [1/1], Training Loss: 201.3223, Valid Loss: 1086.5143
Epoch [14101/30000], Step [1/1], Training Loss: 188.8320, Valid Loss: 1021.4858
Epoch [14201/30000], Step [1/1], Training Loss: 176.5364, Valid Loss: 1038.1144
Epoch [14301/30000], Step [1/1], Training Loss: 163.7931, Valid Loss: 974.6953
Epoch [14401/30000], Step [1/1], Training Loss: 151.7032, Valid Loss: 1156.6667
Epoch [14501/30000], Step [1/1], Training Loss: 140.5862, Valid Loss: 952.2382
Epoch [14601/30000], Step [1/1], Training Loss: 2080.5488, Valid Loss: 1223.8381
Epoch [14701/30000], Step [1/1], Training Loss: 162.0860, Valid Loss: 723.0477
Epoch [14801/30000], Step [1/1], Training Loss: 125.2558, Valid Loss: 635.1048
Epoch [14901/30000], Step [1/1], Training Loss: 124.4727, Valid Loss: 743.2191
Epoch [15001/30000], Step [1/1], Training Loss: 111.3975, Valid Loss: 688.6857
Epoch [15101/30000], Step [1/1], Training Loss: 104.1787, Valid Loss: 699.3810
Epoch [15201/30000], Step [1/1], Training Loss: 95.2668, Valid Loss: 780.8381
Epoch [15301/30000], Step [1/1], Training Loss: 90.3359, Valid Loss: 743.1429
Epoch [15401/30000], Step [1/1], Training Loss: 83.9335, Valid Loss: 745.5620
Epoch [15501/30000], Step [1/1], Training Loss: 77.8662, Valid Loss: 673.2000
Epoch [15601/30000], Step [1/1], Training Loss: 72.6358, Valid Loss: 698.1524
Epoch [15701/30000], Step [1/1], Training Loss: 66.6958, Valid Loss: 652.5905
Epoch [15801/30000], Step [1/1], Training Loss: 61.5672, Valid Loss: 696.7715
Epoch [15901/30000], Step [1/1], Training Loss: 56.4762, Valid Loss: 666.6000
Epoch [16001/30000], Step [1/1], Training Loss: 51.3584, Valid Loss: 709.4762
Epoch [16101/30000], Step [1/1], Training Loss: 47.1579, Valid Loss: 729.4667
Epoch [16201/30000], Step [1/1], Training Loss: 43.9424, Valid Loss: 730.6191
Epoch [16301/30000], Step [1/1], Training Loss: 38.8253, Valid Loss: 765.6191
Epoch [16401/30000], Step [1/1], Training Loss: 35.2456, Valid Loss: 717.0381
Epoch [16501/30000], Step [1/1], Training Loss: 31.4769, Valid Loss: 741.8857
Epoch [16601/30000], Step [1/1], Training Loss: 27.8618, Valid Loss: 736.6667
Epoch [16701/30000], Step [1/1], Training Loss: 24.7638, Valid Loss: 753.9048
Epoch [16801/30000], Step [1/1], Training Loss: 21.8016, Valid Loss: 724.0381
Epoch [16901/30000], Step [1/1], Training Loss: 19.2656, Valid Loss: 737.2095
Epoch [17001/30000], Step [1/1], Training Loss: 16.9094, Valid Loss: 745.2381
Epoch [17101/30000], Step [1/1], Training Loss: 15.2673, Valid Loss: 797.4286
Epoch [17201/30000], Step [1/1], Training Loss: 12.7312, Valid Loss: 802.8381
Epoch [17301/30000], Step [1/1], Training Loss: 11.0608, Valid Loss: 852.7715
Epoch [17401/30000], Step [1/1], Training Loss: 9.9484, Valid Loss: 768.4286
Epoch [17501/30000], Step [1/1], Training Loss: 8.2220, Valid Loss: 781.5524
Epoch [17601/30000], Step [1/1], Training Loss: 7.0515, Valid Loss: 946.9810
Epoch [17701/30000], Step [1/1], Training Loss: 6.0483, Valid Loss: 829.1714
Epoch [17801/30000], Step [1/1], Training Loss: 5.1012, Valid Loss: 802.2095
Epoch [17901/30000], Step [1/1], Training Loss: 4.4437, Valid Loss: 840.4857
Epoch [18001/30000], Step [1/1], Training Loss: 1014.1805, Valid Loss: 499.8191
Epoch [18101/30000], Step [1/1], Training Loss: 651.9634, Valid Loss: 610.5143
Epoch [18201/30000], Step [1/1], Training Loss: 545.9745, Valid Loss: 564.1619
Epoch [18301/30000], Step [1/1], Training Loss: 149.9732, Valid Loss: 869.2191
Epoch [18401/30000], Step [1/1], Training Loss: 183.5086, Valid Loss: 849.8953
Epoch [18501/30000], Step [1/1], Training Loss: 287.7666, Valid Loss: 915.6762
Epoch [18601/30000], Step [1/1], Training Loss: 672.2655, Valid Loss: 860.0477
Epoch [18701/30000], Step [1/1], Training Loss: 185.6506, Valid Loss: 858.4667
Epoch [18801/30000], Step [1/1], Training Loss: 46.3007, Valid Loss: 1010.9048
Epoch [18901/30000], Step [1/1], Training Loss: 18.8331, Valid Loss: 931.0572
Epoch [19001/30000], Step [1/1], Training Loss: 13.6891, Valid Loss: 885.2191
Epoch [19101/30000], Step [1/1], Training Loss: 49.9852, Valid Loss: 935.3905
Epoch [19201/30000], Step [1/1], Training Loss: 23.6086, Valid Loss: 961.4763
Epoch [19301/30000], Step [1/1], Training Loss: 9.3105, Valid Loss: 830.7524
Epoch [19401/30000], Step [1/1], Training Loss: 7.9709, Valid Loss: 877.5239
Epoch [19501/30000], Step [1/1], Training Loss: 9.5241, Valid Loss: 897.5620
Epoch [19601/30000], Step [1/1], Training Loss: 7.2548, Valid Loss: 863.3143
Epoch [19701/30000], Step [1/1], Training Loss: 6.1453, Valid Loss: 843.1619
Epoch [19801/30000], Step [1/1], Training Loss: 5.1601, Valid Loss: 802.9238
Epoch [19901/30000], Step [1/1], Training Loss: 5.7968, Valid Loss: 813.2953
Epoch [20001/30000], Step [1/1], Training Loss: 5.9076, Valid Loss: 934.3048
Epoch [20101/30000], Step [1/1], Training Loss: 8.8509, Valid Loss: 851.7143
Epoch [20201/30000], Step [1/1], Training Loss: 10.7746, Valid Loss: 966.0572
Epoch [20301/30000], Step [1/1], Training Loss: 6.5524, Valid Loss: 761.4572
Epoch [20401/30000], Step [1/1], Training Loss: 7.0194, Valid Loss: 986.9429

[Epoch 25000] Rounded prediction: 
tensor([ 11.,  17.,  15.,  16.,  17.,  11.,  14.,  11.,  10.,  10.,  10.,   6.,
         11.,  10.,  10.,  13.,  12.,  22.,  13.,  21.,  12.,  24.,  26.,  45.,
          0.,  21.,  39.,  33.,  33.,  43.,  17.,  21.,   3.,  36.,  51.,  34.,
         20.,  31.,  16.,  37.,  20.,  98.,  77.,  59.,   0.,  21.,  31.,  33.,
         30.,  13.,  19.,  23.,   0.,  27.,  74.,   0.,   0.,  11.,  20.,  27.,
         27.,   0.,   0.,  29.,   0.,  10.,   2.,  22.,  34.,  28.,  12.,  23.,
         28.,  21.,  19.,  23.,  39.,  65.,  22.,  30.,  39.,  32.,  85.,  73.,
         20.,  34.,  18.,   6.,  17.,  23.,  41.,  95., 102.,  97.,  87.,  53.,
         69.,  67.,  87.,  46.,  43.,  87.,  41.,  12.,  47.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [20501/30000], Step [1/1], Training Loss: 6.2375, Valid Loss: 736.2191
Epoch [20601/30000], Step [1/1], Training Loss: 28.5527, Valid Loss: 859.3334
Epoch [20701/30000], Step [1/1], Training Loss: 4.0155, Valid Loss: 832.5429
Epoch [20801/30000], Step [1/1], Training Loss: 3.9712, Valid Loss: 890.3334
Epoch [20901/30000], Step [1/1], Training Loss: 405.7215, Valid Loss: 707.7619
Epoch [21001/30000], Step [1/1], Training Loss: 23.5359, Valid Loss: 523.9619
Epoch [21101/30000], Step [1/1], Training Loss: 15.2926, Valid Loss: 603.6857
Epoch [21201/30000], Step [1/1], Training Loss: 8.4416, Valid Loss: 603.0190
Epoch [21301/30000], Step [1/1], Training Loss: 8.0539, Valid Loss: 559.3334
Epoch [21401/30000], Step [1/1], Training Loss: 6.6776, Valid Loss: 615.8000
Epoch [21501/30000], Step [1/1], Training Loss: 9.6175, Valid Loss: 557.3810
Epoch [21601/30000], Step [1/1], Training Loss: 7.9208, Valid Loss: 616.5620
Epoch [21701/30000], Step [1/1], Training Loss: 3.6687, Valid Loss: 649.7905
Epoch [21801/30000], Step [1/1], Training Loss: 4.3291, Valid Loss: 625.5715
Epoch [21901/30000], Step [1/1], Training Loss: 4.3097, Valid Loss: 666.2381
Epoch [22001/30000], Step [1/1], Training Loss: 2.9572, Valid Loss: 616.9810
Epoch [22101/30000], Step [1/1], Training Loss: 6.1162, Valid Loss: 618.7714
Epoch [22201/30000], Step [1/1], Training Loss: 7.0499, Valid Loss: 601.5620
Epoch [22301/30000], Step [1/1], Training Loss: 3.4383, Valid Loss: 541.8667
Epoch [22401/30000], Step [1/1], Training Loss: 2.6888, Valid Loss: 649.5048
Epoch [22501/30000], Step [1/1], Training Loss: 2.8178, Valid Loss: 617.8857
Epoch [22601/30000], Step [1/1], Training Loss: 2.3675, Valid Loss: 718.0000
Epoch [22701/30000], Step [1/1], Training Loss: 1.5802, Valid Loss: 704.4762
Epoch [22801/30000], Step [1/1], Training Loss: 1.6937, Valid Loss: 743.1714
Epoch [22901/30000], Step [1/1], Training Loss: 1.5885, Valid Loss: 704.5524
Epoch [23001/30000], Step [1/1], Training Loss: 1.8851, Valid Loss: 671.1238
Epoch [23101/30000], Step [1/1], Training Loss: 11.2093, Valid Loss: 740.0286
Epoch [23201/30000], Step [1/1], Training Loss: 1.4979, Valid Loss: 732.0477
Epoch [23301/30000], Step [1/1], Training Loss: 1.1704, Valid Loss: 668.5905
Epoch [23401/30000], Step [1/1], Training Loss: 1.9853, Valid Loss: 628.9048
Epoch [23501/30000], Step [1/1], Training Loss: 4.1511, Valid Loss: 627.6857
Epoch [23601/30000], Step [1/1], Training Loss: 1.1536, Valid Loss: 711.9524
Epoch [23701/30000], Step [1/1], Training Loss: 1.2810, Valid Loss: 703.4762
Epoch [23801/30000], Step [1/1], Training Loss: 1.7203, Valid Loss: 726.0477
Epoch [23901/30000], Step [1/1], Training Loss: 1.5621, Valid Loss: 728.3810
Epoch [24001/30000], Step [1/1], Training Loss: 0.9037, Valid Loss: 808.1905
Epoch [24101/30000], Step [1/1], Training Loss: 3.6318, Valid Loss: 711.4572
Epoch [24201/30000], Step [1/1], Training Loss: 1.7108, Valid Loss: 792.9429
Epoch [24301/30000], Step [1/1], Training Loss: 1.2031, Valid Loss: 709.0000
Epoch [24401/30000], Step [1/1], Training Loss: 0.9455, Valid Loss: 716.7905
Epoch [24501/30000], Step [1/1], Training Loss: 0.9610, Valid Loss: 737.4476
Epoch [24601/30000], Step [1/1], Training Loss: 0.9723, Valid Loss: 851.9048
Epoch [24701/30000], Step [1/1], Training Loss: 0.9232, Valid Loss: 841.0286
Epoch [24801/30000], Step [1/1], Training Loss: 1.6862, Valid Loss: 853.6381
Epoch [24901/30000], Step [1/1], Training Loss: 2.4133, Valid Loss: 940.7524
Epoch [25001/30000], Step [1/1], Training Loss: 0.9325, Valid Loss: 819.0953
Epoch [25101/30000], Step [1/1], Training Loss: 1.4915, Valid Loss: 769.3429
Epoch [25201/30000], Step [1/1], Training Loss: 1054.7191, Valid Loss: 1216.5428
Epoch [25301/30000], Step [1/1], Training Loss: 89.0361, Valid Loss: 1282.4952
Epoch [25401/30000], Step [1/1], Training Loss: 58.2986, Valid Loss: 1055.6191
Epoch [25501/30000], Step [1/1], Training Loss: 68.4040, Valid Loss: 1100.9714
Epoch [25601/30000], Step [1/1], Training Loss: 61.5229, Valid Loss: 1116.3239
Epoch [25701/30000], Step [1/1], Training Loss: 54.3610, Valid Loss: 1088.1715
Epoch [25801/30000], Step [1/1], Training Loss: 66.5127, Valid Loss: 1093.1620
Epoch [25901/30000], Step [1/1], Training Loss: 55.0681, Valid Loss: 1273.8953
Epoch [26001/30000], Step [1/1], Training Loss: 55.9767, Valid Loss: 1292.0000
Epoch [26101/30000], Step [1/1], Training Loss: 56.3022, Valid Loss: 1138.4667
Epoch [26201/30000], Step [1/1], Training Loss: 66.3163, Valid Loss: 1145.4381
Epoch [26301/30000], Step [1/1], Training Loss: 56.9730, Valid Loss: 1130.8762
Epoch [26401/30000], Step [1/1], Training Loss: 56.6029, Valid Loss: 1235.4191
Epoch [26501/30000], Step [1/1], Training Loss: 57.3657, Valid Loss: 1193.6287
Epoch [26601/30000], Step [1/1], Training Loss: 59.5259, Valid Loss: 1277.0476
Epoch [26701/30000], Step [1/1], Training Loss: 57.8732, Valid Loss: 1092.6763
Epoch [26801/30000], Step [1/1], Training Loss: 60.0837, Valid Loss: 1230.8191
Epoch [26901/30000], Step [1/1], Training Loss: 48.8007, Valid Loss: 1215.8953
Epoch [27001/30000], Step [1/1], Training Loss: 52.8284, Valid Loss: 1209.6382
Epoch [27101/30000], Step [1/1], Training Loss: 56.8956, Valid Loss: 1242.7144
Epoch [27201/30000], Step [1/1], Training Loss: 55.4914, Valid Loss: 1213.8572
Epoch [27301/30000], Step [1/1], Training Loss: 53.4630, Valid Loss: 1211.3239
Epoch [27401/30000], Step [1/1], Training Loss: 55.5553, Valid Loss: 1020.5810
Epoch [27501/30000], Step [1/1], Training Loss: 55.8949, Valid Loss: 1114.3619
Epoch [27601/30000], Step [1/1], Training Loss: 55.5560, Valid Loss: 1282.2096
Epoch [27701/30000], Step [1/1], Training Loss: 55.7339, Valid Loss: 1277.0668
Epoch [27801/30000], Step [1/1], Training Loss: 55.5572, Valid Loss: 1256.1429
Epoch [27901/30000], Step [1/1], Training Loss: 58.1881, Valid Loss: 1138.0286
Epoch [28001/30000], Step [1/1], Training Loss: 55.4315, Valid Loss: 1138.5714
Epoch [28101/30000], Step [1/1], Training Loss: 53.6019, Valid Loss: 1068.8000
Epoch [28201/30000], Step [1/1], Training Loss: 58.2236, Valid Loss: 1184.9048
Epoch [28301/30000], Step [1/1], Training Loss: 291.8516, Valid Loss: 982.7239
Epoch [28401/30000], Step [1/1], Training Loss: 3017.2061, Valid Loss: 1463.8096
Epoch [28501/30000], Step [1/1], Training Loss: 37.5580, Valid Loss: 966.8381
Epoch [28601/30000], Step [1/1], Training Loss: 16.4082, Valid Loss: 1210.0668
Epoch [28701/30000], Step [1/1], Training Loss: 9.5295, Valid Loss: 1138.9524
Epoch [28801/30000], Step [1/1], Training Loss: 59.1082, Valid Loss: 1138.7620
Epoch [28901/30000], Step [1/1], Training Loss: 13.2436, Valid Loss: 1451.1715
Epoch [29001/30000], Step [1/1], Training Loss: 6.2434, Valid Loss: 1313.4286
Epoch [29101/30000], Step [1/1], Training Loss: 5.0393, Valid Loss: 1400.8667
Epoch [29201/30000], Step [1/1], Training Loss: 4.5450, Valid Loss: 1441.6953
Epoch [29301/30000], Step [1/1], Training Loss: 3.6198, Valid Loss: 1212.4476
Epoch [29401/30000], Step [1/1], Training Loss: 3.8925, Valid Loss: 1342.8857
Epoch [29501/30000], Step [1/1], Training Loss: 2.7120, Valid Loss: 1408.9048
Epoch [29601/30000], Step [1/1], Training Loss: 3.2944, Valid Loss: 1291.6096
Epoch [29701/30000], Step [1/1], Training Loss: 2.8614, Valid Loss: 1390.6953
Epoch [29801/30000], Step [1/1], Training Loss: 2.1543, Valid Loss: 1108.8572
Epoch [29901/30000], Step [1/1], Training Loss: 2.1770, Valid Loss: 1277.5048

 End Time: 2021/04/19, 02:14:46




##########################################################

Epochs=30000 	batch=245 	lr=0.0003
window=2 	seq_len=7 	hidden_size=512 	layers=3

Start Time = 2021/04/19, 02:14:46
##########################################################


[Epoch 0] Rounded prediction: 
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([ 16.,  15.,  10.,  15.,  15.,  18.,  20.,  23.,  26.,  20.,  16.,  16.,
         14.,  15.,  17.,  25.,  15.,  16.,  22.,  17.,  17.,  28.,   0.,  30.,
          0.,   0.,   5.,   8.,   0.,  14.,   0.,   7.,  15.,  13.,   0.,   0.,
          8.,   0.,   0.,   0.,   0.,  92.,  16.,  29.,  15.,   3.,   0.,   0.,
          0.,   0.,   0.,   0.,  13.,   0.,  10.,  19.,   0.,   0.,   0.,   0.,
          0.,   0.,   0.,   0.,   4.,   0.,   0.,  13.,   0.,  16.,  12.,   0.,
         12.,   8.,  20.,  22.,  20.,  37.,  12.,  42.,  37.,  29.,  43.,  55.,
         50.,  29.,   3.,   0.,   0.,   9.,  19.,  72., 163.,  99.,  48.,  42.,
         32.,  28.,  25.,  25.,  30.,  38.,  38.,  27.,   4.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([ 17.,  16.,  17.,  16.,  15.,  20.,  22.,  22.,  20.,  19.,  23.,  24.,
         20.,  20.,  22.,  31.,  21.,   7.,  25.,  30.,   0.,  28.,  25.,  12.,
          0.,   0.,   0.,   0.,   0.,  20.,   0.,   0.,   0.,   0.,   0.,   0.,
         15.,   5.,   0.,   0.,  12.,  91.,  15.,  23.,  12.,   1.,   0.,   0.,
          0.,   0.,  32.,   0.,   0.,  12.,  49.,   0.,   0.,  10.,   0.,   0.,
          0.,   1.,   4.,   0.,   0.,   0.,   0.,   0.,  24.,  10.,   0.,   0.,
          0.,   6.,  27.,  23.,  20.,  29.,  40.,  15.,  15.,  16.,  44.,  35.,
         38.,  20.,   0.,   0.,   0.,  11.,  14.,  62., 109.,  89.,  55.,  44.,
         47.,  38.,  31.,  19.,   3.,  31.,  23.,  10.,   2.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128655.6016, Valid Loss: 216.1143
Epoch [101/30000], Step [1/1], Training Loss: 116821.5234, Valid Loss: 317.3524
Epoch [201/30000], Step [1/1], Training Loss: 110483.0625, Valid Loss: 990.9238
Epoch [301/30000], Step [1/1], Training Loss: 104755.0156, Valid Loss: 2025.5906
Epoch [401/30000], Step [1/1], Training Loss: 99519.3438, Valid Loss: 1001.4191
Epoch [501/30000], Step [1/1], Training Loss: 94214.0234, Valid Loss: 114.8000
Epoch [601/30000], Step [1/1], Training Loss: 89439.7500, Valid Loss: 150.6762
Epoch [701/30000], Step [1/1], Training Loss: 84875.5469, Valid Loss: 110.2000
Epoch [801/30000], Step [1/1], Training Loss: 80608.4844, Valid Loss: 158.6190
Epoch [901/30000], Step [1/1], Training Loss: 76749.3672, Valid Loss: 140.3238
Epoch [1001/30000], Step [1/1], Training Loss: 72856.6094, Valid Loss: 120.6286
Epoch [1101/30000], Step [1/1], Training Loss: 69408.8984, Valid Loss: 126.9714
Epoch [1201/30000], Step [1/1], Training Loss: 66006.9141, Valid Loss: 129.1905
Epoch [1301/30000], Step [1/1], Training Loss: 62917.0586, Valid Loss: 128.8857
Epoch [1401/30000], Step [1/1], Training Loss: 60206.6953, Valid Loss: 174.2286
Epoch [1501/30000], Step [1/1], Training Loss: 57362.9414, Valid Loss: 137.5619
Epoch [1601/30000], Step [1/1], Training Loss: 54826.0938, Valid Loss: 154.7333
Epoch [1701/30000], Step [1/1], Training Loss: 52464.2305, Valid Loss: 137.1143
Epoch [1801/30000], Step [1/1], Training Loss: 50306.7891, Valid Loss: 145.8667
Epoch [1901/30000], Step [1/1], Training Loss: 47978.3711, Valid Loss: 109.5524
Epoch [2001/30000], Step [1/1], Training Loss: 45791.0664, Valid Loss: 105.8000
Epoch [2101/30000], Step [1/1], Training Loss: 43743.2969, Valid Loss: 143.4857
Epoch [2201/30000], Step [1/1], Training Loss: 42003.2461, Valid Loss: 110.6857
Epoch [2301/30000], Step [1/1], Training Loss: 40306.8398, Valid Loss: 133.8762
Epoch [2401/30000], Step [1/1], Training Loss: 38314.4766, Valid Loss: 151.6953
Epoch [2501/30000], Step [1/1], Training Loss: 36645.8008, Valid Loss: 144.9429
Epoch [2601/30000], Step [1/1], Training Loss: 35074.9141, Valid Loss: 165.6286
Epoch [2701/30000], Step [1/1], Training Loss: 33568.7969, Valid Loss: 145.5714
Epoch [2801/30000], Step [1/1], Training Loss: 32074.6934, Valid Loss: 159.2191
Epoch [2901/30000], Step [1/1], Training Loss: 31446.6211, Valid Loss: 169.8191
Epoch [3001/30000], Step [1/1], Training Loss: 29435.6855, Valid Loss: 180.2000
Epoch [3101/30000], Step [1/1], Training Loss: 28028.2441, Valid Loss: 218.3238
Epoch [3201/30000], Step [1/1], Training Loss: 26718.3281, Valid Loss: 224.6953
Epoch [3301/30000], Step [1/1], Training Loss: 25531.6348, Valid Loss: 220.6190
Epoch [3401/30000], Step [1/1], Training Loss: 24352.1465, Valid Loss: 202.1143
Epoch [3501/30000], Step [1/1], Training Loss: 23206.8340, Valid Loss: 205.7810
Epoch [3601/30000], Step [1/1], Training Loss: 23088.8320, Valid Loss: 191.5905
Epoch [3701/30000], Step [1/1], Training Loss: 21327.4043, Valid Loss: 216.4191
Epoch [3801/30000], Step [1/1], Training Loss: 20322.6055, Valid Loss: 255.6572
Epoch [3901/30000], Step [1/1], Training Loss: 19410.6816, Valid Loss: 220.2857
Epoch [4001/30000], Step [1/1], Training Loss: 18508.7441, Valid Loss: 249.1238
Epoch [4101/30000], Step [1/1], Training Loss: 17726.4648, Valid Loss: 242.2095
Epoch [4201/30000], Step [1/1], Training Loss: 17011.5547, Valid Loss: 238.0762
Epoch [4301/30000], Step [1/1], Training Loss: 16302.4404, Valid Loss: 254.3143
Epoch [4401/30000], Step [1/1], Training Loss: 15642.5400, Valid Loss: 230.7619
Epoch [4501/30000], Step [1/1], Training Loss: 15100.3203, Valid Loss: 268.6190
Epoch [4601/30000], Step [1/1], Training Loss: 14527.9932, Valid Loss: 323.3333
Epoch [4701/30000], Step [1/1], Training Loss: 16817.9980, Valid Loss: 311.8191
Epoch [4801/30000], Step [1/1], Training Loss: 13735.3418, Valid Loss: 199.5524
Epoch [4901/30000], Step [1/1], Training Loss: 12845.1035, Valid Loss: 334.6286
Epoch [5001/30000], Step [1/1], Training Loss: 12247.8252, Valid Loss: 453.1143
Epoch [5101/30000], Step [1/1], Training Loss: 11865.8037, Valid Loss: 351.3143
Epoch [5201/30000], Step [1/1], Training Loss: 11328.8340, Valid Loss: 408.6381
Epoch [5301/30000], Step [1/1], Training Loss: 11412.1543, Valid Loss: 445.6000
Epoch [5401/30000], Step [1/1], Training Loss: 10698.4639, Valid Loss: 438.5334
Epoch [5501/30000], Step [1/1], Training Loss: 10334.8359, Valid Loss: 456.7143
Epoch [5601/30000], Step [1/1], Training Loss: 10041.0742, Valid Loss: 418.1810
Epoch [5701/30000], Step [1/1], Training Loss: 9740.0713, Valid Loss: 517.2381
Epoch [5801/30000], Step [1/1], Training Loss: 9379.8623, Valid Loss: 430.4000
Epoch [5901/30000], Step [1/1], Training Loss: 9199.4131, Valid Loss: 403.2667
Epoch [6001/30000], Step [1/1], Training Loss: 8880.1045, Valid Loss: 493.4953
Epoch [6101/30000], Step [1/1], Training Loss: 8621.6445, Valid Loss: 456.5810
Epoch [6201/30000], Step [1/1], Training Loss: 8291.3086, Valid Loss: 460.6953
Epoch [6301/30000], Step [1/1], Training Loss: 8951.7109, Valid Loss: 484.2857
Epoch [6401/30000], Step [1/1], Training Loss: 6955.7437, Valid Loss: 389.1619
Epoch [6501/30000], Step [1/1], Training Loss: 6277.6992, Valid Loss: 432.1048
Epoch [6601/30000], Step [1/1], Training Loss: 9100.3203, Valid Loss: 480.0000
Epoch [6701/30000], Step [1/1], Training Loss: 7188.1084, Valid Loss: 448.1429
Epoch [6801/30000], Step [1/1], Training Loss: 7952.6802, Valid Loss: 505.5048
Epoch [6901/30000], Step [1/1], Training Loss: 7766.9590, Valid Loss: 475.2191
Epoch [7001/30000], Step [1/1], Training Loss: 7481.9580, Valid Loss: 498.6667
Epoch [7101/30000], Step [1/1], Training Loss: 7212.1787, Valid Loss: 548.2476
Epoch [7201/30000], Step [1/1], Training Loss: 5990.7095, Valid Loss: 415.5524
Epoch [7301/30000], Step [1/1], Training Loss: 5804.0278, Valid Loss: 408.5810
Epoch [7401/30000], Step [1/1], Training Loss: 5638.2773, Valid Loss: 508.7143
Epoch [7501/30000], Step [1/1], Training Loss: 5504.3408, Valid Loss: 491.9333
Epoch [7601/30000], Step [1/1], Training Loss: 5777.1333, Valid Loss: 389.9619
Epoch [7701/30000], Step [1/1], Training Loss: 3512.8462, Valid Loss: 382.9048
Epoch [7801/30000], Step [1/1], Training Loss: 4034.5686, Valid Loss: 459.9048
Epoch [7901/30000], Step [1/1], Training Loss: 3114.7041, Valid Loss: 377.6667
Epoch [8001/30000], Step [1/1], Training Loss: 4658.0435, Valid Loss: 415.7905
Epoch [8101/30000], Step [1/1], Training Loss: 4479.2788, Valid Loss: 474.7524
Epoch [8201/30000], Step [1/1], Training Loss: 4338.0884, Valid Loss: 410.1714
Epoch [8301/30000], Step [1/1], Training Loss: 4212.9458, Valid Loss: 417.6095
Epoch [8401/30000], Step [1/1], Training Loss: 4104.2446, Valid Loss: 448.1429
Epoch [8501/30000], Step [1/1], Training Loss: 3978.0107, Valid Loss: 443.9238
Epoch [8601/30000], Step [1/1], Training Loss: 3854.6562, Valid Loss: 457.7333
Epoch [8701/30000], Step [1/1], Training Loss: 3796.7390, Valid Loss: 477.5714
Epoch [8801/30000], Step [1/1], Training Loss: 3832.6619, Valid Loss: 443.5524
Epoch [8901/30000], Step [1/1], Training Loss: 3639.9373, Valid Loss: 462.2381
Epoch [9001/30000], Step [1/1], Training Loss: 3541.5391, Valid Loss: 490.0096
Epoch [9101/30000], Step [1/1], Training Loss: 3402.0837, Valid Loss: 482.4953
Epoch [9201/30000], Step [1/1], Training Loss: 3307.4253, Valid Loss: 422.7238
Epoch [9301/30000], Step [1/1], Training Loss: 3269.1350, Valid Loss: 508.2477
Epoch [9401/30000], Step [1/1], Training Loss: 3246.2947, Valid Loss: 427.9238
Epoch [9501/30000], Step [1/1], Training Loss: 3165.7888, Valid Loss: 431.4953
Epoch [9601/30000], Step [1/1], Training Loss: 1462.7939, Valid Loss: 298.5334
Epoch [9701/30000], Step [1/1], Training Loss: 1798.6681, Valid Loss: 262.4572
Epoch [9801/30000], Step [1/1], Training Loss: 1268.7036, Valid Loss: 298.6476
Epoch [9901/30000], Step [1/1], Training Loss: 1196.7339, Valid Loss: 370.2857
Epoch [10001/30000], Step [1/1], Training Loss: 1151.6152, Valid Loss: 359.0191
Epoch [10101/30000], Step [1/1], Training Loss: 1103.0438, Valid Loss: 351.7429

[Epoch 15000] Rounded prediction: 
tensor([ 16.,  13.,   7.,  13.,   7.,  16.,  20.,  11.,  18.,   8.,  13.,  21.,
          0.,  23.,  22.,  31.,  25.,  22.,  33.,  30.,   4.,  26.,  31.,  62.,
         37.,  31.,   0.,   0.,  22.,  14.,  75.,  41.,  10.,   0.,   0.,  16.,
         25.,   0.,   0.,   0.,  23.,  57.,  61.,   0.,  12.,  10.,   0.,   0.,
          0.,   0.,   0.,   4.,   0.,   0., 108.,  63.,  34.,   0.,  14.,   3.,
          9.,   0.,  11.,  13.,   9.,   0.,   0.,   9.,   0.,  32.,  20.,   0.,
          0.,  18.,   2.,  22.,   0., 108.,  58.,  73.,  29.,  39.,  50.,  40.,
         90.,  48.,  15.,   0.,   2.,   4.,  15.,  57., 110., 108.,  77.,  50.,
         56.,  51.,  39.,  41.,  31.,  48.,  61.,  51.,   7.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([ 23.,  19.,  15.,  22.,  17.,  21.,  23.,  16.,  15.,  15.,  21.,  16.,
         23.,  25.,  22.,  29.,  32.,  34.,  33.,  33.,  25.,  30.,  26.,  29.,
         38.,  23.,  13.,   0.,   9.,  25.,  58.,   0.,   0.,   0.,   2.,   0.,
         27.,   6.,   0.,  23.,  35.,  57.,  84.,  21.,   0.,   0.,   0.,   1.,
          0.,  15.,   4.,   5.,  23.,  34.,  39.,  21.,   0.,   0.,  16.,   4.,
          3.,  16.,   0.,   0.,  20.,   0.,   0.,   0.,  41.,  38.,   0.,  22.,
          0.,  35.,  28.,  32.,  27.,  50.,  37.,  38.,  33.,  27.,  52.,  65.,
         58.,  40.,   3.,   0.,   5.,  21.,  47.,  51.,  71., 107.,  46.,  80.,
         63.,  43.,  33.,  24.,  26.,  60.,  42.,  24.,  22.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [10201/30000], Step [1/1], Training Loss: 1058.1355, Valid Loss: 321.2762
Epoch [10301/30000], Step [1/1], Training Loss: 1016.2166, Valid Loss: 356.3429
Epoch [10401/30000], Step [1/1], Training Loss: 975.8942, Valid Loss: 325.6572
Epoch [10501/30000], Step [1/1], Training Loss: 937.1969, Valid Loss: 302.0191
Epoch [10601/30000], Step [1/1], Training Loss: 903.0192, Valid Loss: 336.3619
Epoch [10701/30000], Step [1/1], Training Loss: 864.0560, Valid Loss: 365.2476
Epoch [10801/30000], Step [1/1], Training Loss: 827.4759, Valid Loss: 389.5238
Epoch [10901/30000], Step [1/1], Training Loss: 794.6097, Valid Loss: 323.8191
Epoch [11001/30000], Step [1/1], Training Loss: 765.1313, Valid Loss: 359.6953
Epoch [11101/30000], Step [1/1], Training Loss: 734.1074, Valid Loss: 337.8000
Epoch [11201/30000], Step [1/1], Training Loss: 705.9186, Valid Loss: 338.4095
Epoch [11301/30000], Step [1/1], Training Loss: 679.1924, Valid Loss: 426.7619
Epoch [11401/30000], Step [1/1], Training Loss: 653.7825, Valid Loss: 337.5048
Epoch [11501/30000], Step [1/1], Training Loss: 628.3165, Valid Loss: 393.7619
Epoch [11601/30000], Step [1/1], Training Loss: 603.5480, Valid Loss: 332.8286
Epoch [11701/30000], Step [1/1], Training Loss: 1381.6766, Valid Loss: 212.3143
Epoch [11801/30000], Step [1/1], Training Loss: 1061.0294, Valid Loss: 337.8857
Epoch [11901/30000], Step [1/1], Training Loss: 3160.7898, Valid Loss: 419.8667
Epoch [12001/30000], Step [1/1], Training Loss: 551.4628, Valid Loss: 475.4762
Epoch [12101/30000], Step [1/1], Training Loss: 1117.9176, Valid Loss: 417.3810
Epoch [12201/30000], Step [1/1], Training Loss: 839.1711, Valid Loss: 442.5714
Epoch [12301/30000], Step [1/1], Training Loss: 479.8036, Valid Loss: 489.4000
Epoch [12401/30000], Step [1/1], Training Loss: 453.1076, Valid Loss: 537.4572
Epoch [12501/30000], Step [1/1], Training Loss: 446.3146, Valid Loss: 540.8000
Epoch [12601/30000], Step [1/1], Training Loss: 667.0750, Valid Loss: 541.5524
Epoch [12701/30000], Step [1/1], Training Loss: 869.2355, Valid Loss: 514.2762
Epoch [12801/30000], Step [1/1], Training Loss: 409.0435, Valid Loss: 658.6857
Epoch [12901/30000], Step [1/1], Training Loss: 373.2645, Valid Loss: 629.0190
Epoch [13001/30000], Step [1/1], Training Loss: 368.3467, Valid Loss: 559.7238
Epoch [13101/30000], Step [1/1], Training Loss: 341.7886, Valid Loss: 552.0667
Epoch [13201/30000], Step [1/1], Training Loss: 325.2523, Valid Loss: 568.5238
Epoch [13301/30000], Step [1/1], Training Loss: 310.1674, Valid Loss: 626.5905
Epoch [13401/30000], Step [1/1], Training Loss: 294.0439, Valid Loss: 608.4381
Epoch [13501/30000], Step [1/1], Training Loss: 279.3654, Valid Loss: 649.8857
Epoch [13601/30000], Step [1/1], Training Loss: 265.3032, Valid Loss: 631.6857
Epoch [13701/30000], Step [1/1], Training Loss: 250.8109, Valid Loss: 532.2191
Epoch [13801/30000], Step [1/1], Training Loss: 237.8342, Valid Loss: 579.1524
Epoch [13901/30000], Step [1/1], Training Loss: 222.6173, Valid Loss: 668.2095
Epoch [14001/30000], Step [1/1], Training Loss: 208.4185, Valid Loss: 628.9429
Epoch [14101/30000], Step [1/1], Training Loss: 196.7106, Valid Loss: 775.8857
Epoch [14201/30000], Step [1/1], Training Loss: 182.5284, Valid Loss: 677.7715
Epoch [14301/30000], Step [1/1], Training Loss: 173.5078, Valid Loss: 702.0286
Epoch [14401/30000], Step [1/1], Training Loss: 158.1406, Valid Loss: 820.0858
Epoch [14501/30000], Step [1/1], Training Loss: 149.2178, Valid Loss: 748.6286
Epoch [14601/30000], Step [1/1], Training Loss: 138.1976, Valid Loss: 799.0000
Epoch [14701/30000], Step [1/1], Training Loss: 125.6569, Valid Loss: 739.8762
Epoch [14801/30000], Step [1/1], Training Loss: 116.1584, Valid Loss: 703.4095
Epoch [14901/30000], Step [1/1], Training Loss: 106.2402, Valid Loss: 788.9333
Epoch [15001/30000], Step [1/1], Training Loss: 96.9395, Valid Loss: 818.5905
Epoch [15101/30000], Step [1/1], Training Loss: 88.7867, Valid Loss: 746.6191
Epoch [15201/30000], Step [1/1], Training Loss: 81.5660, Valid Loss: 779.8096
Epoch [15301/30000], Step [1/1], Training Loss: 72.1175, Valid Loss: 742.7715
Epoch [15401/30000], Step [1/1], Training Loss: 4610.7705, Valid Loss: 473.4572
Epoch [15501/30000], Step [1/1], Training Loss: 158.6165, Valid Loss: 346.4286
Epoch [15601/30000], Step [1/1], Training Loss: 98.8512, Valid Loss: 454.8571
Epoch [15701/30000], Step [1/1], Training Loss: 88.5976, Valid Loss: 368.3048
Epoch [15801/30000], Step [1/1], Training Loss: 70.4799, Valid Loss: 356.9524
Epoch [15901/30000], Step [1/1], Training Loss: 60.2965, Valid Loss: 306.7715
Epoch [16001/30000], Step [1/1], Training Loss: 60.9107, Valid Loss: 342.8286
Epoch [16101/30000], Step [1/1], Training Loss: 53.1881, Valid Loss: 355.7524
Epoch [16201/30000], Step [1/1], Training Loss: 44.0076, Valid Loss: 342.6953
Epoch [16301/30000], Step [1/1], Training Loss: 38.6600, Valid Loss: 388.2000
Epoch [16401/30000], Step [1/1], Training Loss: 36.3310, Valid Loss: 386.5238
Epoch [16501/30000], Step [1/1], Training Loss: 32.1695, Valid Loss: 394.9143
Epoch [16601/30000], Step [1/1], Training Loss: 30.5447, Valid Loss: 470.5524
Epoch [16701/30000], Step [1/1], Training Loss: 27.0138, Valid Loss: 474.1905
Epoch [16801/30000], Step [1/1], Training Loss: 24.3370, Valid Loss: 353.9524
Epoch [16901/30000], Step [1/1], Training Loss: 21.5486, Valid Loss: 390.2095
Epoch [17001/30000], Step [1/1], Training Loss: 19.0653, Valid Loss: 414.8191
Epoch [17101/30000], Step [1/1], Training Loss: 17.0534, Valid Loss: 415.2667
Epoch [17201/30000], Step [1/1], Training Loss: 15.6667, Valid Loss: 377.6762
Epoch [17301/30000], Step [1/1], Training Loss: 13.8549, Valid Loss: 419.0381
Epoch [17401/30000], Step [1/1], Training Loss: 11.5511, Valid Loss: 363.2857
Epoch [17501/30000], Step [1/1], Training Loss: 10.2200, Valid Loss: 398.6381
Epoch [17601/30000], Step [1/1], Training Loss: 8.7015, Valid Loss: 376.2286
Epoch [17701/30000], Step [1/1], Training Loss: 7.5368, Valid Loss: 380.4762
Epoch [17801/30000], Step [1/1], Training Loss: 7.1118, Valid Loss: 349.7238
Epoch [17901/30000], Step [1/1], Training Loss: 16.3235, Valid Loss: 408.7619
Epoch [18001/30000], Step [1/1], Training Loss: 5.6002, Valid Loss: 379.2095
Epoch [18101/30000], Step [1/1], Training Loss: 4.3229, Valid Loss: 424.3715
Epoch [18201/30000], Step [1/1], Training Loss: 3.9500, Valid Loss: 409.7333
Epoch [18301/30000], Step [1/1], Training Loss: 4.4839, Valid Loss: 472.0572
Epoch [18401/30000], Step [1/1], Training Loss: 2.8506, Valid Loss: 377.6572
Epoch [18501/30000], Step [1/1], Training Loss: 2.2897, Valid Loss: 368.8095
Epoch [18601/30000], Step [1/1], Training Loss: 1.5772, Valid Loss: 436.5048
Epoch [18701/30000], Step [1/1], Training Loss: 7378.8809, Valid Loss: 528.8667
Epoch [18801/30000], Step [1/1], Training Loss: 622.2011, Valid Loss: 551.2857
Epoch [18901/30000], Step [1/1], Training Loss: 181.1093, Valid Loss: 554.6762
Epoch [19001/30000], Step [1/1], Training Loss: 30.2784, Valid Loss: 845.8000
Epoch [19101/30000], Step [1/1], Training Loss: 13.8045, Valid Loss: 588.9810
Epoch [19201/30000], Step [1/1], Training Loss: 15.3334, Valid Loss: 614.4667
Epoch [19301/30000], Step [1/1], Training Loss: 41.5235, Valid Loss: 716.4762
Epoch [19401/30000], Step [1/1], Training Loss: 7.7192, Valid Loss: 648.4667
Epoch [19501/30000], Step [1/1], Training Loss: 9.2067, Valid Loss: 617.8000
Epoch [19601/30000], Step [1/1], Training Loss: 7.1167, Valid Loss: 573.9143
Epoch [19701/30000], Step [1/1], Training Loss: 11.5867, Valid Loss: 641.9619
Epoch [19801/30000], Step [1/1], Training Loss: 5.9439, Valid Loss: 522.6857
Epoch [19901/30000], Step [1/1], Training Loss: 5.1389, Valid Loss: 530.2095
Epoch [20001/30000], Step [1/1], Training Loss: 949.8328, Valid Loss: 533.9810
Epoch [20101/30000], Step [1/1], Training Loss: 311.6657, Valid Loss: 390.7810
Epoch [20201/30000], Step [1/1], Training Loss: 769.2510, Valid Loss: 660.7905
Epoch [20301/30000], Step [1/1], Training Loss: 15.6525, Valid Loss: 520.8096
Epoch [20401/30000], Step [1/1], Training Loss: 11.7290, Valid Loss: 443.9905
Epoch [20501/30000], Step [1/1], Training Loss: 11.5033, Valid Loss: 448.8191
Epoch [20601/30000], Step [1/1], Training Loss: 5.5779, Valid Loss: 541.9143
Epoch [20701/30000], Step [1/1], Training Loss: 5.0111, Valid Loss: 548.4572
Epoch [20801/30000], Step [1/1], Training Loss: 3.4562, Valid Loss: 482.2286
Epoch [20901/30000], Step [1/1], Training Loss: 3.9566, Valid Loss: 530.4857
Epoch [21001/30000], Step [1/1], Training Loss: 3.6079, Valid Loss: 374.0762
Epoch [21101/30000], Step [1/1], Training Loss: 3.3526, Valid Loss: 516.9524
Epoch [21201/30000], Step [1/1], Training Loss: 3.0184, Valid Loss: 490.9333
Epoch [21301/30000], Step [1/1], Training Loss: 3.0085, Valid Loss: 422.2000
Epoch [21401/30000], Step [1/1], Training Loss: 2.8637, Valid Loss: 385.7429
Epoch [21501/30000], Step [1/1], Training Loss: 2.2325, Valid Loss: 470.4476
Epoch [21601/30000], Step [1/1], Training Loss: 3.3391, Valid Loss: 486.5429
Epoch [21701/30000], Step [1/1], Training Loss: 2.2190, Valid Loss: 418.2095
Epoch [21801/30000], Step [1/1], Training Loss: 2.0952, Valid Loss: 422.1048
Epoch [21901/30000], Step [1/1], Training Loss: 1.6387, Valid Loss: 400.4476
Epoch [22001/30000], Step [1/1], Training Loss: 2.4557, Valid Loss: 461.6000
Epoch [22101/30000], Step [1/1], Training Loss: 1.7652, Valid Loss: 372.8381
Epoch [22201/30000], Step [1/1], Training Loss: 1.7880, Valid Loss: 489.1905
Epoch [22301/30000], Step [1/1], Training Loss: 1.5563, Valid Loss: 375.9048




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=512 	layers=3

Start Time = 2021/04/19, 02:22:34
##########################################################


[Epoch 0] Rounded prediction: 
tensor([0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.],
       device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([10., 17., 13., 14., 13., 16., 19., 11.,  0., 10.,  4.,  9.,  5.,  7.,
         3.,  6.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 14.,
         2.,  5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  7.,  4.,  0.,  5.,  2.,  4.,  6.,  1.,  9., 19.,
        13.,  6.,  3.,  4.,  9., 10.,  9., 15., 26., 25., 23., 24., 27., 24.,
        32., 32., 27., 29., 26., 21., 26.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([14., 21., 17., 14., 13., 18., 17., 13., 10., 11., 10.,  9.,  9.,  7.,
         7., 10.,  5.,  7.,  5.,  8.,  7.,  7., 10.,  7.,  5.,  6.,  8.,  7.,
         5.,  5.,  6.,  5.,  7.,  7.,  3.,  7.,  5.,  6.,  3.,  4.,  3., 10.,
         6.,  8.,  8.,  8.,  7.,  5.,  3.,  7.,  6.,  4.,  7.,  6.,  6.,  4.,
         5.,  9.,  9.,  3.,  4.,  7.,  5., 10.,  4.,  8.,  5., 10.,  8.,  9.,
         8.,  7.,  7., 10., 11., 11.,  6., 12., 10., 12.,  9.,  9., 13., 15.,
        14., 10.,  7.,  8., 10., 11., 13., 12., 22., 28., 25., 26., 22., 13.,
        19., 21., 18., 26., 25., 15., 23.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128623.0234, Valid Loss: 232.6000
Epoch [101/30000], Step [1/1], Training Loss: 121435.1797, Valid Loss: 109.4000
Epoch [201/30000], Step [1/1], Training Loss: 119044.5938, Valid Loss: 173.9238
Epoch [301/30000], Step [1/1], Training Loss: 116799.4297, Valid Loss: 317.3524
Epoch [401/30000], Step [1/1], Training Loss: 114638.4141, Valid Loss: 491.8762
Epoch [501/30000], Step [1/1], Training Loss: 112553.1016, Valid Loss: 716.4000
Epoch [601/30000], Step [1/1], Training Loss: 110529.0391, Valid Loss: 990.9238
Epoch [701/30000], Step [1/1], Training Loss: 108571.2344, Valid Loss: 1308.8667
Epoch [801/30000], Step [1/1], Training Loss: 106669.6797, Valid Loss: 1611.0668
Epoch [901/30000], Step [1/1], Training Loss: 104822.3516, Valid Loss: 2021.1429
Epoch [1001/30000], Step [1/1], Training Loss: 103023.7969, Valid Loss: 1842.0382
Epoch [1101/30000], Step [1/1], Training Loss: 101269.7969, Valid Loss: 1472.1429
Epoch [1201/30000], Step [1/1], Training Loss: 99564.9609, Valid Loss: 1440.8096
Epoch [1301/30000], Step [1/1], Training Loss: 97627.8984, Valid Loss: 121.1810
Epoch [1401/30000], Step [1/1], Training Loss: 95887.0000, Valid Loss: 110.9429
Epoch [1501/30000], Step [1/1], Training Loss: 94192.7422, Valid Loss: 117.1429
Epoch [1601/30000], Step [1/1], Training Loss: 92511.9922, Valid Loss: 126.9429
Epoch [1701/30000], Step [1/1], Training Loss: 90873.3828, Valid Loss: 119.2191
Epoch [1801/30000], Step [1/1], Training Loss: 89275.2969, Valid Loss: 123.2762
Epoch [1901/30000], Step [1/1], Training Loss: 87691.5156, Valid Loss: 128.6286
Epoch [2001/30000], Step [1/1], Training Loss: 86147.3984, Valid Loss: 130.5333
Epoch [2101/30000], Step [1/1], Training Loss: 84636.0547, Valid Loss: 123.0476
Epoch [2201/30000], Step [1/1], Training Loss: 83152.4609, Valid Loss: 113.9333
Epoch [2301/30000], Step [1/1], Training Loss: 81698.5547, Valid Loss: 120.3810
Epoch [2401/30000], Step [1/1], Training Loss: 80273.6641, Valid Loss: 119.2667
Epoch [2501/30000], Step [1/1], Training Loss: 78864.2422, Valid Loss: 123.3333
Epoch [2601/30000], Step [1/1], Training Loss: 77455.7031, Valid Loss: 117.5810
Epoch [2701/30000], Step [1/1], Training Loss: 76086.8672, Valid Loss: 117.6572
Epoch [2801/30000], Step [1/1], Training Loss: 74748.9922, Valid Loss: 119.1714
Epoch [2901/30000], Step [1/1], Training Loss: 73441.2578, Valid Loss: 124.5905
Epoch [3001/30000], Step [1/1], Training Loss: 72159.6484, Valid Loss: 124.9333
Epoch [3101/30000], Step [1/1], Training Loss: 70900.6172, Valid Loss: 126.5048
Epoch [3201/30000], Step [1/1], Training Loss: 69666.0703, Valid Loss: 123.3429
Epoch [3301/30000], Step [1/1], Training Loss: 68458.4375, Valid Loss: 121.6572
Epoch [3401/30000], Step [1/1], Training Loss: 67273.6797, Valid Loss: 119.2571
Epoch [3501/30000], Step [1/1], Training Loss: 66114.3828, Valid Loss: 112.1524
Epoch [3601/30000], Step [1/1], Training Loss: 64977.8438, Valid Loss: 114.4095
Epoch [3701/30000], Step [1/1], Training Loss: 63865.5195, Valid Loss: 120.4476
Epoch [3801/30000], Step [1/1], Training Loss: 62775.3008, Valid Loss: 112.6381
Epoch [3901/30000], Step [1/1], Training Loss: 61711.1562, Valid Loss: 110.7524
Epoch [4001/30000], Step [1/1], Training Loss: 60664.5430, Valid Loss: 109.4381
Epoch [4101/30000], Step [1/1], Training Loss: 59668.2969, Valid Loss: 107.6286
Epoch [4201/30000], Step [1/1], Training Loss: 58656.8203, Valid Loss: 91.3619
Epoch [4301/30000], Step [1/1], Training Loss: 57640.8555, Valid Loss: 94.8667
Epoch [4401/30000], Step [1/1], Training Loss: 56611.4414, Valid Loss: 90.2000
Epoch [4501/30000], Step [1/1], Training Loss: 55654.8633, Valid Loss: 92.7143
Epoch [4601/30000], Step [1/1], Training Loss: 54695.8789, Valid Loss: 92.5619
Epoch [4701/30000], Step [1/1], Training Loss: 53741.9062, Valid Loss: 94.8286
Epoch [4801/30000], Step [1/1], Training Loss: 52824.5391, Valid Loss: 96.4381
Epoch [4901/30000], Step [1/1], Training Loss: 51916.2305, Valid Loss: 98.6000
Epoch [5001/30000], Step [1/1], Training Loss: 50977.2461, Valid Loss: 85.9905
Epoch [5101/30000], Step [1/1], Training Loss: 50052.0781, Valid Loss: 80.2000
Epoch [5201/30000], Step [1/1], Training Loss: 49218.2930, Valid Loss: 86.4191
Epoch [5301/30000], Step [1/1], Training Loss: 48309.0156, Valid Loss: 81.4857
Epoch [5401/30000], Step [1/1], Training Loss: 47475.3867, Valid Loss: 80.9333
Epoch [5501/30000], Step [1/1], Training Loss: 46659.1992, Valid Loss: 84.6952
Epoch [5601/30000], Step [1/1], Training Loss: 45860.5352, Valid Loss: 86.4476
Epoch [5701/30000], Step [1/1], Training Loss: 45066.1562, Valid Loss: 84.8476
Epoch [5801/30000], Step [1/1], Training Loss: 44318.1953, Valid Loss: 77.4857
Epoch [5901/30000], Step [1/1], Training Loss: 43496.9609, Valid Loss: 81.7143
Epoch [6001/30000], Step [1/1], Training Loss: 42721.1797, Valid Loss: 75.5714
Epoch [6101/30000], Step [1/1], Training Loss: 42012.1016, Valid Loss: 74.3143
Epoch [6201/30000], Step [1/1], Training Loss: 41264.1406, Valid Loss: 75.0000
Epoch [6301/30000], Step [1/1], Training Loss: 40555.0039, Valid Loss: 76.9810
Epoch [6401/30000], Step [1/1], Training Loss: 39865.1406, Valid Loss: 75.3333
Epoch [6501/30000], Step [1/1], Training Loss: 39196.5352, Valid Loss: 75.5524
Epoch [6601/30000], Step [1/1], Training Loss: 38527.9883, Valid Loss: 78.2762
Epoch [6701/30000], Step [1/1], Training Loss: 37855.3008, Valid Loss: 74.0857
Epoch [6801/30000], Step [1/1], Training Loss: 37141.9688, Valid Loss: 75.1333
Epoch [6901/30000], Step [1/1], Training Loss: 36419.2734, Valid Loss: 70.3810
Epoch [7001/30000], Step [1/1], Training Loss: 35744.5039, Valid Loss: 74.0952
Epoch [7101/30000], Step [1/1], Training Loss: 35047.1484, Valid Loss: 68.9429
Epoch [7201/30000], Step [1/1], Training Loss: 34450.5586, Valid Loss: 74.2286
Epoch [7301/30000], Step [1/1], Training Loss: 33806.6289, Valid Loss: 64.1714
Epoch [7401/30000], Step [1/1], Training Loss: 33204.1367, Valid Loss: 53.3714
Epoch [7501/30000], Step [1/1], Training Loss: 32620.4746, Valid Loss: 42.3619
Epoch [7601/30000], Step [1/1], Training Loss: 32053.1426, Valid Loss: 45.4667
Epoch [7701/30000], Step [1/1], Training Loss: 31497.3984, Valid Loss: 45.9810
Epoch [7801/30000], Step [1/1], Training Loss: 30955.9355, Valid Loss: 46.6286
Epoch [7901/30000], Step [1/1], Training Loss: 30420.9941, Valid Loss: 46.0476
Epoch [8001/30000], Step [1/1], Training Loss: 29905.6543, Valid Loss: 42.0571
Epoch [8101/30000], Step [1/1], Training Loss: 29401.9961, Valid Loss: 46.2190
Epoch [8201/30000], Step [1/1], Training Loss: 28738.8770, Valid Loss: 50.0476
Epoch [8301/30000], Step [1/1], Training Loss: 28041.1016, Valid Loss: 48.3048
Epoch [8401/30000], Step [1/1], Training Loss: 27491.0605, Valid Loss: 48.8952
Epoch [8501/30000], Step [1/1], Training Loss: 26972.3418, Valid Loss: 49.1524
Epoch [8601/30000], Step [1/1], Training Loss: 26480.9629, Valid Loss: 43.8476
Epoch [8701/30000], Step [1/1], Training Loss: 26007.0859, Valid Loss: 42.2286
Epoch [8801/30000], Step [1/1], Training Loss: 25543.1660, Valid Loss: 50.0381
Epoch [8901/30000], Step [1/1], Training Loss: 25073.5000, Valid Loss: 49.8095
Epoch [9001/30000], Step [1/1], Training Loss: 24628.5000, Valid Loss: 48.0000
Epoch [9101/30000], Step [1/1], Training Loss: 24182.1562, Valid Loss: 45.8476
Epoch [9201/30000], Step [1/1], Training Loss: 23713.8379, Valid Loss: 48.0191
Epoch [9301/30000], Step [1/1], Training Loss: 23227.1152, Valid Loss: 49.5429
Epoch [9401/30000], Step [1/1], Training Loss: 22412.5078, Valid Loss: 50.3143
Epoch [9501/30000], Step [1/1], Training Loss: 22120.5879, Valid Loss: 52.5333
Epoch [9601/30000], Step [1/1], Training Loss: 21403.0332, Valid Loss: 58.2381
Epoch [9701/30000], Step [1/1], Training Loss: 20956.0059, Valid Loss: 56.2286
Epoch [9801/30000], Step [1/1], Training Loss: 20527.7207, Valid Loss: 57.7524
Epoch [9901/30000], Step [1/1], Training Loss: 20111.3398, Valid Loss: 55.8381
Epoch [10001/30000], Step [1/1], Training Loss: 19687.3770, Valid Loss: 57.9810
Epoch [10101/30000], Step [1/1], Training Loss: 19208.5723, Valid Loss: 55.5714

[Epoch 15000] Rounded prediction: 
tensor([14., 22., 15., 12., 14., 15., 14., 14., 11., 13., 10.,  9.,  7., 10.,
         8.,  8.,  7.,  8.,  8.,  8.,  9.,  8., 13.,  9.,  6.,  8., 12.,  8.,
        10.,  7.,  7.,  3.,  7., 10.,  9.,  6.,  6., 11.,  6.,  9.,  5., 10.,
         6.,  8.,  2.,  6., 10.,  9.,  5.,  7.,  9.,  8.,  9.,  7., 11.,  3.,
         5.,  8., 13.,  8.,  5., 12.,  6., 11.,  7.,  9.,  7., 12.,  9., 10.,
        10.,  6.,  7.,  9.,  9., 10.,  8., 15., 10., 15.,  8., 10., 16., 18.,
        15.,  9.,  5.,  8., 14., 12., 13., 19., 31., 29., 28., 29., 23., 16.,
        22., 30., 26., 25., 28., 23., 21.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([13., 20., 17., 14., 15., 14., 14., 13., 10., 12., 10., 11.,  9.,  9.,
         6.,  9.,  6.,  7.,  7., 10., 11.,  6., 10.,  8.,  3.,  4.,  9.,  8.,
         8.,  7.,  4.,  2.,  3., 11.,  9.,  6.,  4.,  9.,  4., 11.,  5., 11.,
        10.,  9.,  1., 10.,  9., 10.,  6.,  7.,  8.,  6., 11.,  5., 13.,  1.,
         4.,  7., 12.,  7.,  5., 11.,  2., 12.,  3., 12.,  4., 13.,  7.,  7.,
         9.,  6.,  6.,  9., 10., 11.,  7., 17.,  8., 16., 10.,  9., 19., 17.,
        12.,  8.,  6.,  9., 10., 12., 17., 20., 30., 32., 30., 32., 28., 19.,
        23., 26., 22., 24., 26., 17., 20.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [10201/30000], Step [1/1], Training Loss: 18750.6758, Valid Loss: 54.7714
Epoch [10301/30000], Step [1/1], Training Loss: 18395.5312, Valid Loss: 53.9714
Epoch [10401/30000], Step [1/1], Training Loss: 17953.0078, Valid Loss: 50.7714
Epoch [10501/30000], Step [1/1], Training Loss: 17568.3105, Valid Loss: 49.7333
Epoch [10601/30000], Step [1/1], Training Loss: 17192.9922, Valid Loss: 51.5714
Epoch [10701/30000], Step [1/1], Training Loss: 16831.4277, Valid Loss: 52.1619
Epoch [10801/30000], Step [1/1], Training Loss: 16502.7676, Valid Loss: 49.8762
Epoch [10901/30000], Step [1/1], Training Loss: 16142.0000, Valid Loss: 50.7905
Epoch [11001/30000], Step [1/1], Training Loss: 15803.0479, Valid Loss: 51.5524
Epoch [11101/30000], Step [1/1], Training Loss: 15472.1250, Valid Loss: 50.3429
Epoch [11201/30000], Step [1/1], Training Loss: 15147.7207, Valid Loss: 49.9714
Epoch [11301/30000], Step [1/1], Training Loss: 14831.7607, Valid Loss: 50.3048
Epoch [11401/30000], Step [1/1], Training Loss: 14515.5811, Valid Loss: 50.7143
Epoch [11501/30000], Step [1/1], Training Loss: 14203.3643, Valid Loss: 52.7429
Epoch [11601/30000], Step [1/1], Training Loss: 13908.0488, Valid Loss: 51.1238
Epoch [11701/30000], Step [1/1], Training Loss: 13618.7441, Valid Loss: 52.7333
Epoch [11801/30000], Step [1/1], Training Loss: 13325.3203, Valid Loss: 50.9333
Epoch [11901/30000], Step [1/1], Training Loss: 13030.2822, Valid Loss: 51.3524
Epoch [12001/30000], Step [1/1], Training Loss: 12751.0820, Valid Loss: 52.4095
Epoch [12101/30000], Step [1/1], Training Loss: 12482.8838, Valid Loss: 52.2952
Epoch [12201/30000], Step [1/1], Training Loss: 12182.1279, Valid Loss: 52.9333
Epoch [12301/30000], Step [1/1], Training Loss: 11907.2178, Valid Loss: 52.5048
Epoch [12401/30000], Step [1/1], Training Loss: 11645.5332, Valid Loss: 51.1619
Epoch [12501/30000], Step [1/1], Training Loss: 11388.9160, Valid Loss: 52.3238
Epoch [12601/30000], Step [1/1], Training Loss: 11136.7061, Valid Loss: 51.2762
Epoch [12701/30000], Step [1/1], Training Loss: 10892.0137, Valid Loss: 54.2000
Epoch [12801/30000], Step [1/1], Training Loss: 10650.8828, Valid Loss: 52.6095
Epoch [12901/30000], Step [1/1], Training Loss: 10414.7910, Valid Loss: 53.6952
Epoch [13001/30000], Step [1/1], Training Loss: 10184.9795, Valid Loss: 51.7714
Epoch [13101/30000], Step [1/1], Training Loss: 9957.6133, Valid Loss: 53.4857
Epoch [13201/30000], Step [1/1], Training Loss: 9735.4541, Valid Loss: 53.9238
Epoch [13301/30000], Step [1/1], Training Loss: 9522.9092, Valid Loss: 51.8476
Epoch [13401/30000], Step [1/1], Training Loss: 9310.6084, Valid Loss: 53.1524
Epoch [13501/30000], Step [1/1], Training Loss: 9402.0615, Valid Loss: 53.4952
Epoch [13601/30000], Step [1/1], Training Loss: 8939.4512, Valid Loss: 45.8190
Epoch [13701/30000], Step [1/1], Training Loss: 8726.2314, Valid Loss: 42.9143
Epoch [13801/30000], Step [1/1], Training Loss: 8522.9590, Valid Loss: 49.1238
Epoch [13901/30000], Step [1/1], Training Loss: 8326.8857, Valid Loss: 46.4667
Epoch [14001/30000], Step [1/1], Training Loss: 8140.2920, Valid Loss: 45.3619
Epoch [14101/30000], Step [1/1], Training Loss: 7957.2734, Valid Loss: 48.8952
Epoch [14201/30000], Step [1/1], Training Loss: 7778.5112, Valid Loss: 45.8857
Epoch [14301/30000], Step [1/1], Training Loss: 7603.9053, Valid Loss: 44.9429
Epoch [14401/30000], Step [1/1], Training Loss: 7434.5322, Valid Loss: 44.7429
Epoch [14501/30000], Step [1/1], Training Loss: 7267.5181, Valid Loss: 46.0476
Epoch [14601/30000], Step [1/1], Training Loss: 7107.5327, Valid Loss: 46.6476
Epoch [14701/30000], Step [1/1], Training Loss: 6949.7651, Valid Loss: 43.9238
Epoch [14801/30000], Step [1/1], Training Loss: 6773.7368, Valid Loss: 40.5048
Epoch [14901/30000], Step [1/1], Training Loss: 6615.3623, Valid Loss: 42.2000
Epoch [15001/30000], Step [1/1], Training Loss: 6460.3462, Valid Loss: 43.4667
Epoch [15101/30000], Step [1/1], Training Loss: 6307.6792, Valid Loss: 41.5238
Epoch [15201/30000], Step [1/1], Training Loss: 6160.4956, Valid Loss: 43.8095
Epoch [15301/30000], Step [1/1], Training Loss: 6013.9971, Valid Loss: 42.0857
Epoch [15401/30000], Step [1/1], Training Loss: 5872.1763, Valid Loss: 44.3714
Epoch [15501/30000], Step [1/1], Training Loss: 5733.8657, Valid Loss: 44.1333
Epoch [15601/30000], Step [1/1], Training Loss: 5598.7827, Valid Loss: 43.4667
Epoch [15701/30000], Step [1/1], Training Loss: 5467.8545, Valid Loss: 48.8095
Epoch [15801/30000], Step [1/1], Training Loss: 5338.5557, Valid Loss: 46.3333
Epoch [15901/30000], Step [1/1], Training Loss: 5211.5566, Valid Loss: 45.5714
Epoch [16001/30000], Step [1/1], Training Loss: 5088.5503, Valid Loss: 45.2190
Epoch [16101/30000], Step [1/1], Training Loss: 4966.8315, Valid Loss: 44.8190
Epoch [16201/30000], Step [1/1], Training Loss: 4848.3726, Valid Loss: 45.2952
Epoch [16301/30000], Step [1/1], Training Loss: 4733.3926, Valid Loss: 43.1143
Epoch [16401/30000], Step [1/1], Training Loss: 4620.8218, Valid Loss: 45.4286
Epoch [16501/30000], Step [1/1], Training Loss: 4508.0381, Valid Loss: 44.7810
Epoch [16601/30000], Step [1/1], Training Loss: 4396.4238, Valid Loss: 44.2190
Epoch [16701/30000], Step [1/1], Training Loss: 4289.8555, Valid Loss: 44.7905
Epoch [16801/30000], Step [1/1], Training Loss: 4186.1860, Valid Loss: 44.9143
Epoch [16901/30000], Step [1/1], Training Loss: 4085.2935, Valid Loss: 48.6571
Epoch [17001/30000], Step [1/1], Training Loss: 3987.8911, Valid Loss: 44.6857
Epoch [17101/30000], Step [1/1], Training Loss: 3891.7725, Valid Loss: 45.5524
Epoch [17201/30000], Step [1/1], Training Loss: 3797.9690, Valid Loss: 46.3333
Epoch [17301/30000], Step [1/1], Training Loss: 3720.0564, Valid Loss: 45.6095
Epoch [17401/30000], Step [1/1], Training Loss: 3637.4258, Valid Loss: 52.3619
Epoch [17501/30000], Step [1/1], Training Loss: 3538.7949, Valid Loss: 48.0286
Epoch [17601/30000], Step [1/1], Training Loss: 3453.2244, Valid Loss: 46.6857
Epoch [17701/30000], Step [1/1], Training Loss: 3370.9084, Valid Loss: 48.7810
Epoch [17801/30000], Step [1/1], Training Loss: 3288.0667, Valid Loss: 48.7143
Epoch [17901/30000], Step [1/1], Training Loss: 3208.6802, Valid Loss: 49.5905
Epoch [18001/30000], Step [1/1], Training Loss: 3130.8259, Valid Loss: 48.8476
Epoch [18101/30000], Step [1/1], Training Loss: 3055.3674, Valid Loss: 49.4095
Epoch [18201/30000], Step [1/1], Training Loss: 2981.7107, Valid Loss: 48.5143
Epoch [18301/30000], Step [1/1], Training Loss: 2909.1643, Valid Loss: 48.5143
Epoch [18401/30000], Step [1/1], Training Loss: 2839.2109, Valid Loss: 51.5429
Epoch [18501/30000], Step [1/1], Training Loss: 2837.0657, Valid Loss: 50.2000
Epoch [18601/30000], Step [1/1], Training Loss: 2704.1252, Valid Loss: 50.5619
Epoch [18701/30000], Step [1/1], Training Loss: 2637.1182, Valid Loss: 50.7619
Epoch [18801/30000], Step [1/1], Training Loss: 2571.2939, Valid Loss: 50.1048
Epoch [18901/30000], Step [1/1], Training Loss: 2507.4280, Valid Loss: 49.1238
Epoch [19001/30000], Step [1/1], Training Loss: 2444.1233, Valid Loss: 49.7810
Epoch [19101/30000], Step [1/1], Training Loss: 2383.6182, Valid Loss: 50.4857
Epoch [19201/30000], Step [1/1], Training Loss: 2323.8044, Valid Loss: 50.8571
Epoch [19301/30000], Step [1/1], Training Loss: 2264.7021, Valid Loss: 49.3429
Epoch [19401/30000], Step [1/1], Training Loss: 2208.1523, Valid Loss: 47.9619
Epoch [19501/30000], Step [1/1], Training Loss: 2153.0215, Valid Loss: 48.8571
Epoch [19601/30000], Step [1/1], Training Loss: 2098.9478, Valid Loss: 49.3238
Epoch [19701/30000], Step [1/1], Training Loss: 2046.6665, Valid Loss: 49.5429
Epoch [19801/30000], Step [1/1], Training Loss: 1995.8380, Valid Loss: 49.9810
Epoch [19901/30000], Step [1/1], Training Loss: 1946.2047, Valid Loss: 49.7714
Epoch [20001/30000], Step [1/1], Training Loss: 1898.8207, Valid Loss: 46.6571
Epoch [20101/30000], Step [1/1], Training Loss: 1852.6837, Valid Loss: 48.9810
Epoch [20201/30000], Step [1/1], Training Loss: 1807.5350, Valid Loss: 49.2952
Epoch [20301/30000], Step [1/1], Training Loss: 1764.1979, Valid Loss: 50.0476
Epoch [20401/30000], Step [1/1], Training Loss: 1722.5573, Valid Loss: 48.3905

[Epoch 25000] Rounded prediction: 
tensor([12., 20., 16., 13., 14., 14., 14., 12., 10., 10., 11., 11.,  8., 12.,
         8., 12., 10., 10.,  8., 11., 11.,  8.,  9.,  8.,  5.,  2., 10., 10.,
         5.,  6.,  5.,  3.,  1., 10.,  8.,  5.,  4.,  8.,  4., 11.,  7., 11.,
         5.,  5.,  1.,  6.,  7.,  8.,  6.,  7.,  8.,  9., 11.,  4., 12.,  4.,
         2.,  4.,  9.,  8.,  4., 11.,  3., 12.,  4., 13.,  7., 11.,  7., 10.,
        12., 10., 10., 12., 11., 11.,  9., 16., 11., 14., 10., 11., 20., 26.,
        14.,  5.,  7.,  8., 10., 11., 17., 25., 29., 29., 29., 32., 31., 29.,
        39., 31., 25., 36., 31., 13., 21.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [20501/30000], Step [1/1], Training Loss: 1682.0516, Valid Loss: 50.2571
Epoch [20601/30000], Step [1/1], Training Loss: 1643.1060, Valid Loss: 48.4762
Epoch [20701/30000], Step [1/1], Training Loss: 1605.6887, Valid Loss: 47.8190
Epoch [20801/30000], Step [1/1], Training Loss: 1568.7704, Valid Loss: 45.8476
Epoch [20901/30000], Step [1/1], Training Loss: 1533.8839, Valid Loss: 47.3143
Epoch [21001/30000], Step [1/1], Training Loss: 1499.4670, Valid Loss: 49.9714
Epoch [21101/30000], Step [1/1], Training Loss: 1465.6836, Valid Loss: 48.0191
Epoch [21201/30000], Step [1/1], Training Loss: 1433.8531, Valid Loss: 49.8381
Epoch [21301/30000], Step [1/1], Training Loss: 1402.0192, Valid Loss: 50.2095
Epoch [21401/30000], Step [1/1], Training Loss: 1371.5260, Valid Loss: 49.8762
Epoch [21501/30000], Step [1/1], Training Loss: 1341.6624, Valid Loss: 49.6381
Epoch [21601/30000], Step [1/1], Training Loss: 1312.9165, Valid Loss: 46.2857
Epoch [21701/30000], Step [1/1], Training Loss: 1284.3463, Valid Loss: 50.0286
Epoch [21801/30000], Step [1/1], Training Loss: 1256.7648, Valid Loss: 48.0762
Epoch [21901/30000], Step [1/1], Training Loss: 1229.8921, Valid Loss: 46.9429
Epoch [22001/30000], Step [1/1], Training Loss: 1203.8832, Valid Loss: 47.7238
Epoch [22101/30000], Step [1/1], Training Loss: 1178.4639, Valid Loss: 48.4571
Epoch [22201/30000], Step [1/1], Training Loss: 1153.6030, Valid Loss: 47.5905
Epoch [22301/30000], Step [1/1], Training Loss: 1129.3013, Valid Loss: 48.9048
Epoch [22401/30000], Step [1/1], Training Loss: 1104.9434, Valid Loss: 46.0476
Epoch [22501/30000], Step [1/1], Training Loss: 1081.0900, Valid Loss: 50.1333
Epoch [22601/30000], Step [1/1], Training Loss: 1057.7592, Valid Loss: 48.5905
Epoch [22701/30000], Step [1/1], Training Loss: 1034.2271, Valid Loss: 45.4952
Epoch [22801/30000], Step [1/1], Training Loss: 1011.2720, Valid Loss: 47.9619
Epoch [22901/30000], Step [1/1], Training Loss: 988.8040, Valid Loss: 47.2095
Epoch [23001/30000], Step [1/1], Training Loss: 966.5065, Valid Loss: 47.3619
Epoch [23101/30000], Step [1/1], Training Loss: 944.7209, Valid Loss: 49.2286
Epoch [23201/30000], Step [1/1], Training Loss: 923.6224, Valid Loss: 48.3524
Epoch [23301/30000], Step [1/1], Training Loss: 902.5551, Valid Loss: 48.5810
Epoch [23401/30000], Step [1/1], Training Loss: 882.0886, Valid Loss: 49.8952
Epoch [23501/30000], Step [1/1], Training Loss: 862.1901, Valid Loss: 45.9905
Epoch [23601/30000], Step [1/1], Training Loss: 842.6181, Valid Loss: 47.0191
Epoch [23701/30000], Step [1/1], Training Loss: 823.6342, Valid Loss: 46.7810
Epoch [23801/30000], Step [1/1], Training Loss: 804.9805, Valid Loss: 45.4286
Epoch [23901/30000], Step [1/1], Training Loss: 1689.0831, Valid Loss: 61.4381
Epoch [24001/30000], Step [1/1], Training Loss: 782.1727, Valid Loss: 53.1048
Epoch [24101/30000], Step [1/1], Training Loss: 761.8237, Valid Loss: 50.1143
Epoch [24201/30000], Step [1/1], Training Loss: 746.6393, Valid Loss: 51.3524
Epoch [24301/30000], Step [1/1], Training Loss: 730.3859, Valid Loss: 50.0286
Epoch [24401/30000], Step [1/1], Training Loss: 715.4127, Valid Loss: 49.1333
Epoch [24501/30000], Step [1/1], Training Loss: 702.3617, Valid Loss: 48.5333
Epoch [24601/30000], Step [1/1], Training Loss: 688.2148, Valid Loss: 50.1333
Epoch [24701/30000], Step [1/1], Training Loss: 674.6830, Valid Loss: 49.5143
Epoch [24801/30000], Step [1/1], Training Loss: 661.7986, Valid Loss: 48.4952
Epoch [24901/30000], Step [1/1], Training Loss: 646.7130, Valid Loss: 51.5143
Epoch [25001/30000], Step [1/1], Training Loss: 633.4709, Valid Loss: 47.5333
Epoch [25101/30000], Step [1/1], Training Loss: 620.5468, Valid Loss: 51.6095
Epoch [25201/30000], Step [1/1], Training Loss: 607.4442, Valid Loss: 51.3714
Epoch [25301/30000], Step [1/1], Training Loss: 594.2661, Valid Loss: 51.0952
Epoch [25401/30000], Step [1/1], Training Loss: 581.2515, Valid Loss: 48.1810
Epoch [25501/30000], Step [1/1], Training Loss: 569.2139, Valid Loss: 50.2381
Epoch [25601/30000], Step [1/1], Training Loss: 555.8160, Valid Loss: 52.0000
Epoch [25701/30000], Step [1/1], Training Loss: 543.6450, Valid Loss: 51.9143
Epoch [25801/30000], Step [1/1], Training Loss: 531.0897, Valid Loss: 49.4476
Epoch [25901/30000], Step [1/1], Training Loss: 519.0668, Valid Loss: 52.1333
Epoch [26001/30000], Step [1/1], Training Loss: 506.5642, Valid Loss: 51.1429
Epoch [26101/30000], Step [1/1], Training Loss: 494.7995, Valid Loss: 51.6381
Epoch [26201/30000], Step [1/1], Training Loss: 483.2007, Valid Loss: 52.1048
Epoch [26301/30000], Step [1/1], Training Loss: 471.7979, Valid Loss: 53.9143
Epoch [26401/30000], Step [1/1], Training Loss: 460.5979, Valid Loss: 52.0286
Epoch [26501/30000], Step [1/1], Training Loss: 449.6282, Valid Loss: 51.6476
Epoch [26601/30000], Step [1/1], Training Loss: 438.9560, Valid Loss: 51.8762
Epoch [26701/30000], Step [1/1], Training Loss: 428.3732, Valid Loss: 54.2191
Epoch [26801/30000], Step [1/1], Training Loss: 418.2341, Valid Loss: 50.8381
Epoch [26901/30000], Step [1/1], Training Loss: 408.2496, Valid Loss: 51.2286
Epoch [27001/30000], Step [1/1], Training Loss: 398.6028, Valid Loss: 51.7714
Epoch [27101/30000], Step [1/1], Training Loss: 388.8059, Valid Loss: 55.8381
Epoch [27201/30000], Step [1/1], Training Loss: 379.1245, Valid Loss: 53.2286
Epoch [27301/30000], Step [1/1], Training Loss: 369.4688, Valid Loss: 49.8667
Epoch [27401/30000], Step [1/1], Training Loss: 359.9110, Valid Loss: 54.8857
Epoch [27501/30000], Step [1/1], Training Loss: 350.0944, Valid Loss: 53.2762
Epoch [27601/30000], Step [1/1], Training Loss: 340.6373, Valid Loss: 54.8000
Epoch [27701/30000], Step [1/1], Training Loss: 331.2765, Valid Loss: 53.8381
Epoch [27801/30000], Step [1/1], Training Loss: 321.8404, Valid Loss: 54.3143
Epoch [27901/30000], Step [1/1], Training Loss: 312.6698, Valid Loss: 55.8762
Epoch [28001/30000], Step [1/1], Training Loss: 303.8189, Valid Loss: 56.5143
Epoch [28101/30000], Step [1/1], Training Loss: 294.6402, Valid Loss: 53.0952
Epoch [28201/30000], Step [1/1], Training Loss: 285.5672, Valid Loss: 54.5429
Epoch [28301/30000], Step [1/1], Training Loss: 276.8628, Valid Loss: 56.2286
Epoch [28401/30000], Step [1/1], Training Loss: 268.1905, Valid Loss: 55.0286
Epoch [28501/30000], Step [1/1], Training Loss: 259.5632, Valid Loss: 55.2476
Epoch [28601/30000], Step [1/1], Training Loss: 251.1966, Valid Loss: 52.0476
Epoch [28701/30000], Step [1/1], Training Loss: 243.0806, Valid Loss: 56.4286
Epoch [28801/30000], Step [1/1], Training Loss: 234.6898, Valid Loss: 53.6381
Epoch [28901/30000], Step [1/1], Training Loss: 226.7997, Valid Loss: 59.8857
Epoch [29001/30000], Step [1/1], Training Loss: 219.0668, Valid Loss: 55.7619
Epoch [29101/30000], Step [1/1], Training Loss: 211.1091, Valid Loss: 54.5048
Epoch [29201/30000], Step [1/1], Training Loss: 203.5407, Valid Loss: 56.2191
Epoch [29301/30000], Step [1/1], Training Loss: 196.1796, Valid Loss: 55.9048
Epoch [29401/30000], Step [1/1], Training Loss: 188.8982, Valid Loss: 59.1714
Epoch [29501/30000], Step [1/1], Training Loss: 181.9434, Valid Loss: 57.5429
Epoch [29601/30000], Step [1/1], Training Loss: 174.7685, Valid Loss: 57.2667
Epoch [29701/30000], Step [1/1], Training Loss: 167.8273, Valid Loss: 56.6857
Epoch [29801/30000], Step [1/1], Training Loss: 161.2358, Valid Loss: 57.6000
Epoch [29901/30000], Step [1/1], Training Loss: 154.9514, Valid Loss: 59.2000

 End Time: 2021/04/19, 02:31:15




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=512 	layers=3

Start Time = 2021/04/19, 02:31:16
##########################################################


[Epoch 0] Rounded prediction: 
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([12., 14., 14., 13., 12., 13., 12.,  6.,  9., 11.,  6.,  5.,  6.,  6.,
         5.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  9.,
         3.,  0.,  1.,  0.,  6.,  5.,  1.,  0., 24., 25., 21., 15., 22., 17.,
        27., 35., 24., 27., 27., 20., 18.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([14., 15., 14., 12., 11., 13., 14., 11., 10., 11., 10.,  9.,  8., 12.,
         8.,  8.,  5.,  5.,  0.,  5.,  6.,  3.,  3.,  4.,  3.,  0.,  1.,  0.,
         1.,  2.,  8.,  0.,  2.,  4.,  3.,  0.,  1.,  0.,  0.,  2.,  1., 10.,
         6.,  5.,  8.,  8.,  5.,  0.,  0.,  0.,  0.,  0.,  2.,  1.,  5.,  3.,
         2.,  4.,  6.,  0.,  0.,  3.,  0.,  3.,  0.,  1.,  0.,  3.,  0.,  3.,
         3.,  0.,  0.,  3., 10.,  8.,  1., 13.,  5.,  9.,  7.,  4.,  7., 12.,
        14.,  7.,  2.,  4., 11.,  8.,  4., 11., 21., 33., 25., 24., 25., 17.,
        25., 32., 26., 25., 29., 24., 22.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128673.1562, Valid Loss: 238.9238
Epoch [101/30000], Step [1/1], Training Loss: 121069.3359, Valid Loss: 118.3048
Epoch [201/30000], Step [1/1], Training Loss: 118682.1562, Valid Loss: 192.8286
Epoch [301/30000], Step [1/1], Training Loss: 116437.6719, Valid Loss: 317.3524
Epoch [401/30000], Step [1/1], Training Loss: 114281.1875, Valid Loss: 491.8762
Epoch [501/30000], Step [1/1], Training Loss: 112201.3906, Valid Loss: 767.3048
Epoch [601/30000], Step [1/1], Training Loss: 110184.0859, Valid Loss: 990.9238
Epoch [701/30000], Step [1/1], Training Loss: 108231.1328, Valid Loss: 1315.4476
Epoch [801/30000], Step [1/1], Training Loss: 106335.3672, Valid Loss: 1689.9714
Epoch [901/30000], Step [1/1], Training Loss: 104493.5000, Valid Loss: 2113.5334
Epoch [1001/30000], Step [1/1], Training Loss: 102701.0000, Valid Loss: 2046.3334
Epoch [1101/30000], Step [1/1], Training Loss: 100954.1719, Valid Loss: 1483.5048
Epoch [1201/30000], Step [1/1], Training Loss: 99254.7109, Valid Loss: 1353.8762
Epoch [1301/30000], Step [1/1], Training Loss: 97289.3984, Valid Loss: 103.7238
Epoch [1401/30000], Step [1/1], Training Loss: 95561.3281, Valid Loss: 120.8095
Epoch [1501/30000], Step [1/1], Training Loss: 93868.6641, Valid Loss: 131.4095
Epoch [1601/30000], Step [1/1], Training Loss: 92216.1953, Valid Loss: 136.1238
Epoch [1701/30000], Step [1/1], Training Loss: 90570.9219, Valid Loss: 135.6476
Epoch [1801/30000], Step [1/1], Training Loss: 88981.4844, Valid Loss: 127.1810
Epoch [1901/30000], Step [1/1], Training Loss: 87394.4922, Valid Loss: 135.9048
Epoch [2001/30000], Step [1/1], Training Loss: 85857.2188, Valid Loss: 128.2095
Epoch [2101/30000], Step [1/1], Training Loss: 84346.3359, Valid Loss: 130.6952
Epoch [2201/30000], Step [1/1], Training Loss: 82866.7422, Valid Loss: 131.9048
Epoch [2301/30000], Step [1/1], Training Loss: 81416.6328, Valid Loss: 137.8000
Epoch [2401/30000], Step [1/1], Training Loss: 79995.9297, Valid Loss: 135.4191
Epoch [2501/30000], Step [1/1], Training Loss: 78601.4453, Valid Loss: 138.8762
Epoch [2601/30000], Step [1/1], Training Loss: 77234.3125, Valid Loss: 138.2000
Epoch [2701/30000], Step [1/1], Training Loss: 75822.6328, Valid Loss: 127.1905
Epoch [2801/30000], Step [1/1], Training Loss: 74488.7031, Valid Loss: 133.5333
Epoch [2901/30000], Step [1/1], Training Loss: 73184.9844, Valid Loss: 132.7714
Epoch [3001/30000], Step [1/1], Training Loss: 71907.0312, Valid Loss: 138.2381
Epoch [3101/30000], Step [1/1], Training Loss: 70652.7188, Valid Loss: 133.9143
Epoch [3201/30000], Step [1/1], Training Loss: 69425.1562, Valid Loss: 131.5619
Epoch [3301/30000], Step [1/1], Training Loss: 68219.6641, Valid Loss: 133.1905
Epoch [3401/30000], Step [1/1], Training Loss: 67040.7109, Valid Loss: 127.4952
Epoch [3501/30000], Step [1/1], Training Loss: 65884.9688, Valid Loss: 139.3810
Epoch [3601/30000], Step [1/1], Training Loss: 64752.2109, Valid Loss: 134.2381
Epoch [3701/30000], Step [1/1], Training Loss: 63643.4805, Valid Loss: 130.4381
Epoch [3801/30000], Step [1/1], Training Loss: 62778.3633, Valid Loss: 146.6381
Epoch [3901/30000], Step [1/1], Training Loss: 61508.0625, Valid Loss: 142.5524
Epoch [4001/30000], Step [1/1], Training Loss: 60460.7578, Valid Loss: 135.2286
Epoch [4101/30000], Step [1/1], Training Loss: 59444.4805, Valid Loss: 133.0476
Epoch [4201/30000], Step [1/1], Training Loss: 58447.5664, Valid Loss: 137.9048
Epoch [4301/30000], Step [1/1], Training Loss: 57473.0586, Valid Loss: 134.6476
Epoch [4401/30000], Step [1/1], Training Loss: 56521.2969, Valid Loss: 131.4000
Epoch [4501/30000], Step [1/1], Training Loss: 55720.6719, Valid Loss: 130.8952
Epoch [4601/30000], Step [1/1], Training Loss: 54682.3594, Valid Loss: 119.8286
Epoch [4701/30000], Step [1/1], Training Loss: 53787.9492, Valid Loss: 122.2476
Epoch [4801/30000], Step [1/1], Training Loss: 52875.8086, Valid Loss: 125.5333
Epoch [4901/30000], Step [1/1], Training Loss: 51948.7031, Valid Loss: 113.5143
Epoch [5001/30000], Step [1/1], Training Loss: 50909.6211, Valid Loss: 115.2286
Epoch [5101/30000], Step [1/1], Training Loss: 49977.0391, Valid Loss: 115.1048
Epoch [5201/30000], Step [1/1], Training Loss: 49082.8555, Valid Loss: 111.8571
Epoch [5301/30000], Step [1/1], Training Loss: 48228.7617, Valid Loss: 115.0667
Epoch [5401/30000], Step [1/1], Training Loss: 47387.9609, Valid Loss: 114.7524
Epoch [5501/30000], Step [1/1], Training Loss: 46566.1406, Valid Loss: 108.6381
Epoch [5601/30000], Step [1/1], Training Loss: 45724.4297, Valid Loss: 110.7619
Epoch [5701/30000], Step [1/1], Training Loss: 44995.8633, Valid Loss: 109.4286
Epoch [5801/30000], Step [1/1], Training Loss: 44154.6367, Valid Loss: 103.2952
Epoch [5901/30000], Step [1/1], Training Loss: 43416.4570, Valid Loss: 104.0952
Epoch [6001/30000], Step [1/1], Training Loss: 42652.5547, Valid Loss: 106.4762
Epoch [6101/30000], Step [1/1], Training Loss: 41923.9531, Valid Loss: 103.3238
Epoch [6201/30000], Step [1/1], Training Loss: 41198.1562, Valid Loss: 109.7810
Epoch [6301/30000], Step [1/1], Training Loss: 40511.0391, Valid Loss: 111.1238
Epoch [6401/30000], Step [1/1], Training Loss: 39819.0273, Valid Loss: 98.2667
Epoch [6501/30000], Step [1/1], Training Loss: 39146.7070, Valid Loss: 106.8381
Epoch [6601/30000], Step [1/1], Training Loss: 38575.7227, Valid Loss: 97.2762
Epoch [6701/30000], Step [1/1], Training Loss: 37859.7148, Valid Loss: 101.1238
Epoch [6801/30000], Step [1/1], Training Loss: 37227.4805, Valid Loss: 103.2286
Epoch [6901/30000], Step [1/1], Training Loss: 36621.9570, Valid Loss: 101.4286
Epoch [7001/30000], Step [1/1], Training Loss: 35999.6914, Valid Loss: 92.9524
Epoch [7101/30000], Step [1/1], Training Loss: 35212.0039, Valid Loss: 111.3143
Epoch [7201/30000], Step [1/1], Training Loss: 34535.3984, Valid Loss: 92.8667
Epoch [7301/30000], Step [1/1], Training Loss: 33855.3398, Valid Loss: 99.6000
Epoch [7401/30000], Step [1/1], Training Loss: 33211.2891, Valid Loss: 90.6476
Epoch [7501/30000], Step [1/1], Training Loss: 32567.6855, Valid Loss: 92.2476
Epoch [7601/30000], Step [1/1], Training Loss: 31916.1250, Valid Loss: 98.0762
Epoch [7701/30000], Step [1/1], Training Loss: 31315.6660, Valid Loss: 90.6095
Epoch [7801/30000], Step [1/1], Training Loss: 30677.1035, Valid Loss: 94.5810
Epoch [7901/30000], Step [1/1], Training Loss: 30055.1309, Valid Loss: 102.8095
Epoch [8001/30000], Step [1/1], Training Loss: 29473.4492, Valid Loss: 98.9810
Epoch [8101/30000], Step [1/1], Training Loss: 28895.4316, Valid Loss: 97.7714
Epoch [8201/30000], Step [1/1], Training Loss: 28353.2246, Valid Loss: 96.7048
Epoch [8301/30000], Step [1/1], Training Loss: 27776.4199, Valid Loss: 92.7143
Epoch [8401/30000], Step [1/1], Training Loss: 27248.2148, Valid Loss: 102.8286
Epoch [8501/30000], Step [1/1], Training Loss: 26727.7656, Valid Loss: 96.1048
Epoch [8601/30000], Step [1/1], Training Loss: 26195.9551, Valid Loss: 98.0476
Epoch [8701/30000], Step [1/1], Training Loss: 25674.0488, Valid Loss: 82.9048
Epoch [8801/30000], Step [1/1], Training Loss: 25144.9688, Valid Loss: 61.5524
Epoch [8901/30000], Step [1/1], Training Loss: 24630.3477, Valid Loss: 66.2286
Epoch [9001/30000], Step [1/1], Training Loss: 24634.0664, Valid Loss: 71.7333
Epoch [9101/30000], Step [1/1], Training Loss: 23696.0312, Valid Loss: 59.5619
Epoch [9201/30000], Step [1/1], Training Loss: 23200.3848, Valid Loss: 63.2000
Epoch [9301/30000], Step [1/1], Training Loss: 22759.2129, Valid Loss: 64.9143
Epoch [9401/30000], Step [1/1], Training Loss: 22318.5410, Valid Loss: 73.9048
Epoch [9501/30000], Step [1/1], Training Loss: 21864.4785, Valid Loss: 71.9048
Epoch [9601/30000], Step [1/1], Training Loss: 21426.2207, Valid Loss: 69.5238
Epoch [9701/30000], Step [1/1], Training Loss: 21004.1543, Valid Loss: 71.5619
Epoch [9801/30000], Step [1/1], Training Loss: 20612.9355, Valid Loss: 66.0476
Epoch [9901/30000], Step [1/1], Training Loss: 20208.4473, Valid Loss: 66.3619
Epoch [10001/30000], Step [1/1], Training Loss: 19830.2480, Valid Loss: 73.5143
Epoch [10101/30000], Step [1/1], Training Loss: 19462.9824, Valid Loss: 65.7524

[Epoch 15000] Rounded prediction: 
tensor([14., 14., 14., 13., 12., 14., 11., 12., 11., 12., 12.,  9., 12., 11.,
         8., 11.,  7., 10.,  8., 10., 11.,  7.,  7., 10.,  7.,  4.,  5.,  6.,
         7.,  8., 10.,  6.,  3.,  9.,  4.,  7.,  5.,  7.,  4.,  6., 11., 12.,
        11.,  8., 10., 10.,  6.,  6.,  4.,  5.,  5.,  6.,  8.,  6., 12., 10.,
         7.,  3.,  6.,  3.,  7., 10.,  4.,  7.,  3.,  7.,  7.,  8.,  7.,  6.,
         5.,  2.,  8.,  7., 10.,  8.,  5., 18., 10., 14., 11.,  8., 17., 13.,
        15.,  6.,  2.,  7.,  9.,  8., 13., 16., 27., 38., 24., 25., 21., 16.,
        19., 26., 16., 17., 22., 17., 16.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([14., 15., 16., 15., 14., 15., 15., 13., 12., 13., 14., 11., 12., 13.,
        10., 12., 10., 11., 12., 10.,  7., 10., 12., 11.,  9.,  4.,  5.,  8.,
         7.,  8., 10.,  8.,  4.,  6.,  5.,  7.,  5.,  7.,  4.,  6.,  9., 11.,
        11.,  7.,  8.,  8.,  5.,  7.,  5.,  5.,  6.,  4.,  7.,  8., 15., 13.,
         7.,  8.,  8.,  6.,  8.,  9.,  6.,  9.,  5.,  9.,  6., 10., 11.,  6.,
         4.,  4.,  5.,  6.,  8., 13., 10., 19., 12., 16., 12.,  9., 16., 11.,
        12.,  6.,  4.,  5.,  7., 10., 15., 19., 25., 29., 18., 21., 22., 15.,
        18., 21., 17., 19., 24., 18., 16.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [10201/30000], Step [1/1], Training Loss: 19106.6875, Valid Loss: 64.2667
Epoch [10301/30000], Step [1/1], Training Loss: 18725.3105, Valid Loss: 68.3905
Epoch [10401/30000], Step [1/1], Training Loss: 18379.7637, Valid Loss: 69.7143
Epoch [10501/30000], Step [1/1], Training Loss: 18038.8223, Valid Loss: 63.9714
Epoch [10601/30000], Step [1/1], Training Loss: 17710.6699, Valid Loss: 68.0191
Epoch [10701/30000], Step [1/1], Training Loss: 17392.5566, Valid Loss: 68.3048
Epoch [10801/30000], Step [1/1], Training Loss: 17077.0156, Valid Loss: 68.4286
Epoch [10901/30000], Step [1/1], Training Loss: 16931.9590, Valid Loss: 60.5905
Epoch [11001/30000], Step [1/1], Training Loss: 16412.1309, Valid Loss: 74.8191
Epoch [11101/30000], Step [1/1], Training Loss: 16087.4268, Valid Loss: 63.5714
Epoch [11201/30000], Step [1/1], Training Loss: 15919.7822, Valid Loss: 67.6000
Epoch [11301/30000], Step [1/1], Training Loss: 15504.8760, Valid Loss: 67.0857
Epoch [11401/30000], Step [1/1], Training Loss: 15289.5498, Valid Loss: 72.0286
Epoch [11501/30000], Step [1/1], Training Loss: 14712.4707, Valid Loss: 67.2381
Epoch [11601/30000], Step [1/1], Training Loss: 14505.4990, Valid Loss: 68.6286
Epoch [11701/30000], Step [1/1], Training Loss: 14136.0049, Valid Loss: 61.3619
Epoch [11801/30000], Step [1/1], Training Loss: 13875.5898, Valid Loss: 73.3429
Epoch [11901/30000], Step [1/1], Training Loss: 13586.9199, Valid Loss: 64.8286
Epoch [12001/30000], Step [1/1], Training Loss: 13467.3359, Valid Loss: 63.7333
Epoch [12101/30000], Step [1/1], Training Loss: 13082.3994, Valid Loss: 63.5238
Epoch [12201/30000], Step [1/1], Training Loss: 12849.5566, Valid Loss: 61.3619
Epoch [12301/30000], Step [1/1], Training Loss: 12606.8955, Valid Loss: 60.5143
Epoch [12401/30000], Step [1/1], Training Loss: 12374.0664, Valid Loss: 61.8571
Epoch [12501/30000], Step [1/1], Training Loss: 12289.1055, Valid Loss: 59.9810
Epoch [12601/30000], Step [1/1], Training Loss: 11993.3232, Valid Loss: 59.8095
Epoch [12701/30000], Step [1/1], Training Loss: 11724.7822, Valid Loss: 66.0857
Epoch [12801/30000], Step [1/1], Training Loss: 11515.7617, Valid Loss: 64.8381
Epoch [12901/30000], Step [1/1], Training Loss: 11465.0420, Valid Loss: 63.6476
Epoch [13001/30000], Step [1/1], Training Loss: 11122.8291, Valid Loss: 61.3810
Epoch [13101/30000], Step [1/1], Training Loss: 10921.1992, Valid Loss: 65.7524
Epoch [13201/30000], Step [1/1], Training Loss: 10756.6484, Valid Loss: 64.6952
Epoch [13301/30000], Step [1/1], Training Loss: 10284.2373, Valid Loss: 56.6857
Epoch [13401/30000], Step [1/1], Training Loss: 10126.1494, Valid Loss: 77.7524
Epoch [13501/30000], Step [1/1], Training Loss: 9327.1836, Valid Loss: 57.4571
Epoch [13601/30000], Step [1/1], Training Loss: 9092.3691, Valid Loss: 60.6762
Epoch [13701/30000], Step [1/1], Training Loss: 8864.2852, Valid Loss: 61.0381
Epoch [13801/30000], Step [1/1], Training Loss: 8643.4912, Valid Loss: 62.8381
Epoch [13901/30000], Step [1/1], Training Loss: 8436.1934, Valid Loss: 60.2667
Epoch [14001/30000], Step [1/1], Training Loss: 8233.6631, Valid Loss: 58.8952
Epoch [14101/30000], Step [1/1], Training Loss: 8039.1660, Valid Loss: 60.9524
Epoch [14201/30000], Step [1/1], Training Loss: 7851.1958, Valid Loss: 58.7810
Epoch [14301/30000], Step [1/1], Training Loss: 8092.8760, Valid Loss: 68.2190
Epoch [14401/30000], Step [1/1], Training Loss: 7500.4380, Valid Loss: 60.3524
Epoch [14501/30000], Step [1/1], Training Loss: 7316.2407, Valid Loss: 65.4762
Epoch [14601/30000], Step [1/1], Training Loss: 7139.4663, Valid Loss: 61.9524
Epoch [14701/30000], Step [1/1], Training Loss: 6970.9404, Valid Loss: 56.8286
Epoch [14801/30000], Step [1/1], Training Loss: 6805.4297, Valid Loss: 59.0476
Epoch [14901/30000], Step [1/1], Training Loss: 6646.7827, Valid Loss: 61.5143
Epoch [15001/30000], Step [1/1], Training Loss: 6493.1338, Valid Loss: 58.5333
Epoch [15101/30000], Step [1/1], Training Loss: 6341.1460, Valid Loss: 60.2667
Epoch [15201/30000], Step [1/1], Training Loss: 6193.8579, Valid Loss: 59.9619
Epoch [15301/30000], Step [1/1], Training Loss: 6052.1919, Valid Loss: 63.3429
Epoch [15401/30000], Step [1/1], Training Loss: 5913.0869, Valid Loss: 59.6000
Epoch [15501/30000], Step [1/1], Training Loss: 5776.4907, Valid Loss: 60.2762
Epoch [15601/30000], Step [1/1], Training Loss: 5634.8530, Valid Loss: 61.4381
Epoch [15701/30000], Step [1/1], Training Loss: 5501.3677, Valid Loss: 61.2476
Epoch [15801/30000], Step [1/1], Training Loss: 5373.8926, Valid Loss: 61.6286
Epoch [15901/30000], Step [1/1], Training Loss: 5248.4155, Valid Loss: 65.3143
Epoch [16001/30000], Step [1/1], Training Loss: 5125.3447, Valid Loss: 61.8667
Epoch [16101/30000], Step [1/1], Training Loss: 5005.8052, Valid Loss: 62.0095
Epoch [16201/30000], Step [1/1], Training Loss: 4888.2139, Valid Loss: 63.5619
Epoch [16301/30000], Step [1/1], Training Loss: 4774.7007, Valid Loss: 64.7905
Epoch [16401/30000], Step [1/1], Training Loss: 4663.9829, Valid Loss: 65.2381
Epoch [16501/30000], Step [1/1], Training Loss: 4559.2339, Valid Loss: 66.0476
Epoch [16601/30000], Step [1/1], Training Loss: 4452.7500, Valid Loss: 61.9619
Epoch [16701/30000], Step [1/1], Training Loss: 4351.1050, Valid Loss: 64.2095
Epoch [16801/30000], Step [1/1], Training Loss: 4207.8545, Valid Loss: 62.6857
Epoch [16901/30000], Step [1/1], Training Loss: 4095.8823, Valid Loss: 63.3905
Epoch [17001/30000], Step [1/1], Training Loss: 3994.3115, Valid Loss: 58.6762
Epoch [17101/30000], Step [1/1], Training Loss: 3896.6111, Valid Loss: 60.0286
Epoch [17201/30000], Step [1/1], Training Loss: 7303.9355, Valid Loss: 71.2476
Epoch [17301/30000], Step [1/1], Training Loss: 3761.7854, Valid Loss: 73.1048
Epoch [17401/30000], Step [1/1], Training Loss: 3635.8154, Valid Loss: 64.7714
Epoch [17501/30000], Step [1/1], Training Loss: 3546.4233, Valid Loss: 69.3619
Epoch [17601/30000], Step [1/1], Training Loss: 3459.1367, Valid Loss: 68.6952
Epoch [17701/30000], Step [1/1], Training Loss: 3371.9348, Valid Loss: 67.7524
Epoch [17801/30000], Step [1/1], Training Loss: 3288.5342, Valid Loss: 65.4762
Epoch [17901/30000], Step [1/1], Training Loss: 3208.2688, Valid Loss: 67.8476
Epoch [18001/30000], Step [1/1], Training Loss: 3130.9978, Valid Loss: 69.0571
Epoch [18101/30000], Step [1/1], Training Loss: 3058.2170, Valid Loss: 63.6381
Epoch [18201/30000], Step [1/1], Training Loss: 2980.1792, Valid Loss: 67.6857
Epoch [18301/30000], Step [1/1], Training Loss: 2907.4023, Valid Loss: 65.1143
Epoch [18401/30000], Step [1/1], Training Loss: 2836.3118, Valid Loss: 67.9333
Epoch [18501/30000], Step [1/1], Training Loss: 2767.3125, Valid Loss: 67.5429
Epoch [18601/30000], Step [1/1], Training Loss: 2698.0132, Valid Loss: 70.4667
Epoch [18701/30000], Step [1/1], Training Loss: 2630.6414, Valid Loss: 67.2000
Epoch [18801/30000], Step [1/1], Training Loss: 2565.1389, Valid Loss: 67.0476
Epoch [18901/30000], Step [1/1], Training Loss: 2501.8542, Valid Loss: 64.2571
Epoch [19001/30000], Step [1/1], Training Loss: 2439.8154, Valid Loss: 67.8381
Epoch [19101/30000], Step [1/1], Training Loss: 2377.2004, Valid Loss: 69.4095
Epoch [19201/30000], Step [1/1], Training Loss: 2316.7090, Valid Loss: 65.9238
Epoch [19301/30000], Step [1/1], Training Loss: 2258.5930, Valid Loss: 66.2286
Epoch [19401/30000], Step [1/1], Training Loss: 2201.7378, Valid Loss: 65.1524
Epoch [19501/30000], Step [1/1], Training Loss: 2146.0466, Valid Loss: 62.3810
Epoch [19601/30000], Step [1/1], Training Loss: 2092.1870, Valid Loss: 63.9619
Epoch [19701/30000], Step [1/1], Training Loss: 2039.5764, Valid Loss: 64.6952
Epoch [19801/30000], Step [1/1], Training Loss: 1988.6213, Valid Loss: 63.8286
Epoch [19901/30000], Step [1/1], Training Loss: 1940.6360, Valid Loss: 61.5524
Epoch [20001/30000], Step [1/1], Training Loss: 1892.3781, Valid Loss: 58.8000
Epoch [20101/30000], Step [1/1], Training Loss: 1845.8574, Valid Loss: 59.5143
Epoch [20201/30000], Step [1/1], Training Loss: 1801.2667, Valid Loss: 64.5238
Epoch [20301/30000], Step [1/1], Training Loss: 1757.9899, Valid Loss: 61.0476

[Epoch 25000] Rounded prediction: 
tensor([13., 14., 13., 14., 13., 14., 14., 11., 10., 11., 11., 11., 12., 12.,
        12., 11., 11.,  7., 11., 13., 14.,  9., 11., 12.,  8.,  1.,  5., 10.,
        11., 10.,  9.,  8.,  4.,  6.,  8.,  6.,  4.,  7.,  3.,  6.,  9., 15.,
         9.,  7.,  6.,  7.,  7.,  8.,  4.,  3.,  5.,  5., 11.,  7., 12., 10.,
         7.,  6.,  7.,  8.,  6.,  7.,  4.,  9.,  5.,  8., 10., 11., 11., 13.,
         6.,  4.,  8.,  7.,  6., 11., 11., 19., 10., 16., 13., 10., 18., 13.,
        18., 12.,  6.,  5.,  4.,  8., 19., 24., 29., 28., 16., 23., 26., 21.,
        21., 28., 20., 20., 24., 21., 13.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [20401/30000], Step [1/1], Training Loss: 1716.0575, Valid Loss: 63.9333
Epoch [20501/30000], Step [1/1], Training Loss: 1676.5515, Valid Loss: 66.6762
Epoch [20601/30000], Step [1/1], Training Loss: 1637.6185, Valid Loss: 65.3429
Epoch [20701/30000], Step [1/1], Training Loss: 1599.7163, Valid Loss: 63.5524
Epoch [20801/30000], Step [1/1], Training Loss: 1563.5280, Valid Loss: 62.4762
Epoch [20901/30000], Step [1/1], Training Loss: 1528.5978, Valid Loss: 62.2381
Epoch [21001/30000], Step [1/1], Training Loss: 1493.7389, Valid Loss: 63.0952
Epoch [21101/30000], Step [1/1], Training Loss: 1460.7427, Valid Loss: 63.4000
Epoch [21201/30000], Step [1/1], Training Loss: 1428.7040, Valid Loss: 61.3238
Epoch [21301/30000], Step [1/1], Training Loss: 1397.1917, Valid Loss: 64.1905
Epoch [21401/30000], Step [1/1], Training Loss: 1366.9297, Valid Loss: 68.9429
Epoch [21501/30000], Step [1/1], Training Loss: 1336.9468, Valid Loss: 60.1714
Epoch [21601/30000], Step [1/1], Training Loss: 1308.0238, Valid Loss: 64.4381
Epoch [21701/30000], Step [1/1], Training Loss: 1280.2457, Valid Loss: 63.0286
Epoch [21801/30000], Step [1/1], Training Loss: 1252.5522, Valid Loss: 62.6286
Epoch [21901/30000], Step [1/1], Training Loss: 1225.8494, Valid Loss: 63.6476
Epoch [22001/30000], Step [1/1], Training Loss: 1199.6746, Valid Loss: 65.5905
Epoch [22101/30000], Step [1/1], Training Loss: 1174.4755, Valid Loss: 62.2667
Epoch [22201/30000], Step [1/1], Training Loss: 1150.1174, Valid Loss: 64.8381
Epoch [22301/30000], Step [1/1], Training Loss: 1125.2655, Valid Loss: 58.6190
Epoch [22401/30000], Step [1/1], Training Loss: 1101.2388, Valid Loss: 64.6952
Epoch [22501/30000], Step [1/1], Training Loss: 1077.1989, Valid Loss: 63.5714
Epoch [22601/30000], Step [1/1], Training Loss: 1053.8290, Valid Loss: 63.8762
Epoch [22701/30000], Step [1/1], Training Loss: 3236.7581, Valid Loss: 66.4095
Epoch [22801/30000], Step [1/1], Training Loss: 1024.7856, Valid Loss: 62.8952
Epoch [22901/30000], Step [1/1], Training Loss: 1000.1084, Valid Loss: 55.1238
Epoch [23001/30000], Step [1/1], Training Loss: 973.2001, Valid Loss: 54.4476
Epoch [23101/30000], Step [1/1], Training Loss: 953.1287, Valid Loss: 60.2000
Epoch [23201/30000], Step [1/1], Training Loss: 932.7051, Valid Loss: 55.2667
Epoch [23301/30000], Step [1/1], Training Loss: 912.0726, Valid Loss: 54.7714
Epoch [23401/30000], Step [1/1], Training Loss: 891.9301, Valid Loss: 57.0000
Epoch [23501/30000], Step [1/1], Training Loss: 873.7262, Valid Loss: 54.2762
Epoch [23601/30000], Step [1/1], Training Loss: 854.0045, Valid Loss: 53.1333
Epoch [23701/30000], Step [1/1], Training Loss: 835.7363, Valid Loss: 54.2286
Epoch [23801/30000], Step [1/1], Training Loss: 816.8188, Valid Loss: 52.0857
Epoch [23901/30000], Step [1/1], Training Loss: 799.5630, Valid Loss: 55.9905
Epoch [24001/30000], Step [1/1], Training Loss: 782.5461, Valid Loss: 55.2286
Epoch [24101/30000], Step [1/1], Training Loss: 765.0588, Valid Loss: 54.6762
Epoch [24201/30000], Step [1/1], Training Loss: 748.6844, Valid Loss: 48.8571
Epoch [24301/30000], Step [1/1], Training Loss: 732.3928, Valid Loss: 53.6000
Epoch [24401/30000], Step [1/1], Training Loss: 717.1234, Valid Loss: 54.3619
Epoch [24501/30000], Step [1/1], Training Loss: 701.8575, Valid Loss: 52.4762
Epoch [24601/30000], Step [1/1], Training Loss: 687.0873, Valid Loss: 51.7048
Epoch [24701/30000], Step [1/1], Training Loss: 672.5751, Valid Loss: 51.9524
Epoch [24801/30000], Step [1/1], Training Loss: 658.1351, Valid Loss: 51.3714
Epoch [24901/30000], Step [1/1], Training Loss: 643.8334, Valid Loss: 52.0857
Epoch [25001/30000], Step [1/1], Training Loss: 629.7836, Valid Loss: 51.3524
Epoch [25101/30000], Step [1/1], Training Loss: 616.3085, Valid Loss: 54.6857
Epoch [25201/30000], Step [1/1], Training Loss: 602.8102, Valid Loss: 51.2000
Epoch [25301/30000], Step [1/1], Training Loss: 589.1531, Valid Loss: 53.2286
Epoch [25401/30000], Step [1/1], Training Loss: 575.7777, Valid Loss: 51.8952
Epoch [25501/30000], Step [1/1], Training Loss: 562.4760, Valid Loss: 53.4667
Epoch [25601/30000], Step [1/1], Training Loss: 549.5349, Valid Loss: 52.3524
Epoch [25701/30000], Step [1/1], Training Loss: 536.7136, Valid Loss: 53.3905
Epoch [25801/30000], Step [1/1], Training Loss: 524.2491, Valid Loss: 50.2667
Epoch [25901/30000], Step [1/1], Training Loss: 511.9593, Valid Loss: 53.2952
Epoch [26001/30000], Step [1/1], Training Loss: 499.6061, Valid Loss: 51.8762
Epoch [26101/30000], Step [1/1], Training Loss: 487.8614, Valid Loss: 54.2762
Epoch [26201/30000], Step [1/1], Training Loss: 476.0497, Valid Loss: 52.5238
Epoch [26301/30000], Step [1/1], Training Loss: 464.6937, Valid Loss: 55.2000
Epoch [26401/30000], Step [1/1], Training Loss: 453.2158, Valid Loss: 53.0095
Epoch [26501/30000], Step [1/1], Training Loss: 442.1373, Valid Loss: 51.8476
Epoch [26601/30000], Step [1/1], Training Loss: 431.5545, Valid Loss: 52.4571
Epoch [26701/30000], Step [1/1], Training Loss: 421.1599, Valid Loss: 55.0191
Epoch [26801/30000], Step [1/1], Training Loss: 411.1632, Valid Loss: 55.7524
Epoch [26901/30000], Step [1/1], Training Loss: 401.1557, Valid Loss: 51.4000
Epoch [27001/30000], Step [1/1], Training Loss: 391.2786, Valid Loss: 53.3333
Epoch [27101/30000], Step [1/1], Training Loss: 381.4819, Valid Loss: 55.5905
Epoch [27201/30000], Step [1/1], Training Loss: 371.6886, Valid Loss: 53.0286
Epoch [27301/30000], Step [1/1], Training Loss: 361.8819, Valid Loss: 53.9333
Epoch [27401/30000], Step [1/1], Training Loss: 352.3904, Valid Loss: 53.8667
Epoch [27501/30000], Step [1/1], Training Loss: 342.8225, Valid Loss: 52.9143
Epoch [27601/30000], Step [1/1], Training Loss: 333.1953, Valid Loss: 53.2667
Epoch [27701/30000], Step [1/1], Training Loss: 324.1062, Valid Loss: 53.6857
Epoch [27801/30000], Step [1/1], Training Loss: 314.6461, Valid Loss: 53.0095
Epoch [27901/30000], Step [1/1], Training Loss: 305.6277, Valid Loss: 57.8190
Epoch [28001/30000], Step [1/1], Training Loss: 296.2318, Valid Loss: 57.4667
Epoch [28101/30000], Step [1/1], Training Loss: 288.8050, Valid Loss: 53.7714
Epoch [28201/30000], Step [1/1], Training Loss: 278.7155, Valid Loss: 55.5810
Epoch [28301/30000], Step [1/1], Training Loss: 269.8445, Valid Loss: 55.3238
Epoch [28401/30000], Step [1/1], Training Loss: 261.2895, Valid Loss: 57.2286
Epoch [28501/30000], Step [1/1], Training Loss: 253.0404, Valid Loss: 56.3333
Epoch [28601/30000], Step [1/1], Training Loss: 244.6250, Valid Loss: 55.1810
Epoch [28701/30000], Step [1/1], Training Loss: 236.3912, Valid Loss: 55.5429
Epoch [28801/30000], Step [1/1], Training Loss: 228.2850, Valid Loss: 57.6095
Epoch [28901/30000], Step [1/1], Training Loss: 220.4385, Valid Loss: 59.4952
Epoch [29001/30000], Step [1/1], Training Loss: 225.8264, Valid Loss: 65.6476
Epoch [29101/30000], Step [1/1], Training Loss: 213.8454, Valid Loss: 64.4095
Epoch [29201/30000], Step [1/1], Training Loss: 207.2233, Valid Loss: 65.4381
Epoch [29301/30000], Step [1/1], Training Loss: 200.1933, Valid Loss: 59.7048
Epoch [29401/30000], Step [1/1], Training Loss: 194.9170, Valid Loss: 61.1333
Epoch [29501/30000], Step [1/1], Training Loss: 188.6862, Valid Loss: 60.1238
Epoch [29601/30000], Step [1/1], Training Loss: 182.6216, Valid Loss: 61.1333
Epoch [29701/30000], Step [1/1], Training Loss: 177.1014, Valid Loss: 61.8286
Epoch [29801/30000], Step [1/1], Training Loss: 171.2180, Valid Loss: 61.1619
Epoch [29901/30000], Step [1/1], Training Loss: 166.0394, Valid Loss: 62.0381

 End Time: 2021/04/19, 02:40:00




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=512 	layers=3

Start Time = 2021/04/19, 03:12:47
##########################################################


[Epoch 0] Rounded prediction: 
tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([ 8., 13., 13., 14., 15., 14., 18., 14.,  8., 10.,  2.,  5.,  8., 11.,
         2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  3.,  0.,  0.,  0.,  0.,  0.,  3.,  4.,  1., 13.,
        12.,  5.,  0.,  0.,  8.,  6.,  0.,  3., 18., 26., 22., 25., 28., 21.,
        25., 29., 28., 33., 31., 21., 30.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([12., 18., 14., 14., 16., 16., 18., 15., 11., 10., 10., 10., 10., 11.,
         9.,  8.,  5.,  0.,  2.,  3.,  1.,  1.,  0.,  2.,  2.,  0.,  2.,  0.,
         0.,  0.,  1.,  1.,  4.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,
         3.,  6.,  5.,  6.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         2.,  3.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,
         3.,  4.,  0.,  2.,  7.,  5.,  3.,  2.,  6.,  4.,  4.,  4.,  5., 10.,
         4., 10.,  4.,  3., 11.,  9.,  3.,  6., 15., 19., 17., 22., 21., 16.,
        18., 27., 24., 32., 37., 25., 18.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128670.3203, Valid Loss: 238.7429
Epoch [101/30000], Step [1/1], Training Loss: 121294.9688, Valid Loss: 109.4000
Epoch [201/30000], Step [1/1], Training Loss: 118900.4297, Valid Loss: 192.8286
Epoch [301/30000], Step [1/1], Training Loss: 116646.6641, Valid Loss: 317.3524
Epoch [401/30000], Step [1/1], Training Loss: 114486.5156, Valid Loss: 491.8762
Epoch [501/30000], Step [1/1], Training Loss: 112398.4688, Valid Loss: 716.4000
Epoch [601/30000], Step [1/1], Training Loss: 110379.6328, Valid Loss: 990.9238
Epoch [701/30000], Step [1/1], Training Loss: 108422.8125, Valid Loss: 1315.4476
Epoch [801/30000], Step [1/1], Training Loss: 106522.7578, Valid Loss: 1689.9714
Epoch [901/30000], Step [1/1], Training Loss: 104678.3438, Valid Loss: 2078.7620
Epoch [1001/30000], Step [1/1], Training Loss: 102880.5156, Valid Loss: 1721.9048
Epoch [1101/30000], Step [1/1], Training Loss: 101131.0703, Valid Loss: 1369.1715
Epoch [1201/30000], Step [1/1], Training Loss: 99426.6875, Valid Loss: 1301.4286
Epoch [1301/30000], Step [1/1], Training Loss: 97483.2422, Valid Loss: 84.6571
Epoch [1401/30000], Step [1/1], Training Loss: 95746.1016, Valid Loss: 115.4857
Epoch [1501/30000], Step [1/1], Training Loss: 94051.9141, Valid Loss: 122.3524
Epoch [1601/30000], Step [1/1], Training Loss: 92395.0391, Valid Loss: 130.6381
Epoch [1701/30000], Step [1/1], Training Loss: 90775.0938, Valid Loss: 132.7333
Epoch [1801/30000], Step [1/1], Training Loss: 89158.3672, Valid Loss: 131.2191
Epoch [1901/30000], Step [1/1], Training Loss: 87577.4297, Valid Loss: 114.3810
Epoch [2001/30000], Step [1/1], Training Loss: 86029.9688, Valid Loss: 123.4476
Epoch [2101/30000], Step [1/1], Training Loss: 84514.3828, Valid Loss: 119.0476
Epoch [2201/30000], Step [1/1], Training Loss: 83033.7656, Valid Loss: 114.8000
Epoch [2301/30000], Step [1/1], Training Loss: 81578.9062, Valid Loss: 123.4286
Epoch [2401/30000], Step [1/1], Training Loss: 80154.1641, Valid Loss: 117.5048
Epoch [2501/30000], Step [1/1], Training Loss: 78753.1094, Valid Loss: 118.2571
Epoch [2601/30000], Step [1/1], Training Loss: 77380.9844, Valid Loss: 126.5810
Epoch [2701/30000], Step [1/1], Training Loss: 75986.5859, Valid Loss: 122.6286
Epoch [2801/30000], Step [1/1], Training Loss: 74639.3203, Valid Loss: 117.5714
Epoch [2901/30000], Step [1/1], Training Loss: 73331.8750, Valid Loss: 121.8857
Epoch [3001/30000], Step [1/1], Training Loss: 72048.7812, Valid Loss: 122.6190
Epoch [3101/30000], Step [1/1], Training Loss: 70792.5156, Valid Loss: 124.7810
Epoch [3201/30000], Step [1/1], Training Loss: 69561.1406, Valid Loss: 127.2857
Epoch [3301/30000], Step [1/1], Training Loss: 68354.1797, Valid Loss: 125.9810
Epoch [3401/30000], Step [1/1], Training Loss: 67170.8125, Valid Loss: 125.6286
Epoch [3501/30000], Step [1/1], Training Loss: 66012.8672, Valid Loss: 127.5333
Epoch [3601/30000], Step [1/1], Training Loss: 64878.3359, Valid Loss: 126.1429
Epoch [3701/30000], Step [1/1], Training Loss: 63767.2500, Valid Loss: 129.6381
Epoch [3801/30000], Step [1/1], Training Loss: 62701.2812, Valid Loss: 117.7333
Epoch [3901/30000], Step [1/1], Training Loss: 61621.7109, Valid Loss: 107.5048
Epoch [4001/30000], Step [1/1], Training Loss: 60575.6445, Valid Loss: 108.6381
Epoch [4101/30000], Step [1/1], Training Loss: 59557.8945, Valid Loss: 117.4095
Epoch [4201/30000], Step [1/1], Training Loss: 58560.0195, Valid Loss: 101.5143
Epoch [4301/30000], Step [1/1], Training Loss: 57495.3281, Valid Loss: 109.9810
Epoch [4401/30000], Step [1/1], Training Loss: 56489.2344, Valid Loss: 108.2667
Epoch [4501/30000], Step [1/1], Training Loss: 55516.3125, Valid Loss: 112.5810
Epoch [4601/30000], Step [1/1], Training Loss: 54565.8398, Valid Loss: 113.4000
Epoch [4701/30000], Step [1/1], Training Loss: 53605.9336, Valid Loss: 114.5905
Epoch [4801/30000], Step [1/1], Training Loss: 52640.2500, Valid Loss: 114.6286
Epoch [4901/30000], Step [1/1], Training Loss: 51682.2344, Valid Loss: 106.8857
Epoch [5001/30000], Step [1/1], Training Loss: 50751.3125, Valid Loss: 108.7429
Epoch [5101/30000], Step [1/1], Training Loss: 49856.7188, Valid Loss: 102.3810
Epoch [5201/30000], Step [1/1], Training Loss: 48983.3867, Valid Loss: 108.3333
Epoch [5301/30000], Step [1/1], Training Loss: 48123.0117, Valid Loss: 114.0571
Epoch [5401/30000], Step [1/1], Training Loss: 47276.5156, Valid Loss: 107.7048
Epoch [5501/30000], Step [1/1], Training Loss: 46452.3516, Valid Loss: 106.3238
Epoch [5601/30000], Step [1/1], Training Loss: 45648.2109, Valid Loss: 112.0571
Epoch [5701/30000], Step [1/1], Training Loss: 44853.2109, Valid Loss: 107.2571
Epoch [5801/30000], Step [1/1], Training Loss: 44079.6367, Valid Loss: 109.4476
Epoch [5901/30000], Step [1/1], Training Loss: 43320.8281, Valid Loss: 108.8381
Epoch [6001/30000], Step [1/1], Training Loss: 42577.3203, Valid Loss: 108.7333
Epoch [6101/30000], Step [1/1], Training Loss: 41851.5000, Valid Loss: 107.4476
Epoch [6201/30000], Step [1/1], Training Loss: 41138.8516, Valid Loss: 108.4000
Epoch [6301/30000], Step [1/1], Training Loss: 40443.3789, Valid Loss: 110.8667
Epoch [6401/30000], Step [1/1], Training Loss: 39765.4297, Valid Loss: 108.2191
Epoch [6501/30000], Step [1/1], Training Loss: 39444.4219, Valid Loss: 119.5714
Epoch [6601/30000], Step [1/1], Training Loss: 38488.3438, Valid Loss: 107.8667
Epoch [6701/30000], Step [1/1], Training Loss: 37951.5039, Valid Loss: 98.8667
Epoch [6801/30000], Step [1/1], Training Loss: 37109.0469, Valid Loss: 105.2381
Epoch [6901/30000], Step [1/1], Training Loss: 36326.7148, Valid Loss: 103.4381
Epoch [7001/30000], Step [1/1], Training Loss: 35681.7188, Valid Loss: 109.4667
Epoch [7101/30000], Step [1/1], Training Loss: 35049.3047, Valid Loss: 111.8952
Epoch [7201/30000], Step [1/1], Training Loss: 34345.5430, Valid Loss: 112.7619
Epoch [7301/30000], Step [1/1], Training Loss: 33615.8789, Valid Loss: 110.7429
Epoch [7401/30000], Step [1/1], Training Loss: 32895.8594, Valid Loss: 106.7143
Epoch [7501/30000], Step [1/1], Training Loss: 32146.1758, Valid Loss: 96.1143
Epoch [7601/30000], Step [1/1], Training Loss: 31509.9961, Valid Loss: 105.0286
Epoch [7701/30000], Step [1/1], Training Loss: 30882.9258, Valid Loss: 108.0381
Epoch [7801/30000], Step [1/1], Training Loss: 30268.5684, Valid Loss: 110.8571
Epoch [7901/30000], Step [1/1], Training Loss: 29689.6328, Valid Loss: 105.8667
Epoch [8001/30000], Step [1/1], Training Loss: 29127.3379, Valid Loss: 110.7429
Epoch [8101/30000], Step [1/1], Training Loss: 28564.5117, Valid Loss: 117.2762
Epoch [8201/30000], Step [1/1], Training Loss: 28020.5566, Valid Loss: 114.2762
Epoch [8301/30000], Step [1/1], Training Loss: 27490.5781, Valid Loss: 113.0286
Epoch [8401/30000], Step [1/1], Training Loss: 26975.3477, Valid Loss: 118.7429
Epoch [8501/30000], Step [1/1], Training Loss: 26467.9258, Valid Loss: 115.7333
Epoch [8601/30000], Step [1/1], Training Loss: 25931.2441, Valid Loss: 117.3619
Epoch [8701/30000], Step [1/1], Training Loss: 25443.7188, Valid Loss: 112.8857
Epoch [8801/30000], Step [1/1], Training Loss: 24968.5664, Valid Loss: 121.4286
Epoch [8901/30000], Step [1/1], Training Loss: 24501.1543, Valid Loss: 116.2667
Epoch [9001/30000], Step [1/1], Training Loss: 24048.2383, Valid Loss: 116.7619
Epoch [9101/30000], Step [1/1], Training Loss: 23605.0742, Valid Loss: 113.1810
Epoch [9201/30000], Step [1/1], Training Loss: 23195.3164, Valid Loss: 114.3429
Epoch [9301/30000], Step [1/1], Training Loss: 22880.0312, Valid Loss: 86.5905
Epoch [9401/30000], Step [1/1], Training Loss: 22194.0234, Valid Loss: 69.6476
Epoch [9501/30000], Step [1/1], Training Loss: 21761.7559, Valid Loss: 81.6667
Epoch [9601/30000], Step [1/1], Training Loss: 21339.7461, Valid Loss: 83.0286
Epoch [9701/30000], Step [1/1], Training Loss: 20923.8242, Valid Loss: 83.4571
Epoch [9801/30000], Step [1/1], Training Loss: 20523.3184, Valid Loss: 99.4191
Epoch [9901/30000], Step [1/1], Training Loss: 20117.1582, Valid Loss: 101.1333
Epoch [10001/30000], Step [1/1], Training Loss: 19661.6348, Valid Loss: 95.2952
Epoch [10101/30000], Step [1/1], Training Loss: 19213.1973, Valid Loss: 91.7429

[Epoch 15000] Rounded prediction: 
tensor([11., 15., 13., 12., 12., 12., 13., 12.,  8., 10.,  7.,  9.,  8., 10.,
         5.,  6.,  3.,  1.,  0.,  1.,  4.,  0.,  0.,  2.,  0.,  0.,  5.,  3.,
         0.,  0.,  5.,  1.,  6.,  7.,  0.,  0.,  0.,  2.,  0.,  0.,  1.,  9.,
        10.,  7.,  9.,  9.,  6.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  6.,
         3.,  9.,  8.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,
         1.,  0.,  0.,  0.,  3.,  5.,  0.,  2.,  5.,  5.,  5.,  4.,  6., 14.,
         7.,  5.,  0.,  1.,  6.,  6.,  5.,  5., 16., 23., 19., 25., 26., 17.,
        16., 26., 19., 21., 32., 15.,  8.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([11., 14., 11., 12., 12., 13., 13., 12., 11., 12., 11., 11.,  8., 12.,
        10., 11., 11., 10.,  8.,  7.,  5.,  4.,  3.,  6.,  3.,  2.,  5.,  7.,
         0.,  2.,  7.,  7.,  8.,  8.,  7.,  1.,  1.,  4.,  0.,  4.,  6., 15.,
        11.,  9.,  9.,  8.,  7.,  6.,  0.,  0.,  3.,  1.,  6.,  0.,  8., 10.,
         4.,  9.,  9.,  3.,  1.,  4.,  3.,  5.,  3.,  2.,  3.,  4.,  6.,  1.,
         2.,  0.,  0.,  0.,  7., 10.,  1.,  9.,  9.,  9., 10., 10., 13., 17.,
        12.,  7.,  2.,  1.,  8., 10., 12., 11., 22., 26., 22., 30., 29., 23.,
        20., 30., 28., 28., 40., 20.,  9.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [10201/30000], Step [1/1], Training Loss: 18811.5273, Valid Loss: 93.4095
Epoch [10301/30000], Step [1/1], Training Loss: 18395.4180, Valid Loss: 103.9048
Epoch [10401/30000], Step [1/1], Training Loss: 17939.2129, Valid Loss: 93.8286
Epoch [10501/30000], Step [1/1], Training Loss: 17570.6406, Valid Loss: 95.0000
Epoch [10601/30000], Step [1/1], Training Loss: 17189.4180, Valid Loss: 90.9714
Epoch [10701/30000], Step [1/1], Training Loss: 16828.7773, Valid Loss: 92.8857
Epoch [10801/30000], Step [1/1], Training Loss: 16477.4785, Valid Loss: 92.1238
Epoch [10901/30000], Step [1/1], Training Loss: 16118.7393, Valid Loss: 90.1810
Epoch [11001/30000], Step [1/1], Training Loss: 15757.4014, Valid Loss: 87.3905
Epoch [11101/30000], Step [1/1], Training Loss: 15657.6465, Valid Loss: 93.6762
Epoch [11201/30000], Step [1/1], Training Loss: 15639.0820, Valid Loss: 94.7905
Epoch [11301/30000], Step [1/1], Training Loss: 14848.9072, Valid Loss: 87.3905
Epoch [11401/30000], Step [1/1], Training Loss: 14501.6357, Valid Loss: 83.0476
Epoch [11501/30000], Step [1/1], Training Loss: 14192.0752, Valid Loss: 85.5048
Epoch [11601/30000], Step [1/1], Training Loss: 13888.1299, Valid Loss: 78.1619
Epoch [11701/30000], Step [1/1], Training Loss: 13594.7412, Valid Loss: 78.3429
Epoch [11801/30000], Step [1/1], Training Loss: 13312.2490, Valid Loss: 85.9619
Epoch [11901/30000], Step [1/1], Training Loss: 13080.1436, Valid Loss: 84.4667
Epoch [12001/30000], Step [1/1], Training Loss: 12743.0840, Valid Loss: 80.7714
Epoch [12101/30000], Step [1/1], Training Loss: 12472.0361, Valid Loss: 82.0571
Epoch [12201/30000], Step [1/1], Training Loss: 12207.0537, Valid Loss: 77.0857
Epoch [12301/30000], Step [1/1], Training Loss: 11947.1562, Valid Loss: 80.6667
Epoch [12401/30000], Step [1/1], Training Loss: 11693.1338, Valid Loss: 78.4476
Epoch [12501/30000], Step [1/1], Training Loss: 11446.5742, Valid Loss: 80.9905
Epoch [12601/30000], Step [1/1], Training Loss: 11205.0723, Valid Loss: 75.2952
Epoch [12701/30000], Step [1/1], Training Loss: 10963.0938, Valid Loss: 77.1524
Epoch [12801/30000], Step [1/1], Training Loss: 10666.6445, Valid Loss: 87.6000
Epoch [12901/30000], Step [1/1], Training Loss: 10430.9043, Valid Loss: 77.9238
Epoch [13001/30000], Step [1/1], Training Loss: 10200.9805, Valid Loss: 77.8381
Epoch [13101/30000], Step [1/1], Training Loss: 9977.8652, Valid Loss: 80.0952
Epoch [13201/30000], Step [1/1], Training Loss: 9759.9570, Valid Loss: 78.6857
Epoch [13301/30000], Step [1/1], Training Loss: 9542.3154, Valid Loss: 77.2476
Epoch [13401/30000], Step [1/1], Training Loss: 9331.2744, Valid Loss: 78.8286
Epoch [13501/30000], Step [1/1], Training Loss: 9127.0996, Valid Loss: 78.0095
Epoch [13601/30000], Step [1/1], Training Loss: 8933.1582, Valid Loss: 82.3238
Epoch [13701/30000], Step [1/1], Training Loss: 8729.5645, Valid Loss: 78.3429
Epoch [13801/30000], Step [1/1], Training Loss: 8513.4287, Valid Loss: 79.7619
Epoch [13901/30000], Step [1/1], Training Loss: 8317.0840, Valid Loss: 76.6381
Epoch [14001/30000], Step [1/1], Training Loss: 8129.8867, Valid Loss: 75.2952
Epoch [14101/30000], Step [1/1], Training Loss: 7946.4351, Valid Loss: 78.7238
Epoch [14201/30000], Step [1/1], Training Loss: 7768.0640, Valid Loss: 78.6190
Epoch [14301/30000], Step [1/1], Training Loss: 7593.3262, Valid Loss: 79.8762
Epoch [14401/30000], Step [1/1], Training Loss: 7423.3022, Valid Loss: 82.7714
Epoch [14501/30000], Step [1/1], Training Loss: 7258.2119, Valid Loss: 79.1238
Epoch [14601/30000], Step [1/1], Training Loss: 7096.4829, Valid Loss: 78.0667
Epoch [14701/30000], Step [1/1], Training Loss: 6969.5371, Valid Loss: 101.1143
Epoch [14801/30000], Step [1/1], Training Loss: 6799.8467, Valid Loss: 98.0762
Epoch [14901/30000], Step [1/1], Training Loss: 6647.0269, Valid Loss: 103.8000
Epoch [15001/30000], Step [1/1], Training Loss: 6497.7188, Valid Loss: 100.3333
Epoch [15101/30000], Step [1/1], Training Loss: 6354.0933, Valid Loss: 99.6095
Epoch [15201/30000], Step [1/1], Training Loss: 6213.5889, Valid Loss: 104.4762
Epoch [15301/30000], Step [1/1], Training Loss: 6069.3169, Valid Loss: 93.2476
Epoch [15401/30000], Step [1/1], Training Loss: 5931.5361, Valid Loss: 95.3524
Epoch [15501/30000], Step [1/1], Training Loss: 5800.0352, Valid Loss: 93.6000
Epoch [15601/30000], Step [1/1], Training Loss: 5671.6729, Valid Loss: 91.1619
Epoch [15701/30000], Step [1/1], Training Loss: 5546.0298, Valid Loss: 93.9143
Epoch [15801/30000], Step [1/1], Training Loss: 5426.4570, Valid Loss: 90.1429
Epoch [15901/30000], Step [1/1], Training Loss: 5304.5347, Valid Loss: 94.5810
Epoch [16001/30000], Step [1/1], Training Loss: 5188.5190, Valid Loss: 93.2857
Epoch [16101/30000], Step [1/1], Training Loss: 5075.8213, Valid Loss: 93.5810
Epoch [16201/30000], Step [1/1], Training Loss: 4965.6250, Valid Loss: 92.2667
Epoch [16301/30000], Step [1/1], Training Loss: 4859.5864, Valid Loss: 91.6857
Epoch [16401/30000], Step [1/1], Training Loss: 4753.6650, Valid Loss: 91.8857
Epoch [16501/30000], Step [1/1], Training Loss: 4649.2529, Valid Loss: 87.3905
Epoch [16601/30000], Step [1/1], Training Loss: 4481.1289, Valid Loss: 85.0095
Epoch [16701/30000], Step [1/1], Training Loss: 4330.4214, Valid Loss: 79.2190
Epoch [16801/30000], Step [1/1], Training Loss: 4218.4390, Valid Loss: 84.3905
Epoch [16901/30000], Step [1/1], Training Loss: 4116.3330, Valid Loss: 79.7333
Epoch [17001/30000], Step [1/1], Training Loss: 4011.8232, Valid Loss: 81.4762
Epoch [17101/30000], Step [1/1], Training Loss: 3914.3274, Valid Loss: 83.8476
Epoch [17201/30000], Step [1/1], Training Loss: 3830.0369, Valid Loss: 69.9905
Epoch [17301/30000], Step [1/1], Training Loss: 3725.6221, Valid Loss: 80.6095
Epoch [17401/30000], Step [1/1], Training Loss: 3633.9111, Valid Loss: 79.7429
Epoch [17501/30000], Step [1/1], Training Loss: 3545.3547, Valid Loss: 72.4476
Epoch [17601/30000], Step [1/1], Training Loss: 3459.9617, Valid Loss: 76.0191
Epoch [17701/30000], Step [1/1], Training Loss: 3375.4465, Valid Loss: 78.0000
Epoch [17801/30000], Step [1/1], Training Loss: 3294.1973, Valid Loss: 76.9429
Epoch [17901/30000], Step [1/1], Training Loss: 3214.1123, Valid Loss: 75.3810
Epoch [18001/30000], Step [1/1], Training Loss: 3133.3926, Valid Loss: 80.2476
Epoch [18101/30000], Step [1/1], Training Loss: 3057.6973, Valid Loss: 77.4762
Epoch [18201/30000], Step [1/1], Training Loss: 2981.2620, Valid Loss: 77.5333
Epoch [18301/30000], Step [1/1], Training Loss: 2908.6858, Valid Loss: 76.0000
Epoch [18401/30000], Step [1/1], Training Loss: 2837.3516, Valid Loss: 71.7619
Epoch [18501/30000], Step [1/1], Training Loss: 2767.8088, Valid Loss: 69.0286
Epoch [18601/30000], Step [1/1], Training Loss: 2699.3645, Valid Loss: 73.4191
Epoch [18701/30000], Step [1/1], Training Loss: 2632.8342, Valid Loss: 73.4095
Epoch [18801/30000], Step [1/1], Training Loss: 2567.8511, Valid Loss: 74.8286
Epoch [18901/30000], Step [1/1], Training Loss: 2504.9226, Valid Loss: 73.0476
Epoch [19001/30000], Step [1/1], Training Loss: 2458.6675, Valid Loss: 67.3238
Epoch [19101/30000], Step [1/1], Training Loss: 2386.5457, Valid Loss: 76.1429
Epoch [19201/30000], Step [1/1], Training Loss: 2325.0518, Valid Loss: 68.2286
Epoch [19301/30000], Step [1/1], Training Loss: 2266.3013, Valid Loss: 70.8667
Epoch [19401/30000], Step [1/1], Training Loss: 2208.3552, Valid Loss: 66.0952
Epoch [19501/30000], Step [1/1], Training Loss: 2152.8787, Valid Loss: 71.9238
Epoch [19601/30000], Step [1/1], Training Loss: 2099.1240, Valid Loss: 68.3619
Epoch [19701/30000], Step [1/1], Training Loss: 2046.0439, Valid Loss: 68.5143
Epoch [19801/30000], Step [1/1], Training Loss: 1994.8394, Valid Loss: 65.8476
Epoch [19901/30000], Step [1/1], Training Loss: 1945.7493, Valid Loss: 67.1143
Epoch [20001/30000], Step [1/1], Training Loss: 1897.5968, Valid Loss: 65.1048
Epoch [20101/30000], Step [1/1], Training Loss: 1851.0656, Valid Loss: 69.1905
Epoch [20201/30000], Step [1/1], Training Loss: 1806.5443, Valid Loss: 64.7714
Epoch [20301/30000], Step [1/1], Training Loss: 1763.4388, Valid Loss: 66.4571

[Epoch 25000] Rounded prediction: 
tensor([14., 19., 13., 12., 18., 18., 14., 16., 11., 14., 12., 13., 12., 15.,
        13., 17., 15., 16., 13., 12., 11.,  8.,  8.,  6.,  7.,  3.,  3.,  7.,
         2.,  3.,  7.,  8.,  7.,  4.,  5.,  2.,  1.,  4.,  3.,  3.,  6., 11.,
         8.,  8., 10.,  9.,  5.,  5.,  1.,  0.,  3.,  7.,  7.,  1.,  8., 13.,
         5.,  8.,  9.,  5.,  2.,  3.,  5.,  6.,  2.,  3.,  3.,  7.,  5.,  6.,
         6.,  8.,  9.,  6., 12., 21., 10., 13.,  7., 11.,  9., 10., 12., 15.,
        13., 12.,  8.,  6., 17., 18., 15., 14., 22., 33., 27., 31., 35., 23.,
        22., 41., 28., 28., 40., 24., 22.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [20401/30000], Step [1/1], Training Loss: 1721.6447, Valid Loss: 65.2286
Epoch [20501/30000], Step [1/1], Training Loss: 1680.7814, Valid Loss: 67.9619
Epoch [20601/30000], Step [1/1], Training Loss: 1642.0090, Valid Loss: 61.3238
Epoch [20701/30000], Step [1/1], Training Loss: 1604.1952, Valid Loss: 67.8476
Epoch [20801/30000], Step [1/1], Training Loss: 1567.4833, Valid Loss: 60.7429
Epoch [20901/30000], Step [1/1], Training Loss: 1531.9102, Valid Loss: 61.2762
Epoch [21001/30000], Step [1/1], Training Loss: 1498.0436, Valid Loss: 64.1810
Epoch [21101/30000], Step [1/1], Training Loss: 1464.5449, Valid Loss: 64.1143
Epoch [21201/30000], Step [1/1], Training Loss: 1432.0337, Valid Loss: 61.6952
Epoch [21301/30000], Step [1/1], Training Loss: 1400.9901, Valid Loss: 62.9619
Epoch [21401/30000], Step [1/1], Training Loss: 1370.3082, Valid Loss: 61.8857
Epoch [21501/30000], Step [1/1], Training Loss: 1340.3811, Valid Loss: 66.4191
Epoch [21601/30000], Step [1/1], Training Loss: 1311.3207, Valid Loss: 62.4095
Epoch [21701/30000], Step [1/1], Training Loss: 1283.0607, Valid Loss: 62.6381
Epoch [21801/30000], Step [1/1], Training Loss: 1255.9111, Valid Loss: 64.7810
Epoch [21901/30000], Step [1/1], Training Loss: 1228.7858, Valid Loss: 62.2762
Epoch [22001/30000], Step [1/1], Training Loss: 1202.8268, Valid Loss: 60.3619
Epoch [22101/30000], Step [1/1], Training Loss: 1177.4050, Valid Loss: 64.9619
Epoch [22201/30000], Step [1/1], Training Loss: 1152.3884, Valid Loss: 62.1714
Epoch [22301/30000], Step [1/1], Training Loss: 1127.9099, Valid Loss: 64.9524
Epoch [22401/30000], Step [1/1], Training Loss: 1103.7072, Valid Loss: 62.7905
Epoch [22501/30000], Step [1/1], Training Loss: 1080.0155, Valid Loss: 63.3048
Epoch [22601/30000], Step [1/1], Training Loss: 1056.3409, Valid Loss: 59.9238
Epoch [22701/30000], Step [1/1], Training Loss: 1033.5730, Valid Loss: 60.4667
Epoch [22801/30000], Step [1/1], Training Loss: 1010.2165, Valid Loss: 60.9810
Epoch [22901/30000], Step [1/1], Training Loss: 987.4980, Valid Loss: 65.0667
Epoch [23001/30000], Step [1/1], Training Loss: 965.4628, Valid Loss: 62.2286
Epoch [23101/30000], Step [1/1], Training Loss: 943.5428, Valid Loss: 60.1143
Epoch [23201/30000], Step [1/1], Training Loss: 922.3544, Valid Loss: 61.3619
Epoch [23301/30000], Step [1/1], Training Loss: 901.4539, Valid Loss: 62.2381
Epoch [23401/30000], Step [1/1], Training Loss: 885.9001, Valid Loss: 58.6667
Epoch [23501/30000], Step [1/1], Training Loss: 861.4110, Valid Loss: 67.1810
Epoch [23601/30000], Step [1/1], Training Loss: 841.6830, Valid Loss: 58.6000
Epoch [23701/30000], Step [1/1], Training Loss: 822.5237, Valid Loss: 62.6000
Epoch [23801/30000], Step [1/1], Training Loss: 804.0066, Valid Loss: 60.3524
Epoch [23901/30000], Step [1/1], Training Loss: 786.2554, Valid Loss: 63.9048
Epoch [24001/30000], Step [1/1], Training Loss: 768.6370, Valid Loss: 60.9905
Epoch [24101/30000], Step [1/1], Training Loss: 751.5684, Valid Loss: 63.1619
Epoch [24201/30000], Step [1/1], Training Loss: 734.9871, Valid Loss: 60.5714
Epoch [24301/30000], Step [1/1], Training Loss: 719.0533, Valid Loss: 61.1429
Epoch [24401/30000], Step [1/1], Training Loss: 703.6451, Valid Loss: 58.1714
Epoch [24501/30000], Step [1/1], Training Loss: 688.5078, Valid Loss: 58.1238
Epoch [24601/30000], Step [1/1], Training Loss: 674.1763, Valid Loss: 61.9810
Epoch [24701/30000], Step [1/1], Training Loss: 659.3369, Valid Loss: 60.8381
Epoch [24801/30000], Step [1/1], Training Loss: 644.8503, Valid Loss: 61.5714
Epoch [24901/30000], Step [1/1], Training Loss: 651.7308, Valid Loss: 51.5619
Epoch [25001/30000], Step [1/1], Training Loss: 628.4556, Valid Loss: 50.1429
Epoch [25101/30000], Step [1/1], Training Loss: 613.1989, Valid Loss: 50.8000
Epoch [25201/30000], Step [1/1], Training Loss: 601.4202, Valid Loss: 52.7429
Epoch [25301/30000], Step [1/1], Training Loss: 589.4735, Valid Loss: 53.8762
Epoch [25401/30000], Step [1/1], Training Loss: 577.7382, Valid Loss: 51.6381
Epoch [25501/30000], Step [1/1], Training Loss: 565.4824, Valid Loss: 54.1524
Epoch [25601/30000], Step [1/1], Training Loss: 553.8074, Valid Loss: 52.7333
Epoch [25701/30000], Step [1/1], Training Loss: 548.1031, Valid Loss: 52.0191
Epoch [25801/30000], Step [1/1], Training Loss: 530.5479, Valid Loss: 55.5238
Epoch [25901/30000], Step [1/1], Training Loss: 519.3988, Valid Loss: 53.1429
Epoch [26001/30000], Step [1/1], Training Loss: 508.3445, Valid Loss: 52.6476
Epoch [26101/30000], Step [1/1], Training Loss: 497.0362, Valid Loss: 52.9905
Epoch [26201/30000], Step [1/1], Training Loss: 485.7457, Valid Loss: 53.9048
Epoch [26301/30000], Step [1/1], Training Loss: 475.2880, Valid Loss: 52.4571
Epoch [26401/30000], Step [1/1], Training Loss: 464.4059, Valid Loss: 57.2762
Epoch [26501/30000], Step [1/1], Training Loss: 453.8149, Valid Loss: 55.9714
Epoch [26601/30000], Step [1/1], Training Loss: 444.1611, Valid Loss: 52.6095
Epoch [26701/30000], Step [1/1], Training Loss: 433.1839, Valid Loss: 51.7810
Epoch [26801/30000], Step [1/1], Training Loss: 423.2574, Valid Loss: 54.9238
Epoch [26901/30000], Step [1/1], Training Loss: 413.5134, Valid Loss: 52.4762
Epoch [27001/30000], Step [1/1], Training Loss: 404.3588, Valid Loss: 54.3714
Epoch [27101/30000], Step [1/1], Training Loss: 396.3653, Valid Loss: 53.1905
Epoch [27201/30000], Step [1/1], Training Loss: 385.4076, Valid Loss: 54.9143
Epoch [27301/30000], Step [1/1], Training Loss: 375.5574, Valid Loss: 55.8952
Epoch [27401/30000], Step [1/1], Training Loss: 366.2572, Valid Loss: 54.2286
Epoch [27501/30000], Step [1/1], Training Loss: 356.8562, Valid Loss: 54.4667
Epoch [27601/30000], Step [1/1], Training Loss: 347.3406, Valid Loss: 51.6381
Epoch [27701/30000], Step [1/1], Training Loss: 338.2795, Valid Loss: 50.9238
Epoch [27801/30000], Step [1/1], Training Loss: 328.9674, Valid Loss: 56.7619
Epoch [27901/30000], Step [1/1], Training Loss: 319.7226, Valid Loss: 52.7524
Epoch [28001/30000], Step [1/1], Training Loss: 310.9103, Valid Loss: 53.1048
Epoch [28101/30000], Step [1/1], Training Loss: 301.7149, Valid Loss: 52.2191
Epoch [28201/30000], Step [1/1], Training Loss: 292.7422, Valid Loss: 56.6381
Epoch [28301/30000], Step [1/1], Training Loss: 283.9721, Valid Loss: 51.5619
Epoch [28401/30000], Step [1/1], Training Loss: 275.2205, Valid Loss: 52.4952
Epoch [28501/30000], Step [1/1], Training Loss: 266.7411, Valid Loss: 54.6190
Epoch [28601/30000], Step [1/1], Training Loss: 258.2436, Valid Loss: 52.2286
Epoch [28701/30000], Step [1/1], Training Loss: 249.9359, Valid Loss: 51.4571
Epoch [28801/30000], Step [1/1], Training Loss: 241.9012, Valid Loss: 50.7238
Epoch [28901/30000], Step [1/1], Training Loss: 235.5199, Valid Loss: 53.1619
Epoch [29001/30000], Step [1/1], Training Loss: 225.7879, Valid Loss: 54.8667
Epoch [29101/30000], Step [1/1], Training Loss: 218.0390, Valid Loss: 48.0476
Epoch [29201/30000], Step [1/1], Training Loss: 210.2375, Valid Loss: 53.5714
Epoch [29301/30000], Step [1/1], Training Loss: 202.6390, Valid Loss: 51.0762
Epoch [29401/30000], Step [1/1], Training Loss: 195.4374, Valid Loss: 51.0286
Epoch [29501/30000], Step [1/1], Training Loss: 188.3034, Valid Loss: 53.4286
Epoch [29601/30000], Step [1/1], Training Loss: 181.0264, Valid Loss: 53.5238
Epoch [29701/30000], Step [1/1], Training Loss: 174.1733, Valid Loss: 53.9429
Epoch [29801/30000], Step [1/1], Training Loss: 167.1633, Valid Loss: 53.7429
Epoch [29901/30000], Step [1/1], Training Loss: 160.6378, Valid Loss: 55.1619

 End Time: 2021/04/19, 03:21:19




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=512 	layers=3

Start Time = 2021/04/19, 03:21:19
##########################################################


[Epoch 0] Rounded prediction: 
tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],
       device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([ 8., 11., 12., 11., 14., 17., 17., 10., 11., 10., 10., 10.,  8.,  7.,
         8.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  6.,
         9.,  2.,  0.,  0.,  6.,  6.,  5.,  0., 11., 28., 18., 19., 24., 19.,
        23., 29., 23., 30., 28., 18., 23.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([ 8., 15., 12.,  9., 13., 18., 18., 13.,  9., 13.,  8., 12., 10., 11.,
        10.,  6.,  4.,  0.,  2.,  5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  6.,  2.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  1.,
         0.,  0.,  5., 11.,  5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         1.,  9.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,
         6.,  0.,  0.,  5.,  8.,  1.,  0.,  0.,  3.,  3.,  0.,  2.,  0.,  9.,
        16., 15.,  3.,  0.,  6.,  5.,  0.,  0., 17., 24., 17., 26., 36., 27.,
        28., 32., 23., 21., 28., 21., 20.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128664.2422, Valid Loss: 237.9619
Epoch [101/30000], Step [1/1], Training Loss: 121148.2734, Valid Loss: 118.3048
Epoch [201/30000], Step [1/1], Training Loss: 118757.5938, Valid Loss: 192.8286
Epoch [301/30000], Step [1/1], Training Loss: 116512.7734, Valid Loss: 317.3524
Epoch [401/30000], Step [1/1], Training Loss: 114357.9531, Valid Loss: 491.8762
Epoch [501/30000], Step [1/1], Training Loss: 112275.0312, Valid Loss: 716.4000
Epoch [601/30000], Step [1/1], Training Loss: 110256.9922, Valid Loss: 990.9238
Epoch [701/30000], Step [1/1], Training Loss: 108302.5703, Valid Loss: 1315.4476
Epoch [801/30000], Step [1/1], Training Loss: 106405.4766, Valid Loss: 1689.9714
Epoch [901/30000], Step [1/1], Training Loss: 104561.8203, Valid Loss: 2109.8381
Epoch [1001/30000], Step [1/1], Training Loss: 102768.1016, Valid Loss: 1938.9906
Epoch [1101/30000], Step [1/1], Training Loss: 101020.4453, Valid Loss: 1462.4095
Epoch [1201/30000], Step [1/1], Training Loss: 99320.1953, Valid Loss: 1374.2953
Epoch [1301/30000], Step [1/1], Training Loss: 97370.9531, Valid Loss: 112.9048
Epoch [1401/30000], Step [1/1], Training Loss: 95633.3906, Valid Loss: 114.0857
Epoch [1501/30000], Step [1/1], Training Loss: 93939.0547, Valid Loss: 119.5810
Epoch [1601/30000], Step [1/1], Training Loss: 92287.3047, Valid Loss: 125.3143
Epoch [1701/30000], Step [1/1], Training Loss: 90641.9219, Valid Loss: 115.8952
Epoch [1801/30000], Step [1/1], Training Loss: 89037.7812, Valid Loss: 106.3524
Epoch [1901/30000], Step [1/1], Training Loss: 87465.2188, Valid Loss: 113.2381
Epoch [2001/30000], Step [1/1], Training Loss: 85920.2344, Valid Loss: 114.3619
Epoch [2101/30000], Step [1/1], Training Loss: 84411.4062, Valid Loss: 119.1333
Epoch [2201/30000], Step [1/1], Training Loss: 82929.6562, Valid Loss: 112.5333
Epoch [2301/30000], Step [1/1], Training Loss: 81480.8047, Valid Loss: 116.9429
Epoch [2401/30000], Step [1/1], Training Loss: 80052.7891, Valid Loss: 116.4476
Epoch [2501/30000], Step [1/1], Training Loss: 78625.9062, Valid Loss: 125.7429
Epoch [2601/30000], Step [1/1], Training Loss: 77227.9375, Valid Loss: 122.2476
Epoch [2701/30000], Step [1/1], Training Loss: 75866.4844, Valid Loss: 117.2857
Epoch [2801/30000], Step [1/1], Training Loss: 74536.1875, Valid Loss: 124.4381
Epoch [2901/30000], Step [1/1], Training Loss: 73233.9453, Valid Loss: 122.4191
Epoch [3001/30000], Step [1/1], Training Loss: 71953.7109, Valid Loss: 125.8857
Epoch [3101/30000], Step [1/1], Training Loss: 70699.8984, Valid Loss: 126.2667
Epoch [3201/30000], Step [1/1], Training Loss: 69471.3438, Valid Loss: 125.2571
Epoch [3301/30000], Step [1/1], Training Loss: 68266.2266, Valid Loss: 123.5333
Epoch [3401/30000], Step [1/1], Training Loss: 67085.9609, Valid Loss: 128.6190
Epoch [3501/30000], Step [1/1], Training Loss: 65929.9297, Valid Loss: 126.7714
Epoch [3601/30000], Step [1/1], Training Loss: 64797.6914, Valid Loss: 125.0571
Epoch [3701/30000], Step [1/1], Training Loss: 63687.9766, Valid Loss: 124.9619
Epoch [3801/30000], Step [1/1], Training Loss: 62603.9375, Valid Loss: 108.0286
Epoch [3901/30000], Step [1/1], Training Loss: 61538.8906, Valid Loss: 118.7238
Epoch [4001/30000], Step [1/1], Training Loss: 60500.0898, Valid Loss: 119.3619
Epoch [4101/30000], Step [1/1], Training Loss: 59481.6016, Valid Loss: 122.3048
Epoch [4201/30000], Step [1/1], Training Loss: 58485.1289, Valid Loss: 123.4762
Epoch [4301/30000], Step [1/1], Training Loss: 57510.3320, Valid Loss: 121.0952
Epoch [4401/30000], Step [1/1], Training Loss: 56560.1836, Valid Loss: 116.0571
Epoch [4501/30000], Step [1/1], Training Loss: 55627.3789, Valid Loss: 125.2571
Epoch [4601/30000], Step [1/1], Training Loss: 54717.6797, Valid Loss: 128.3048
Epoch [4701/30000], Step [1/1], Training Loss: 53829.8086, Valid Loss: 117.6952
Epoch [4801/30000], Step [1/1], Training Loss: 52963.8438, Valid Loss: 131.9810
Epoch [4901/30000], Step [1/1], Training Loss: 52101.8438, Valid Loss: 124.2286
Epoch [5001/30000], Step [1/1], Training Loss: 50951.0430, Valid Loss: 119.6286
Epoch [5101/30000], Step [1/1], Training Loss: 50033.4258, Valid Loss: 112.2000
Epoch [5201/30000], Step [1/1], Training Loss: 49169.7109, Valid Loss: 119.8476
Epoch [5301/30000], Step [1/1], Training Loss: 48360.7812, Valid Loss: 122.5238
Epoch [5401/30000], Step [1/1], Training Loss: 47443.2539, Valid Loss: 121.5619
Epoch [5501/30000], Step [1/1], Training Loss: 46624.1992, Valid Loss: 117.3714
Epoch [5601/30000], Step [1/1], Training Loss: 45787.0703, Valid Loss: 117.9619
Epoch [5701/30000], Step [1/1], Training Loss: 45042.9922, Valid Loss: 115.0095
Epoch [5801/30000], Step [1/1], Training Loss: 44216.9297, Valid Loss: 120.8095
Epoch [5901/30000], Step [1/1], Training Loss: 43464.3320, Valid Loss: 120.4000
Epoch [6001/30000], Step [1/1], Training Loss: 42746.1367, Valid Loss: 119.2191
Epoch [6101/30000], Step [1/1], Training Loss: 42017.1250, Valid Loss: 118.1524
Epoch [6201/30000], Step [1/1], Training Loss: 41305.3086, Valid Loss: 118.0381
Epoch [6301/30000], Step [1/1], Training Loss: 40612.4688, Valid Loss: 119.2571
Epoch [6401/30000], Step [1/1], Training Loss: 39938.2422, Valid Loss: 121.7810
Epoch [6501/30000], Step [1/1], Training Loss: 39261.0000, Valid Loss: 121.0952
Epoch [6601/30000], Step [1/1], Training Loss: 38495.3828, Valid Loss: 105.5810
Epoch [6701/30000], Step [1/1], Training Loss: 37858.1328, Valid Loss: 108.4286
Epoch [6801/30000], Step [1/1], Training Loss: 37034.0469, Valid Loss: 113.4191
Epoch [6901/30000], Step [1/1], Training Loss: 36301.8008, Valid Loss: 112.8286
Epoch [7001/30000], Step [1/1], Training Loss: 35674.5664, Valid Loss: 116.2191
Epoch [7101/30000], Step [1/1], Training Loss: 34798.7734, Valid Loss: 117.6667
Epoch [7201/30000], Step [1/1], Training Loss: 34125.9219, Valid Loss: 109.2000
Epoch [7301/30000], Step [1/1], Training Loss: 33474.2969, Valid Loss: 114.0000
Epoch [7401/30000], Step [1/1], Training Loss: 32850.0078, Valid Loss: 114.9238
Epoch [7501/30000], Step [1/1], Training Loss: 32229.3789, Valid Loss: 112.7333
Epoch [7601/30000], Step [1/1], Training Loss: 31645.9609, Valid Loss: 116.7333
Epoch [7701/30000], Step [1/1], Training Loss: 30911.6953, Valid Loss: 112.8667
Epoch [7801/30000], Step [1/1], Training Loss: 30261.1777, Valid Loss: 115.0476
Epoch [7901/30000], Step [1/1], Training Loss: 29666.8164, Valid Loss: 115.1333
Epoch [8001/30000], Step [1/1], Training Loss: 29083.8965, Valid Loss: 112.0857
Epoch [8101/30000], Step [1/1], Training Loss: 28607.5996, Valid Loss: 116.6190
Epoch [8201/30000], Step [1/1], Training Loss: 27978.5215, Valid Loss: 114.0571
Epoch [8301/30000], Step [1/1], Training Loss: 27418.3145, Valid Loss: 110.1333
Epoch [8401/30000], Step [1/1], Training Loss: 26887.0898, Valid Loss: 113.6381
Epoch [8501/30000], Step [1/1], Training Loss: 26381.2637, Valid Loss: 114.0762
Epoch [8601/30000], Step [1/1], Training Loss: 25889.2051, Valid Loss: 110.7905
Epoch [8701/30000], Step [1/1], Training Loss: 25409.4688, Valid Loss: 113.9810
Epoch [8801/30000], Step [1/1], Training Loss: 24918.8926, Valid Loss: 113.4857
Epoch [8901/30000], Step [1/1], Training Loss: 24454.8926, Valid Loss: 115.6762
Epoch [9001/30000], Step [1/1], Training Loss: 24003.3086, Valid Loss: 112.3619
Epoch [9101/30000], Step [1/1], Training Loss: 23561.0352, Valid Loss: 114.6381
Epoch [9201/30000], Step [1/1], Training Loss: 23132.4258, Valid Loss: 114.8571
Epoch [9301/30000], Step [1/1], Training Loss: 22709.0605, Valid Loss: 110.8571
Epoch [9401/30000], Step [1/1], Training Loss: 22384.8301, Valid Loss: 114.7429
Epoch [9501/30000], Step [1/1], Training Loss: 21921.8809, Valid Loss: 113.4095
Epoch [9601/30000], Step [1/1], Training Loss: 21519.4648, Valid Loss: 103.8095
Epoch [9701/30000], Step [1/1], Training Loss: 21133.0781, Valid Loss: 106.3048
Epoch [9801/30000], Step [1/1], Training Loss: 20760.0781, Valid Loss: 105.0762
Epoch [9901/30000], Step [1/1], Training Loss: 20351.1055, Valid Loss: 109.9429
Epoch [10001/30000], Step [1/1], Training Loss: 19919.2129, Valid Loss: 107.7238
Epoch [10101/30000], Step [1/1], Training Loss: 19512.1152, Valid Loss: 109.7905

[Epoch 15000] Rounded prediction: 
tensor([ 8., 14.,  8.,  9., 11., 17., 18., 11.,  9., 11.,  6.,  8.,  9.,  7.,
         6.,  6.,  6.,  4.,  6., 15.,  0.,  0.,  2.,  0.,  1.,  0.,  5.,  0.,
         0.,  0.,  0.,  3., 10.,  0.,  0.,  1.,  1.,  3.,  5.,  0.,  0.,  6.,
         0.,  1.,  5., 12.,  6.,  2.,  0.,  6.,  8.,  0.,  0.,  0.,  1.,  1.,
         2., 10.,  5.,  0.,  0.,  0.,  5.,  1.,  2.,  0.,  0.,  0.,  0., 10.,
         8.,  0.,  0.,  2., 11.,  0.,  0.,  7.,  5.,  9.,  0.,  6.,  0., 15.,
        25., 13.,  0.,  0.,  4.,  6.,  1.,  8., 29., 20., 18., 31., 38., 29.,
        32., 32., 26., 24., 25., 16., 19.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([10., 14., 12., 12., 18., 20., 19., 16., 12., 13., 12., 12., 13., 16.,
        13., 14., 13., 13., 13., 14.,  1.,  3.,  1.,  0.,  2.,  3.,  7.,  4.,
         0.,  0.,  2.,  3., 11.,  3.,  1.,  0.,  1.,  4.,  3.,  2.,  2.,  4.,
         3.,  5.,  6., 12.,  8.,  3.,  1.,  2., 10.,  3.,  0.,  0.,  2.,  6.,
         4., 12.,  8.,  0.,  0.,  0.,  4.,  6.,  3.,  0.,  1.,  0.,  0.,  9.,
        10.,  2.,  2., 10., 16.,  6.,  0., 10., 10.,  8.,  1., 10.,  2., 19.,
        32., 18.,  5.,  2.,  8.,  8.,  0., 15., 34., 23., 19., 37., 46., 33.,
        37., 34., 19., 25., 31., 13., 13.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [10201/30000], Step [1/1], Training Loss: 19211.0566, Valid Loss: 111.9619
Epoch [10301/30000], Step [1/1], Training Loss: 18759.1074, Valid Loss: 109.1333
Epoch [10401/30000], Step [1/1], Training Loss: 18378.8066, Valid Loss: 110.8667
Epoch [10501/30000], Step [1/1], Training Loss: 18026.7305, Valid Loss: 106.5143
Epoch [10601/30000], Step [1/1], Training Loss: 17703.7988, Valid Loss: 108.8000
Epoch [10701/30000], Step [1/1], Training Loss: 17361.7324, Valid Loss: 104.6095
Epoch [10801/30000], Step [1/1], Training Loss: 17037.0137, Valid Loss: 101.1333
Epoch [10901/30000], Step [1/1], Training Loss: 16725.2871, Valid Loss: 97.0286
Epoch [11001/30000], Step [1/1], Training Loss: 16423.4844, Valid Loss: 101.3810
Epoch [11101/30000], Step [1/1], Training Loss: 16132.2139, Valid Loss: 98.0571
Epoch [11201/30000], Step [1/1], Training Loss: 15840.2871, Valid Loss: 100.3905
Epoch [11301/30000], Step [1/1], Training Loss: 15559.5117, Valid Loss: 97.7714
Epoch [11401/30000], Step [1/1], Training Loss: 15714.8613, Valid Loss: 110.4286
Epoch [11501/30000], Step [1/1], Training Loss: 15066.5215, Valid Loss: 103.4762
Epoch [11601/30000], Step [1/1], Training Loss: 14439.4854, Valid Loss: 98.3810
Epoch [11701/30000], Step [1/1], Training Loss: 14253.8818, Valid Loss: 95.2381
Epoch [11801/30000], Step [1/1], Training Loss: 13972.7119, Valid Loss: 98.6476
Epoch [11901/30000], Step [1/1], Training Loss: 13706.8525, Valid Loss: 94.8095
Epoch [12001/30000], Step [1/1], Training Loss: 13453.0068, Valid Loss: 94.6095
Epoch [12101/30000], Step [1/1], Training Loss: 13205.1133, Valid Loss: 93.5048
Epoch [12201/30000], Step [1/1], Training Loss: 12969.8271, Valid Loss: 97.4381
Epoch [12301/30000], Step [1/1], Training Loss: 12733.2812, Valid Loss: 95.0762
Epoch [12401/30000], Step [1/1], Training Loss: 12502.9980, Valid Loss: 96.2857
Epoch [12501/30000], Step [1/1], Training Loss: 12285.5088, Valid Loss: 93.5810
Epoch [12601/30000], Step [1/1], Training Loss: 12072.8574, Valid Loss: 98.3048
Epoch [12701/30000], Step [1/1], Training Loss: 11866.2451, Valid Loss: 90.8381
Epoch [12801/30000], Step [1/1], Training Loss: 11666.5088, Valid Loss: 92.0857
Epoch [12901/30000], Step [1/1], Training Loss: 11475.5996, Valid Loss: 95.1143
Epoch [13001/30000], Step [1/1], Training Loss: 11287.2188, Valid Loss: 96.9333
Epoch [13101/30000], Step [1/1], Training Loss: 11107.6826, Valid Loss: 96.7238
Epoch [13201/30000], Step [1/1], Training Loss: 10931.3203, Valid Loss: 95.6190
Epoch [13301/30000], Step [1/1], Training Loss: 10761.8740, Valid Loss: 96.3619
Epoch [13401/30000], Step [1/1], Training Loss: 10598.5664, Valid Loss: 92.7810
Epoch [13501/30000], Step [1/1], Training Loss: 10440.3447, Valid Loss: 98.1524
Epoch [13601/30000], Step [1/1], Training Loss: 10287.4443, Valid Loss: 95.6000
Epoch [13701/30000], Step [1/1], Training Loss: 11123.5381, Valid Loss: 102.1333
Epoch [13801/30000], Step [1/1], Training Loss: 9603.0215, Valid Loss: 85.5429
Epoch [13901/30000], Step [1/1], Training Loss: 9161.9492, Valid Loss: 95.9333
Epoch [14001/30000], Step [1/1], Training Loss: 8652.0381, Valid Loss: 90.2000
Epoch [14101/30000], Step [1/1], Training Loss: 8457.0430, Valid Loss: 96.6667
Epoch [14201/30000], Step [1/1], Training Loss: 8274.3232, Valid Loss: 98.3238
Epoch [14301/30000], Step [1/1], Training Loss: 8098.4858, Valid Loss: 96.9524
Epoch [14401/30000], Step [1/1], Training Loss: 7931.5908, Valid Loss: 97.4857
Epoch [14501/30000], Step [1/1], Training Loss: 7770.0288, Valid Loss: 97.4476
Epoch [14601/30000], Step [1/1], Training Loss: 7614.2324, Valid Loss: 94.5333
Epoch [14701/30000], Step [1/1], Training Loss: 7459.1562, Valid Loss: 97.3905
Epoch [14801/30000], Step [1/1], Training Loss: 7307.1104, Valid Loss: 92.9143
Epoch [14901/30000], Step [1/1], Training Loss: 7167.1206, Valid Loss: 96.9333
Epoch [15001/30000], Step [1/1], Training Loss: 7029.6104, Valid Loss: 94.9238
Epoch [15101/30000], Step [1/1], Training Loss: 6899.3564, Valid Loss: 96.2476
Epoch [15201/30000], Step [1/1], Training Loss: 6774.5874, Valid Loss: 96.7143
Epoch [15301/30000], Step [1/1], Training Loss: 6652.4653, Valid Loss: 96.1524
Epoch [15401/30000], Step [1/1], Training Loss: 6533.0054, Valid Loss: 94.8095
Epoch [15501/30000], Step [1/1], Training Loss: 6384.0732, Valid Loss: 92.6571
Epoch [15601/30000], Step [1/1], Training Loss: 6625.5625, Valid Loss: 97.0286
Epoch [15701/30000], Step [1/1], Training Loss: 5852.6606, Valid Loss: 103.2952
Epoch [15801/30000], Step [1/1], Training Loss: 5718.6953, Valid Loss: 98.9714
Epoch [15901/30000], Step [1/1], Training Loss: 5584.8364, Valid Loss: 103.7048
Epoch [16001/30000], Step [1/1], Training Loss: 5466.4292, Valid Loss: 104.9905
Epoch [16101/30000], Step [1/1], Training Loss: 5320.0444, Valid Loss: 97.6476
Epoch [16201/30000], Step [1/1], Training Loss: 5195.5845, Valid Loss: 98.0286
Epoch [16301/30000], Step [1/1], Training Loss: 5070.6533, Valid Loss: 103.4952
Epoch [16401/30000], Step [1/1], Training Loss: 4817.5645, Valid Loss: 96.8095
Epoch [16501/30000], Step [1/1], Training Loss: 4627.3960, Valid Loss: 101.5905
Epoch [16601/30000], Step [1/1], Training Loss: 4502.5078, Valid Loss: 97.1333
Epoch [16701/30000], Step [1/1], Training Loss: 4385.9116, Valid Loss: 94.3810
Epoch [16801/30000], Step [1/1], Training Loss: 4270.9790, Valid Loss: 97.1333
Epoch [16901/30000], Step [1/1], Training Loss: 4159.9429, Valid Loss: 93.7048
Epoch [17001/30000], Step [1/1], Training Loss: 4054.3364, Valid Loss: 96.9429
Epoch [17101/30000], Step [1/1], Training Loss: 3950.8662, Valid Loss: 92.9143
Epoch [17201/30000], Step [1/1], Training Loss: 3850.9719, Valid Loss: 97.2000
Epoch [17301/30000], Step [1/1], Training Loss: 3753.4697, Valid Loss: 97.2095
Epoch [17401/30000], Step [1/1], Training Loss: 3659.4946, Valid Loss: 96.7238
Epoch [17501/30000], Step [1/1], Training Loss: 3569.5942, Valid Loss: 94.3810
Epoch [17601/30000], Step [1/1], Training Loss: 3479.4934, Valid Loss: 98.3143
Epoch [17701/30000], Step [1/1], Training Loss: 3393.0830, Valid Loss: 96.5238
Epoch [17801/30000], Step [1/1], Training Loss: 3308.7046, Valid Loss: 96.2381
Epoch [17901/30000], Step [1/1], Training Loss: 3226.3740, Valid Loss: 93.3333
Epoch [18001/30000], Step [1/1], Training Loss: 3146.0112, Valid Loss: 98.3238
Epoch [18101/30000], Step [1/1], Training Loss: 3068.3486, Valid Loss: 93.7810
Epoch [18201/30000], Step [1/1], Training Loss: 2992.3904, Valid Loss: 97.7619
Epoch [18301/30000], Step [1/1], Training Loss: 2919.4626, Valid Loss: 88.9143
Epoch [18401/30000], Step [1/1], Training Loss: 2845.4182, Valid Loss: 95.8762
Epoch [18501/30000], Step [1/1], Training Loss: 2775.1245, Valid Loss: 93.1429
Epoch [18601/30000], Step [1/1], Training Loss: 2705.7502, Valid Loss: 94.2286
Epoch [18701/30000], Step [1/1], Training Loss: 2638.5920, Valid Loss: 92.0762
Epoch [18801/30000], Step [1/1], Training Loss: 2573.0200, Valid Loss: 93.0000
Epoch [18901/30000], Step [1/1], Training Loss: 2507.7085, Valid Loss: 91.6000
Epoch [19001/30000], Step [1/1], Training Loss: 2444.2881, Valid Loss: 94.0476
Epoch [19101/30000], Step [1/1], Training Loss: 2383.2344, Valid Loss: 92.3524
Epoch [19201/30000], Step [1/1], Training Loss: 2321.9890, Valid Loss: 89.7905
Epoch [19301/30000], Step [1/1], Training Loss: 2262.9626, Valid Loss: 93.1619
Epoch [19401/30000], Step [1/1], Training Loss: 2205.8757, Valid Loss: 93.7905
Epoch [19501/30000], Step [1/1], Training Loss: 2150.0474, Valid Loss: 94.2857
Epoch [19601/30000], Step [1/1], Training Loss: 2096.5505, Valid Loss: 93.1810
Epoch [19701/30000], Step [1/1], Training Loss: 2044.2739, Valid Loss: 88.2476
Epoch [19801/30000], Step [1/1], Training Loss: 1992.5704, Valid Loss: 92.6762
Epoch [19901/30000], Step [1/1], Training Loss: 1942.9413, Valid Loss: 89.3810
Epoch [20001/30000], Step [1/1], Training Loss: 1895.1641, Valid Loss: 91.9905
Epoch [20101/30000], Step [1/1], Training Loss: 1848.3832, Valid Loss: 96.3810
Epoch [20201/30000], Step [1/1], Training Loss: 1803.8346, Valid Loss: 92.3238
Epoch [20301/30000], Step [1/1], Training Loss: 1761.5045, Valid Loss: 94.3048

[Epoch 25000] Rounded prediction: 
tensor([11., 14., 13., 13., 22., 23., 20., 17., 15., 17., 17., 18., 19., 20.,
        19., 19., 22., 22., 17., 17.,  3.,  4.,  0.,  0.,  5.,  6.,  8.,  3.,
         0.,  0.,  0.,  6., 15.,  4.,  1.,  3.,  4.,  4.,  3.,  1.,  1.,  6.,
         2.,  6.,  9., 15.,  9.,  6.,  2.,  6., 13.,  3.,  0.,  0.,  0.,  8.,
         5., 13.,  8.,  0.,  1.,  0.,  5.,  6.,  7.,  0.,  4.,  0.,  0., 10.,
        15.,  8.,  6., 10., 19., 13.,  3.,  2., 13.,  6.,  1., 14.,  0., 17.,
        37., 21.,  6.,  4., 12., 13.,  5., 13., 31., 23., 26., 40., 49., 30.,
        29., 30., 16., 16., 22., 16., 13.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [20401/30000], Step [1/1], Training Loss: 1718.6102, Valid Loss: 90.7048
Epoch [20501/30000], Step [1/1], Training Loss: 1678.3213, Valid Loss: 89.4381
Epoch [20601/30000], Step [1/1], Training Loss: 1639.6300, Valid Loss: 94.2286
Epoch [20701/30000], Step [1/1], Training Loss: 1601.4630, Valid Loss: 94.9429
Epoch [20801/30000], Step [1/1], Training Loss: 1565.4028, Valid Loss: 90.4952
Epoch [20901/30000], Step [1/1], Training Loss: 1569.4630, Valid Loss: 106.5714
Epoch [21001/30000], Step [1/1], Training Loss: 1506.9188, Valid Loss: 106.2762
Epoch [21101/30000], Step [1/1], Training Loss: 1472.4983, Valid Loss: 113.2667
Epoch [21201/30000], Step [1/1], Training Loss: 1439.3038, Valid Loss: 108.9333
Epoch [21301/30000], Step [1/1], Training Loss: 1407.9120, Valid Loss: 106.2952
Epoch [21401/30000], Step [1/1], Training Loss: 1378.6841, Valid Loss: 108.2571
Epoch [21501/30000], Step [1/1], Training Loss: 1348.7100, Valid Loss: 107.2667
Epoch [21601/30000], Step [1/1], Training Loss: 1320.7307, Valid Loss: 109.2762
Epoch [21701/30000], Step [1/1], Training Loss: 1293.6337, Valid Loss: 105.8952
Epoch [21801/30000], Step [1/1], Training Loss: 1266.5386, Valid Loss: 111.0667
Epoch [21901/30000], Step [1/1], Training Loss: 1241.0640, Valid Loss: 109.5429
Epoch [22001/30000], Step [1/1], Training Loss: 1214.9216, Valid Loss: 106.8095
Epoch [22101/30000], Step [1/1], Training Loss: 1189.7692, Valid Loss: 103.5048
Epoch [22201/30000], Step [1/1], Training Loss: 1165.8370, Valid Loss: 104.1048
Epoch [22301/30000], Step [1/1], Training Loss: 1142.1938, Valid Loss: 106.9524
Epoch [22401/30000], Step [1/1], Training Loss: 1119.3018, Valid Loss: 103.4952
Epoch [22501/30000], Step [1/1], Training Loss: 1095.5551, Valid Loss: 110.3238
Epoch [22601/30000], Step [1/1], Training Loss: 1073.6180, Valid Loss: 109.7333
Epoch [22701/30000], Step [1/1], Training Loss: 1052.4210, Valid Loss: 107.1429
Epoch [22801/30000], Step [1/1], Training Loss: 1031.3701, Valid Loss: 101.3048
Epoch [22901/30000], Step [1/1], Training Loss: 1003.7568, Valid Loss: 111.0095
Epoch [23001/30000], Step [1/1], Training Loss: 979.9037, Valid Loss: 109.6762
Epoch [23101/30000], Step [1/1], Training Loss: 958.1147, Valid Loss: 110.1143
Epoch [23201/30000], Step [1/1], Training Loss: 935.8062, Valid Loss: 111.5048
Epoch [23301/30000], Step [1/1], Training Loss: 914.7996, Valid Loss: 106.1905
Epoch [23401/30000], Step [1/1], Training Loss: 893.6980, Valid Loss: 106.6095
Epoch [23501/30000], Step [1/1], Training Loss: 874.1450, Valid Loss: 107.9048
Epoch [23601/30000], Step [1/1], Training Loss: 853.3326, Valid Loss: 105.7619
Epoch [23701/30000], Step [1/1], Training Loss: 833.9502, Valid Loss: 106.3333
Epoch [23801/30000], Step [1/1], Training Loss: 814.7613, Valid Loss: 105.2286
Epoch [23901/30000], Step [1/1], Training Loss: 797.0535, Valid Loss: 109.5238
Epoch [24001/30000], Step [1/1], Training Loss: 778.6777, Valid Loss: 109.1143
Epoch [24101/30000], Step [1/1], Training Loss: 760.9999, Valid Loss: 102.6286
Epoch [24201/30000], Step [1/1], Training Loss: 744.2609, Valid Loss: 109.8286
Epoch [24301/30000], Step [1/1], Training Loss: 727.8940, Valid Loss: 104.6952
Epoch [24401/30000], Step [1/1], Training Loss: 712.0436, Valid Loss: 109.8857
Epoch [24501/30000], Step [1/1], Training Loss: 696.4712, Valid Loss: 104.6381
Epoch [24601/30000], Step [1/1], Training Loss: 681.2681, Valid Loss: 106.1714
Epoch [24701/30000], Step [1/1], Training Loss: 666.6301, Valid Loss: 104.9905
Epoch [24801/30000], Step [1/1], Training Loss: 651.8688, Valid Loss: 102.9048
Epoch [24901/30000], Step [1/1], Training Loss: 637.4232, Valid Loss: 103.6190
Epoch [25001/30000], Step [1/1], Training Loss: 623.3903, Valid Loss: 103.5429
Epoch [25101/30000], Step [1/1], Training Loss: 609.6062, Valid Loss: 104.0762
Epoch [25201/30000], Step [1/1], Training Loss: 595.8694, Valid Loss: 104.9048
Epoch [25301/30000], Step [1/1], Training Loss: 582.3812, Valid Loss: 102.0381
Epoch [25401/30000], Step [1/1], Training Loss: 569.1357, Valid Loss: 104.4191
Epoch [25501/30000], Step [1/1], Training Loss: 555.4411, Valid Loss: 108.2762
Epoch [25601/30000], Step [1/1], Training Loss: 542.5129, Valid Loss: 102.2095
Epoch [25701/30000], Step [1/1], Training Loss: 529.6936, Valid Loss: 101.3333
Epoch [25801/30000], Step [1/1], Training Loss: 517.0684, Valid Loss: 105.0191
Epoch [25901/30000], Step [1/1], Training Loss: 505.1221, Valid Loss: 104.6952
Epoch [26001/30000], Step [1/1], Training Loss: 492.6862, Valid Loss: 104.0381
Epoch [26101/30000], Step [1/1], Training Loss: 480.6077, Valid Loss: 102.8762
Epoch [26201/30000], Step [1/1], Training Loss: 469.2634, Valid Loss: 107.5619
Epoch [26301/30000], Step [1/1], Training Loss: 457.7985, Valid Loss: 114.7238
Epoch [26401/30000], Step [1/1], Training Loss: 446.5227, Valid Loss: 106.0286
Epoch [26501/30000], Step [1/1], Training Loss: 435.7194, Valid Loss: 109.2286
Epoch [26601/30000], Step [1/1], Training Loss: 425.0918, Valid Loss: 109.6095
Epoch [26701/30000], Step [1/1], Training Loss: 414.9178, Valid Loss: 106.8191
Epoch [26801/30000], Step [1/1], Training Loss: 404.9829, Valid Loss: 108.8476
Epoch [26901/30000], Step [1/1], Training Loss: 394.8249, Valid Loss: 107.9714
Epoch [27001/30000], Step [1/1], Training Loss: 385.2022, Valid Loss: 107.6572
Epoch [27101/30000], Step [1/1], Training Loss: 375.2180, Valid Loss: 108.5905
Epoch [27201/30000], Step [1/1], Training Loss: 365.5155, Valid Loss: 106.5905
Epoch [27301/30000], Step [1/1], Training Loss: 355.6884, Valid Loss: 106.6095
Epoch [27401/30000], Step [1/1], Training Loss: 346.0346, Valid Loss: 105.4571
Epoch [27501/30000], Step [1/1], Training Loss: 336.5156, Valid Loss: 106.3714
Epoch [27601/30000], Step [1/1], Training Loss: 327.2290, Valid Loss: 107.9143
Epoch [27701/30000], Step [1/1], Training Loss: 317.8576, Valid Loss: 109.0000
Epoch [27801/30000], Step [1/1], Training Loss: 308.6182, Valid Loss: 110.2191
Epoch [27901/30000], Step [1/1], Training Loss: 299.4899, Valid Loss: 112.7333
Epoch [28001/30000], Step [1/1], Training Loss: 290.4187, Valid Loss: 112.8476
Epoch [28101/30000], Step [1/1], Training Loss: 281.6552, Valid Loss: 109.0857
Epoch [28201/30000], Step [1/1], Training Loss: 272.8197, Valid Loss: 112.8857
Epoch [28301/30000], Step [1/1], Training Loss: 264.1156, Valid Loss: 109.2571
Epoch [28401/30000], Step [1/1], Training Loss: 255.9247, Valid Loss: 109.9524
Epoch [28501/30000], Step [1/1], Training Loss: 247.1706, Valid Loss: 116.3048
Epoch [28601/30000], Step [1/1], Training Loss: 239.2006, Valid Loss: 114.8381
Epoch [28701/30000], Step [1/1], Training Loss: 231.0183, Valid Loss: 112.2762
Epoch [28801/30000], Step [1/1], Training Loss: 223.0530, Valid Loss: 114.5143
Epoch [28901/30000], Step [1/1], Training Loss: 215.1826, Valid Loss: 112.4000
Epoch [29001/30000], Step [1/1], Training Loss: 207.6147, Valid Loss: 114.4000
Epoch [29101/30000], Step [1/1], Training Loss: 200.2003, Valid Loss: 116.2000
Epoch [29201/30000], Step [1/1], Training Loss: 192.6175, Valid Loss: 117.5619
Epoch [29301/30000], Step [1/1], Training Loss: 185.4844, Valid Loss: 122.3429
Epoch [29401/30000], Step [1/1], Training Loss: 178.4161, Valid Loss: 118.4191
Epoch [29501/30000], Step [1/1], Training Loss: 171.5789, Valid Loss: 119.1143
Epoch [29601/30000], Step [1/1], Training Loss: 164.9617, Valid Loss: 116.7619
Epoch [29701/30000], Step [1/1], Training Loss: 158.0883, Valid Loss: 114.4476
Epoch [29801/30000], Step [1/1], Training Loss: 151.7434, Valid Loss: 114.1238
Epoch [29901/30000], Step [1/1], Training Loss: 145.5095, Valid Loss: 116.7143

 End Time: 2021/04/19, 03:29:58




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=256 	layers=3

Start Time = 2021/04/19, 03:33:19
##########################################################


[Epoch 0] Rounded prediction: 
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([ 7., 18., 12., 17., 21., 19., 25., 16., 15., 19., 21., 23., 20., 15.,
        23., 11., 12.,  2.,  3.,  4.,  8.,  8.,  8.,  9.,  8.,  1.,  7., 11.,
         7.,  3., 11.,  1.,  4.,  8.,  6.,  3.,  3.,  3.,  3.,  2.,  3., 13.,
        16., 15.,  5.,  8.,  9.,  7.,  7., 11.,  9.,  6.,  7.,  1.,  5.,  5.,
         3.,  9., 10.,  8.,  5.,  8.,  8., 15.,  7., 10., 13., 14., 16., 23.,
        23., 20., 25., 29., 21.,  8., 13.,  3., 11., 16., 14., 27., 13., 23.,
        32., 34., 29., 28., 24., 22.,  8.,  0., 12., 11., 20., 39., 55., 41.,
        39., 46., 39., 45., 41., 27., 27.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([ 9.,  9., 10., 18., 21., 21., 31., 18., 13., 15., 13., 12., 13., 13.,
        10., 10.,  5.,  4.,  1.,  3.,  5.,  4.,  2.,  6.,  2.,  0.,  0.,  2.,
         0.,  0.,  5.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 15.,
         8.,  9.,  0.,  0.,  0.,  2.,  0.,  0.,  1.,  2.,  3.,  0.,  4.,  6.,
         0.,  3.,  0.,  0.,  0.,  2.,  1.,  8.,  1.,  7.,  6.,  9.,  9., 13.,
         7.,  6.,  6.,  9., 12.,  7.,  4.,  3.,  8., 12., 12., 12., 12., 19.,
        23., 23., 13.,  5., 11., 19.,  3.,  4., 20., 16., 15., 34., 45., 33.,
        32., 42., 32., 24., 30., 13., 17.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128672.5000, Valid Loss: 238.9238
Epoch [101/30000], Step [1/1], Training Loss: 123739.1641, Valid Loss: 94.8762
Epoch [201/30000], Step [1/1], Training Loss: 122399.8672, Valid Loss: 97.5905
Epoch [301/30000], Step [1/1], Training Loss: 121177.3906, Valid Loss: 109.4000
Epoch [401/30000], Step [1/1], Training Loss: 120003.2578, Valid Loss: 142.1143
Epoch [501/30000], Step [1/1], Training Loss: 118858.2500, Valid Loss: 192.8286
Epoch [601/30000], Step [1/1], Training Loss: 117740.3672, Valid Loss: 236.6381
Epoch [701/30000], Step [1/1], Training Loss: 116642.7031, Valid Loss: 317.3524
Epoch [801/30000], Step [1/1], Training Loss: 115564.3203, Valid Loss: 381.1619
Epoch [901/30000], Step [1/1], Training Loss: 114503.0781, Valid Loss: 491.8762
Epoch [1001/30000], Step [1/1], Training Loss: 113457.2812, Valid Loss: 575.6857
Epoch [1101/30000], Step [1/1], Training Loss: 112429.3906, Valid Loss: 716.4000
Epoch [1201/30000], Step [1/1], Training Loss: 111415.5547, Valid Loss: 820.2095
Epoch [1301/30000], Step [1/1], Training Loss: 110416.2656, Valid Loss: 990.9238
Epoch [1401/30000], Step [1/1], Training Loss: 109431.1328, Valid Loss: 1114.7334
Epoch [1501/30000], Step [1/1], Training Loss: 108459.9062, Valid Loss: 1315.4476
Epoch [1601/30000], Step [1/1], Training Loss: 107501.7891, Valid Loss: 1459.2572
Epoch [1701/30000], Step [1/1], Training Loss: 106555.4844, Valid Loss: 1689.9714
Epoch [1801/30000], Step [1/1], Training Loss: 105622.3516, Valid Loss: 1853.7810
Epoch [1901/30000], Step [1/1], Training Loss: 104700.2266, Valid Loss: 2114.4954
Epoch [2001/30000], Step [1/1], Training Loss: 103789.5938, Valid Loss: 2298.3049
Epoch [2101/30000], Step [1/1], Training Loss: 102890.6719, Valid Loss: 2490.1145
Epoch [2201/30000], Step [1/1], Training Loss: 101997.8828, Valid Loss: 1530.9619
Epoch [2301/30000], Step [1/1], Training Loss: 101118.3125, Valid Loss: 1355.5333
Epoch [2401/30000], Step [1/1], Training Loss: 100248.7734, Valid Loss: 1343.1715
Epoch [2501/30000], Step [1/1], Training Loss: 99391.5859, Valid Loss: 1308.6858
Epoch [2601/30000], Step [1/1], Training Loss: 98541.7578, Valid Loss: 1293.5333
Epoch [2701/30000], Step [1/1], Training Loss: 97701.7500, Valid Loss: 1323.1239
Epoch [2801/30000], Step [1/1], Training Loss: 96873.8984, Valid Loss: 1405.3524
Epoch [2901/30000], Step [1/1], Training Loss: 96055.9609, Valid Loss: 1363.2286
Epoch [3001/30000], Step [1/1], Training Loss: 95247.7031, Valid Loss: 1379.9429
Epoch [3101/30000], Step [1/1], Training Loss: 94423.1016, Valid Loss: 836.6762
Epoch [3201/30000], Step [1/1], Training Loss: 93184.1484, Valid Loss: 106.8857
Epoch [3301/30000], Step [1/1], Training Loss: 92321.6562, Valid Loss: 116.9048
Epoch [3401/30000], Step [1/1], Training Loss: 91473.7578, Valid Loss: 104.2286
Epoch [3501/30000], Step [1/1], Training Loss: 90626.0234, Valid Loss: 100.5810
Epoch [3601/30000], Step [1/1], Training Loss: 89785.8047, Valid Loss: 111.8571
Epoch [3701/30000], Step [1/1], Training Loss: 88948.4141, Valid Loss: 107.0095
Epoch [3801/30000], Step [1/1], Training Loss: 88132.0625, Valid Loss: 113.2381
Epoch [3901/30000], Step [1/1], Training Loss: 87321.0391, Valid Loss: 112.5429
Epoch [4001/30000], Step [1/1], Training Loss: 86520.1094, Valid Loss: 115.1333
Epoch [4101/30000], Step [1/1], Training Loss: 85727.2344, Valid Loss: 120.7810
Epoch [4201/30000], Step [1/1], Training Loss: 84939.2188, Valid Loss: 126.6190
Epoch [4301/30000], Step [1/1], Training Loss: 84159.8516, Valid Loss: 123.0571
Epoch [4401/30000], Step [1/1], Training Loss: 83388.4609, Valid Loss: 116.4762
Epoch [4501/30000], Step [1/1], Training Loss: 82624.3672, Valid Loss: 119.5143
Epoch [4601/30000], Step [1/1], Training Loss: 81866.4766, Valid Loss: 112.2476
Epoch [4701/30000], Step [1/1], Training Loss: 81115.6641, Valid Loss: 115.3333
Epoch [4801/30000], Step [1/1], Training Loss: 80368.4844, Valid Loss: 105.8476
Epoch [4901/30000], Step [1/1], Training Loss: 79632.4531, Valid Loss: 105.3429
Epoch [5001/30000], Step [1/1], Training Loss: 78887.7266, Valid Loss: 124.6572
Epoch [5101/30000], Step [1/1], Training Loss: 78136.2344, Valid Loss: 102.6762
Epoch [5201/30000], Step [1/1], Training Loss: 77407.9922, Valid Loss: 100.5238
Epoch [5301/30000], Step [1/1], Training Loss: 76687.3359, Valid Loss: 106.0952
Epoch [5401/30000], Step [1/1], Training Loss: 75977.4688, Valid Loss: 109.4286
Epoch [5501/30000], Step [1/1], Training Loss: 75274.6719, Valid Loss: 96.0571
Epoch [5601/30000], Step [1/1], Training Loss: 74577.2812, Valid Loss: 102.5143
Epoch [5701/30000], Step [1/1], Training Loss: 73885.7188, Valid Loss: 103.6381
Epoch [5801/30000], Step [1/1], Training Loss: 73203.0625, Valid Loss: 110.0952
Epoch [5901/30000], Step [1/1], Training Loss: 72524.1094, Valid Loss: 105.2857
Epoch [6001/30000], Step [1/1], Training Loss: 71853.2812, Valid Loss: 101.4762
Epoch [6101/30000], Step [1/1], Training Loss: 71189.0234, Valid Loss: 99.4762
Epoch [6201/30000], Step [1/1], Training Loss: 70530.9141, Valid Loss: 105.2191
Epoch [6301/30000], Step [1/1], Training Loss: 69878.7422, Valid Loss: 100.6476
Epoch [6401/30000], Step [1/1], Training Loss: 69232.7812, Valid Loss: 98.9429
Epoch [6501/30000], Step [1/1], Training Loss: 68596.3047, Valid Loss: 107.7429
Epoch [6601/30000], Step [1/1], Training Loss: 67959.1328, Valid Loss: 107.3238
Epoch [6701/30000], Step [1/1], Training Loss: 67332.6641, Valid Loss: 105.0476
Epoch [6801/30000], Step [1/1], Training Loss: 66712.5781, Valid Loss: 111.5524
Epoch [6901/30000], Step [1/1], Training Loss: 66096.1094, Valid Loss: 106.0762
Epoch [7001/30000], Step [1/1], Training Loss: 65487.1875, Valid Loss: 111.7238
Epoch [7101/30000], Step [1/1], Training Loss: 64885.3125, Valid Loss: 113.0571
Epoch [7201/30000], Step [1/1], Training Loss: 64288.4531, Valid Loss: 102.1333
Epoch [7301/30000], Step [1/1], Training Loss: 63697.8750, Valid Loss: 105.0571
Epoch [7401/30000], Step [1/1], Training Loss: 63114.0469, Valid Loss: 92.1524
Epoch [7501/30000], Step [1/1], Training Loss: 62535.7344, Valid Loss: 102.1714
Epoch [7601/30000], Step [1/1], Training Loss: 61963.3281, Valid Loss: 103.0571
Epoch [7701/30000], Step [1/1], Training Loss: 61397.5781, Valid Loss: 99.9429
Epoch [7801/30000], Step [1/1], Training Loss: 60836.3125, Valid Loss: 103.5714
Epoch [7901/30000], Step [1/1], Training Loss: 60283.2227, Valid Loss: 97.2190
Epoch [8001/30000], Step [1/1], Training Loss: 59734.4180, Valid Loss: 99.3143
Epoch [8101/30000], Step [1/1], Training Loss: 59195.7070, Valid Loss: 92.3238
Epoch [8201/30000], Step [1/1], Training Loss: 58655.4844, Valid Loss: 78.3619
Epoch [8301/30000], Step [1/1], Training Loss: 58079.0430, Valid Loss: 87.3238
Epoch [8401/30000], Step [1/1], Training Loss: 57479.8242, Valid Loss: 83.2286
Epoch [8501/30000], Step [1/1], Training Loss: 56924.3242, Valid Loss: 85.9048
Epoch [8601/30000], Step [1/1], Training Loss: 56357.8555, Valid Loss: 91.5429
Epoch [8701/30000], Step [1/1], Training Loss: 55813.3828, Valid Loss: 96.5429
Epoch [8801/30000], Step [1/1], Training Loss: 55288.5938, Valid Loss: 93.1619
Epoch [8901/30000], Step [1/1], Training Loss: 54751.8008, Valid Loss: 87.2000
Epoch [9001/30000], Step [1/1], Training Loss: 54231.1797, Valid Loss: 91.1524
Epoch [9101/30000], Step [1/1], Training Loss: 53708.3398, Valid Loss: 89.2381
Epoch [9201/30000], Step [1/1], Training Loss: 53201.5117, Valid Loss: 89.8952
Epoch [9301/30000], Step [1/1], Training Loss: 52694.8398, Valid Loss: 89.7333
Epoch [9401/30000], Step [1/1], Training Loss: 52193.6484, Valid Loss: 94.5048
Epoch [9501/30000], Step [1/1], Training Loss: 51699.0273, Valid Loss: 91.8286
Epoch [9601/30000], Step [1/1], Training Loss: 51207.7539, Valid Loss: 91.5429
Epoch [9701/30000], Step [1/1], Training Loss: 50723.6484, Valid Loss: 91.6952
Epoch [9801/30000], Step [1/1], Training Loss: 50244.7266, Valid Loss: 90.1238
Epoch [9901/30000], Step [1/1], Training Loss: 49774.1328, Valid Loss: 92.5048
Epoch [10001/30000], Step [1/1], Training Loss: 49300.0508, Valid Loss: 91.4381
Epoch [10101/30000], Step [1/1], Training Loss: 48833.6797, Valid Loss: 90.1714

[Epoch 15000] Rounded prediction: 
tensor([ 9.,  8.,  8., 15., 17., 21., 26., 13., 14., 10., 12., 10., 11., 12.,
        11., 14.,  3.,  4.,  2.,  5.,  8.,  1.,  5., 12.,  1.,  0.,  1.,  4.,
         1.,  0., 13.,  0.,  0.,  4.,  2.,  0.,  0.,  0.,  0.,  3.,  2., 27.,
        11., 12.,  0.,  0.,  2.,  5.,  3.,  1.,  4.,  6.,  9.,  0., 14.,  6.,
         0.,  3.,  0.,  3.,  0.,  5.,  0.,  8.,  2., 11.,  6.,  8.,  8., 10.,
         8.,  7.,  6.,  8., 11.,  8.,  6.,  6.,  7., 15., 13.,  8., 14., 19.,
        15., 15.,  8.,  4., 10., 16.,  7., 10., 26., 18., 18., 25., 37., 32.,
        37., 53., 40., 40., 41., 24., 29.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([12.,  8.,  9., 17., 14., 20., 23., 14., 13., 12., 12., 10., 13., 16.,
         9., 13.,  5.,  7.,  7.,  9., 15.,  6.,  8., 14.,  1.,  0.,  4.,  7.,
         4.,  3., 17.,  0.,  1.,  7.,  7.,  3.,  1.,  4.,  0.,  8.,  5., 32.,
        12., 11.,  0.,  0.,  5.,  9.,  5.,  8.,  7.,  9., 16.,  4., 17.,  6.,
         0.,  4.,  3.,  7.,  2., 10.,  1., 12.,  3., 16., 10., 15., 13., 10.,
        12., 11., 10., 11., 13., 16.,  6., 17.,  6., 18., 16.,  5., 22., 22.,
        12., 19.,  9.,  7., 10., 13., 11., 24., 33., 26., 24., 23., 33., 28.,
        31., 30., 43., 28., 33., 18., 24.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [10201/30000], Step [1/1], Training Loss: 48374.6992, Valid Loss: 88.2952
Epoch [10301/30000], Step [1/1], Training Loss: 47915.6289, Valid Loss: 84.5524
Epoch [10401/30000], Step [1/1], Training Loss: 47433.7852, Valid Loss: 88.3238
Epoch [10501/30000], Step [1/1], Training Loss: 46979.8008, Valid Loss: 86.9810
Epoch [10601/30000], Step [1/1], Training Loss: 46530.5508, Valid Loss: 95.9905
Epoch [10701/30000], Step [1/1], Training Loss: 46092.5586, Valid Loss: 96.7524
Epoch [10801/30000], Step [1/1], Training Loss: 45654.9141, Valid Loss: 89.8476
Epoch [10901/30000], Step [1/1], Training Loss: 45220.5508, Valid Loss: 90.9238
Epoch [11001/30000], Step [1/1], Training Loss: 44794.4062, Valid Loss: 88.7238
Epoch [11101/30000], Step [1/1], Training Loss: 44374.0234, Valid Loss: 94.2476
Epoch [11201/30000], Step [1/1], Training Loss: 43954.5938, Valid Loss: 92.0571
Epoch [11301/30000], Step [1/1], Training Loss: 43539.3789, Valid Loss: 90.4857
Epoch [11401/30000], Step [1/1], Training Loss: 43132.3789, Valid Loss: 87.6571
Epoch [11501/30000], Step [1/1], Training Loss: 42726.8203, Valid Loss: 90.5714
Epoch [11601/30000], Step [1/1], Training Loss: 42359.0469, Valid Loss: 93.8000
Epoch [11701/30000], Step [1/1], Training Loss: 41930.7383, Valid Loss: 88.5333
Epoch [11801/30000], Step [1/1], Training Loss: 41538.9102, Valid Loss: 84.4476
Epoch [11901/30000], Step [1/1], Training Loss: 41156.2773, Valid Loss: 80.1619
Epoch [12001/30000], Step [1/1], Training Loss: 40773.8438, Valid Loss: 84.8000
Epoch [12101/30000], Step [1/1], Training Loss: 40395.3164, Valid Loss: 83.2000
Epoch [12201/30000], Step [1/1], Training Loss: 40021.2617, Valid Loss: 82.1143
Epoch [12301/30000], Step [1/1], Training Loss: 39654.5703, Valid Loss: 84.1429
Epoch [12401/30000], Step [1/1], Training Loss: 39291.6172, Valid Loss: 81.8571
Epoch [12501/30000], Step [1/1], Training Loss: 39089.1836, Valid Loss: 76.5143
Epoch [12601/30000], Step [1/1], Training Loss: 38558.2461, Valid Loss: 77.0286
Epoch [12701/30000], Step [1/1], Training Loss: 38146.7148, Valid Loss: 74.0952
Epoch [12801/30000], Step [1/1], Training Loss: 37870.1055, Valid Loss: 77.1333
Epoch [12901/30000], Step [1/1], Training Loss: 37472.6133, Valid Loss: 80.3429
Epoch [13001/30000], Step [1/1], Training Loss: 37073.2852, Valid Loss: 71.7048
Epoch [13101/30000], Step [1/1], Training Loss: 36838.9375, Valid Loss: 66.1810
Epoch [13201/30000], Step [1/1], Training Loss: 36153.0742, Valid Loss: 74.0667
Epoch [13301/30000], Step [1/1], Training Loss: 35603.1328, Valid Loss: 67.3714
Epoch [13401/30000], Step [1/1], Training Loss: 35275.7617, Valid Loss: 71.6476
Epoch [13501/30000], Step [1/1], Training Loss: 34908.8320, Valid Loss: 70.5524
Epoch [13601/30000], Step [1/1], Training Loss: 34481.4375, Valid Loss: 76.5048
Epoch [13701/30000], Step [1/1], Training Loss: 34117.4570, Valid Loss: 68.5619
Epoch [13801/30000], Step [1/1], Training Loss: 33763.3984, Valid Loss: 75.0571
Epoch [13901/30000], Step [1/1], Training Loss: 33421.2617, Valid Loss: 71.4762
Epoch [14001/30000], Step [1/1], Training Loss: 33102.0469, Valid Loss: 73.4476
Epoch [14101/30000], Step [1/1], Training Loss: 32748.6875, Valid Loss: 68.9810
Epoch [14201/30000], Step [1/1], Training Loss: 32421.4785, Valid Loss: 71.6667
Epoch [14301/30000], Step [1/1], Training Loss: 32102.5391, Valid Loss: 68.2286
Epoch [14401/30000], Step [1/1], Training Loss: 31778.0234, Valid Loss: 68.2476
Epoch [14501/30000], Step [1/1], Training Loss: 31463.7246, Valid Loss: 71.0286
Epoch [14601/30000], Step [1/1], Training Loss: 31150.3125, Valid Loss: 72.1905
Epoch [14701/30000], Step [1/1], Training Loss: 30844.1504, Valid Loss: 72.6952
Epoch [14801/30000], Step [1/1], Training Loss: 30543.0469, Valid Loss: 73.0762
Epoch [14901/30000], Step [1/1], Training Loss: 30242.2734, Valid Loss: 75.6286
Epoch [15001/30000], Step [1/1], Training Loss: 29944.8301, Valid Loss: 75.9048
Epoch [15101/30000], Step [1/1], Training Loss: 29653.3555, Valid Loss: 70.1048
Epoch [15201/30000], Step [1/1], Training Loss: 29366.9004, Valid Loss: 70.9238
Epoch [15301/30000], Step [1/1], Training Loss: 29084.6699, Valid Loss: 71.8571
Epoch [15401/30000], Step [1/1], Training Loss: 28801.6348, Valid Loss: 77.0095
Epoch [15501/30000], Step [1/1], Training Loss: 28580.3887, Valid Loss: 69.8000
Epoch [15601/30000], Step [1/1], Training Loss: 28103.7676, Valid Loss: 68.1619
Epoch [15701/30000], Step [1/1], Training Loss: 27594.2227, Valid Loss: 63.9714
Epoch [15801/30000], Step [1/1], Training Loss: 27276.6875, Valid Loss: 66.6857
Epoch [15901/30000], Step [1/1], Training Loss: 26991.6543, Valid Loss: 68.8857
Epoch [16001/30000], Step [1/1], Training Loss: 26708.2871, Valid Loss: 73.6095
Epoch [16101/30000], Step [1/1], Training Loss: 26426.0898, Valid Loss: 73.4952
Epoch [16201/30000], Step [1/1], Training Loss: 26154.2891, Valid Loss: 75.8476
Epoch [16301/30000], Step [1/1], Training Loss: 25882.1328, Valid Loss: 71.2190
Epoch [16401/30000], Step [1/1], Training Loss: 25613.9941, Valid Loss: 72.8000
Epoch [16501/30000], Step [1/1], Training Loss: 25354.7656, Valid Loss: 72.0095
Epoch [16601/30000], Step [1/1], Training Loss: 25095.9727, Valid Loss: 75.0476
Epoch [16701/30000], Step [1/1], Training Loss: 24840.6895, Valid Loss: 66.8571
Epoch [16801/30000], Step [1/1], Training Loss: 24587.6289, Valid Loss: 69.8476
Epoch [16901/30000], Step [1/1], Training Loss: 24340.6953, Valid Loss: 65.9810
Epoch [17001/30000], Step [1/1], Training Loss: 24095.8887, Valid Loss: 70.3714
Epoch [17101/30000], Step [1/1], Training Loss: 23854.3398, Valid Loss: 70.4476
Epoch [17201/30000], Step [1/1], Training Loss: 23614.9277, Valid Loss: 70.6381
Epoch [17301/30000], Step [1/1], Training Loss: 23380.2793, Valid Loss: 71.4191
Epoch [17401/30000], Step [1/1], Training Loss: 23147.4629, Valid Loss: 71.6762
Epoch [17501/30000], Step [1/1], Training Loss: 22923.4316, Valid Loss: 69.0762
Epoch [17601/30000], Step [1/1], Training Loss: 22683.6641, Valid Loss: 64.9143
Epoch [17701/30000], Step [1/1], Training Loss: 22644.5117, Valid Loss: 63.1810
Epoch [17801/30000], Step [1/1], Training Loss: 22265.0820, Valid Loss: 64.0762
Epoch [17901/30000], Step [1/1], Training Loss: 22027.7363, Valid Loss: 66.1333
Epoch [18001/30000], Step [1/1], Training Loss: 21810.5625, Valid Loss: 66.6857
Epoch [18101/30000], Step [1/1], Training Loss: 21598.1406, Valid Loss: 66.5810
Epoch [18201/30000], Step [1/1], Training Loss: 21387.3750, Valid Loss: 67.1238
Epoch [18301/30000], Step [1/1], Training Loss: 21181.6895, Valid Loss: 70.4095
Epoch [18401/30000], Step [1/1], Training Loss: 20977.4492, Valid Loss: 67.3714
Epoch [18501/30000], Step [1/1], Training Loss: 20776.8711, Valid Loss: 67.2571
Epoch [18601/30000], Step [1/1], Training Loss: 20572.9199, Valid Loss: 66.3810
Epoch [18701/30000], Step [1/1], Training Loss: 20099.2188, Valid Loss: 69.6667
Epoch [18801/30000], Step [1/1], Training Loss: 19800.4473, Valid Loss: 68.6476
Epoch [18901/30000], Step [1/1], Training Loss: 19585.8359, Valid Loss: 66.6190
Epoch [19001/30000], Step [1/1], Training Loss: 19376.2324, Valid Loss: 66.6476
Epoch [19101/30000], Step [1/1], Training Loss: 19173.4375, Valid Loss: 67.0095
Epoch [19201/30000], Step [1/1], Training Loss: 18966.2129, Valid Loss: 68.8857
Epoch [19301/30000], Step [1/1], Training Loss: 18767.6523, Valid Loss: 68.8286
Epoch [19401/30000], Step [1/1], Training Loss: 18572.8184, Valid Loss: 65.4476
Epoch [19501/30000], Step [1/1], Training Loss: 18380.9141, Valid Loss: 67.6190
Epoch [19601/30000], Step [1/1], Training Loss: 18188.5586, Valid Loss: 64.7143
Epoch [19701/30000], Step [1/1], Training Loss: 18001.4434, Valid Loss: 67.6286
Epoch [19801/30000], Step [1/1], Training Loss: 17819.1934, Valid Loss: 70.4000
Epoch [19901/30000], Step [1/1], Training Loss: 17637.1074, Valid Loss: 68.4381
Epoch [20001/30000], Step [1/1], Training Loss: 17285.2148, Valid Loss: 64.7619
Epoch [20101/30000], Step [1/1], Training Loss: 17320.5254, Valid Loss: 67.5048
Epoch [20201/30000], Step [1/1], Training Loss: 17251.8887, Valid Loss: 62.1143
Epoch [20301/30000], Step [1/1], Training Loss: 16733.5898, Valid Loss: 68.0000

[Epoch 25000] Rounded prediction: 
tensor([13., 12., 10., 15., 15., 20., 22., 13., 16., 13., 16.,  9., 14., 16.,
        10., 16.,  4., 11.,  5.,  8., 10.,  0.,  4., 10.,  0.,  0.,  5.,  6.,
         2.,  0., 14.,  0.,  1., 10.,  4.,  1.,  0.,  2.,  2.,  7.,  2., 34.,
         6.,  5.,  0.,  0.,  8.,  8.,  5.,  9.,  7., 12., 15.,  0., 17.,  1.,
         0.,  4.,  2.,  5.,  1.,  7.,  1., 15.,  6., 18.,  4., 12.,  6.,  5.,
        20., 16., 10., 12., 16., 14.,  0., 19.,  0., 14., 13.,  0., 22., 16.,
         4., 16.,  6., 11., 11., 14.,  4., 22., 30., 22., 20., 20., 28., 21.,
        25., 33., 33., 26., 28., 20., 20.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [20401/30000], Step [1/1], Training Loss: 16545.1973, Valid Loss: 66.9238
Epoch [20501/30000], Step [1/1], Training Loss: 16369.2881, Valid Loss: 66.8191
Epoch [20601/30000], Step [1/1], Training Loss: 16190.0176, Valid Loss: 67.0476
Epoch [20701/30000], Step [1/1], Training Loss: 16014.7256, Valid Loss: 69.2857
Epoch [20801/30000], Step [1/1], Training Loss: 15841.0127, Valid Loss: 67.0762
Epoch [20901/30000], Step [1/1], Training Loss: 15673.9863, Valid Loss: 65.7905
Epoch [21001/30000], Step [1/1], Training Loss: 15506.6299, Valid Loss: 65.9429
Epoch [21101/30000], Step [1/1], Training Loss: 15346.3779, Valid Loss: 67.1143
Epoch [21201/30000], Step [1/1], Training Loss: 15182.7139, Valid Loss: 65.3429
Epoch [21301/30000], Step [1/1], Training Loss: 15031.0781, Valid Loss: 66.9714
Epoch [21401/30000], Step [1/1], Training Loss: 14863.7344, Valid Loss: 69.8476
Epoch [21501/30000], Step [1/1], Training Loss: 14709.9814, Valid Loss: 66.9810
Epoch [21601/30000], Step [1/1], Training Loss: 14632.4824, Valid Loss: 63.4000
Epoch [21701/30000], Step [1/1], Training Loss: 14181.8779, Valid Loss: 66.7810
Epoch [21801/30000], Step [1/1], Training Loss: 14007.9854, Valid Loss: 64.8000
Epoch [21901/30000], Step [1/1], Training Loss: 13845.1592, Valid Loss: 67.4381
Epoch [22001/30000], Step [1/1], Training Loss: 13690.1221, Valid Loss: 62.6095
Epoch [22101/30000], Step [1/1], Training Loss: 13533.3525, Valid Loss: 64.1143
Epoch [22201/30000], Step [1/1], Training Loss: 13383.2754, Valid Loss: 66.1714
Epoch [22301/30000], Step [1/1], Training Loss: 13235.6191, Valid Loss: 67.8667
Epoch [22401/30000], Step [1/1], Training Loss: 13089.3955, Valid Loss: 69.1714
Epoch [22501/30000], Step [1/1], Training Loss: 12944.1201, Valid Loss: 64.0857
Epoch [22601/30000], Step [1/1], Training Loss: 12801.1260, Valid Loss: 64.5429
Epoch [22701/30000], Step [1/1], Training Loss: 12660.8184, Valid Loss: 67.4952
Epoch [22801/30000], Step [1/1], Training Loss: 12529.3428, Valid Loss: 66.5714
Epoch [22901/30000], Step [1/1], Training Loss: 12386.3604, Valid Loss: 67.9524
Epoch [23001/30000], Step [1/1], Training Loss: 12283.5879, Valid Loss: 69.1524
Epoch [23101/30000], Step [1/1], Training Loss: 12122.6709, Valid Loss: 65.5810
Epoch [23201/30000], Step [1/1], Training Loss: 11987.1543, Valid Loss: 66.2000
Epoch [23301/30000], Step [1/1], Training Loss: 11856.6143, Valid Loss: 68.5333
Epoch [23401/30000], Step [1/1], Training Loss: 11729.2100, Valid Loss: 68.6286
Epoch [23501/30000], Step [1/1], Training Loss: 11603.4697, Valid Loss: 71.0381
Epoch [23601/30000], Step [1/1], Training Loss: 11467.8496, Valid Loss: 71.8286
Epoch [23701/30000], Step [1/1], Training Loss: 11171.1855, Valid Loss: 67.4952
Epoch [23801/30000], Step [1/1], Training Loss: 11002.8965, Valid Loss: 70.5714
Epoch [23901/30000], Step [1/1], Training Loss: 10869.3232, Valid Loss: 70.2571
Epoch [24001/30000], Step [1/1], Training Loss: 10743.1885, Valid Loss: 67.9429
Epoch [24101/30000], Step [1/1], Training Loss: 10619.6162, Valid Loss: 69.5143
Epoch [24201/30000], Step [1/1], Training Loss: 10499.8906, Valid Loss: 73.2476
Epoch [24301/30000], Step [1/1], Training Loss: 10382.0908, Valid Loss: 69.0857
Epoch [24401/30000], Step [1/1], Training Loss: 10264.2900, Valid Loss: 69.2286
Epoch [24501/30000], Step [1/1], Training Loss: 10148.5967, Valid Loss: 71.4571
Epoch [24601/30000], Step [1/1], Training Loss: 10030.4033, Valid Loss: 71.2000
Epoch [24701/30000], Step [1/1], Training Loss: 9915.1104, Valid Loss: 73.0667
Epoch [24801/30000], Step [1/1], Training Loss: 9795.9678, Valid Loss: 73.2095
Epoch [24901/30000], Step [1/1], Training Loss: 9681.9883, Valid Loss: 71.2000
Epoch [25001/30000], Step [1/1], Training Loss: 9567.0850, Valid Loss: 73.6762
Epoch [25101/30000], Step [1/1], Training Loss: 9456.8633, Valid Loss: 70.6095
Epoch [25201/30000], Step [1/1], Training Loss: 9349.5703, Valid Loss: 72.3048
Epoch [25301/30000], Step [1/1], Training Loss: 9241.2783, Valid Loss: 70.6952
Epoch [25401/30000], Step [1/1], Training Loss: 9132.3662, Valid Loss: 71.5714
Epoch [25501/30000], Step [1/1], Training Loss: 9000.9629, Valid Loss: 71.5714
Epoch [25601/30000], Step [1/1], Training Loss: 8878.9951, Valid Loss: 72.7048
Epoch [25701/30000], Step [1/1], Training Loss: 8770.8311, Valid Loss: 73.7619
Epoch [25801/30000], Step [1/1], Training Loss: 8668.2432, Valid Loss: 71.0000
Epoch [25901/30000], Step [1/1], Training Loss: 8566.6660, Valid Loss: 71.3905
Epoch [26001/30000], Step [1/1], Training Loss: 8467.4717, Valid Loss: 71.8286
Epoch [26101/30000], Step [1/1], Training Loss: 8367.9795, Valid Loss: 72.7429
Epoch [26201/30000], Step [1/1], Training Loss: 8268.6533, Valid Loss: 73.1619
Epoch [26301/30000], Step [1/1], Training Loss: 8172.8057, Valid Loss: 73.3619
Epoch [26401/30000], Step [1/1], Training Loss: 8079.0127, Valid Loss: 70.4667
Epoch [26501/30000], Step [1/1], Training Loss: 7969.1685, Valid Loss: 72.3810
Epoch [26601/30000], Step [1/1], Training Loss: 7858.0093, Valid Loss: 74.6286
Epoch [26701/30000], Step [1/1], Training Loss: 7720.6519, Valid Loss: 73.1619
Epoch [26801/30000], Step [1/1], Training Loss: 7814.1060, Valid Loss: 75.1048
Epoch [26901/30000], Step [1/1], Training Loss: 7409.7354, Valid Loss: 73.4476
Epoch [27001/30000], Step [1/1], Training Loss: 7308.1177, Valid Loss: 77.3619
Epoch [27101/30000], Step [1/1], Training Loss: 7211.9253, Valid Loss: 75.4571
Epoch [27201/30000], Step [1/1], Training Loss: 7123.8145, Valid Loss: 76.4191
Epoch [27301/30000], Step [1/1], Training Loss: 7031.3003, Valid Loss: 73.9905
Epoch [27401/30000], Step [1/1], Training Loss: 6944.0415, Valid Loss: 76.5810
Epoch [27501/30000], Step [1/1], Training Loss: 6857.9565, Valid Loss: 75.0286
Epoch [27601/30000], Step [1/1], Training Loss: 6772.4917, Valid Loss: 77.9524
Epoch [27701/30000], Step [1/1], Training Loss: 6691.0356, Valid Loss: 75.5524
Epoch [27801/30000], Step [1/1], Training Loss: 6608.7598, Valid Loss: 75.7619
Epoch [27901/30000], Step [1/1], Training Loss: 6528.5874, Valid Loss: 74.5905
Epoch [28001/30000], Step [1/1], Training Loss: 6449.7471, Valid Loss: 76.2952
Epoch [28101/30000], Step [1/1], Training Loss: 6372.6611, Valid Loss: 74.7429
Epoch [28201/30000], Step [1/1], Training Loss: 6295.4053, Valid Loss: 73.6286
Epoch [28301/30000], Step [1/1], Training Loss: 6218.9111, Valid Loss: 73.3905
Epoch [28401/30000], Step [1/1], Training Loss: 6144.5610, Valid Loss: 74.1238
Epoch [28501/30000], Step [1/1], Training Loss: 6070.5708, Valid Loss: 76.8476
Epoch [28601/30000], Step [1/1], Training Loss: 5994.0981, Valid Loss: 72.3238
Epoch [28701/30000], Step [1/1], Training Loss: 5921.7720, Valid Loss: 76.0857
Epoch [28801/30000], Step [1/1], Training Loss: 5850.4258, Valid Loss: 75.5429
Epoch [28901/30000], Step [1/1], Training Loss: 5781.1509, Valid Loss: 73.2381
Epoch [29001/30000], Step [1/1], Training Loss: 5712.6851, Valid Loss: 73.1714
Epoch [29101/30000], Step [1/1], Training Loss: 5646.3276, Valid Loss: 73.6952
Epoch [29201/30000], Step [1/1], Training Loss: 5569.1445, Valid Loss: 71.4857
Epoch [29301/30000], Step [1/1], Training Loss: 5490.1934, Valid Loss: 72.3524
Epoch [29401/30000], Step [1/1], Training Loss: 5419.8130, Valid Loss: 69.6286
Epoch [29501/30000], Step [1/1], Training Loss: 5351.9624, Valid Loss: 77.9143
Epoch [29601/30000], Step [1/1], Training Loss: 10597.9629, Valid Loss: 77.6476
Epoch [29701/30000], Step [1/1], Training Loss: 5236.4639, Valid Loss: 69.3048
Epoch [29801/30000], Step [1/1], Training Loss: 5165.9048, Valid Loss: 74.3524
Epoch [29901/30000], Step [1/1], Training Loss: 5102.8950, Valid Loss: 73.0571

 End Time: 2021/04/19, 03:39:47




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=256 	layers=3

Start Time = 2021/04/19, 03:39:47
##########################################################


[Epoch 0] Rounded prediction: 
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([ 7.,  8.,  6.,  4.,  7., 11., 10.,  6.,  0.,  4.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,
        11., 13.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  7.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  5.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  7., 13., 12., 17., 15., 23.,
        41., 35., 17.,  0.,  0.,  0.,  0., 14., 38., 40., 33., 45., 57., 43.,
        44., 48., 30., 30., 48., 24., 12.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([ 7., 11.,  6.,  7.,  8., 12., 15.,  9.,  4.,  4.,  1.,  0.,  0.,  3.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  9.,
        14.,  9.,  5.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,
         2.,  4.,  2.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  1.,  0.,  6.,
         5.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  5., 17., 10., 13.,  4., 13.,
        42., 31., 10.,  0.,  0.,  2.,  0.,  6., 29., 37., 31., 49., 49., 35.,
        33., 43., 31., 23., 32., 24., 17.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128683.6250, Valid Loss: 238.9238
Epoch [101/30000], Step [1/1], Training Loss: 123756.2734, Valid Loss: 94.8762
Epoch [201/30000], Step [1/1], Training Loss: 122413.7031, Valid Loss: 97.5905
Epoch [301/30000], Step [1/1], Training Loss: 121190.4609, Valid Loss: 109.4000
Epoch [401/30000], Step [1/1], Training Loss: 120015.7344, Valid Loss: 142.1143
Epoch [501/30000], Step [1/1], Training Loss: 118873.0938, Valid Loss: 192.8286
Epoch [601/30000], Step [1/1], Training Loss: 117751.6016, Valid Loss: 236.6381
Epoch [701/30000], Step [1/1], Training Loss: 116654.2812, Valid Loss: 317.3524
Epoch [801/30000], Step [1/1], Training Loss: 115573.4922, Valid Loss: 381.1619
Epoch [901/30000], Step [1/1], Training Loss: 114514.3125, Valid Loss: 491.8762
Epoch [1001/30000], Step [1/1], Training Loss: 113468.4453, Valid Loss: 575.6857
Epoch [1101/30000], Step [1/1], Training Loss: 112440.3125, Valid Loss: 716.4000
Epoch [1201/30000], Step [1/1], Training Loss: 111425.5234, Valid Loss: 820.2095
Epoch [1301/30000], Step [1/1], Training Loss: 110426.6406, Valid Loss: 990.9238
Epoch [1401/30000], Step [1/1], Training Loss: 109441.2031, Valid Loss: 1114.7334
Epoch [1501/30000], Step [1/1], Training Loss: 108469.9531, Valid Loss: 1315.4476
Epoch [1601/30000], Step [1/1], Training Loss: 107511.7500, Valid Loss: 1459.2572
Epoch [1701/30000], Step [1/1], Training Loss: 106565.3047, Valid Loss: 1689.9714
Epoch [1801/30000], Step [1/1], Training Loss: 105631.4062, Valid Loss: 1853.7810
Epoch [1901/30000], Step [1/1], Training Loss: 104710.1250, Valid Loss: 2025.5906
Epoch [2001/30000], Step [1/1], Training Loss: 103798.8984, Valid Loss: 2298.3049
Epoch [2101/30000], Step [1/1], Training Loss: 102899.4375, Valid Loss: 2490.1145
Epoch [2201/30000], Step [1/1], Training Loss: 102009.9609, Valid Loss: 1999.7144
Epoch [2301/30000], Step [1/1], Training Loss: 101128.5703, Valid Loss: 1586.4952
Epoch [2401/30000], Step [1/1], Training Loss: 100259.1641, Valid Loss: 1409.4286
Epoch [2501/30000], Step [1/1], Training Loss: 99399.5703, Valid Loss: 1368.3429
Epoch [2601/30000], Step [1/1], Training Loss: 98314.7188, Valid Loss: 155.6762
Epoch [2701/30000], Step [1/1], Training Loss: 97399.9375, Valid Loss: 106.1619
Epoch [2801/30000], Step [1/1], Training Loss: 96514.7344, Valid Loss: 126.9048
Epoch [2901/30000], Step [1/1], Training Loss: 95630.1172, Valid Loss: 141.0095
Epoch [3001/30000], Step [1/1], Training Loss: 94764.4688, Valid Loss: 140.0381
Epoch [3101/30000], Step [1/1], Training Loss: 93907.9141, Valid Loss: 146.2476
Epoch [3201/30000], Step [1/1], Training Loss: 93057.4375, Valid Loss: 137.2000
Epoch [3301/30000], Step [1/1], Training Loss: 92219.5312, Valid Loss: 155.4381
Epoch [3401/30000], Step [1/1], Training Loss: 91389.0234, Valid Loss: 138.4667
Epoch [3501/30000], Step [1/1], Training Loss: 90566.7891, Valid Loss: 139.4095
Epoch [3601/30000], Step [1/1], Training Loss: 89755.0469, Valid Loss: 137.9429
Epoch [3701/30000], Step [1/1], Training Loss: 88947.2812, Valid Loss: 146.2571
Epoch [3801/30000], Step [1/1], Training Loss: 88151.2344, Valid Loss: 143.1048
Epoch [3901/30000], Step [1/1], Training Loss: 87312.4844, Valid Loss: 130.8190
Epoch [4001/30000], Step [1/1], Training Loss: 86506.4062, Valid Loss: 138.5524
Epoch [4101/30000], Step [1/1], Training Loss: 85709.5234, Valid Loss: 138.1429
Epoch [4201/30000], Step [1/1], Training Loss: 84927.1562, Valid Loss: 137.1429
Epoch [4301/30000], Step [1/1], Training Loss: 84148.9219, Valid Loss: 140.2857
Epoch [4401/30000], Step [1/1], Training Loss: 83380.5625, Valid Loss: 137.2476
Epoch [4501/30000], Step [1/1], Training Loss: 82617.4766, Valid Loss: 130.3048
Epoch [4601/30000], Step [1/1], Training Loss: 81860.8125, Valid Loss: 132.0095
Epoch [4701/30000], Step [1/1], Training Loss: 81113.0859, Valid Loss: 140.9619
Epoch [4801/30000], Step [1/1], Training Loss: 80369.5547, Valid Loss: 132.5143
Epoch [4901/30000], Step [1/1], Training Loss: 79634.1250, Valid Loss: 133.1810
Epoch [5001/30000], Step [1/1], Training Loss: 78905.8359, Valid Loss: 133.3905
Epoch [5101/30000], Step [1/1], Training Loss: 78182.8672, Valid Loss: 133.6190
Epoch [5201/30000], Step [1/1], Training Loss: 77466.4453, Valid Loss: 134.5048
Epoch [5301/30000], Step [1/1], Training Loss: 76759.2109, Valid Loss: 133.6952
Epoch [5401/30000], Step [1/1], Training Loss: 76054.3516, Valid Loss: 132.4191
Epoch [5501/30000], Step [1/1], Training Loss: 75358.6562, Valid Loss: 128.3429
Epoch [5601/30000], Step [1/1], Training Loss: 74689.1953, Valid Loss: 128.3429
Epoch [5701/30000], Step [1/1], Training Loss: 73918.9609, Valid Loss: 128.2857
Epoch [5801/30000], Step [1/1], Training Loss: 73226.1328, Valid Loss: 127.7143
Epoch [5901/30000], Step [1/1], Training Loss: 72547.2734, Valid Loss: 132.8190
Epoch [6001/30000], Step [1/1], Training Loss: 71873.9453, Valid Loss: 127.1714
Epoch [6101/30000], Step [1/1], Training Loss: 71209.3828, Valid Loss: 125.8381
Epoch [6201/30000], Step [1/1], Training Loss: 70551.6562, Valid Loss: 127.9524
Epoch [6301/30000], Step [1/1], Training Loss: 69897.2188, Valid Loss: 125.2191
Epoch [6401/30000], Step [1/1], Training Loss: 69250.4219, Valid Loss: 123.3524
Epoch [6501/30000], Step [1/1], Training Loss: 68608.3125, Valid Loss: 128.1810
Epoch [6601/30000], Step [1/1], Training Loss: 67977.7734, Valid Loss: 126.9048
Epoch [6701/30000], Step [1/1], Training Loss: 67357.2344, Valid Loss: 111.2191
Epoch [6801/30000], Step [1/1], Training Loss: 66726.9375, Valid Loss: 112.5524
Epoch [6901/30000], Step [1/1], Training Loss: 66109.8750, Valid Loss: 101.9524
Epoch [7001/30000], Step [1/1], Training Loss: 65498.5039, Valid Loss: 102.3238
Epoch [7101/30000], Step [1/1], Training Loss: 64899.4570, Valid Loss: 104.1524
Epoch [7201/30000], Step [1/1], Training Loss: 64300.1758, Valid Loss: 106.8191
Epoch [7301/30000], Step [1/1], Training Loss: 63702.3008, Valid Loss: 107.4381
Epoch [7401/30000], Step [1/1], Training Loss: 63126.9062, Valid Loss: 108.7810
Epoch [7501/30000], Step [1/1], Training Loss: 62534.4844, Valid Loss: 112.1143
Epoch [7601/30000], Step [1/1], Training Loss: 61970.7383, Valid Loss: 107.0667
Epoch [7701/30000], Step [1/1], Training Loss: 61393.2109, Valid Loss: 109.7048
Epoch [7801/30000], Step [1/1], Training Loss: 60831.0859, Valid Loss: 110.9810
Epoch [7901/30000], Step [1/1], Training Loss: 60275.3789, Valid Loss: 114.1810
Epoch [8001/30000], Step [1/1], Training Loss: 59725.5352, Valid Loss: 112.0762
Epoch [8101/30000], Step [1/1], Training Loss: 59179.6211, Valid Loss: 115.0571
Epoch [8201/30000], Step [1/1], Training Loss: 58648.0898, Valid Loss: 109.4857
Epoch [8301/30000], Step [1/1], Training Loss: 58110.6133, Valid Loss: 115.4191
Epoch [8401/30000], Step [1/1], Training Loss: 57530.3242, Valid Loss: 116.5143
Epoch [8501/30000], Step [1/1], Training Loss: 56987.5625, Valid Loss: 110.4762
Epoch [8601/30000], Step [1/1], Training Loss: 56431.8555, Valid Loss: 113.5524
Epoch [8701/30000], Step [1/1], Training Loss: 55901.9727, Valid Loss: 113.0571
Epoch [8801/30000], Step [1/1], Training Loss: 55379.8125, Valid Loss: 111.7143
Epoch [8901/30000], Step [1/1], Training Loss: 54861.7031, Valid Loss: 117.4095
Epoch [9001/30000], Step [1/1], Training Loss: 54304.3398, Valid Loss: 118.9238
Epoch [9101/30000], Step [1/1], Training Loss: 53788.0781, Valid Loss: 117.4095
Epoch [9201/30000], Step [1/1], Training Loss: 53276.2188, Valid Loss: 118.7714
Epoch [9301/30000], Step [1/1], Training Loss: 52773.6719, Valid Loss: 117.3810
Epoch [9401/30000], Step [1/1], Training Loss: 52262.3789, Valid Loss: 116.5429
Epoch [9501/30000], Step [1/1], Training Loss: 51747.7812, Valid Loss: 116.2571
Epoch [9601/30000], Step [1/1], Training Loss: 51239.7188, Valid Loss: 120.5429
Epoch [9701/30000], Step [1/1], Training Loss: 50749.3867, Valid Loss: 123.2571
Epoch [9801/30000], Step [1/1], Training Loss: 50255.4766, Valid Loss: 118.3143
Epoch [9901/30000], Step [1/1], Training Loss: 49769.0234, Valid Loss: 115.7714
Epoch [10001/30000], Step [1/1], Training Loss: 49293.3555, Valid Loss: 119.3905

[Epoch 15000] Rounded prediction: 
tensor([ 4.,  9.,  6.,  7., 13.,  9., 14.,  9.,  3.,  4.,  4.,  3.,  0.,  6.,
         0.,  3.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  8.,  0.,  0.,  7.,
         0.,  0.,  0.,  1.,  0.,  8.,  3.,  3.,  0.,  4.,  0.,  0.,  2., 10.,
        11.,  9.,  6.,  4.,  4.,  1.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,
         3.,  6.,  6.,  0.,  1.,  1.,  0.,  2.,  2.,  0.,  5.,  1.,  5.,  0.,
         0.,  0.,  0.,  3.,  0.,  0.,  0.,  4.,  8., 15.,  5., 12.,  8., 11.,
        25., 21.,  9.,  0.,  1.,  7.,  9.,  6., 18., 34., 24., 35., 41., 29.,
        21., 29., 24., 21., 27., 19., 17.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([ 5.,  9.,  6.,  9., 12., 10., 13.,  9.,  5.,  7.,  4.,  2.,  0.,  8.,
         3.,  1.,  0.,  0.,  0.,  0.,  1.,  5.,  6.,  5.,  6.,  3.,  5.,  7.,
         6.,  7.,  5.,  6.,  1., 10.,  7.,  6.,  4.,  5.,  3.,  3.,  5.,  9.,
        14.,  8.,  9.,  6.,  8.,  5.,  5.,  2.,  1.,  0.,  4.,  3.,  0.,  6.,
         4.,  6.,  8.,  5.,  7.,  5.,  6.,  3.,  9.,  3.,  4.,  4.,  4.,  4.,
         5.,  3.,  0.,  0.,  4.,  0.,  1.,  5.,  6., 16., 13., 11., 12.,  8.,
        30., 23., 13.,  0.,  1.,  6.,  7.,  4., 22., 33., 19., 34., 45., 24.,
        22., 27., 24., 17., 26., 18., 17.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [10101/30000], Step [1/1], Training Loss: 48821.7773, Valid Loss: 120.9905
Epoch [10201/30000], Step [1/1], Training Loss: 48386.6445, Valid Loss: 116.6667
Epoch [10301/30000], Step [1/1], Training Loss: 47882.4961, Valid Loss: 117.6286
Epoch [10401/30000], Step [1/1], Training Loss: 47408.1172, Valid Loss: 114.9905
Epoch [10501/30000], Step [1/1], Training Loss: 46954.5859, Valid Loss: 121.2000
Epoch [10601/30000], Step [1/1], Training Loss: 46504.9219, Valid Loss: 119.5429
Epoch [10701/30000], Step [1/1], Training Loss: 46058.8320, Valid Loss: 119.8000
Epoch [10801/30000], Step [1/1], Training Loss: 45619.9453, Valid Loss: 121.0095
Epoch [10901/30000], Step [1/1], Training Loss: 45184.3828, Valid Loss: 120.5143
Epoch [11001/30000], Step [1/1], Training Loss: 44753.7188, Valid Loss: 114.5619
Epoch [11101/30000], Step [1/1], Training Loss: 44328.7344, Valid Loss: 116.8381
Epoch [11201/30000], Step [1/1], Training Loss: 43907.4883, Valid Loss: 113.7810
Epoch [11301/30000], Step [1/1], Training Loss: 43492.8398, Valid Loss: 112.4667
Epoch [11401/30000], Step [1/1], Training Loss: 43095.0117, Valid Loss: 113.0000
Epoch [11501/30000], Step [1/1], Training Loss: 42875.6289, Valid Loss: 113.6286
Epoch [11601/30000], Step [1/1], Training Loss: 42314.3633, Valid Loss: 105.9524
Epoch [11701/30000], Step [1/1], Training Loss: 41862.0312, Valid Loss: 103.6476
Epoch [11801/30000], Step [1/1], Training Loss: 41461.0156, Valid Loss: 103.2571
Epoch [11901/30000], Step [1/1], Training Loss: 41067.9648, Valid Loss: 106.3714
Epoch [12001/30000], Step [1/1], Training Loss: 40677.3750, Valid Loss: 109.0762
Epoch [12101/30000], Step [1/1], Training Loss: 40293.9766, Valid Loss: 107.5619
Epoch [12201/30000], Step [1/1], Training Loss: 39914.7227, Valid Loss: 113.4191
Epoch [12301/30000], Step [1/1], Training Loss: 39540.4180, Valid Loss: 110.3143
Epoch [12401/30000], Step [1/1], Training Loss: 39169.8672, Valid Loss: 109.0000
Epoch [12501/30000], Step [1/1], Training Loss: 38800.5352, Valid Loss: 113.7905
Epoch [12601/30000], Step [1/1], Training Loss: 38438.6484, Valid Loss: 115.6572
Epoch [12701/30000], Step [1/1], Training Loss: 38080.6680, Valid Loss: 112.4191
Epoch [12801/30000], Step [1/1], Training Loss: 37726.8633, Valid Loss: 109.7905
Epoch [12901/30000], Step [1/1], Training Loss: 37377.4570, Valid Loss: 111.8381
Epoch [13001/30000], Step [1/1], Training Loss: 37031.9102, Valid Loss: 111.6572
Epoch [13101/30000], Step [1/1], Training Loss: 36690.9844, Valid Loss: 111.4476
Epoch [13201/30000], Step [1/1], Training Loss: 36354.1484, Valid Loss: 112.6190
Epoch [13301/30000], Step [1/1], Training Loss: 36021.1562, Valid Loss: 108.1048
Epoch [13401/30000], Step [1/1], Training Loss: 35690.0508, Valid Loss: 108.6000
Epoch [13501/30000], Step [1/1], Training Loss: 35369.9922, Valid Loss: 104.9619
Epoch [13601/30000], Step [1/1], Training Loss: 35044.9219, Valid Loss: 106.5714
Epoch [13701/30000], Step [1/1], Training Loss: 34725.3750, Valid Loss: 106.2952
Epoch [13801/30000], Step [1/1], Training Loss: 34411.0664, Valid Loss: 108.4667
Epoch [13901/30000], Step [1/1], Training Loss: 34101.4297, Valid Loss: 105.0000
Epoch [14001/30000], Step [1/1], Training Loss: 33796.0781, Valid Loss: 103.7238
Epoch [14101/30000], Step [1/1], Training Loss: 33493.4219, Valid Loss: 105.1714
Epoch [14201/30000], Step [1/1], Training Loss: 33196.0703, Valid Loss: 107.6190
Epoch [14301/30000], Step [1/1], Training Loss: 32902.4375, Valid Loss: 105.5429
Epoch [14401/30000], Step [1/1], Training Loss: 32611.2480, Valid Loss: 105.7048
Epoch [14501/30000], Step [1/1], Training Loss: 32325.4141, Valid Loss: 104.0762
Epoch [14601/30000], Step [1/1], Training Loss: 32043.0566, Valid Loss: 102.2286
Epoch [14701/30000], Step [1/1], Training Loss: 31890.4805, Valid Loss: 109.8191
Epoch [14801/30000], Step [1/1], Training Loss: 31479.4395, Valid Loss: 99.6857
Epoch [14901/30000], Step [1/1], Training Loss: 31183.0938, Valid Loss: 95.7333
Epoch [15001/30000], Step [1/1], Training Loss: 30908.7949, Valid Loss: 94.1333
Epoch [15101/30000], Step [1/1], Training Loss: 30639.0078, Valid Loss: 96.0571
Epoch [15201/30000], Step [1/1], Training Loss: 30374.0840, Valid Loss: 87.2095
Epoch [15301/30000], Step [1/1], Training Loss: 30114.6348, Valid Loss: 94.4857
Epoch [15401/30000], Step [1/1], Training Loss: 29858.3398, Valid Loss: 97.5810
Epoch [15501/30000], Step [1/1], Training Loss: 29606.7031, Valid Loss: 94.6000
Epoch [15601/30000], Step [1/1], Training Loss: 29358.6914, Valid Loss: 95.1810
Epoch [15701/30000], Step [1/1], Training Loss: 29113.1172, Valid Loss: 91.4381
Epoch [15801/30000], Step [1/1], Training Loss: 28872.9258, Valid Loss: 98.0095
Epoch [15901/30000], Step [1/1], Training Loss: 28634.9746, Valid Loss: 91.0762
Epoch [16001/30000], Step [1/1], Training Loss: 28402.5703, Valid Loss: 90.2190
Epoch [16101/30000], Step [1/1], Training Loss: 28173.1348, Valid Loss: 93.2000
Epoch [16201/30000], Step [1/1], Training Loss: 27947.7227, Valid Loss: 87.5238
Epoch [16301/30000], Step [1/1], Training Loss: 27725.2832, Valid Loss: 94.1238
Epoch [16401/30000], Step [1/1], Training Loss: 27507.7598, Valid Loss: 91.2095
Epoch [16501/30000], Step [1/1], Training Loss: 27292.4238, Valid Loss: 93.1143
Epoch [16601/30000], Step [1/1], Training Loss: 27077.8691, Valid Loss: 89.7048
Epoch [16701/30000], Step [1/1], Training Loss: 26333.8945, Valid Loss: 68.8762
Epoch [16801/30000], Step [1/1], Training Loss: 25202.9414, Valid Loss: 62.8190
Epoch [16901/30000], Step [1/1], Training Loss: 24656.7852, Valid Loss: 75.2095
Epoch [17001/30000], Step [1/1], Training Loss: 24334.1641, Valid Loss: 76.6952
Epoch [17101/30000], Step [1/1], Training Loss: 24057.2773, Valid Loss: 80.5905
Epoch [17201/30000], Step [1/1], Training Loss: 23799.4375, Valid Loss: 77.1619
Epoch [17301/30000], Step [1/1], Training Loss: 23539.6738, Valid Loss: 77.2190
Epoch [17401/30000], Step [1/1], Training Loss: 23277.8301, Valid Loss: 80.9333
Epoch [17501/30000], Step [1/1], Training Loss: 23031.6973, Valid Loss: 78.6381
Epoch [17601/30000], Step [1/1], Training Loss: 22808.4277, Valid Loss: 77.9524
Epoch [17701/30000], Step [1/1], Training Loss: 22550.9863, Valid Loss: 80.3333
Epoch [17801/30000], Step [1/1], Training Loss: 22317.3887, Valid Loss: 82.3619
Epoch [17901/30000], Step [1/1], Training Loss: 22088.2285, Valid Loss: 79.6476
Epoch [18001/30000], Step [1/1], Training Loss: 21857.3945, Valid Loss: 79.1143
Epoch [18101/30000], Step [1/1], Training Loss: 21594.5293, Valid Loss: 81.8095
Epoch [18201/30000], Step [1/1], Training Loss: 21353.2852, Valid Loss: 83.7238
Epoch [18301/30000], Step [1/1], Training Loss: 21159.4414, Valid Loss: 81.9905
Epoch [18401/30000], Step [1/1], Training Loss: 20914.4805, Valid Loss: 84.9714
Epoch [18501/30000], Step [1/1], Training Loss: 20701.0586, Valid Loss: 83.2857
Epoch [18601/30000], Step [1/1], Training Loss: 20490.0098, Valid Loss: 84.5714
Epoch [18701/30000], Step [1/1], Training Loss: 20285.4395, Valid Loss: 86.5810
Epoch [18801/30000], Step [1/1], Training Loss: 20080.2852, Valid Loss: 78.2571
Epoch [18901/30000], Step [1/1], Training Loss: 19882.3379, Valid Loss: 79.1143
Epoch [19001/30000], Step [1/1], Training Loss: 19687.3301, Valid Loss: 90.0381
Epoch [19101/30000], Step [1/1], Training Loss: 19508.3184, Valid Loss: 83.9238
Epoch [19201/30000], Step [1/1], Training Loss: 19306.7559, Valid Loss: 85.3714
Epoch [19301/30000], Step [1/1], Training Loss: 19121.3691, Valid Loss: 77.0095
Epoch [19401/30000], Step [1/1], Training Loss: 18989.6113, Valid Loss: 79.6000
Epoch [19501/30000], Step [1/1], Training Loss: 18748.1738, Valid Loss: 91.5714
Epoch [19601/30000], Step [1/1], Training Loss: 18534.7578, Valid Loss: 86.4667
Epoch [19701/30000], Step [1/1], Training Loss: 18346.0527, Valid Loss: 87.2571
Epoch [19801/30000], Step [1/1], Training Loss: 18192.4824, Valid Loss: 79.5619
Epoch [19901/30000], Step [1/1], Training Loss: 17857.0742, Valid Loss: 86.0476
Epoch [20001/30000], Step [1/1], Training Loss: 17672.3691, Valid Loss: 87.0667
Epoch [20101/30000], Step [1/1], Training Loss: 17496.1699, Valid Loss: 87.6571

[Epoch 25000] Rounded prediction: 
tensor([ 8., 10.,  6., 12., 15., 13., 16., 12.,  9., 11., 10.,  8.,  4., 12.,
         8.,  9.,  5.,  0.,  0.,  0.,  3.,  1.,  0.,  6.,  0.,  3.,  3.,  7.,
         8.,  7.,  0.,  6.,  1.,  4.,  8.,  6.,  6.,  5.,  6.,  1.,  4., 15.,
        16.,  9.,  8.,  5.,  8.,  8.,  6.,  2.,  0.,  0.,  4.,  0.,  0.,  4.,
         4.,  4.,  9.,  4.,  7.,  5.,  8.,  4.,  7.,  2.,  0.,  0.,  2.,  0.,
         0.,  0.,  0.,  0.,  5.,  6.,  0.,  2.,  4., 14.,  8.,  6.,  9.,  6.,
        26., 17.,  7.,  0.,  2., 10.,  7.,  5., 29., 36., 20., 36., 39., 23.,
        22., 21., 20., 27., 25., 16., 15.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [20201/30000], Step [1/1], Training Loss: 17312.4609, Valid Loss: 91.6762
Epoch [20301/30000], Step [1/1], Training Loss: 17139.8223, Valid Loss: 88.5905
Epoch [20401/30000], Step [1/1], Training Loss: 16965.5664, Valid Loss: 86.4667
Epoch [20501/30000], Step [1/1], Training Loss: 16795.3164, Valid Loss: 85.3333
Epoch [20601/30000], Step [1/1], Training Loss: 16668.5586, Valid Loss: 78.7619
Epoch [20701/30000], Step [1/1], Training Loss: 16337.2441, Valid Loss: 89.3619
Epoch [20801/30000], Step [1/1], Training Loss: 16214.0361, Valid Loss: 96.8571
Epoch [20901/30000], Step [1/1], Training Loss: 16024.4521, Valid Loss: 81.2667
Epoch [21001/30000], Step [1/1], Training Loss: 15791.1348, Valid Loss: 81.3905
Epoch [21101/30000], Step [1/1], Training Loss: 15631.1426, Valid Loss: 81.2667
Epoch [21201/30000], Step [1/1], Training Loss: 15461.4609, Valid Loss: 86.1333
Epoch [21301/30000], Step [1/1], Training Loss: 15297.5693, Valid Loss: 88.0095
Epoch [21401/30000], Step [1/1], Training Loss: 15144.6367, Valid Loss: 83.6190
Epoch [21501/30000], Step [1/1], Training Loss: 14990.8994, Valid Loss: 82.2476
Epoch [21601/30000], Step [1/1], Training Loss: 14829.9102, Valid Loss: 81.2857
Epoch [21701/30000], Step [1/1], Training Loss: 14758.8125, Valid Loss: 78.7143
Epoch [21801/30000], Step [1/1], Training Loss: 14537.2402, Valid Loss: 79.0571
Epoch [21901/30000], Step [1/1], Training Loss: 14436.9697, Valid Loss: 76.7810
Epoch [22001/30000], Step [1/1], Training Loss: 14241.8037, Valid Loss: 82.4476
Epoch [22101/30000], Step [1/1], Training Loss: 14086.5078, Valid Loss: 80.9905
Epoch [22201/30000], Step [1/1], Training Loss: 13948.0625, Valid Loss: 81.8191
Epoch [22301/30000], Step [1/1], Training Loss: 13825.1064, Valid Loss: 83.8191
Epoch [22401/30000], Step [1/1], Training Loss: 13679.3604, Valid Loss: 77.6286
Epoch [22501/30000], Step [1/1], Training Loss: 13569.4570, Valid Loss: 79.7619
Epoch [22601/30000], Step [1/1], Training Loss: 13408.5518, Valid Loss: 90.5048
Epoch [22701/30000], Step [1/1], Training Loss: 13271.1689, Valid Loss: 86.7429
Epoch [22801/30000], Step [1/1], Training Loss: 13167.5342, Valid Loss: 87.8857
Epoch [22901/30000], Step [1/1], Training Loss: 13011.0986, Valid Loss: 91.0191
Epoch [23001/30000], Step [1/1], Training Loss: 12887.1709, Valid Loss: 86.2381
Epoch [23101/30000], Step [1/1], Training Loss: 12780.6709, Valid Loss: 86.4000
Epoch [23201/30000], Step [1/1], Training Loss: 12654.3232, Valid Loss: 89.5143
Epoch [23301/30000], Step [1/1], Training Loss: 12512.5811, Valid Loss: 90.6571
Epoch [23401/30000], Step [1/1], Training Loss: 12625.9502, Valid Loss: 93.9333
Epoch [23501/30000], Step [1/1], Training Loss: 12293.4072, Valid Loss: 91.3048
Epoch [23601/30000], Step [1/1], Training Loss: 12163.4805, Valid Loss: 85.7333
Epoch [23701/30000], Step [1/1], Training Loss: 12041.7305, Valid Loss: 89.3810
Epoch [23801/30000], Step [1/1], Training Loss: 11916.6963, Valid Loss: 82.1429
Epoch [23901/30000], Step [1/1], Training Loss: 11799.0771, Valid Loss: 78.9905
Epoch [24001/30000], Step [1/1], Training Loss: 11677.3008, Valid Loss: 80.2857
Epoch [24101/30000], Step [1/1], Training Loss: 11565.2227, Valid Loss: 77.6000
Epoch [24201/30000], Step [1/1], Training Loss: 11498.8271, Valid Loss: 78.3714
Epoch [24301/30000], Step [1/1], Training Loss: 11316.4121, Valid Loss: 77.2381
Epoch [24401/30000], Step [1/1], Training Loss: 11177.7197, Valid Loss: 77.9429
Epoch [24501/30000], Step [1/1], Training Loss: 11023.3818, Valid Loss: 74.3238
Epoch [24601/30000], Step [1/1], Training Loss: 10889.0957, Valid Loss: 74.5238
Epoch [24701/30000], Step [1/1], Training Loss: 10728.6562, Valid Loss: 83.2952
Epoch [24801/30000], Step [1/1], Training Loss: 10549.5684, Valid Loss: 79.5905
Epoch [24901/30000], Step [1/1], Training Loss: 10411.9951, Valid Loss: 85.4952
Epoch [25001/30000], Step [1/1], Training Loss: 10093.9180, Valid Loss: 92.7048
Epoch [25101/30000], Step [1/1], Training Loss: 9836.0361, Valid Loss: 85.8857
Epoch [25201/30000], Step [1/1], Training Loss: 9510.7266, Valid Loss: 98.7429
Epoch [25301/30000], Step [1/1], Training Loss: 9172.6172, Valid Loss: 107.2476
Epoch [25401/30000], Step [1/1], Training Loss: 8986.3506, Valid Loss: 99.8191
Epoch [25501/30000], Step [1/1], Training Loss: 8845.3086, Valid Loss: 98.9619
Epoch [25601/30000], Step [1/1], Training Loss: 8695.8330, Valid Loss: 103.4952
Epoch [25701/30000], Step [1/1], Training Loss: 8579.5938, Valid Loss: 94.0095
Epoch [25801/30000], Step [1/1], Training Loss: 8461.4014, Valid Loss: 90.7333
Epoch [25901/30000], Step [1/1], Training Loss: 8349.9492, Valid Loss: 95.8286
Epoch [26001/30000], Step [1/1], Training Loss: 8228.3320, Valid Loss: 93.5810
Epoch [26101/30000], Step [1/1], Training Loss: 8118.2617, Valid Loss: 94.1619
Epoch [26201/30000], Step [1/1], Training Loss: 8008.8076, Valid Loss: 93.1238
Epoch [26301/30000], Step [1/1], Training Loss: 7903.6582, Valid Loss: 90.4762
Epoch [26401/30000], Step [1/1], Training Loss: 7798.2158, Valid Loss: 90.5810
Epoch [26501/30000], Step [1/1], Training Loss: 7696.0112, Valid Loss: 92.9810
Epoch [26601/30000], Step [1/1], Training Loss: 7596.9307, Valid Loss: 93.1333
Epoch [26701/30000], Step [1/1], Training Loss: 7498.5435, Valid Loss: 93.8952
Epoch [26801/30000], Step [1/1], Training Loss: 7401.0083, Valid Loss: 85.6667
Epoch [26901/30000], Step [1/1], Training Loss: 7306.3301, Valid Loss: 93.8191
Epoch [27001/30000], Step [1/1], Training Loss: 7211.8428, Valid Loss: 90.3810
Epoch [27101/30000], Step [1/1], Training Loss: 7118.6348, Valid Loss: 86.3524
Epoch [27201/30000], Step [1/1], Training Loss: 7026.7837, Valid Loss: 85.0095
Epoch [27301/30000], Step [1/1], Training Loss: 6939.8970, Valid Loss: 89.0476
Epoch [27401/30000], Step [1/1], Training Loss: 6849.8364, Valid Loss: 85.4286
Epoch [27501/30000], Step [1/1], Training Loss: 6758.2979, Valid Loss: 84.4667
Epoch [27601/30000], Step [1/1], Training Loss: 6702.2095, Valid Loss: 89.8191
Epoch [27701/30000], Step [1/1], Training Loss: 6603.8203, Valid Loss: 101.8095
Epoch [27801/30000], Step [1/1], Training Loss: 6503.6387, Valid Loss: 94.6286
Epoch [27901/30000], Step [1/1], Training Loss: 6418.4497, Valid Loss: 94.3810
Epoch [28001/30000], Step [1/1], Training Loss: 6331.7476, Valid Loss: 89.3905
Epoch [28101/30000], Step [1/1], Training Loss: 6252.9585, Valid Loss: 91.8476
Epoch [28201/30000], Step [1/1], Training Loss: 6168.3667, Valid Loss: 93.4095
Epoch [28301/30000], Step [1/1], Training Loss: 6088.0215, Valid Loss: 95.2000
Epoch [28401/30000], Step [1/1], Training Loss: 6009.3091, Valid Loss: 89.6762
Epoch [28501/30000], Step [1/1], Training Loss: 5931.4790, Valid Loss: 90.0000
Epoch [28601/30000], Step [1/1], Training Loss: 5853.3901, Valid Loss: 98.6476
Epoch [28701/30000], Step [1/1], Training Loss: 7867.9292, Valid Loss: 93.7619
Epoch [28801/30000], Step [1/1], Training Loss: 6642.9492, Valid Loss: 85.0286
Epoch [28901/30000], Step [1/1], Training Loss: 6575.1631, Valid Loss: 87.1143
Epoch [29001/30000], Step [1/1], Training Loss: 5780.6562, Valid Loss: 76.9619
Epoch [29101/30000], Step [1/1], Training Loss: 5684.7559, Valid Loss: 82.3524
Epoch [29201/30000], Step [1/1], Training Loss: 5670.8857, Valid Loss: 78.5429
Epoch [29301/30000], Step [1/1], Training Loss: 5537.8696, Valid Loss: 80.2381
Epoch [29401/30000], Step [1/1], Training Loss: 5471.4312, Valid Loss: 81.2571
Epoch [29501/30000], Step [1/1], Training Loss: 5400.8125, Valid Loss: 76.4571
Epoch [29601/30000], Step [1/1], Training Loss: 5336.4561, Valid Loss: 78.3524
Epoch [29701/30000], Step [1/1], Training Loss: 5273.2764, Valid Loss: 77.6952
Epoch [29801/30000], Step [1/1], Training Loss: 5211.8267, Valid Loss: 76.4571
Epoch [29901/30000], Step [1/1], Training Loss: 5175.3398, Valid Loss: 88.8952

 End Time: 2021/04/19, 03:46:22




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=512 	layers=3

Start Time = 2021/04/19, 03:47:17
##########################################################


[Epoch 0] Rounded prediction: 
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([ 6., 16., 16., 17., 20., 19., 20., 13.,  0., 15.,  2., 10., 12., 12.,
        10.,  6.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0., 12.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,
         3.,  4.,  5.,  6., 13., 13.,  5.,  0., 17., 34., 23., 13., 20., 21.,
        34., 30., 34., 30., 40., 28., 29.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([ 9., 17., 18., 21., 17., 19., 18., 14., 16., 13., 17., 12., 18., 21.,
        15., 19., 10., 14., 10., 18., 10.,  3.,  0.,  4.,  4.,  4.,  6.,  5.,
         6.,  0.,  0.,  0.,  0.,  5.,  1.,  3.,  5.,  1.,  1.,  0.,  0., 10.,
         5.,  6.,  1.,  2.,  4.,  4.,  0.,  4.,  4.,  5.,  2.,  2.,  6.,  1.,
         0.,  9.,  7.,  0.,  4.,  3.,  2.,  3.,  4.,  3.,  3.,  2.,  0.,  9.,
         8.,  9., 11.,  7., 23., 11.,  5., 11., 11.,  8., 10.,  3., 10., 21.,
        14., 14.,  6.,  8., 15., 15.,  8., 12., 39., 39., 28., 32., 32., 21.,
        24., 29., 33., 29., 29., 26., 27.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128673.0000, Valid Loss: 238.9238
Epoch [101/30000], Step [1/1], Training Loss: 121023.7969, Valid Loss: 118.3048
Epoch [201/30000], Step [1/1], Training Loss: 118632.5625, Valid Loss: 192.8286
Epoch [301/30000], Step [1/1], Training Loss: 116386.5938, Valid Loss: 331.0095
Epoch [401/30000], Step [1/1], Training Loss: 114229.6016, Valid Loss: 532.7809
Epoch [501/30000], Step [1/1], Training Loss: 112148.6797, Valid Loss: 767.3048
Epoch [601/30000], Step [1/1], Training Loss: 110132.0625, Valid Loss: 1051.8286
Epoch [701/30000], Step [1/1], Training Loss: 108179.9688, Valid Loss: 1385.6572
Epoch [801/30000], Step [1/1], Training Loss: 106285.0859, Valid Loss: 1689.9714
Epoch [901/30000], Step [1/1], Training Loss: 104445.3984, Valid Loss: 2114.4954
Epoch [1001/30000], Step [1/1], Training Loss: 102652.0469, Valid Loss: 2184.2668
Epoch [1101/30000], Step [1/1], Training Loss: 100906.4297, Valid Loss: 2012.9238
Epoch [1201/30000], Step [1/1], Training Loss: 99209.6484, Valid Loss: 2501.7239
Epoch [1301/30000], Step [1/1], Training Loss: 97557.2812, Valid Loss: 2676.0381
Epoch [1401/30000], Step [1/1], Training Loss: 95942.6641, Valid Loss: 1653.7048
Epoch [1501/30000], Step [1/1], Training Loss: 93914.7031, Valid Loss: 111.6857
Epoch [1601/30000], Step [1/1], Training Loss: 92232.0234, Valid Loss: 120.1143
Epoch [1701/30000], Step [1/1], Training Loss: 90594.6406, Valid Loss: 140.5714
Epoch [1801/30000], Step [1/1], Training Loss: 88968.6719, Valid Loss: 140.5333
Epoch [1901/30000], Step [1/1], Training Loss: 87394.7109, Valid Loss: 145.1619
Epoch [2001/30000], Step [1/1], Training Loss: 85851.0312, Valid Loss: 134.9429
Epoch [2101/30000], Step [1/1], Training Loss: 84333.6797, Valid Loss: 141.7238
Epoch [2201/30000], Step [1/1], Training Loss: 82852.4219, Valid Loss: 134.2857
Epoch [2301/30000], Step [1/1], Training Loss: 81398.2656, Valid Loss: 135.6952
Epoch [2401/30000], Step [1/1], Training Loss: 79970.8516, Valid Loss: 150.9333
Epoch [2501/30000], Step [1/1], Training Loss: 78565.6953, Valid Loss: 133.0476
Epoch [2601/30000], Step [1/1], Training Loss: 77138.7031, Valid Loss: 131.8571
Epoch [2701/30000], Step [1/1], Training Loss: 75780.0938, Valid Loss: 126.5333
Epoch [2801/30000], Step [1/1], Training Loss: 74450.4609, Valid Loss: 130.7429
Epoch [2901/30000], Step [1/1], Training Loss: 73145.8359, Valid Loss: 130.8571
Epoch [3001/30000], Step [1/1], Training Loss: 71867.0234, Valid Loss: 130.7429
Epoch [3101/30000], Step [1/1], Training Loss: 70613.0938, Valid Loss: 125.7714
Epoch [3201/30000], Step [1/1], Training Loss: 69382.3984, Valid Loss: 135.3333
Epoch [3301/30000], Step [1/1], Training Loss: 68179.8281, Valid Loss: 131.8190
Epoch [3401/30000], Step [1/1], Training Loss: 66999.2656, Valid Loss: 137.6667
Epoch [3501/30000], Step [1/1], Training Loss: 65844.3906, Valid Loss: 132.8381
Epoch [3601/30000], Step [1/1], Training Loss: 64712.7539, Valid Loss: 131.3238
Epoch [3701/30000], Step [1/1], Training Loss: 63605.0000, Valid Loss: 127.3333
Epoch [3801/30000], Step [1/1], Training Loss: 62529.5781, Valid Loss: 117.8381
Epoch [3901/30000], Step [1/1], Training Loss: 61460.9023, Valid Loss: 137.3619
Epoch [4001/30000], Step [1/1], Training Loss: 60409.9453, Valid Loss: 119.0095
Epoch [4101/30000], Step [1/1], Training Loss: 59399.2422, Valid Loss: 119.2762
Epoch [4201/30000], Step [1/1], Training Loss: 58296.5703, Valid Loss: 118.0286
Epoch [4301/30000], Step [1/1], Training Loss: 57292.6641, Valid Loss: 119.4476
Epoch [4401/30000], Step [1/1], Training Loss: 56249.5508, Valid Loss: 111.3810
Epoch [4501/30000], Step [1/1], Training Loss: 55258.9883, Valid Loss: 111.8571
Epoch [4601/30000], Step [1/1], Training Loss: 54288.3438, Valid Loss: 114.2381
Epoch [4701/30000], Step [1/1], Training Loss: 53335.6914, Valid Loss: 110.7429
Epoch [4801/30000], Step [1/1], Training Loss: 52406.5938, Valid Loss: 110.5810
Epoch [4901/30000], Step [1/1], Training Loss: 51495.7695, Valid Loss: 109.8191
Epoch [5001/30000], Step [1/1], Training Loss: 50602.7617, Valid Loss: 113.1524
Epoch [5101/30000], Step [1/1], Training Loss: 49726.8672, Valid Loss: 103.2381
Epoch [5201/30000], Step [1/1], Training Loss: 48874.6914, Valid Loss: 106.0381
Epoch [5301/30000], Step [1/1], Training Loss: 47999.0078, Valid Loss: 109.1619
Epoch [5401/30000], Step [1/1], Training Loss: 47220.4219, Valid Loss: 105.4952
Epoch [5501/30000], Step [1/1], Training Loss: 46364.1016, Valid Loss: 112.1714
Epoch [5601/30000], Step [1/1], Training Loss: 45467.0820, Valid Loss: 101.4667
Epoch [5701/30000], Step [1/1], Training Loss: 44686.8086, Valid Loss: 91.3524
Epoch [5801/30000], Step [1/1], Training Loss: 44222.4961, Valid Loss: 91.9048
Epoch [5901/30000], Step [1/1], Training Loss: 43151.8945, Valid Loss: 100.8857
Epoch [6001/30000], Step [1/1], Training Loss: 42351.5820, Valid Loss: 91.1714
Epoch [6101/30000], Step [1/1], Training Loss: 41605.9453, Valid Loss: 100.5048
Epoch [6201/30000], Step [1/1], Training Loss: 40878.9336, Valid Loss: 95.2381
Epoch [6301/30000], Step [1/1], Training Loss: 40170.2969, Valid Loss: 96.8476
Epoch [6401/30000], Step [1/1], Training Loss: 39472.0664, Valid Loss: 98.6476
Epoch [6501/30000], Step [1/1], Training Loss: 38778.7930, Valid Loss: 93.8857
Epoch [6601/30000], Step [1/1], Training Loss: 38102.8828, Valid Loss: 90.2286
Epoch [6701/30000], Step [1/1], Training Loss: 37446.1523, Valid Loss: 100.0571
Epoch [6801/30000], Step [1/1], Training Loss: 37058.0195, Valid Loss: 94.3619
Epoch [6901/30000], Step [1/1], Training Loss: 36385.7578, Valid Loss: 79.4762
Epoch [7001/30000], Step [1/1], Training Loss: 35592.1523, Valid Loss: 88.3619
Epoch [7101/30000], Step [1/1], Training Loss: 34972.0391, Valid Loss: 75.1905
Epoch [7201/30000], Step [1/1], Training Loss: 34356.7422, Valid Loss: 83.9143
Epoch [7301/30000], Step [1/1], Training Loss: 33689.8633, Valid Loss: 79.9619
Epoch [7401/30000], Step [1/1], Training Loss: 33034.3984, Valid Loss: 83.2571
Epoch [7501/30000], Step [1/1], Training Loss: 32409.7715, Valid Loss: 87.9524
Epoch [7601/30000], Step [1/1], Training Loss: 31829.2363, Valid Loss: 77.9238
Epoch [7701/30000], Step [1/1], Training Loss: 31264.6230, Valid Loss: 82.4286
Epoch [7801/30000], Step [1/1], Training Loss: 30716.2520, Valid Loss: 69.8381
Epoch [7901/30000], Step [1/1], Training Loss: 30183.9531, Valid Loss: 78.9619
Epoch [8001/30000], Step [1/1], Training Loss: 29411.6953, Valid Loss: 79.1810
Epoch [8101/30000], Step [1/1], Training Loss: 28696.6445, Valid Loss: 75.7143
Epoch [8201/30000], Step [1/1], Training Loss: 28022.0723, Valid Loss: 81.6000
Epoch [8301/30000], Step [1/1], Training Loss: 27451.4883, Valid Loss: 73.1048
Epoch [8401/30000], Step [1/1], Training Loss: 26937.1680, Valid Loss: 77.4381
Epoch [8501/30000], Step [1/1], Training Loss: 26382.7422, Valid Loss: 74.8667
Epoch [8601/30000], Step [1/1], Training Loss: 25850.9902, Valid Loss: 75.1714
Epoch [8701/30000], Step [1/1], Training Loss: 25320.3828, Valid Loss: 75.6952
Epoch [8801/30000], Step [1/1], Training Loss: 24769.4141, Valid Loss: 65.8381
Epoch [8901/30000], Step [1/1], Training Loss: 24245.5234, Valid Loss: 65.0952
Epoch [9001/30000], Step [1/1], Training Loss: 23723.1211, Valid Loss: 73.0191
Epoch [9101/30000], Step [1/1], Training Loss: 23226.3145, Valid Loss: 72.2000
Epoch [9201/30000], Step [1/1], Training Loss: 22748.3770, Valid Loss: 71.9429
Epoch [9301/30000], Step [1/1], Training Loss: 22282.1855, Valid Loss: 71.0571
Epoch [9401/30000], Step [1/1], Training Loss: 22133.3242, Valid Loss: 95.5429
Epoch [9501/30000], Step [1/1], Training Loss: 21564.3027, Valid Loss: 64.5048
Epoch [9601/30000], Step [1/1], Training Loss: 20975.5156, Valid Loss: 67.6476
Epoch [9701/30000], Step [1/1], Training Loss: 20531.1680, Valid Loss: 67.7429
Epoch [9801/30000], Step [1/1], Training Loss: 20107.8730, Valid Loss: 66.4286
Epoch [9901/30000], Step [1/1], Training Loss: 19692.9766, Valid Loss: 64.1048
Epoch [10001/30000], Step [1/1], Training Loss: 19288.6875, Valid Loss: 71.1048
Epoch [10101/30000], Step [1/1], Training Loss: 18895.4316, Valid Loss: 67.2762

[Epoch 15000] Rounded prediction: 
tensor([12., 17., 19., 18., 14., 18., 17., 15., 13., 15., 14., 13., 16., 16.,
        12., 11.,  7., 14., 11., 14.,  7.,  5.,  4.,  8.,  3.,  3.,  3.,  4.,
         2.,  5., 11.,  3.,  3.,  4.,  0.,  5.,  2.,  5.,  0.,  4.,  4., 16.,
         9.,  8.,  6.,  6.,  6.,  2.,  3.,  4.,  7.,  2.,  0.,  0., 12.,  7.,
         6.,  6.,  5.,  0.,  3.,  6.,  4.,  5.,  4.,  4.,  1.,  6.,  2., 12.,
         4.,  7., 10.,  9., 13.,  9., 11., 10., 11., 13.,  7.,  9.,  6., 22.,
        23.,  9.,  4.,  7., 12., 11., 12., 27., 41., 37., 28., 31., 37., 20.,
        23., 23., 25., 26., 23., 20., 23.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([12., 17., 18., 18., 14., 19., 15., 15., 14., 15., 15., 15., 17., 18.,
        14., 17., 10., 13.,  8., 13.,  8.,  3.,  1.,  6.,  8.,  1.,  0.,  2.,
         7.,  3.,  6.,  6.,  2.,  3.,  1.,  8.,  3.,  4.,  0.,  4.,  5., 16.,
        11.,  8.,  3.,  9.,  3.,  0.,  2.,  2.,  1.,  1.,  0.,  2., 10.,  7.,
         8.,  5.,  2.,  2.,  3.,  7.,  2.,  1.,  0.,  1.,  1.,  4.,  5.,  4.,
         3.,  1.,  9.,  5., 14., 14.,  7., 14., 15., 19.,  7.,  6.,  7., 18.,
        32.,  9.,  3.,  9., 13., 16., 13., 39., 42., 30., 23., 31., 39., 16.,
        22., 20., 24., 28., 30., 24., 22.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [10201/30000], Step [1/1], Training Loss: 18509.8652, Valid Loss: 60.6667
Epoch [10301/30000], Step [1/1], Training Loss: 18132.9375, Valid Loss: 65.9905
Epoch [10401/30000], Step [1/1], Training Loss: 17763.0332, Valid Loss: 70.0000
Epoch [10501/30000], Step [1/1], Training Loss: 17401.9434, Valid Loss: 66.3238
Epoch [10601/30000], Step [1/1], Training Loss: 17011.0273, Valid Loss: 68.6762
Epoch [10701/30000], Step [1/1], Training Loss: 16659.0625, Valid Loss: 68.5714
Epoch [10801/30000], Step [1/1], Training Loss: 16309.4023, Valid Loss: 66.5238
Epoch [10901/30000], Step [1/1], Training Loss: 15971.4277, Valid Loss: 68.5810
Epoch [11001/30000], Step [1/1], Training Loss: 15641.0967, Valid Loss: 69.7714
Epoch [11101/30000], Step [1/1], Training Loss: 15319.4609, Valid Loss: 66.6000
Epoch [11201/30000], Step [1/1], Training Loss: 15004.5840, Valid Loss: 71.7048
Epoch [11301/30000], Step [1/1], Training Loss: 14694.0840, Valid Loss: 65.6571
Epoch [11401/30000], Step [1/1], Training Loss: 14394.1582, Valid Loss: 65.7810
Epoch [11501/30000], Step [1/1], Training Loss: 14099.4082, Valid Loss: 65.9714
Epoch [11601/30000], Step [1/1], Training Loss: 13811.5850, Valid Loss: 65.5810
Epoch [11701/30000], Step [1/1], Training Loss: 13532.1719, Valid Loss: 68.0762
Epoch [11801/30000], Step [1/1], Training Loss: 13254.7588, Valid Loss: 70.1714
Epoch [11901/30000], Step [1/1], Training Loss: 12967.7646, Valid Loss: 76.1143
Epoch [12001/30000], Step [1/1], Training Loss: 13215.6455, Valid Loss: 79.8095
Epoch [12101/30000], Step [1/1], Training Loss: 12746.7402, Valid Loss: 89.3810
Epoch [12201/30000], Step [1/1], Training Loss: 12465.1484, Valid Loss: 87.9619
Epoch [12301/30000], Step [1/1], Training Loss: 12213.2412, Valid Loss: 85.4000
Epoch [12401/30000], Step [1/1], Training Loss: 11960.0742, Valid Loss: 76.8762
Epoch [12501/30000], Step [1/1], Training Loss: 11542.6963, Valid Loss: 78.4381
Epoch [12601/30000], Step [1/1], Training Loss: 11263.7559, Valid Loss: 77.2381
Epoch [12701/30000], Step [1/1], Training Loss: 11023.7285, Valid Loss: 66.6952
Epoch [12801/30000], Step [1/1], Training Loss: 10787.7598, Valid Loss: 66.6000
Epoch [12901/30000], Step [1/1], Training Loss: 10559.6191, Valid Loss: 60.0571
Epoch [13001/30000], Step [1/1], Training Loss: 10336.0410, Valid Loss: 64.9524
Epoch [13101/30000], Step [1/1], Training Loss: 10091.5293, Valid Loss: 62.6857
Epoch [13201/30000], Step [1/1], Training Loss: 9774.5635, Valid Loss: 66.2286
Epoch [13301/30000], Step [1/1], Training Loss: 9610.0576, Valid Loss: 62.1619
Epoch [13401/30000], Step [1/1], Training Loss: 9343.8086, Valid Loss: 68.6190
Epoch [13501/30000], Step [1/1], Training Loss: 9133.4941, Valid Loss: 67.7048
Epoch [13601/30000], Step [1/1], Training Loss: 8930.5752, Valid Loss: 68.9905
Epoch [13701/30000], Step [1/1], Training Loss: 8727.8506, Valid Loss: 67.1429
Epoch [13801/30000], Step [1/1], Training Loss: 8531.1748, Valid Loss: 62.5238
Epoch [13901/30000], Step [1/1], Training Loss: 8318.9111, Valid Loss: 69.5143
Epoch [14001/30000], Step [1/1], Training Loss: 8127.7446, Valid Loss: 67.9905
Epoch [14101/30000], Step [1/1], Training Loss: 7943.3633, Valid Loss: 66.4286
Epoch [14201/30000], Step [1/1], Training Loss: 7765.3608, Valid Loss: 64.3714
Epoch [14301/30000], Step [1/1], Training Loss: 7590.3687, Valid Loss: 61.6571
Epoch [14401/30000], Step [1/1], Training Loss: 7421.6094, Valid Loss: 65.8952
Epoch [14501/30000], Step [1/1], Training Loss: 7256.8032, Valid Loss: 61.8286
Epoch [14601/30000], Step [1/1], Training Loss: 7093.6455, Valid Loss: 67.6952
Epoch [14701/30000], Step [1/1], Training Loss: 6929.3364, Valid Loss: 64.6190
Epoch [14801/30000], Step [1/1], Training Loss: 6774.5303, Valid Loss: 63.5905
Epoch [14901/30000], Step [1/1], Training Loss: 6621.8018, Valid Loss: 62.2476
Epoch [15001/30000], Step [1/1], Training Loss: 6473.4727, Valid Loss: 66.0286
Epoch [15101/30000], Step [1/1], Training Loss: 6328.6187, Valid Loss: 62.7714
Epoch [15201/30000], Step [1/1], Training Loss: 6186.7529, Valid Loss: 64.6286
Epoch [15301/30000], Step [1/1], Training Loss: 6049.6191, Valid Loss: 62.7333
Epoch [15401/30000], Step [1/1], Training Loss: 5914.4326, Valid Loss: 65.4286
Epoch [15501/30000], Step [1/1], Training Loss: 5781.7246, Valid Loss: 64.0381
Epoch [15601/30000], Step [1/1], Training Loss: 5653.3696, Valid Loss: 65.6667
Epoch [15701/30000], Step [1/1], Training Loss: 5528.5356, Valid Loss: 62.2857
Epoch [15801/30000], Step [1/1], Training Loss: 5406.6885, Valid Loss: 63.1048
Epoch [15901/30000], Step [1/1], Training Loss: 5287.6045, Valid Loss: 66.3238
Epoch [16001/30000], Step [1/1], Training Loss: 5171.4683, Valid Loss: 64.2762
Epoch [16101/30000], Step [1/1], Training Loss: 5058.4526, Valid Loss: 59.4000
Epoch [16201/30000], Step [1/1], Training Loss: 4948.6709, Valid Loss: 61.5810
Epoch [16301/30000], Step [1/1], Training Loss: 5090.8716, Valid Loss: 72.4952
Epoch [16401/30000], Step [1/1], Training Loss: 4722.6084, Valid Loss: 72.1238
Epoch [16501/30000], Step [1/1], Training Loss: 4602.8301, Valid Loss: 64.5905
Epoch [16601/30000], Step [1/1], Training Loss: 4495.5698, Valid Loss: 58.3905
Epoch [16701/30000], Step [1/1], Training Loss: 4401.4243, Valid Loss: 71.6667
Epoch [16801/30000], Step [1/1], Training Loss: 4292.7178, Valid Loss: 70.0191
Epoch [16901/30000], Step [1/1], Training Loss: 4197.8940, Valid Loss: 74.4857
Epoch [17001/30000], Step [1/1], Training Loss: 4102.0093, Valid Loss: 70.9048
Epoch [17101/30000], Step [1/1], Training Loss: 4011.3848, Valid Loss: 67.0000
Epoch [17201/30000], Step [1/1], Training Loss: 3924.2869, Valid Loss: 71.5048
Epoch [17301/30000], Step [1/1], Training Loss: 3838.6819, Valid Loss: 68.1619
Epoch [17401/30000], Step [1/1], Training Loss: 3756.7078, Valid Loss: 62.5905
Epoch [17501/30000], Step [1/1], Training Loss: 3675.7095, Valid Loss: 70.5714
Epoch [17601/30000], Step [1/1], Training Loss: 3531.3025, Valid Loss: 60.7048
Epoch [17701/30000], Step [1/1], Training Loss: 3394.5769, Valid Loss: 74.4381
Epoch [17801/30000], Step [1/1], Training Loss: 3310.2563, Valid Loss: 65.3429
Epoch [17901/30000], Step [1/1], Training Loss: 3227.5991, Valid Loss: 72.8857
Epoch [18001/30000], Step [1/1], Training Loss: 3146.3574, Valid Loss: 67.8571
Epoch [18101/30000], Step [1/1], Training Loss: 3068.9336, Valid Loss: 67.3524
Epoch [18201/30000], Step [1/1], Training Loss: 2992.8696, Valid Loss: 68.7048
Epoch [18301/30000], Step [1/1], Training Loss: 2917.6658, Valid Loss: 67.7905
Epoch [18401/30000], Step [1/1], Training Loss: 2844.9639, Valid Loss: 71.0381
Epoch [18501/30000], Step [1/1], Training Loss: 2774.3445, Valid Loss: 68.6095
Epoch [18601/30000], Step [1/1], Training Loss: 2703.8137, Valid Loss: 72.1333
Epoch [18701/30000], Step [1/1], Training Loss: 2636.0388, Valid Loss: 68.2190
Epoch [18801/30000], Step [1/1], Training Loss: 2570.0178, Valid Loss: 70.8191
Epoch [18901/30000], Step [1/1], Training Loss: 2504.5251, Valid Loss: 72.7238
Epoch [19001/30000], Step [1/1], Training Loss: 2443.0007, Valid Loss: 68.2190
Epoch [19101/30000], Step [1/1], Training Loss: 2379.2961, Valid Loss: 69.5333
Epoch [19201/30000], Step [1/1], Training Loss: 2319.1838, Valid Loss: 67.2095
Epoch [19301/30000], Step [1/1], Training Loss: 2260.0571, Valid Loss: 71.8952
Epoch [19401/30000], Step [1/1], Training Loss: 2202.5632, Valid Loss: 66.4952
Epoch [19501/30000], Step [1/1], Training Loss: 2147.3110, Valid Loss: 67.4095
Epoch [19601/30000], Step [1/1], Training Loss: 2092.6050, Valid Loss: 67.3238
Epoch [19701/30000], Step [1/1], Training Loss: 2040.2188, Valid Loss: 70.8571
Epoch [19801/30000], Step [1/1], Training Loss: 1989.2764, Valid Loss: 67.9810
Epoch [19901/30000], Step [1/1], Training Loss: 1948.2922, Valid Loss: 70.1429
Epoch [20001/30000], Step [1/1], Training Loss: 1892.2148, Valid Loss: 68.6762
Epoch [20101/30000], Step [1/1], Training Loss: 1845.3741, Valid Loss: 68.3810
Epoch [20201/30000], Step [1/1], Training Loss: 1800.6938, Valid Loss: 68.8286
Epoch [20301/30000], Step [1/1], Training Loss: 1757.5804, Valid Loss: 66.0381
Epoch [20401/30000], Step [1/1], Training Loss: 1715.5939, Valid Loss: 67.6667

[Epoch 25000] Rounded prediction: 
tensor([11., 18., 17., 17., 13., 19., 15., 16., 13., 15., 14., 14., 14., 18.,
        11., 14.,  7., 16., 14., 15., 15.,  9., 13., 10.,  7.,  5.,  5.,  3.,
         6.,  6.,  8.,  7.,  4.,  6.,  2.,  9.,  3.,  7.,  0.,  6.,  6., 18.,
        10.,  7.,  3.,  8.,  7.,  2.,  3.,  4.,  3.,  4.,  8.,  4., 11.,  5.,
         8.,  6.,  6.,  3.,  2.,  9.,  1.,  9.,  3.,  9.,  4., 10.,  6.,  7.,
         7.,  6.,  8.,  8., 12., 24., 11., 24., 14., 19.,  9., 11., 11., 22.,
        29.,  9.,  4.,  6.,  9., 11., 16., 44., 37., 36., 26., 31., 29., 15.,
        28., 28., 27., 30., 32., 23., 21.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [20501/30000], Step [1/1], Training Loss: 4086.8157, Valid Loss: 127.1333
Epoch [20601/30000], Step [1/1], Training Loss: 1650.4702, Valid Loss: 66.9238
Epoch [20701/30000], Step [1/1], Training Loss: 1605.9851, Valid Loss: 61.5048
Epoch [20801/30000], Step [1/1], Training Loss: 1569.2087, Valid Loss: 64.0000
Epoch [20901/30000], Step [1/1], Training Loss: 1532.5126, Valid Loss: 60.6190
Epoch [21001/30000], Step [1/1], Training Loss: 1497.9991, Valid Loss: 64.4286
Epoch [21101/30000], Step [1/1], Training Loss: 1464.3231, Valid Loss: 62.1714
Epoch [21201/30000], Step [1/1], Training Loss: 1432.9907, Valid Loss: 63.3429
Epoch [21301/30000], Step [1/1], Training Loss: 1400.8740, Valid Loss: 56.9524
Epoch [21401/30000], Step [1/1], Training Loss: 1370.5974, Valid Loss: 60.6952
Epoch [21501/30000], Step [1/1], Training Loss: 1340.9479, Valid Loss: 58.0095
Epoch [21601/30000], Step [1/1], Training Loss: 1311.6074, Valid Loss: 64.0476
Epoch [21701/30000], Step [1/1], Training Loss: 1283.2404, Valid Loss: 56.0857
Epoch [21801/30000], Step [1/1], Training Loss: 1255.6311, Valid Loss: 55.2191
Epoch [21901/30000], Step [1/1], Training Loss: 1228.8800, Valid Loss: 58.2191
Epoch [22001/30000], Step [1/1], Training Loss: 1203.1183, Valid Loss: 59.3333
Epoch [22101/30000], Step [1/1], Training Loss: 1178.0238, Valid Loss: 57.2571
Epoch [22201/30000], Step [1/1], Training Loss: 1152.8472, Valid Loss: 57.5238
Epoch [22301/30000], Step [1/1], Training Loss: 1128.2644, Valid Loss: 58.5905
Epoch [22401/30000], Step [1/1], Training Loss: 1104.6082, Valid Loss: 57.0476
Epoch [22501/30000], Step [1/1], Training Loss: 1081.0016, Valid Loss: 60.0095
Epoch [22601/30000], Step [1/1], Training Loss: 1057.2084, Valid Loss: 59.5238
Epoch [22701/30000], Step [1/1], Training Loss: 1033.8011, Valid Loss: 59.3238
Epoch [22801/30000], Step [1/1], Training Loss: 1010.8575, Valid Loss: 60.7143
Epoch [22901/30000], Step [1/1], Training Loss: 988.5199, Valid Loss: 62.2571
Epoch [23001/30000], Step [1/1], Training Loss: 966.0918, Valid Loss: 61.9143
Epoch [23101/30000], Step [1/1], Training Loss: 944.4922, Valid Loss: 57.7810
Epoch [23201/30000], Step [1/1], Training Loss: 923.1489, Valid Loss: 55.4667
Epoch [23301/30000], Step [1/1], Training Loss: 902.2814, Valid Loss: 55.5238
Epoch [23401/30000], Step [1/1], Training Loss: 881.6940, Valid Loss: 56.3810
Epoch [23501/30000], Step [1/1], Training Loss: 861.9381, Valid Loss: 57.8476
Epoch [23601/30000], Step [1/1], Training Loss: 842.1969, Valid Loss: 57.7429
Epoch [23701/30000], Step [1/1], Training Loss: 823.3247, Valid Loss: 61.7143
Epoch [23801/30000], Step [1/1], Training Loss: 804.5426, Valid Loss: 56.7429
Epoch [23901/30000], Step [1/1], Training Loss: 786.4618, Valid Loss: 53.7524
Epoch [24001/30000], Step [1/1], Training Loss: 768.9987, Valid Loss: 58.2667
Epoch [24101/30000], Step [1/1], Training Loss: 751.9756, Valid Loss: 59.5143
Epoch [24201/30000], Step [1/1], Training Loss: 735.3248, Valid Loss: 61.2476
Epoch [24301/30000], Step [1/1], Training Loss: 719.4027, Valid Loss: 56.7619
Epoch [24401/30000], Step [1/1], Training Loss: 703.9528, Valid Loss: 56.6952
Epoch [24501/30000], Step [1/1], Training Loss: 688.8175, Valid Loss: 55.0952
Epoch [24601/30000], Step [1/1], Training Loss: 674.4891, Valid Loss: 55.3238
Epoch [24701/30000], Step [1/1], Training Loss: 660.6243, Valid Loss: 51.7810
Epoch [24801/30000], Step [1/1], Training Loss: 647.0862, Valid Loss: 54.7810
Epoch [24901/30000], Step [1/1], Training Loss: 632.1204, Valid Loss: 55.1238
Epoch [25001/30000], Step [1/1], Training Loss: 618.0273, Valid Loss: 54.9143
Epoch [25101/30000], Step [1/1], Training Loss: 603.9493, Valid Loss: 61.8000
Epoch [25201/30000], Step [1/1], Training Loss: 590.3188, Valid Loss: 56.9333
Epoch [25301/30000], Step [1/1], Training Loss: 576.7348, Valid Loss: 59.0381
Epoch [25401/30000], Step [1/1], Training Loss: 563.1453, Valid Loss: 57.1143
Epoch [25501/30000], Step [1/1], Training Loss: 550.2216, Valid Loss: 56.5048
Epoch [25601/30000], Step [1/1], Training Loss: 537.3564, Valid Loss: 55.3143
Epoch [25701/30000], Step [1/1], Training Loss: 524.2993, Valid Loss: 53.5143
Epoch [25801/30000], Step [1/1], Training Loss: 511.8460, Valid Loss: 60.3048
Epoch [25901/30000], Step [1/1], Training Loss: 499.4823, Valid Loss: 57.1143
Epoch [26001/30000], Step [1/1], Training Loss: 487.6399, Valid Loss: 55.4571
Epoch [26101/30000], Step [1/1], Training Loss: 475.8181, Valid Loss: 53.8667
Epoch [26201/30000], Step [1/1], Training Loss: 464.2157, Valid Loss: 59.5143
Epoch [26301/30000], Step [1/1], Training Loss: 453.0088, Valid Loss: 56.5619
Epoch [26401/30000], Step [1/1], Training Loss: 441.9711, Valid Loss: 55.9714
Epoch [26501/30000], Step [1/1], Training Loss: 431.1772, Valid Loss: 58.4381
Epoch [26601/30000], Step [1/1], Training Loss: 420.7790, Valid Loss: 56.2000
Epoch [26701/30000], Step [1/1], Training Loss: 410.3697, Valid Loss: 59.5238
Epoch [26801/30000], Step [1/1], Training Loss: 400.5197, Valid Loss: 58.8190
Epoch [26901/30000], Step [1/1], Training Loss: 391.0233, Valid Loss: 57.7714
Epoch [27001/30000], Step [1/1], Training Loss: 380.7969, Valid Loss: 55.9714
Epoch [27101/30000], Step [1/1], Training Loss: 518.4764, Valid Loss: 88.6762
Epoch [27201/30000], Step [1/1], Training Loss: 371.7345, Valid Loss: 75.8857
Epoch [27301/30000], Step [1/1], Training Loss: 363.0011, Valid Loss: 74.2095
Epoch [27401/30000], Step [1/1], Training Loss: 353.8841, Valid Loss: 68.8571
Epoch [27501/30000], Step [1/1], Training Loss: 346.7430, Valid Loss: 75.4095
Epoch [27601/30000], Step [1/1], Training Loss: 337.6311, Valid Loss: 65.7048
Epoch [27701/30000], Step [1/1], Training Loss: 329.7338, Valid Loss: 74.9714
Epoch [27801/30000], Step [1/1], Training Loss: 321.6000, Valid Loss: 71.2952
Epoch [27901/30000], Step [1/1], Training Loss: 314.0421, Valid Loss: 72.0571
Epoch [28001/30000], Step [1/1], Training Loss: 306.2511, Valid Loss: 72.5714
Epoch [28101/30000], Step [1/1], Training Loss: 298.2763, Valid Loss: 77.5905
Epoch [28201/30000], Step [1/1], Training Loss: 290.5195, Valid Loss: 67.5048
Epoch [28301/30000], Step [1/1], Training Loss: 282.6279, Valid Loss: 69.0667
Epoch [28401/30000], Step [1/1], Training Loss: 274.6968, Valid Loss: 72.5238
Epoch [28501/30000], Step [1/1], Training Loss: 267.0101, Valid Loss: 69.4191
Epoch [28601/30000], Step [1/1], Training Loss: 259.2343, Valid Loss: 80.5524
Epoch [28701/30000], Step [1/1], Training Loss: 251.8587, Valid Loss: 73.2571
Epoch [28801/30000], Step [1/1], Training Loss: 244.4307, Valid Loss: 75.6000
Epoch [28901/30000], Step [1/1], Training Loss: 237.2306, Valid Loss: 69.6667
Epoch [29001/30000], Step [1/1], Training Loss: 228.8771, Valid Loss: 75.1619
Epoch [29101/30000], Step [1/1], Training Loss: 221.6960, Valid Loss: 72.2571
Epoch [29201/30000], Step [1/1], Training Loss: 214.3427, Valid Loss: 66.1429
Epoch [29301/30000], Step [1/1], Training Loss: 207.0135, Valid Loss: 70.4381
Epoch [29401/30000], Step [1/1], Training Loss: 199.9287, Valid Loss: 67.8667
Epoch [29501/30000], Step [1/1], Training Loss: 192.8881, Valid Loss: 71.7238
Epoch [29601/30000], Step [1/1], Training Loss: 185.9052, Valid Loss: 72.7429
Epoch [29701/30000], Step [1/1], Training Loss: 179.1922, Valid Loss: 72.3905
Epoch [29801/30000], Step [1/1], Training Loss: 172.5795, Valid Loss: 67.9524
Epoch [29901/30000], Step [1/1], Training Loss: 166.1852, Valid Loss: 83.0857

 End Time: 2021/04/19, 03:55:57




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=512 	layers=3

Start Time = 2021/04/19, 03:55:58
##########################################################


[Epoch 0] Rounded prediction: 
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([11., 18., 16., 11., 22., 20., 24., 13., 13., 14., 10.,  8., 13., 11.,
         9.,  5.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  8.,  0.,  0.,  1.,  0.,  7.,  4.,  4.,  0., 12.,
        16., 11.,  3., 12., 18., 15.,  4.,  7., 32., 32., 22., 26., 28., 23.,
        26., 33., 30., 35., 34., 28., 30.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([12., 21., 16., 16., 22., 23., 20., 17., 12., 16., 16., 11., 13., 17.,
         8., 12., 11.,  4.,  8., 10.,  8.,  9., 11., 12.,  6.,  7., 11., 10.,
        10.,  9., 11.,  5.,  8., 12.,  6.,  8.,  8.,  5.,  3.,  8.,  7., 21.,
        10.,  8.,  8., 12.,  9.,  7.,  4.,  8.,  4.,  7.,  6.,  4., 10.,  5.,
         7., 15.,  9.,  3.,  8., 10.,  3., 12.,  5., 11.,  6., 11.,  9., 11.,
         7.,  7.,  7., 12., 17.,  9.,  5., 12., 10., 11., 12., 12., 14., 22.,
        19., 10., 10., 15., 22., 19., 12., 13., 35., 32., 23., 34., 34., 24.,
        37., 38., 29., 35., 34., 27., 31.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128664.9609, Valid Loss: 237.4667
Epoch [101/30000], Step [1/1], Training Loss: 120998.8047, Valid Loss: 118.3048
Epoch [201/30000], Step [1/1], Training Loss: 118608.1094, Valid Loss: 192.8286
Epoch [301/30000], Step [1/1], Training Loss: 116367.5703, Valid Loss: 348.2571
Epoch [401/30000], Step [1/1], Training Loss: 114209.9922, Valid Loss: 532.7809
Epoch [501/30000], Step [1/1], Training Loss: 112129.9688, Valid Loss: 767.3048
Epoch [601/30000], Step [1/1], Training Loss: 110115.3438, Valid Loss: 1051.8286
Epoch [701/30000], Step [1/1], Training Loss: 108164.8672, Valid Loss: 1386.3524
Epoch [801/30000], Step [1/1], Training Loss: 106269.3672, Valid Loss: 1689.9714
Epoch [901/30000], Step [1/1], Training Loss: 104428.3047, Valid Loss: 2092.1714
Epoch [1001/30000], Step [1/1], Training Loss: 102636.6250, Valid Loss: 1805.0953
Epoch [1101/30000], Step [1/1], Training Loss: 100891.5859, Valid Loss: 1835.4476
Epoch [1201/30000], Step [1/1], Training Loss: 99193.3828, Valid Loss: 1981.7334
Epoch [1301/30000], Step [1/1], Training Loss: 97286.4297, Valid Loss: 441.2953
Epoch [1401/30000], Step [1/1], Training Loss: 95533.1406, Valid Loss: 94.7048
Epoch [1501/30000], Step [1/1], Training Loss: 93825.4297, Valid Loss: 114.4286
Epoch [1601/30000], Step [1/1], Training Loss: 92150.5625, Valid Loss: 117.6952
Epoch [1701/30000], Step [1/1], Training Loss: 90512.8281, Valid Loss: 124.3524
Epoch [1801/30000], Step [1/1], Training Loss: 88910.7969, Valid Loss: 126.0286
Epoch [1901/30000], Step [1/1], Training Loss: 87346.1953, Valid Loss: 122.4952
Epoch [2001/30000], Step [1/1], Training Loss: 85804.1406, Valid Loss: 125.1905
Epoch [2101/30000], Step [1/1], Training Loss: 84294.5547, Valid Loss: 120.1429
Epoch [2201/30000], Step [1/1], Training Loss: 82815.6562, Valid Loss: 118.6667
Epoch [2301/30000], Step [1/1], Training Loss: 81364.8359, Valid Loss: 117.0191
Epoch [2401/30000], Step [1/1], Training Loss: 79940.5547, Valid Loss: 116.2000
Epoch [2501/30000], Step [1/1], Training Loss: 78543.8359, Valid Loss: 119.3048
Epoch [2601/30000], Step [1/1], Training Loss: 77116.9844, Valid Loss: 114.0952
Epoch [2701/30000], Step [1/1], Training Loss: 75759.5391, Valid Loss: 117.3714
Epoch [2801/30000], Step [1/1], Training Loss: 74429.9766, Valid Loss: 119.5238
Epoch [2901/30000], Step [1/1], Training Loss: 73128.2344, Valid Loss: 115.9143
Epoch [3001/30000], Step [1/1], Training Loss: 71851.2578, Valid Loss: 112.5524
Epoch [3101/30000], Step [1/1], Training Loss: 70599.0312, Valid Loss: 109.1905
Epoch [3201/30000], Step [1/1], Training Loss: 69372.3047, Valid Loss: 116.6572
Epoch [3301/30000], Step [1/1], Training Loss: 68169.1094, Valid Loss: 116.6572
Epoch [3401/30000], Step [1/1], Training Loss: 66992.1328, Valid Loss: 111.8381
Epoch [3501/30000], Step [1/1], Training Loss: 65835.4141, Valid Loss: 117.0667
Epoch [3601/30000], Step [1/1], Training Loss: 64705.6055, Valid Loss: 112.3905
Epoch [3701/30000], Step [1/1], Training Loss: 63597.1797, Valid Loss: 114.6572
Epoch [3801/30000], Step [1/1], Training Loss: 62513.6250, Valid Loss: 114.1524
Epoch [3901/30000], Step [1/1], Training Loss: 61452.5352, Valid Loss: 113.7524
Epoch [4001/30000], Step [1/1], Training Loss: 60415.1484, Valid Loss: 111.2286
Epoch [4101/30000], Step [1/1], Training Loss: 59398.2773, Valid Loss: 112.7714
Epoch [4201/30000], Step [1/1], Training Loss: 58402.2266, Valid Loss: 114.9905
Epoch [4301/30000], Step [1/1], Training Loss: 57429.4844, Valid Loss: 112.2000
Epoch [4401/30000], Step [1/1], Training Loss: 56493.2852, Valid Loss: 115.0762
Epoch [4501/30000], Step [1/1], Training Loss: 55465.6758, Valid Loss: 98.8286
Epoch [4601/30000], Step [1/1], Training Loss: 54449.5664, Valid Loss: 100.3048
Epoch [4701/30000], Step [1/1], Training Loss: 53475.4531, Valid Loss: 99.2857
Epoch [4801/30000], Step [1/1], Training Loss: 52613.2070, Valid Loss: 98.2476
Epoch [4901/30000], Step [1/1], Training Loss: 51553.5117, Valid Loss: 98.5238
Epoch [5001/30000], Step [1/1], Training Loss: 50628.2344, Valid Loss: 95.6286
Epoch [5101/30000], Step [1/1], Training Loss: 49741.7852, Valid Loss: 91.9143
Epoch [5201/30000], Step [1/1], Training Loss: 48854.7109, Valid Loss: 101.0286
Epoch [5301/30000], Step [1/1], Training Loss: 47995.6992, Valid Loss: 95.9524
Epoch [5401/30000], Step [1/1], Training Loss: 47161.7852, Valid Loss: 100.3429
Epoch [5501/30000], Step [1/1], Training Loss: 46333.3320, Valid Loss: 101.8476
Epoch [5601/30000], Step [1/1], Training Loss: 45525.8945, Valid Loss: 102.6381
Epoch [5701/30000], Step [1/1], Training Loss: 44739.2891, Valid Loss: 105.2381
Epoch [5801/30000], Step [1/1], Training Loss: 43965.4023, Valid Loss: 99.8571
Epoch [5901/30000], Step [1/1], Training Loss: 43205.6172, Valid Loss: 97.8571
Epoch [6001/30000], Step [1/1], Training Loss: 42462.8164, Valid Loss: 104.8952
Epoch [6101/30000], Step [1/1], Training Loss: 41735.8828, Valid Loss: 96.3810
Epoch [6201/30000], Step [1/1], Training Loss: 41030.3164, Valid Loss: 99.0762
Epoch [6301/30000], Step [1/1], Training Loss: 40486.6680, Valid Loss: 86.0571
Epoch [6401/30000], Step [1/1], Training Loss: 39777.0312, Valid Loss: 101.9429
Epoch [6501/30000], Step [1/1], Training Loss: 39074.0938, Valid Loss: 89.0286
Epoch [6601/30000], Step [1/1], Training Loss: 38403.8516, Valid Loss: 92.5810
Epoch [6701/30000], Step [1/1], Training Loss: 37637.5195, Valid Loss: 88.7810
Epoch [6801/30000], Step [1/1], Training Loss: 36863.4336, Valid Loss: 83.6190
Epoch [6901/30000], Step [1/1], Training Loss: 36148.4297, Valid Loss: 88.0762
Epoch [7001/30000], Step [1/1], Training Loss: 35482.9766, Valid Loss: 87.1333
Epoch [7101/30000], Step [1/1], Training Loss: 34849.8594, Valid Loss: 90.2952
Epoch [7201/30000], Step [1/1], Training Loss: 34229.9023, Valid Loss: 87.8000
Epoch [7301/30000], Step [1/1], Training Loss: 33625.8789, Valid Loss: 88.5333
Epoch [7401/30000], Step [1/1], Training Loss: 33252.6367, Valid Loss: 81.8095
Epoch [7501/30000], Step [1/1], Training Loss: 32458.7910, Valid Loss: 77.3333
Epoch [7601/30000], Step [1/1], Training Loss: 31607.6113, Valid Loss: 62.4381
Epoch [7701/30000], Step [1/1], Training Loss: 30881.9492, Valid Loss: 68.1714
Epoch [7801/30000], Step [1/1], Training Loss: 30244.8340, Valid Loss: 61.9143
Epoch [7901/30000], Step [1/1], Training Loss: 29639.2637, Valid Loss: 63.7429
Epoch [8001/30000], Step [1/1], Training Loss: 29063.6035, Valid Loss: 69.1333
Epoch [8101/30000], Step [1/1], Training Loss: 28504.2637, Valid Loss: 64.4857
Epoch [8201/30000], Step [1/1], Training Loss: 27950.2109, Valid Loss: 61.6286
Epoch [8301/30000], Step [1/1], Training Loss: 27414.4141, Valid Loss: 62.7714
Epoch [8401/30000], Step [1/1], Training Loss: 26892.4668, Valid Loss: 60.5810
Epoch [8501/30000], Step [1/1], Training Loss: 26385.1074, Valid Loss: 57.8190
Epoch [8601/30000], Step [1/1], Training Loss: 25893.4473, Valid Loss: 58.1810
Epoch [8701/30000], Step [1/1], Training Loss: 25389.0645, Valid Loss: 53.7429
Epoch [8801/30000], Step [1/1], Training Loss: 24913.0801, Valid Loss: 61.5810
Epoch [8901/30000], Step [1/1], Training Loss: 24451.6113, Valid Loss: 62.1238
Epoch [9001/30000], Step [1/1], Training Loss: 24001.7480, Valid Loss: 50.8952
Epoch [9101/30000], Step [1/1], Training Loss: 23563.9648, Valid Loss: 53.4762
Epoch [9201/30000], Step [1/1], Training Loss: 23138.7441, Valid Loss: 55.6190
Epoch [9301/30000], Step [1/1], Training Loss: 22720.4863, Valid Loss: 59.0667
Epoch [9401/30000], Step [1/1], Training Loss: 22322.2852, Valid Loss: 54.4571
Epoch [9501/30000], Step [1/1], Training Loss: 22394.2754, Valid Loss: 52.0000
Epoch [9601/30000], Step [1/1], Training Loss: 21568.0332, Valid Loss: 53.8857
Epoch [9701/30000], Step [1/1], Training Loss: 21152.1953, Valid Loss: 49.2571
Epoch [9801/30000], Step [1/1], Training Loss: 20719.0645, Valid Loss: 46.5810
Epoch [9901/30000], Step [1/1], Training Loss: 20296.7559, Valid Loss: 52.1619
Epoch [10001/30000], Step [1/1], Training Loss: 19899.5059, Valid Loss: 51.1905
Epoch [10101/30000], Step [1/1], Training Loss: 19529.0957, Valid Loss: 53.4381

[Epoch 15000] Rounded prediction: 
tensor([13., 19., 15., 16., 21., 23., 24., 18., 14., 16., 16., 15., 15., 17.,
        14., 11., 10.,  7.,  9., 12., 10.,  9.,  8., 10.,  3.,  1., 12.,  8.,
         8.,  6., 13.,  4.,  4., 12.,  4.,  7.,  3.,  8.,  2.,  6.,  8., 21.,
         7.,  7.,  5., 10.,  7.,  5.,  4.,  6.,  4.,  6., 11.,  0.,  8.,  6.,
         5., 11.,  6.,  6.,  5.,  6.,  4., 11.,  3., 10.,  6., 13.,  8., 10.,
        11.,  7.,  8., 13., 15., 11.,  4., 20.,  8., 20., 11., 10., 11., 22.,
        23., 14., 12., 10., 20., 17., 16., 18., 39., 34., 26., 33., 34., 25.,
        34., 32., 28., 30., 31., 26., 32.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([12., 20., 14., 16., 19., 21., 22., 17., 14., 16., 13., 13., 13., 16.,
        12., 13., 12., 12.,  9., 12.,  9.,  6., 12.,  8.,  3.,  0., 12.,  7.,
         5.,  6., 15.,  3.,  4., 12.,  2.,  7.,  0.,  8.,  4.,  9., 10., 22.,
         8., 10.,  4.,  9.,  8.,  6.,  3.,  4.,  3.,  4.,  5.,  0., 18.,  3.,
         3.,  9.,  9.,  3.,  3., 11.,  3., 11.,  0.,  8.,  1., 13.,  6.,  7.,
        10.,  6.,  6.,  8., 14.,  9.,  6., 15.,  9., 21., 13., 12., 15., 22.,
        23., 12., 10.,  7., 16., 14., 12., 24., 42., 30., 28., 36., 36., 27.,
        36., 32., 25., 32., 27., 23., 27.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [10201/30000], Step [1/1], Training Loss: 19155.7715, Valid Loss: 50.1238
Epoch [10301/30000], Step [1/1], Training Loss: 18799.5332, Valid Loss: 54.2000
Epoch [10401/30000], Step [1/1], Training Loss: 18463.0488, Valid Loss: 50.7429
Epoch [10501/30000], Step [1/1], Training Loss: 18101.0684, Valid Loss: 54.1714
Epoch [10601/30000], Step [1/1], Training Loss: 17756.6641, Valid Loss: 54.4095
Epoch [10701/30000], Step [1/1], Training Loss: 17409.8027, Valid Loss: 54.3714
Epoch [10801/30000], Step [1/1], Training Loss: 16934.8203, Valid Loss: 52.7524
Epoch [10901/30000], Step [1/1], Training Loss: 16542.0254, Valid Loss: 55.6571
Epoch [11001/30000], Step [1/1], Training Loss: 16193.4121, Valid Loss: 53.2857
Epoch [11101/30000], Step [1/1], Training Loss: 15872.0381, Valid Loss: 57.4000
Epoch [11201/30000], Step [1/1], Training Loss: 15554.0000, Valid Loss: 55.7714
Epoch [11301/30000], Step [1/1], Training Loss: 15253.1963, Valid Loss: 55.2095
Epoch [11401/30000], Step [1/1], Training Loss: 14975.4297, Valid Loss: 57.0571
Epoch [11501/30000], Step [1/1], Training Loss: 14681.4355, Valid Loss: 57.8095
Epoch [11601/30000], Step [1/1], Training Loss: 14401.3496, Valid Loss: 56.9429
Epoch [11701/30000], Step [1/1], Training Loss: 14132.3496, Valid Loss: 58.6857
Epoch [11801/30000], Step [1/1], Training Loss: 13873.2227, Valid Loss: 56.4381
Epoch [11901/30000], Step [1/1], Training Loss: 13621.1133, Valid Loss: 58.4476
Epoch [12001/30000], Step [1/1], Training Loss: 13377.6953, Valid Loss: 55.1048
Epoch [12101/30000], Step [1/1], Training Loss: 13140.0635, Valid Loss: 56.9524
Epoch [12201/30000], Step [1/1], Training Loss: 12926.8701, Valid Loss: 57.9048
Epoch [12301/30000], Step [1/1], Training Loss: 12692.7109, Valid Loss: 60.2857
Epoch [12401/30000], Step [1/1], Training Loss: 12480.4131, Valid Loss: 58.9810
Epoch [12501/30000], Step [1/1], Training Loss: 12366.7666, Valid Loss: 57.6952
Epoch [12601/30000], Step [1/1], Training Loss: 12067.7793, Valid Loss: 55.8381
Epoch [12701/30000], Step [1/1], Training Loss: 11850.9795, Valid Loss: 55.1619
Epoch [12801/30000], Step [1/1], Training Loss: 11653.3223, Valid Loss: 63.4286
Epoch [12901/30000], Step [1/1], Training Loss: 11461.8301, Valid Loss: 57.1429
Epoch [13001/30000], Step [1/1], Training Loss: 11281.5967, Valid Loss: 63.2857
Epoch [13101/30000], Step [1/1], Training Loss: 11100.6348, Valid Loss: 61.4952
Epoch [13201/30000], Step [1/1], Training Loss: 10918.6641, Valid Loss: 59.0476
Epoch [13301/30000], Step [1/1], Training Loss: 10749.1484, Valid Loss: 62.7619
Epoch [13401/30000], Step [1/1], Training Loss: 10579.8662, Valid Loss: 60.5143
Epoch [13501/30000], Step [1/1], Training Loss: 10418.1553, Valid Loss: 65.8667
Epoch [13601/30000], Step [1/1], Training Loss: 10262.1270, Valid Loss: 67.3810
Epoch [13701/30000], Step [1/1], Training Loss: 10783.9102, Valid Loss: 99.0191
Epoch [13801/30000], Step [1/1], Training Loss: 9472.0176, Valid Loss: 59.4095
Epoch [13901/30000], Step [1/1], Training Loss: 9204.8438, Valid Loss: 55.6476
Epoch [14001/30000], Step [1/1], Training Loss: 8978.0498, Valid Loss: 57.5905
Epoch [14101/30000], Step [1/1], Training Loss: 8767.0811, Valid Loss: 62.5619
Epoch [14201/30000], Step [1/1], Training Loss: 8586.0049, Valid Loss: 63.6286
Epoch [14301/30000], Step [1/1], Training Loss: 8383.9492, Valid Loss: 58.2857
Epoch [14401/30000], Step [1/1], Training Loss: 8160.6401, Valid Loss: 59.2667
Epoch [14501/30000], Step [1/1], Training Loss: 7830.4673, Valid Loss: 63.5429
Epoch [14601/30000], Step [1/1], Training Loss: 7331.9321, Valid Loss: 61.0381
Epoch [14701/30000], Step [1/1], Training Loss: 7114.7139, Valid Loss: 54.7905
Epoch [14801/30000], Step [1/1], Training Loss: 6940.8643, Valid Loss: 56.8095
Epoch [14901/30000], Step [1/1], Training Loss: 6772.6548, Valid Loss: 54.8857
Epoch [15001/30000], Step [1/1], Training Loss: 6610.0889, Valid Loss: 52.2667
Epoch [15101/30000], Step [1/1], Training Loss: 6454.8843, Valid Loss: 57.2952
Epoch [15201/30000], Step [1/1], Training Loss: 6303.2061, Valid Loss: 55.2476
Epoch [15301/30000], Step [1/1], Training Loss: 6155.1753, Valid Loss: 56.2381
Epoch [15401/30000], Step [1/1], Training Loss: 6014.8115, Valid Loss: 56.5429
Epoch [15501/30000], Step [1/1], Training Loss: 5875.4824, Valid Loss: 53.6476
Epoch [15601/30000], Step [1/1], Training Loss: 5743.1724, Valid Loss: 57.6095
Epoch [15701/30000], Step [1/1], Training Loss: 5614.0151, Valid Loss: 54.6762
Epoch [15801/30000], Step [1/1], Training Loss: 5490.0840, Valid Loss: 61.0000
Epoch [15901/30000], Step [1/1], Training Loss: 5364.7217, Valid Loss: 61.3048
Epoch [16001/30000], Step [1/1], Training Loss: 5181.3374, Valid Loss: 60.4381
Epoch [16101/30000], Step [1/1], Training Loss: 5055.1260, Valid Loss: 58.1619
Epoch [16201/30000], Step [1/1], Training Loss: 4933.6069, Valid Loss: 57.1333
Epoch [16301/30000], Step [1/1], Training Loss: 4814.5376, Valid Loss: 60.0476
Epoch [16401/30000], Step [1/1], Training Loss: 4699.4702, Valid Loss: 63.4571
Epoch [16501/30000], Step [1/1], Training Loss: 4588.0762, Valid Loss: 61.1333
Epoch [16601/30000], Step [1/1], Training Loss: 4480.4595, Valid Loss: 58.3143
Epoch [16701/30000], Step [1/1], Training Loss: 4375.3408, Valid Loss: 59.9524
Epoch [16801/30000], Step [1/1], Training Loss: 4273.5376, Valid Loss: 63.3143
Epoch [16901/30000], Step [1/1], Training Loss: 4306.0625, Valid Loss: 58.6286
Epoch [17001/30000], Step [1/1], Training Loss: 4078.2036, Valid Loss: 68.3429
Epoch [17101/30000], Step [1/1], Training Loss: 3926.1692, Valid Loss: 65.8667
Epoch [17201/30000], Step [1/1], Training Loss: 3826.5227, Valid Loss: 60.2571
Epoch [17301/30000], Step [1/1], Training Loss: 3733.5403, Valid Loss: 59.5810
Epoch [17401/30000], Step [1/1], Training Loss: 3640.6379, Valid Loss: 58.1810
Epoch [17501/30000], Step [1/1], Training Loss: 3553.7126, Valid Loss: 60.0095
Epoch [17601/30000], Step [1/1], Training Loss: 3464.4382, Valid Loss: 58.2191
Epoch [17701/30000], Step [1/1], Training Loss: 3379.0156, Valid Loss: 54.0952
Epoch [17801/30000], Step [1/1], Training Loss: 3296.1167, Valid Loss: 56.4952
Epoch [17901/30000], Step [1/1], Training Loss: 3215.0559, Valid Loss: 57.8857
Epoch [18001/30000], Step [1/1], Training Loss: 3135.9043, Valid Loss: 57.0476
Epoch [18101/30000], Step [1/1], Training Loss: 3056.7590, Valid Loss: 57.0667
Epoch [18201/30000], Step [1/1], Training Loss: 2981.4524, Valid Loss: 63.0476
Epoch [18301/30000], Step [1/1], Training Loss: 2908.1606, Valid Loss: 60.2571
Epoch [18401/30000], Step [1/1], Training Loss: 2836.1726, Valid Loss: 60.7143
Epoch [18501/30000], Step [1/1], Training Loss: 2766.9946, Valid Loss: 55.9048
Epoch [18601/30000], Step [1/1], Training Loss: 2698.6914, Valid Loss: 54.7810
Epoch [18701/30000], Step [1/1], Training Loss: 2630.7349, Valid Loss: 58.5714
Epoch [18801/30000], Step [1/1], Training Loss: 2564.8357, Valid Loss: 58.5143
Epoch [18901/30000], Step [1/1], Training Loss: 2499.9856, Valid Loss: 62.4000
Epoch [19001/30000], Step [1/1], Training Loss: 2437.0183, Valid Loss: 59.9524
Epoch [19101/30000], Step [1/1], Training Loss: 2375.1672, Valid Loss: 57.3333
Epoch [19201/30000], Step [1/1], Training Loss: 2315.4968, Valid Loss: 58.1429
Epoch [19301/30000], Step [1/1], Training Loss: 2256.9617, Valid Loss: 57.8476
Epoch [19401/30000], Step [1/1], Training Loss: 2200.1772, Valid Loss: 61.4667
Epoch [19501/30000], Step [1/1], Training Loss: 2144.9626, Valid Loss: 57.0857
Epoch [19601/30000], Step [1/1], Training Loss: 2090.4539, Valid Loss: 55.4667
Epoch [19701/30000], Step [1/1], Training Loss: 2038.6324, Valid Loss: 55.8571
Epoch [19801/30000], Step [1/1], Training Loss: 1987.4226, Valid Loss: 57.3333
Epoch [19901/30000], Step [1/1], Training Loss: 1937.7402, Valid Loss: 55.9619
Epoch [20001/30000], Step [1/1], Training Loss: 1890.4763, Valid Loss: 58.3048
Epoch [20101/30000], Step [1/1], Training Loss: 1844.3790, Valid Loss: 54.0857
Epoch [20201/30000], Step [1/1], Training Loss: 1799.2479, Valid Loss: 54.4190
Epoch [20301/30000], Step [1/1], Training Loss: 1756.1655, Valid Loss: 56.6190

[Epoch 25000] Rounded prediction: 
tensor([12., 20., 16., 15., 17., 20., 20., 17., 13., 16., 14., 10., 10., 13.,
         5.,  6.,  0.,  0.,  0.,  5.,  5.,  3.,  9., 11.,  2.,  0.,  9.,  7.,
         3.,  5., 15.,  2.,  0., 11.,  1.,  7.,  0.,  7.,  2.,  8.,  8., 22.,
         6.,  8.,  2.,  9.,  6.,  1.,  0.,  0.,  0.,  0.,  3.,  0., 21.,  6.,
         3.,  9.,  8.,  0.,  3.,  9.,  0.,  9.,  0.,  5.,  0.,  6.,  1.,  1.,
         0.,  0.,  0.,  3.,  2.,  2.,  0., 18., 12., 16., 10.,  4.,  9., 20.,
        16.,  0.,  0.,  2., 11.,  5.,  2., 24., 46., 29., 25., 35., 32., 21.,
        34., 34., 25., 31., 30., 19., 25.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [20401/30000], Step [1/1], Training Loss: 1714.6150, Valid Loss: 53.6381
Epoch [20501/30000], Step [1/1], Training Loss: 1674.3453, Valid Loss: 57.8286
Epoch [20601/30000], Step [1/1], Training Loss: 1635.5828, Valid Loss: 53.4952
Epoch [20701/30000], Step [1/1], Training Loss: 1598.3148, Valid Loss: 54.2476
Epoch [20801/30000], Step [1/1], Training Loss: 1561.8849, Valid Loss: 55.8571
Epoch [20901/30000], Step [1/1], Training Loss: 1526.3298, Valid Loss: 55.0191
Epoch [21001/30000], Step [1/1], Training Loss: 1492.1758, Valid Loss: 57.4857
Epoch [21101/30000], Step [1/1], Training Loss: 1459.0818, Valid Loss: 53.1048
Epoch [21201/30000], Step [1/1], Training Loss: 1426.8694, Valid Loss: 53.2762
Epoch [21301/30000], Step [1/1], Training Loss: 1395.4084, Valid Loss: 54.1048
Epoch [21401/30000], Step [1/1], Training Loss: 1364.9098, Valid Loss: 55.8095
Epoch [21501/30000], Step [1/1], Training Loss: 1335.5348, Valid Loss: 53.6571
Epoch [21601/30000], Step [1/1], Training Loss: 1306.2860, Valid Loss: 54.4095
Epoch [21701/30000], Step [1/1], Training Loss: 1278.3055, Valid Loss: 52.1333
Epoch [21801/30000], Step [1/1], Training Loss: 1250.7557, Valid Loss: 52.9048
Epoch [21901/30000], Step [1/1], Training Loss: 1224.1061, Valid Loss: 53.1048
Epoch [22001/30000], Step [1/1], Training Loss: 1198.2306, Valid Loss: 54.7714
Epoch [22101/30000], Step [1/1], Training Loss: 1173.0844, Valid Loss: 52.9619
Epoch [22201/30000], Step [1/1], Training Loss: 1148.0206, Valid Loss: 55.7143
Epoch [22301/30000], Step [1/1], Training Loss: 1123.6227, Valid Loss: 56.6571
Epoch [22401/30000], Step [1/1], Training Loss: 1099.5018, Valid Loss: 52.4667
Epoch [22501/30000], Step [1/1], Training Loss: 1075.7024, Valid Loss: 51.6000
Epoch [22601/30000], Step [1/1], Training Loss: 1052.1384, Valid Loss: 51.4000
Epoch [22701/30000], Step [1/1], Training Loss: 1028.8114, Valid Loss: 54.6095
Epoch [22801/30000], Step [1/1], Training Loss: 1005.9534, Valid Loss: 54.1524
Epoch [22901/30000], Step [1/1], Training Loss: 1000.5389, Valid Loss: 79.5714
Epoch [23001/30000], Step [1/1], Training Loss: 973.2325, Valid Loss: 82.0000
Epoch [23101/30000], Step [1/1], Training Loss: 949.7721, Valid Loss: 84.7714
Epoch [23201/30000], Step [1/1], Training Loss: 927.2138, Valid Loss: 83.2095
Epoch [23301/30000], Step [1/1], Training Loss: 906.9248, Valid Loss: 82.3143
Epoch [23401/30000], Step [1/1], Training Loss: 886.0427, Valid Loss: 82.1429
Epoch [23501/30000], Step [1/1], Training Loss: 866.9169, Valid Loss: 81.4952
Epoch [23601/30000], Step [1/1], Training Loss: 847.8167, Valid Loss: 85.0191
Epoch [23701/30000], Step [1/1], Training Loss: 829.3546, Valid Loss: 83.4000
Epoch [23801/30000], Step [1/1], Training Loss: 811.4254, Valid Loss: 82.7714
Epoch [23901/30000], Step [1/1], Training Loss: 793.7256, Valid Loss: 83.4095
Epoch [24001/30000], Step [1/1], Training Loss: 776.1238, Valid Loss: 80.9143
Epoch [24101/30000], Step [1/1], Training Loss: 759.6920, Valid Loss: 79.2667
Epoch [24201/30000], Step [1/1], Training Loss: 743.2458, Valid Loss: 81.5524
Epoch [24301/30000], Step [1/1], Training Loss: 727.3658, Valid Loss: 82.3905
Epoch [24401/30000], Step [1/1], Training Loss: 711.6217, Valid Loss: 82.5429
Epoch [24501/30000], Step [1/1], Training Loss: 696.8943, Valid Loss: 80.6000
Epoch [24601/30000], Step [1/1], Training Loss: 682.1757, Valid Loss: 81.8381
Epoch [24701/30000], Step [1/1], Training Loss: 668.2210, Valid Loss: 80.3810
Epoch [24801/30000], Step [1/1], Training Loss: 654.5956, Valid Loss: 77.5143
Epoch [24901/30000], Step [1/1], Training Loss: 641.5574, Valid Loss: 79.1714
Epoch [25001/30000], Step [1/1], Training Loss: 629.1433, Valid Loss: 79.0952
Epoch [25101/30000], Step [1/1], Training Loss: 614.8859, Valid Loss: 79.0667
Epoch [25201/30000], Step [1/1], Training Loss: 599.7687, Valid Loss: 78.6952
Epoch [25301/30000], Step [1/1], Training Loss: 586.2698, Valid Loss: 79.4571
Epoch [25401/30000], Step [1/1], Training Loss: 572.7242, Valid Loss: 82.0857
Epoch [25501/30000], Step [1/1], Training Loss: 559.4686, Valid Loss: 77.4952
Epoch [25601/30000], Step [1/1], Training Loss: 546.2871, Valid Loss: 78.6190
Epoch [25701/30000], Step [1/1], Training Loss: 533.3415, Valid Loss: 76.8286
Epoch [25801/30000], Step [1/1], Training Loss: 520.7021, Valid Loss: 76.7048
Epoch [25901/30000], Step [1/1], Training Loss: 508.4937, Valid Loss: 79.1619
Epoch [26001/30000], Step [1/1], Training Loss: 496.2168, Valid Loss: 78.6762
Epoch [26101/30000], Step [1/1], Training Loss: 484.1749, Valid Loss: 77.1714
Epoch [26201/30000], Step [1/1], Training Loss: 472.5183, Valid Loss: 77.9810
Epoch [26301/30000], Step [1/1], Training Loss: 461.0441, Valid Loss: 79.7714
Epoch [26401/30000], Step [1/1], Training Loss: 449.8130, Valid Loss: 77.7333
Epoch [26501/30000], Step [1/1], Training Loss: 438.9960, Valid Loss: 81.5238
Epoch [26601/30000], Step [1/1], Training Loss: 428.3610, Valid Loss: 79.6952
Epoch [26701/30000], Step [1/1], Training Loss: 417.8295, Valid Loss: 84.2000
Epoch [26801/30000], Step [1/1], Training Loss: 407.7403, Valid Loss: 75.6476
Epoch [26901/30000], Step [1/1], Training Loss: 397.9376, Valid Loss: 80.3429
Epoch [27001/30000], Step [1/1], Training Loss: 387.9499, Valid Loss: 78.1524
Epoch [27101/30000], Step [1/1], Training Loss: 378.1607, Valid Loss: 76.6952
Epoch [27201/30000], Step [1/1], Training Loss: 368.3366, Valid Loss: 78.7048
Epoch [27301/30000], Step [1/1], Training Loss: 358.5984, Valid Loss: 80.6952
Epoch [27401/30000], Step [1/1], Training Loss: 349.0040, Valid Loss: 80.0191
Epoch [27501/30000], Step [1/1], Training Loss: 339.5144, Valid Loss: 80.0476
Epoch [27601/30000], Step [1/1], Training Loss: 330.0087, Valid Loss: 77.7810
Epoch [27701/30000], Step [1/1], Training Loss: 320.6170, Valid Loss: 81.0191
Epoch [27801/30000], Step [1/1], Training Loss: 311.3914, Valid Loss: 76.7619
Epoch [27901/30000], Step [1/1], Training Loss: 302.1806, Valid Loss: 78.3048
Epoch [28001/30000], Step [1/1], Training Loss: 293.0449, Valid Loss: 76.0952
Epoch [28101/30000], Step [1/1], Training Loss: 284.1912, Valid Loss: 76.8191
Epoch [28201/30000], Step [1/1], Training Loss: 275.4414, Valid Loss: 74.6190
Epoch [28301/30000], Step [1/1], Training Loss: 266.6569, Valid Loss: 79.9048
Epoch [28401/30000], Step [1/1], Training Loss: 258.3654, Valid Loss: 80.2476
Epoch [28501/30000], Step [1/1], Training Loss: 249.7454, Valid Loss: 77.2857
Epoch [28601/30000], Step [1/1], Training Loss: 241.5403, Valid Loss: 79.9810
Epoch [28701/30000], Step [1/1], Training Loss: 233.4964, Valid Loss: 78.7238
Epoch [28801/30000], Step [1/1], Training Loss: 225.2655, Valid Loss: 79.7714
Epoch [28901/30000], Step [1/1], Training Loss: 217.4425, Valid Loss: 81.5048
Epoch [29001/30000], Step [1/1], Training Loss: 209.8468, Valid Loss: 80.2381
Epoch [29101/30000], Step [1/1], Training Loss: 202.2766, Valid Loss: 78.6381
Epoch [29201/30000], Step [1/1], Training Loss: 194.8158, Valid Loss: 81.7524
Epoch [29301/30000], Step [1/1], Training Loss: 187.5384, Valid Loss: 82.1810
Epoch [29401/30000], Step [1/1], Training Loss: 181.1592, Valid Loss: 81.5048
Epoch [29501/30000], Step [1/1], Training Loss: 184.9751, Valid Loss: 61.6667
Epoch [29601/30000], Step [1/1], Training Loss: 175.3389, Valid Loss: 60.0476
Epoch [29701/30000], Step [1/1], Training Loss: 168.9937, Valid Loss: 61.4667
Epoch [29801/30000], Step [1/1], Training Loss: 162.6284, Valid Loss: 62.3619
Epoch [29901/30000], Step [1/1], Training Loss: 158.3512, Valid Loss: 64.0095

 End Time: 2021/04/19, 04:04:40




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=512 	layers=3

Start Time = 2021/04/19, 04:16:01
##########################################################


[Epoch 0] Rounded prediction: 
tensor([1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.],
       device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([11., 15., 15., 11., 18., 18., 18., 15., 14., 13., 14.,  9., 10., 14.,
        10.,  8.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  2.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  9.,
         2.,  3.,  2.,  7., 13., 14.,  4.,  1., 15., 36., 27., 16., 15., 15.,
        22., 26., 26., 34., 26., 22., 28.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([12., 16., 14., 14., 15., 17., 18., 14., 11., 12., 11.,  8.,  8., 13.,
        11.,  9.,  5.,  7.,  6.,  5.,  8.,  6.,  7.,  7.,  5.,  1.,  4.,  3.,
         5.,  7.,  8.,  6.,  5.,  5.,  3.,  6.,  4.,  6.,  1.,  4.,  5., 14.,
         8.,  7.,  7.,  7.,  6.,  5.,  2.,  1.,  5.,  3.,  6.,  2.,  6.,  8.,
         5.,  8.,  5.,  4.,  4.,  6.,  4.,  6.,  3.,  6.,  5.,  8., 10.,  8.,
        10.,  6.,  6.,  7.,  7.,  8.,  5., 11.,  9., 11., 11.,  8., 15., 14.,
        12., 11.,  7., 11., 11., 12., 12., 15., 26., 25., 22., 22., 25., 19.,
        25., 29., 26., 33., 22., 18., 25.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128621.5938, Valid Loss: 236.2000
Epoch [101/30000], Step [1/1], Training Loss: 121260.9609, Valid Loss: 109.4000
Epoch [201/30000], Step [1/1], Training Loss: 118867.7031, Valid Loss: 192.8286
Epoch [301/30000], Step [1/1], Training Loss: 116620.0781, Valid Loss: 317.3524
Epoch [401/30000], Step [1/1], Training Loss: 114459.7422, Valid Loss: 491.8762
Epoch [501/30000], Step [1/1], Training Loss: 112377.1250, Valid Loss: 716.4000
Epoch [601/30000], Step [1/1], Training Loss: 110357.3203, Valid Loss: 990.9238
Epoch [701/30000], Step [1/1], Training Loss: 108400.2656, Valid Loss: 1315.4476
Epoch [801/30000], Step [1/1], Training Loss: 106501.3750, Valid Loss: 1689.9714
Epoch [901/30000], Step [1/1], Training Loss: 104656.8906, Valid Loss: 2086.1333
Epoch [1001/30000], Step [1/1], Training Loss: 102860.8906, Valid Loss: 1846.7429
Epoch [1101/30000], Step [1/1], Training Loss: 101111.4141, Valid Loss: 1474.3715
Epoch [1201/30000], Step [1/1], Training Loss: 99381.8750, Valid Loss: 651.2858
Epoch [1301/30000], Step [1/1], Training Loss: 97432.3594, Valid Loss: 99.4667
Epoch [1401/30000], Step [1/1], Training Loss: 95699.1797, Valid Loss: 130.9048
Epoch [1501/30000], Step [1/1], Training Loss: 94009.1797, Valid Loss: 124.2191
Epoch [1601/30000], Step [1/1], Training Loss: 92360.9844, Valid Loss: 132.5048
Epoch [1701/30000], Step [1/1], Training Loss: 90751.7422, Valid Loss: 130.1619
Epoch [1801/30000], Step [1/1], Training Loss: 89131.4453, Valid Loss: 124.2857
Epoch [1901/30000], Step [1/1], Training Loss: 87552.7578, Valid Loss: 128.9333
Epoch [2001/30000], Step [1/1], Training Loss: 86010.3984, Valid Loss: 120.5143
Epoch [2101/30000], Step [1/1], Training Loss: 84494.2656, Valid Loss: 119.6476
Epoch [2201/30000], Step [1/1], Training Loss: 83015.8203, Valid Loss: 118.2000
Epoch [2301/30000], Step [1/1], Training Loss: 81560.7656, Valid Loss: 116.8952
Epoch [2401/30000], Step [1/1], Training Loss: 80137.7188, Valid Loss: 113.0952
Epoch [2501/30000], Step [1/1], Training Loss: 78759.9141, Valid Loss: 115.7429
Epoch [2601/30000], Step [1/1], Training Loss: 77368.3750, Valid Loss: 119.3429
Epoch [2701/30000], Step [1/1], Training Loss: 76020.1562, Valid Loss: 129.0000
Epoch [2801/30000], Step [1/1], Training Loss: 74630.5781, Valid Loss: 111.3524
Epoch [2901/30000], Step [1/1], Training Loss: 73321.7656, Valid Loss: 117.2095
Epoch [3001/30000], Step [1/1], Training Loss: 72039.2266, Valid Loss: 124.9048
Epoch [3101/30000], Step [1/1], Training Loss: 70784.4844, Valid Loss: 119.9810
Epoch [3201/30000], Step [1/1], Training Loss: 69551.3828, Valid Loss: 120.8762
Epoch [3301/30000], Step [1/1], Training Loss: 68344.9609, Valid Loss: 123.4476
Epoch [3401/30000], Step [1/1], Training Loss: 67161.5391, Valid Loss: 126.1143
Epoch [3501/30000], Step [1/1], Training Loss: 66003.6172, Valid Loss: 125.6000
Epoch [3601/30000], Step [1/1], Training Loss: 64870.0938, Valid Loss: 125.7333
Epoch [3701/30000], Step [1/1], Training Loss: 63758.0195, Valid Loss: 126.2857
Epoch [3801/30000], Step [1/1], Training Loss: 62670.6367, Valid Loss: 123.5143
Epoch [3901/30000], Step [1/1], Training Loss: 61620.4961, Valid Loss: 123.7524
Epoch [4001/30000], Step [1/1], Training Loss: 60569.7500, Valid Loss: 125.2381
Epoch [4101/30000], Step [1/1], Training Loss: 59546.8555, Valid Loss: 124.8952
Epoch [4201/30000], Step [1/1], Training Loss: 58560.1250, Valid Loss: 132.4762
Epoch [4301/30000], Step [1/1], Training Loss: 57574.7344, Valid Loss: 115.8571
Epoch [4401/30000], Step [1/1], Training Loss: 56619.8672, Valid Loss: 126.2000
Epoch [4501/30000], Step [1/1], Training Loss: 55688.8789, Valid Loss: 123.0762
Epoch [4601/30000], Step [1/1], Training Loss: 54779.8750, Valid Loss: 123.5333
Epoch [4701/30000], Step [1/1], Training Loss: 53744.7188, Valid Loss: 121.9810
Epoch [4801/30000], Step [1/1], Training Loss: 52661.4375, Valid Loss: 112.6190
Epoch [4901/30000], Step [1/1], Training Loss: 51703.7656, Valid Loss: 110.3429
Epoch [5001/30000], Step [1/1], Training Loss: 50781.5469, Valid Loss: 118.0191
Epoch [5101/30000], Step [1/1], Training Loss: 49879.9375, Valid Loss: 113.5524
Epoch [5201/30000], Step [1/1], Training Loss: 49006.3242, Valid Loss: 119.2191
Epoch [5301/30000], Step [1/1], Training Loss: 48145.6641, Valid Loss: 113.8857
Epoch [5401/30000], Step [1/1], Training Loss: 47299.1211, Valid Loss: 117.1429
Epoch [5501/30000], Step [1/1], Training Loss: 46478.4570, Valid Loss: 112.9524
Epoch [5601/30000], Step [1/1], Training Loss: 45670.4922, Valid Loss: 113.2191
Epoch [5701/30000], Step [1/1], Training Loss: 44879.7617, Valid Loss: 115.1048
Epoch [5801/30000], Step [1/1], Training Loss: 44101.4883, Valid Loss: 119.2191
Epoch [5901/30000], Step [1/1], Training Loss: 43340.6719, Valid Loss: 115.1524
Epoch [6001/30000], Step [1/1], Training Loss: 42594.4805, Valid Loss: 114.5714
Epoch [6101/30000], Step [1/1], Training Loss: 41865.8164, Valid Loss: 111.4381
Epoch [6201/30000], Step [1/1], Training Loss: 41153.3906, Valid Loss: 113.0762
Epoch [6301/30000], Step [1/1], Training Loss: 40455.8008, Valid Loss: 112.1048
Epoch [6401/30000], Step [1/1], Training Loss: 39772.9609, Valid Loss: 108.5238
Epoch [6501/30000], Step [1/1], Training Loss: 39178.7109, Valid Loss: 108.2476
Epoch [6601/30000], Step [1/1], Training Loss: 38576.0000, Valid Loss: 102.8095
Epoch [6701/30000], Step [1/1], Training Loss: 37845.5156, Valid Loss: 100.2667
Epoch [6801/30000], Step [1/1], Training Loss: 37470.7070, Valid Loss: 110.2667
Epoch [6901/30000], Step [1/1], Training Loss: 36462.9688, Valid Loss: 105.2000
Epoch [7001/30000], Step [1/1], Training Loss: 35898.9258, Valid Loss: 95.4095
Epoch [7101/30000], Step [1/1], Training Loss: 34954.7383, Valid Loss: 96.6667
Epoch [7201/30000], Step [1/1], Training Loss: 34199.0859, Valid Loss: 100.3619
Epoch [7301/30000], Step [1/1], Training Loss: 33458.4609, Valid Loss: 88.4381
Epoch [7401/30000], Step [1/1], Training Loss: 32736.1230, Valid Loss: 86.9810
Epoch [7501/30000], Step [1/1], Training Loss: 32100.9961, Valid Loss: 94.0095
Epoch [7601/30000], Step [1/1], Training Loss: 31491.5742, Valid Loss: 86.4286
Epoch [7701/30000], Step [1/1], Training Loss: 30900.1387, Valid Loss: 88.4000
Epoch [7801/30000], Step [1/1], Training Loss: 30762.4375, Valid Loss: 86.2857
Epoch [7901/30000], Step [1/1], Training Loss: 29741.5273, Valid Loss: 93.9333
Epoch [8001/30000], Step [1/1], Training Loss: 29170.6523, Valid Loss: 90.8191
Epoch [8101/30000], Step [1/1], Training Loss: 28615.9531, Valid Loss: 91.4762
Epoch [8201/30000], Step [1/1], Training Loss: 28082.4512, Valid Loss: 92.4000
Epoch [8301/30000], Step [1/1], Training Loss: 27555.7988, Valid Loss: 89.1048
Epoch [8401/30000], Step [1/1], Training Loss: 27040.1621, Valid Loss: 88.1810
Epoch [8501/30000], Step [1/1], Training Loss: 26537.4316, Valid Loss: 86.6190
Epoch [8601/30000], Step [1/1], Training Loss: 26050.3398, Valid Loss: 84.9048
Epoch [8701/30000], Step [1/1], Training Loss: 25562.8945, Valid Loss: 92.0381
Epoch [8801/30000], Step [1/1], Training Loss: 25099.7012, Valid Loss: 84.7714
Epoch [8901/30000], Step [1/1], Training Loss: 24615.7363, Valid Loss: 92.6667
Epoch [9001/30000], Step [1/1], Training Loss: 24157.3457, Valid Loss: 81.3810
Epoch [9101/30000], Step [1/1], Training Loss: 23886.7715, Valid Loss: 91.4762
Epoch [9201/30000], Step [1/1], Training Loss: 23257.1230, Valid Loss: 49.9619
Epoch [9301/30000], Step [1/1], Training Loss: 22649.0723, Valid Loss: 50.6571
Epoch [9401/30000], Step [1/1], Training Loss: 22161.5020, Valid Loss: 50.9905
Epoch [9501/30000], Step [1/1], Training Loss: 21722.4453, Valid Loss: 55.4857
Epoch [9601/30000], Step [1/1], Training Loss: 21304.9258, Valid Loss: 55.2762
Epoch [9701/30000], Step [1/1], Training Loss: 21078.8203, Valid Loss: 58.1333
Epoch [9801/30000], Step [1/1], Training Loss: 20909.3535, Valid Loss: 64.8667
Epoch [9901/30000], Step [1/1], Training Loss: 20189.9375, Valid Loss: 60.1905
Epoch [10001/30000], Step [1/1], Training Loss: 19634.5508, Valid Loss: 55.0286
Epoch [10101/30000], Step [1/1], Training Loss: 19083.1211, Valid Loss: 60.0667

[Epoch 15000] Rounded prediction: 
tensor([13., 15., 13., 12., 13., 16., 15., 13., 13., 13., 14., 12., 13., 14.,
        13., 16., 16., 15., 14., 16., 15., 12., 14., 11., 11., 12., 11., 12.,
        11., 10., 11.,  6., 10., 10.,  9., 10., 11., 11., 11., 12.,  8., 16.,
         4.,  5.,  5., 10.,  8., 11., 11., 11., 15., 15., 13., 13., 16.,  8.,
         9., 11., 13.,  9., 10., 12., 11., 16., 15., 15., 11., 15., 13., 13.,
        14., 13., 13., 14., 14., 17., 14., 18., 10., 16., 12., 11., 17., 11.,
        16., 13., 10., 10., 14., 16., 16., 14., 18., 13., 15., 20., 30., 21.,
        25., 27., 25., 27., 20., 14., 24.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([13., 16., 14., 13., 16., 16., 16., 13., 13., 15., 14., 15., 13., 18.,
        17., 18., 18., 17., 17., 15., 16., 13., 12., 11.,  8., 12.,  8., 12.,
        10.,  9.,  9.,  5.,  6.,  8., 11.,  9.,  7., 10.,  9.,  8.,  5., 15.,
         2.,  6.,  5.,  8.,  7., 10.,  9., 13., 17., 16., 14., 12., 13.,  7.,
         8.,  7., 11.,  8.,  8.,  9., 11., 13., 14., 12., 13., 13., 15., 12.,
        16., 14., 14., 15., 14., 22., 16., 15., 12., 15., 11.,  9., 18., 10.,
        13., 12.,  9.,  9., 16., 18., 19., 13., 16., 15., 16., 25., 38., 22.,
        27., 28., 25., 26., 18., 14., 23.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [10201/30000], Step [1/1], Training Loss: 18679.2832, Valid Loss: 55.1238
Epoch [10301/30000], Step [1/1], Training Loss: 18275.9121, Valid Loss: 53.8571
Epoch [10401/30000], Step [1/1], Training Loss: 17897.2891, Valid Loss: 54.9619
Epoch [10501/30000], Step [1/1], Training Loss: 17522.9805, Valid Loss: 56.1333
Epoch [10601/30000], Step [1/1], Training Loss: 17155.7949, Valid Loss: 53.8476
Epoch [10701/30000], Step [1/1], Training Loss: 16799.5684, Valid Loss: 51.1143
Epoch [10801/30000], Step [1/1], Training Loss: 16443.5723, Valid Loss: 53.2286
Epoch [10901/30000], Step [1/1], Training Loss: 16079.7158, Valid Loss: 50.6762
Epoch [11001/30000], Step [1/1], Training Loss: 15805.1484, Valid Loss: 52.1429
Epoch [11101/30000], Step [1/1], Training Loss: 15438.3105, Valid Loss: 49.0476
Epoch [11201/30000], Step [1/1], Training Loss: 15049.9463, Valid Loss: 50.4952
Epoch [11301/30000], Step [1/1], Training Loss: 14727.2705, Valid Loss: 52.0095
Epoch [11401/30000], Step [1/1], Training Loss: 14412.8027, Valid Loss: 49.6667
Epoch [11501/30000], Step [1/1], Training Loss: 14108.8438, Valid Loss: 49.8286
Epoch [11601/30000], Step [1/1], Training Loss: 13810.1172, Valid Loss: 51.9905
Epoch [11701/30000], Step [1/1], Training Loss: 13513.2471, Valid Loss: 50.1524
Epoch [11801/30000], Step [1/1], Training Loss: 13225.9033, Valid Loss: 48.8190
Epoch [11901/30000], Step [1/1], Training Loss: 12944.4014, Valid Loss: 47.5048
Epoch [12001/30000], Step [1/1], Training Loss: 12668.0059, Valid Loss: 49.5714
Epoch [12101/30000], Step [1/1], Training Loss: 12597.8135, Valid Loss: 53.6000
Epoch [12201/30000], Step [1/1], Training Loss: 12141.7324, Valid Loss: 52.8952
Epoch [12301/30000], Step [1/1], Training Loss: 11881.1191, Valid Loss: 51.5810
Epoch [12401/30000], Step [1/1], Training Loss: 11632.8770, Valid Loss: 47.9429
Epoch [12501/30000], Step [1/1], Training Loss: 11388.4492, Valid Loss: 54.4571
Epoch [12601/30000], Step [1/1], Training Loss: 11137.3076, Valid Loss: 50.7048
Epoch [12701/30000], Step [1/1], Training Loss: 10899.7148, Valid Loss: 51.9524
Epoch [12801/30000], Step [1/1], Training Loss: 10659.4551, Valid Loss: 50.2857
Epoch [12901/30000], Step [1/1], Training Loss: 10450.0967, Valid Loss: 52.0381
Epoch [13001/30000], Step [1/1], Training Loss: 10203.7910, Valid Loss: 52.3333
Epoch [13101/30000], Step [1/1], Training Loss: 9974.0742, Valid Loss: 48.8857
Epoch [13201/30000], Step [1/1], Training Loss: 9751.5293, Valid Loss: 52.1524
Epoch [13301/30000], Step [1/1], Training Loss: 9527.5039, Valid Loss: 54.6476
Epoch [13401/30000], Step [1/1], Training Loss: 9298.6074, Valid Loss: 52.3429
Epoch [13501/30000], Step [1/1], Training Loss: 9087.9736, Valid Loss: 51.5429
Epoch [13601/30000], Step [1/1], Training Loss: 8882.7871, Valid Loss: 49.3619
Epoch [13701/30000], Step [1/1], Training Loss: 8683.6631, Valid Loss: 51.4667
Epoch [13801/30000], Step [1/1], Training Loss: 8488.4141, Valid Loss: 51.5238
Epoch [13901/30000], Step [1/1], Training Loss: 8334.7500, Valid Loss: 59.6286
Epoch [14001/30000], Step [1/1], Training Loss: 8127.4590, Valid Loss: 62.2857
Epoch [14101/30000], Step [1/1], Training Loss: 7940.0059, Valid Loss: 59.8762
Epoch [14201/30000], Step [1/1], Training Loss: 7760.6504, Valid Loss: 59.4762
Epoch [14301/30000], Step [1/1], Training Loss: 7586.7783, Valid Loss: 56.9905
Epoch [14401/30000], Step [1/1], Training Loss: 7418.0552, Valid Loss: 61.1810
Epoch [14501/30000], Step [1/1], Training Loss: 7263.7690, Valid Loss: 62.0000
Epoch [14601/30000], Step [1/1], Training Loss: 7092.2817, Valid Loss: 59.3714
Epoch [14701/30000], Step [1/1], Training Loss: 6935.0303, Valid Loss: 62.9429
Epoch [14801/30000], Step [1/1], Training Loss: 6775.8413, Valid Loss: 60.8571
Epoch [14901/30000], Step [1/1], Training Loss: 6626.0850, Valid Loss: 66.1429
Epoch [15001/30000], Step [1/1], Training Loss: 6477.4849, Valid Loss: 64.7429
Epoch [15101/30000], Step [1/1], Training Loss: 6332.8032, Valid Loss: 62.6667
Epoch [15201/30000], Step [1/1], Training Loss: 6190.7212, Valid Loss: 61.9905
Epoch [15301/30000], Step [1/1], Training Loss: 6053.1055, Valid Loss: 66.3048
Epoch [15401/30000], Step [1/1], Training Loss: 5919.3975, Valid Loss: 63.5429
Epoch [15501/30000], Step [1/1], Training Loss: 5787.7930, Valid Loss: 65.0857
Epoch [15601/30000], Step [1/1], Training Loss: 5660.1895, Valid Loss: 63.8952
Epoch [15701/30000], Step [1/1], Training Loss: 5536.5967, Valid Loss: 64.8191
Epoch [15801/30000], Step [1/1], Training Loss: 5414.7227, Valid Loss: 65.6095
Epoch [15901/30000], Step [1/1], Training Loss: 5297.4399, Valid Loss: 68.4952
Epoch [16001/30000], Step [1/1], Training Loss: 5181.2188, Valid Loss: 67.0762
Epoch [16101/30000], Step [1/1], Training Loss: 5193.6953, Valid Loss: 65.4571
Epoch [16201/30000], Step [1/1], Training Loss: 4915.5337, Valid Loss: 62.4952
Epoch [16301/30000], Step [1/1], Training Loss: 4796.6479, Valid Loss: 59.6381
Epoch [16401/30000], Step [1/1], Training Loss: 4684.0303, Valid Loss: 62.3238
Epoch [16501/30000], Step [1/1], Training Loss: 4575.3062, Valid Loss: 58.9619
Epoch [16601/30000], Step [1/1], Training Loss: 4469.9775, Valid Loss: 59.1143
Epoch [16701/30000], Step [1/1], Training Loss: 4368.5767, Valid Loss: 61.9429
Epoch [16801/30000], Step [1/1], Training Loss: 4268.0557, Valid Loss: 60.7905
Epoch [16901/30000], Step [1/1], Training Loss: 4172.3433, Valid Loss: 60.9810
Epoch [17001/30000], Step [1/1], Training Loss: 4078.6687, Valid Loss: 61.6381
Epoch [17101/30000], Step [1/1], Training Loss: 3986.9299, Valid Loss: 59.8190
Epoch [17201/30000], Step [1/1], Training Loss: 3898.8389, Valid Loss: 61.4476
Epoch [17301/30000], Step [1/1], Training Loss: 3812.2981, Valid Loss: 60.6000
Epoch [17401/30000], Step [1/1], Training Loss: 3728.7273, Valid Loss: 61.0571
Epoch [17501/30000], Step [1/1], Training Loss: 3657.3630, Valid Loss: 64.6476
Epoch [17601/30000], Step [1/1], Training Loss: 3568.0342, Valid Loss: 63.8667
Epoch [17701/30000], Step [1/1], Training Loss: 3429.8079, Valid Loss: 61.3905
Epoch [17801/30000], Step [1/1], Training Loss: 3314.5193, Valid Loss: 64.0286
Epoch [17901/30000], Step [1/1], Training Loss: 3231.9807, Valid Loss: 61.4952
Epoch [18001/30000], Step [1/1], Training Loss: 3151.3218, Valid Loss: 63.3810
Epoch [18101/30000], Step [1/1], Training Loss: 3073.7542, Valid Loss: 62.5048
Epoch [18201/30000], Step [1/1], Training Loss: 2996.8000, Valid Loss: 63.3524
Epoch [18301/30000], Step [1/1], Training Loss: 2922.7041, Valid Loss: 62.6095
Epoch [18401/30000], Step [1/1], Training Loss: 2849.8425, Valid Loss: 60.3524
Epoch [18501/30000], Step [1/1], Training Loss: 2779.1238, Valid Loss: 62.2667
Epoch [18601/30000], Step [1/1], Training Loss: 2709.2759, Valid Loss: 62.3714
Epoch [18701/30000], Step [1/1], Training Loss: 2641.2959, Valid Loss: 60.5429
Epoch [18801/30000], Step [1/1], Training Loss: 2574.7861, Valid Loss: 60.0857
Epoch [18901/30000], Step [1/1], Training Loss: 2510.1562, Valid Loss: 66.2286
Epoch [19001/30000], Step [1/1], Training Loss: 2446.3210, Valid Loss: 62.8095
Epoch [19101/30000], Step [1/1], Training Loss: 2384.6995, Valid Loss: 62.1333
Epoch [19201/30000], Step [1/1], Training Loss: 2324.6733, Valid Loss: 62.2191
Epoch [19301/30000], Step [1/1], Training Loss: 2265.3059, Valid Loss: 62.7143
Epoch [19401/30000], Step [1/1], Training Loss: 2208.2085, Valid Loss: 62.2286
Epoch [19501/30000], Step [1/1], Training Loss: 2152.0210, Valid Loss: 64.7429
Epoch [19601/30000], Step [1/1], Training Loss: 2097.5818, Valid Loss: 63.9619
Epoch [19701/30000], Step [1/1], Training Loss: 2045.0178, Valid Loss: 64.4667
Epoch [19801/30000], Step [1/1], Training Loss: 1994.0042, Valid Loss: 65.6476
Epoch [19901/30000], Step [1/1], Training Loss: 1944.1091, Valid Loss: 63.5714
Epoch [20001/30000], Step [1/1], Training Loss: 1896.3192, Valid Loss: 65.3048
Epoch [20101/30000], Step [1/1], Training Loss: 1849.5212, Valid Loss: 66.6952
Epoch [20201/30000], Step [1/1], Training Loss: 1806.8777, Valid Loss: 68.1714
Epoch [20301/30000], Step [1/1], Training Loss: 1761.6951, Valid Loss: 68.8571
Epoch [20401/30000], Step [1/1], Training Loss: 1719.7173, Valid Loss: 67.5524

[Epoch 25000] Rounded prediction: 
tensor([10., 18., 16., 15., 20., 19., 20., 15., 15., 18., 16., 17., 17., 20.,
        17., 21., 23., 24., 20., 19., 20., 18., 16., 15., 14., 17., 11., 18.,
        12., 14., 13., 11.,  8., 13., 14., 11., 15., 16., 16., 12., 13., 13.,
         6.,  6.,  9., 10.,  9., 14., 14., 14., 18., 18., 16., 17., 22., 11.,
        10., 10., 17., 11., 12., 16., 16., 14., 19., 17., 15., 17., 20., 14.,
        19., 19., 20., 15., 22., 28., 14., 20., 12., 15., 17., 10., 23., 11.,
        12., 19., 16., 15., 25., 24., 21., 18., 11.,  9., 11., 15., 21., 18.,
        24., 27., 29., 27., 21., 16., 27.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [20501/30000], Step [1/1], Training Loss: 1679.2542, Valid Loss: 67.0095
Epoch [20601/30000], Step [1/1], Training Loss: 1640.3802, Valid Loss: 66.8667
Epoch [20701/30000], Step [1/1], Training Loss: 1602.5948, Valid Loss: 67.6190
Epoch [20801/30000], Step [1/1], Training Loss: 1566.2526, Valid Loss: 66.7905
Epoch [20901/30000], Step [1/1], Training Loss: 1530.6049, Valid Loss: 64.4857
Epoch [21001/30000], Step [1/1], Training Loss: 1496.3276, Valid Loss: 69.1238
Epoch [21101/30000], Step [1/1], Training Loss: 1462.9285, Valid Loss: 66.7810
Epoch [21201/30000], Step [1/1], Training Loss: 1430.7382, Valid Loss: 64.1429
Epoch [21301/30000], Step [1/1], Training Loss: 1399.6816, Valid Loss: 65.4857
Epoch [21401/30000], Step [1/1], Training Loss: 1369.7662, Valid Loss: 68.2000
Epoch [21501/30000], Step [1/1], Training Loss: 1339.3356, Valid Loss: 67.4381
Epoch [21601/30000], Step [1/1], Training Loss: 1310.0089, Valid Loss: 65.1619
Epoch [21701/30000], Step [1/1], Training Loss: 1698.3765, Valid Loss: 129.6000
Epoch [21801/30000], Step [1/1], Training Loss: 1293.2637, Valid Loss: 113.2667
Epoch [21901/30000], Step [1/1], Training Loss: 1244.4425, Valid Loss: 92.6095
Epoch [22001/30000], Step [1/1], Training Loss: 1217.3226, Valid Loss: 98.9238
Epoch [22101/30000], Step [1/1], Training Loss: 1190.1952, Valid Loss: 88.3333
Epoch [22201/30000], Step [1/1], Training Loss: 1166.0493, Valid Loss: 89.6476
Epoch [22301/30000], Step [1/1], Training Loss: 1142.2446, Valid Loss: 96.3619
Epoch [22401/30000], Step [1/1], Training Loss: 1119.1740, Valid Loss: 93.6190
Epoch [22501/30000], Step [1/1], Training Loss: 1096.3398, Valid Loss: 93.7714
Epoch [22601/30000], Step [1/1], Training Loss: 1072.8926, Valid Loss: 93.8571
Epoch [22701/30000], Step [1/1], Training Loss: 1050.9207, Valid Loss: 91.6190
Epoch [22801/30000], Step [1/1], Training Loss: 1028.5635, Valid Loss: 94.0095
Epoch [22901/30000], Step [1/1], Training Loss: 1007.0297, Valid Loss: 90.3905
Epoch [23001/30000], Step [1/1], Training Loss: 985.4453, Valid Loss: 86.4952
Epoch [23101/30000], Step [1/1], Training Loss: 963.9203, Valid Loss: 96.2667
Epoch [23201/30000], Step [1/1], Training Loss: 943.0184, Valid Loss: 95.0952
Epoch [23301/30000], Step [1/1], Training Loss: 922.6317, Valid Loss: 92.8762
Epoch [23401/30000], Step [1/1], Training Loss: 902.0175, Valid Loss: 96.0286
Epoch [23501/30000], Step [1/1], Training Loss: 882.5317, Valid Loss: 96.2762
Epoch [23601/30000], Step [1/1], Training Loss: 862.5898, Valid Loss: 97.2667
Epoch [23701/30000], Step [1/1], Training Loss: 844.0739, Valid Loss: 89.0476
Epoch [23801/30000], Step [1/1], Training Loss: 826.8751, Valid Loss: 92.3810
Epoch [23901/30000], Step [1/1], Training Loss: 807.0281, Valid Loss: 89.4381
Epoch [24001/30000], Step [1/1], Training Loss: 789.6949, Valid Loss: 88.2857
Epoch [24101/30000], Step [1/1], Training Loss: 772.4026, Valid Loss: 89.8952
Epoch [24201/30000], Step [1/1], Training Loss: 755.5294, Valid Loss: 88.3524
Epoch [24301/30000], Step [1/1], Training Loss: 738.9646, Valid Loss: 87.2952
Epoch [24401/30000], Step [1/1], Training Loss: 722.8144, Valid Loss: 91.4381
Epoch [24501/30000], Step [1/1], Training Loss: 707.3467, Valid Loss: 84.8952
Epoch [24601/30000], Step [1/1], Training Loss: 692.3119, Valid Loss: 93.4476
Epoch [24701/30000], Step [1/1], Training Loss: 678.7220, Valid Loss: 86.0857
Epoch [24801/30000], Step [1/1], Training Loss: 664.3979, Valid Loss: 89.7238
Epoch [24901/30000], Step [1/1], Training Loss: 1214.1687, Valid Loss: 86.8857
Epoch [25001/30000], Step [1/1], Training Loss: 639.1478, Valid Loss: 103.0857
Epoch [25101/30000], Step [1/1], Training Loss: 624.5232, Valid Loss: 96.9333
Epoch [25201/30000], Step [1/1], Training Loss: 611.0552, Valid Loss: 93.0286
Epoch [25301/30000], Step [1/1], Training Loss: 597.7386, Valid Loss: 97.5333
Epoch [25401/30000], Step [1/1], Training Loss: 583.9958, Valid Loss: 87.3524
Epoch [25501/30000], Step [1/1], Training Loss: 571.1139, Valid Loss: 86.3714
Epoch [25601/30000], Step [1/1], Training Loss: 557.3768, Valid Loss: 89.1333
Epoch [25701/30000], Step [1/1], Training Loss: 561.8983, Valid Loss: 88.8857
Epoch [25801/30000], Step [1/1], Training Loss: 532.1328, Valid Loss: 84.8095
Epoch [25901/30000], Step [1/1], Training Loss: 519.6683, Valid Loss: 85.4952
Epoch [26001/30000], Step [1/1], Training Loss: 507.3450, Valid Loss: 83.7524
Epoch [26101/30000], Step [1/1], Training Loss: 495.6539, Valid Loss: 83.2762
Epoch [26201/30000], Step [1/1], Training Loss: 483.6291, Valid Loss: 83.1524
Epoch [26301/30000], Step [1/1], Training Loss: 472.1558, Valid Loss: 83.8381
Epoch [26401/30000], Step [1/1], Training Loss: 461.0091, Valid Loss: 81.0857
Epoch [26501/30000], Step [1/1], Training Loss: 449.7661, Valid Loss: 81.7810
Epoch [26601/30000], Step [1/1], Training Loss: 439.0008, Valid Loss: 77.9429
Epoch [26701/30000], Step [1/1], Training Loss: 428.6422, Valid Loss: 84.6667
Epoch [26801/30000], Step [1/1], Training Loss: 418.2473, Valid Loss: 80.6190
Epoch [26901/30000], Step [1/1], Training Loss: 407.9705, Valid Loss: 78.1524
Epoch [27001/30000], Step [1/1], Training Loss: 398.0867, Valid Loss: 80.8095
Epoch [27101/30000], Step [1/1], Training Loss: 388.2747, Valid Loss: 80.0286
Epoch [27201/30000], Step [1/1], Training Loss: 378.4166, Valid Loss: 78.1333
Epoch [27301/30000], Step [1/1], Training Loss: 369.0776, Valid Loss: 78.4667
Epoch [27401/30000], Step [1/1], Training Loss: 359.3836, Valid Loss: 80.6667
Epoch [27501/30000], Step [1/1], Training Loss: 349.9174, Valid Loss: 74.8286
Epoch [27601/30000], Step [1/1], Training Loss: 340.2442, Valid Loss: 79.0667
Epoch [27701/30000], Step [1/1], Training Loss: 341.5470, Valid Loss: 96.2286
Epoch [27801/30000], Step [1/1], Training Loss: 333.3371, Valid Loss: 63.8857
Epoch [27901/30000], Step [1/1], Training Loss: 321.3110, Valid Loss: 69.1905
Epoch [28001/30000], Step [1/1], Training Loss: 313.4018, Valid Loss: 69.5333
Epoch [28101/30000], Step [1/1], Training Loss: 303.7101, Valid Loss: 70.1619
Epoch [28201/30000], Step [1/1], Training Loss: 296.2963, Valid Loss: 71.7619
Epoch [28301/30000], Step [1/1], Training Loss: 287.8354, Valid Loss: 70.2286
Epoch [28401/30000], Step [1/1], Training Loss: 280.5667, Valid Loss: 67.2095
Epoch [28501/30000], Step [1/1], Training Loss: 273.1331, Valid Loss: 69.0857
Epoch [28601/30000], Step [1/1], Training Loss: 265.4481, Valid Loss: 69.9429
Epoch [28701/30000], Step [1/1], Training Loss: 257.7787, Valid Loss: 70.5143
Epoch [28801/30000], Step [1/1], Training Loss: 250.7025, Valid Loss: 71.3714
Epoch [28901/30000], Step [1/1], Training Loss: 242.9496, Valid Loss: 71.6286
Epoch [29001/30000], Step [1/1], Training Loss: 235.3028, Valid Loss: 72.3905
Epoch [29101/30000], Step [1/1], Training Loss: 228.0662, Valid Loss: 71.3810
Epoch [29201/30000], Step [1/1], Training Loss: 221.1237, Valid Loss: 74.0667
Epoch [29301/30000], Step [1/1], Training Loss: 213.5294, Valid Loss: 68.7048
Epoch [29401/30000], Step [1/1], Training Loss: 206.4863, Valid Loss: 71.8191
Epoch [29501/30000], Step [1/1], Training Loss: 199.6704, Valid Loss: 68.5238
Epoch [29601/30000], Step [1/1], Training Loss: 192.7006, Valid Loss: 68.5238
Epoch [29701/30000], Step [1/1], Training Loss: 185.9978, Valid Loss: 69.1905
Epoch [29801/30000], Step [1/1], Training Loss: 179.2708, Valid Loss: 72.9905
Epoch [29901/30000], Step [1/1], Training Loss: 172.5385, Valid Loss: 71.2762

 End Time: 2021/04/19, 04:24:33




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=512 	layers=3

Start Time = 2021/04/19, 04:24:34
##########################################################


[Epoch 0] Rounded prediction: 
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([ 7., 14., 11., 10., 17., 16., 17., 10.,  2.,  7.,  0.,  3.,  4.,  5.,
         4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  6.,
         1.,  3.,  3.,  0., 17.,  9.,  0.,  0.,  3., 14., 16., 17., 23., 23.,
        31., 37., 38., 27., 30., 30., 29.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([12., 19., 15., 15., 18., 16., 18., 13., 11., 10., 10., 10., 10.,  8.,
         6.,  8.,  4.,  0.,  7.,  9.,  1.,  2.,  2.,  2.,  0.,  3.,  6.,  3.,
         2.,  0.,  1.,  4.,  4.,  4.,  1.,  3.,  2.,  5.,  4.,  4.,  0.,  7.,
         4.,  3.,  2.,  6.,  8.,  2.,  3.,  4.,  6.,  3.,  0.,  0.,  5.,  0.,
         0.,  9., 11.,  0.,  3.,  3.,  1.,  8.,  0.,  0.,  0.,  1.,  3.,  7.,
         0.,  6.,  4.,  7., 11.,  2.,  0.,  6.,  5.,  4.,  3.,  7.,  6., 12.,
        16., 11.,  6.,  3., 16.,  6.,  2.,  4., 21., 29., 19., 20., 26., 22.,
        26., 38., 31., 21., 31., 37., 28.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128661.8594, Valid Loss: 238.9238
Epoch [101/30000], Step [1/1], Training Loss: 121083.6719, Valid Loss: 118.3048
Epoch [201/30000], Step [1/1], Training Loss: 118694.1172, Valid Loss: 192.8286
Epoch [301/30000], Step [1/1], Training Loss: 116447.7656, Valid Loss: 317.3524
Epoch [401/30000], Step [1/1], Training Loss: 114291.2031, Valid Loss: 491.8762
Epoch [501/30000], Step [1/1], Training Loss: 112207.6797, Valid Loss: 743.0191
Epoch [601/30000], Step [1/1], Training Loss: 110191.8516, Valid Loss: 990.9238
Epoch [701/30000], Step [1/1], Training Loss: 108238.6719, Valid Loss: 1315.4476
Epoch [801/30000], Step [1/1], Training Loss: 106342.5312, Valid Loss: 1689.9714
Epoch [901/30000], Step [1/1], Training Loss: 104500.3516, Valid Loss: 2114.4954
Epoch [1001/30000], Step [1/1], Training Loss: 102706.8594, Valid Loss: 1959.5620
Epoch [1101/30000], Step [1/1], Training Loss: 100959.8438, Valid Loss: 1400.6477
Epoch [1201/30000], Step [1/1], Training Loss: 99259.5703, Valid Loss: 1319.4286
Epoch [1301/30000], Step [1/1], Training Loss: 97301.3125, Valid Loss: 93.2857
Epoch [1401/30000], Step [1/1], Training Loss: 95569.1797, Valid Loss: 111.2667
Epoch [1501/30000], Step [1/1], Training Loss: 93879.3125, Valid Loss: 123.1714
Epoch [1601/30000], Step [1/1], Training Loss: 92210.0547, Valid Loss: 128.3619
Epoch [1701/30000], Step [1/1], Training Loss: 90562.8203, Valid Loss: 141.7619
Epoch [1801/30000], Step [1/1], Training Loss: 88965.5703, Valid Loss: 131.2095
Epoch [1901/30000], Step [1/1], Training Loss: 87398.6797, Valid Loss: 143.7143
Epoch [2001/30000], Step [1/1], Training Loss: 85859.6797, Valid Loss: 133.4667
Epoch [2101/30000], Step [1/1], Training Loss: 84351.8047, Valid Loss: 135.6572
Epoch [2201/30000], Step [1/1], Training Loss: 82875.9531, Valid Loss: 136.2857
Epoch [2301/30000], Step [1/1], Training Loss: 81421.4766, Valid Loss: 129.0857
Epoch [2401/30000], Step [1/1], Training Loss: 79999.2500, Valid Loss: 126.7429
Epoch [2501/30000], Step [1/1], Training Loss: 78601.9609, Valid Loss: 140.7619
Epoch [2601/30000], Step [1/1], Training Loss: 77246.0000, Valid Loss: 127.2476
Epoch [2701/30000], Step [1/1], Training Loss: 75837.3828, Valid Loss: 121.4762
Epoch [2801/30000], Step [1/1], Training Loss: 74496.4062, Valid Loss: 128.4857
Epoch [2901/30000], Step [1/1], Training Loss: 73193.8359, Valid Loss: 127.2762
Epoch [3001/30000], Step [1/1], Training Loss: 71917.1797, Valid Loss: 125.2191
Epoch [3101/30000], Step [1/1], Training Loss: 70659.5391, Valid Loss: 123.1810
Epoch [3201/30000], Step [1/1], Training Loss: 69429.3203, Valid Loss: 123.6572
Epoch [3301/30000], Step [1/1], Training Loss: 68224.8828, Valid Loss: 131.4762
Epoch [3401/30000], Step [1/1], Training Loss: 67045.0547, Valid Loss: 131.2286
Epoch [3501/30000], Step [1/1], Training Loss: 65889.5234, Valid Loss: 132.3810
Epoch [3601/30000], Step [1/1], Training Loss: 64757.5039, Valid Loss: 130.3524
Epoch [3701/30000], Step [1/1], Training Loss: 63650.4727, Valid Loss: 126.4381
Epoch [3801/30000], Step [1/1], Training Loss: 62563.9805, Valid Loss: 130.0667
Epoch [3901/30000], Step [1/1], Training Loss: 61501.6211, Valid Loss: 134.6286
Epoch [4001/30000], Step [1/1], Training Loss: 60463.4219, Valid Loss: 128.0857
Epoch [4101/30000], Step [1/1], Training Loss: 59448.0234, Valid Loss: 126.3714
Epoch [4201/30000], Step [1/1], Training Loss: 58378.6250, Valid Loss: 121.9810
Epoch [4301/30000], Step [1/1], Training Loss: 57380.7617, Valid Loss: 120.0857
Epoch [4401/30000], Step [1/1], Training Loss: 56379.3828, Valid Loss: 120.6381
Epoch [4501/30000], Step [1/1], Training Loss: 55389.7070, Valid Loss: 115.9524
Epoch [4601/30000], Step [1/1], Training Loss: 54418.9023, Valid Loss: 112.3619
Epoch [4701/30000], Step [1/1], Training Loss: 53441.8828, Valid Loss: 114.6286
Epoch [4801/30000], Step [1/1], Training Loss: 52513.7852, Valid Loss: 112.8857
Epoch [4901/30000], Step [1/1], Training Loss: 51589.9258, Valid Loss: 118.0191
Epoch [5001/30000], Step [1/1], Training Loss: 50686.6562, Valid Loss: 118.9238
Epoch [5101/30000], Step [1/1], Training Loss: 49782.7617, Valid Loss: 113.8952
Epoch [5201/30000], Step [1/1], Training Loss: 49170.8477, Valid Loss: 116.1143
Epoch [5301/30000], Step [1/1], Training Loss: 48107.5156, Valid Loss: 113.5905
Epoch [5401/30000], Step [1/1], Training Loss: 47220.5312, Valid Loss: 107.9048
Epoch [5501/30000], Step [1/1], Training Loss: 46350.0117, Valid Loss: 111.5429
Epoch [5601/30000], Step [1/1], Training Loss: 45632.0156, Valid Loss: 110.4476
Epoch [5701/30000], Step [1/1], Training Loss: 44798.5391, Valid Loss: 111.9524
Epoch [5801/30000], Step [1/1], Training Loss: 44013.8828, Valid Loss: 116.9524
Epoch [5901/30000], Step [1/1], Training Loss: 43188.0703, Valid Loss: 115.0476
Epoch [6001/30000], Step [1/1], Training Loss: 42476.0156, Valid Loss: 114.3048
Epoch [6101/30000], Step [1/1], Training Loss: 41686.3281, Valid Loss: 111.8381
Epoch [6201/30000], Step [1/1], Training Loss: 40979.1055, Valid Loss: 112.0762
Epoch [6301/30000], Step [1/1], Training Loss: 40238.9766, Valid Loss: 105.6952
Epoch [6401/30000], Step [1/1], Training Loss: 39524.6094, Valid Loss: 112.4571
Epoch [6501/30000], Step [1/1], Training Loss: 38829.0195, Valid Loss: 110.4857
Epoch [6601/30000], Step [1/1], Training Loss: 38158.1094, Valid Loss: 104.1905
Epoch [6701/30000], Step [1/1], Training Loss: 37499.1875, Valid Loss: 106.2286
Epoch [6801/30000], Step [1/1], Training Loss: 36854.0781, Valid Loss: 107.3143
Epoch [6901/30000], Step [1/1], Training Loss: 36225.9570, Valid Loss: 108.3905
Epoch [7001/30000], Step [1/1], Training Loss: 35585.0625, Valid Loss: 106.5048
Epoch [7101/30000], Step [1/1], Training Loss: 35524.7930, Valid Loss: 106.5905
Epoch [7201/30000], Step [1/1], Training Loss: 34573.4062, Valid Loss: 104.8571
Epoch [7301/30000], Step [1/1], Training Loss: 33203.7344, Valid Loss: 112.8381
Epoch [7401/30000], Step [1/1], Training Loss: 32494.5977, Valid Loss: 108.2762
Epoch [7501/30000], Step [1/1], Training Loss: 31865.6797, Valid Loss: 112.1143
Epoch [7601/30000], Step [1/1], Training Loss: 31253.2246, Valid Loss: 109.0381
Epoch [7701/30000], Step [1/1], Training Loss: 30647.9844, Valid Loss: 112.8095
Epoch [7801/30000], Step [1/1], Training Loss: 30065.1836, Valid Loss: 105.5429
Epoch [7901/30000], Step [1/1], Training Loss: 29489.0527, Valid Loss: 100.4952
Epoch [8001/30000], Step [1/1], Training Loss: 28926.8281, Valid Loss: 97.0476
Epoch [8101/30000], Step [1/1], Training Loss: 28377.2734, Valid Loss: 91.8667
Epoch [8201/30000], Step [1/1], Training Loss: 27841.3418, Valid Loss: 96.6190
Epoch [8301/30000], Step [1/1], Training Loss: 27314.2031, Valid Loss: 84.9143
Epoch [8401/30000], Step [1/1], Training Loss: 26801.3262, Valid Loss: 87.8952
Epoch [8501/30000], Step [1/1], Training Loss: 26297.5508, Valid Loss: 84.1810
Epoch [8601/30000], Step [1/1], Training Loss: 25807.8066, Valid Loss: 88.1714
Epoch [8701/30000], Step [1/1], Training Loss: 25460.5312, Valid Loss: 95.3429
Epoch [8801/30000], Step [1/1], Training Loss: 24957.9648, Valid Loss: 108.5429
Epoch [8901/30000], Step [1/1], Training Loss: 24336.8438, Valid Loss: 81.5905
Epoch [9001/30000], Step [1/1], Training Loss: 23858.9258, Valid Loss: 90.6381
Epoch [9101/30000], Step [1/1], Training Loss: 23409.3203, Valid Loss: 88.4667
Epoch [9201/30000], Step [1/1], Training Loss: 22966.8672, Valid Loss: 97.8000
Epoch [9301/30000], Step [1/1], Training Loss: 22534.9727, Valid Loss: 91.2286
Epoch [9401/30000], Step [1/1], Training Loss: 22112.0762, Valid Loss: 92.1048
Epoch [9501/30000], Step [1/1], Training Loss: 21701.6562, Valid Loss: 88.6667
Epoch [9601/30000], Step [1/1], Training Loss: 21303.7969, Valid Loss: 96.4095
Epoch [9701/30000], Step [1/1], Training Loss: 20921.5645, Valid Loss: 92.6667
Epoch [9801/30000], Step [1/1], Training Loss: 20588.2109, Valid Loss: 86.6476
Epoch [9901/30000], Step [1/1], Training Loss: 19980.6426, Valid Loss: 72.1524
Epoch [10001/30000], Step [1/1], Training Loss: 19553.3184, Valid Loss: 73.9238
Epoch [10101/30000], Step [1/1], Training Loss: 19175.3555, Valid Loss: 82.5810

[Epoch 15000] Rounded prediction: 
tensor([12., 18., 11., 12., 14., 11., 13., 12., 10., 12., 11.,  9.,  6.,  8.,
         4.,  7.,  6.,  5.,  7.,  8.,  4.,  7.,  6.,  6.,  7.,  4.,  8., 12.,
         7.,  0.,  8.,  6.,  8.,  8.,  2.,  7.,  2.,  9.,  6., 10.,  2., 17.,
         9.,  5.,  4., 11.,  6.,  8.,  7.,  7.,  5.,  7.,  2.,  1.,  6.,  4.,
         0.,  8., 14.,  4.,  7.,  4.,  6.,  6.,  4.,  7.,  3.,  8.,  3.,  9.,
         6.,  6.,  3., 10.,  6.,  1.,  1.,  9.,  5., 10.,  5., 10., 10., 19.,
        14., 12.,  5.,  4., 15.,  7.,  2.,  7., 34., 34., 22., 23., 24., 17.,
        26., 34., 23., 19., 32., 30., 24.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([13., 16., 11., 13., 14., 14., 14., 13., 11., 12., 11., 10., 12.,  8.,
         9., 10.,  7.,  7.,  6.,  9.,  4.,  1.,  5.,  8.,  3.,  2.,  8., 10.,
         6.,  3.,  9.,  3.,  7.,  9.,  1.,  9.,  3.,  7.,  8., 10.,  2., 19.,
        11.,  7.,  3., 11.,  6.,  7.,  7.,  7.,  9., 10.,  2.,  2.,  8.,  6.,
         0.,  8., 13.,  6.,  6.,  6.,  5., 12.,  6.,  5.,  3.,  9.,  1.,  9.,
         7.,  7.,  0.,  8.,  6.,  3.,  0., 12.,  9., 14., 10.,  8., 15., 17.,
        15.,  9.,  4.,  1., 15.,  8.,  2., 13., 37., 33., 25., 27., 30., 21.,
        23., 33., 26., 18., 26., 23., 20.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [10201/30000], Step [1/1], Training Loss: 18806.9277, Valid Loss: 84.9524
Epoch [10301/30000], Step [1/1], Training Loss: 18438.2578, Valid Loss: 83.3238
Epoch [10401/30000], Step [1/1], Training Loss: 18081.9961, Valid Loss: 79.0095
Epoch [10501/30000], Step [1/1], Training Loss: 17736.8047, Valid Loss: 76.5238
Epoch [10601/30000], Step [1/1], Training Loss: 17394.8145, Valid Loss: 81.9143
Epoch [10701/30000], Step [1/1], Training Loss: 17063.1699, Valid Loss: 79.7810
Epoch [10801/30000], Step [1/1], Training Loss: 16694.2598, Valid Loss: 76.1238
Epoch [10901/30000], Step [1/1], Training Loss: 16366.7422, Valid Loss: 77.3143
Epoch [11001/30000], Step [1/1], Training Loss: 15909.0322, Valid Loss: 75.7238
Epoch [11101/30000], Step [1/1], Training Loss: 15670.9189, Valid Loss: 89.7810
Epoch [11201/30000], Step [1/1], Training Loss: 15226.9414, Valid Loss: 79.1048
Epoch [11301/30000], Step [1/1], Training Loss: 14879.6250, Valid Loss: 71.3333
Epoch [11401/30000], Step [1/1], Training Loss: 14536.7510, Valid Loss: 77.3524
Epoch [11501/30000], Step [1/1], Training Loss: 14624.9150, Valid Loss: 74.3333
Epoch [11601/30000], Step [1/1], Training Loss: 13978.8877, Valid Loss: 58.7714
Epoch [11701/30000], Step [1/1], Training Loss: 13672.7598, Valid Loss: 63.4667
Epoch [11801/30000], Step [1/1], Training Loss: 13398.1641, Valid Loss: 61.9429
Epoch [11901/30000], Step [1/1], Training Loss: 13017.7373, Valid Loss: 61.6381
Epoch [12001/30000], Step [1/1], Training Loss: 12741.0176, Valid Loss: 66.2952
Epoch [12101/30000], Step [1/1], Training Loss: 12471.8232, Valid Loss: 60.7905
Epoch [12201/30000], Step [1/1], Training Loss: 12208.8086, Valid Loss: 63.1143
Epoch [12301/30000], Step [1/1], Training Loss: 11948.2363, Valid Loss: 63.7714
Epoch [12401/30000], Step [1/1], Training Loss: 11680.8418, Valid Loss: 64.0000
Epoch [12501/30000], Step [1/1], Training Loss: 11425.1162, Valid Loss: 59.3810
Epoch [12601/30000], Step [1/1], Training Loss: 11179.9111, Valid Loss: 66.2286
Epoch [12701/30000], Step [1/1], Training Loss: 10936.9502, Valid Loss: 60.7810
Epoch [12801/30000], Step [1/1], Training Loss: 10705.8770, Valid Loss: 64.2952
Epoch [12901/30000], Step [1/1], Training Loss: 10474.6357, Valid Loss: 61.5810
Epoch [13001/30000], Step [1/1], Training Loss: 10253.1064, Valid Loss: 68.2571
Epoch [13101/30000], Step [1/1], Training Loss: 10035.3457, Valid Loss: 66.5619
Epoch [13201/30000], Step [1/1], Training Loss: 9822.7373, Valid Loss: 64.3810
Epoch [13301/30000], Step [1/1], Training Loss: 9615.6016, Valid Loss: 61.4000
Epoch [13401/30000], Step [1/1], Training Loss: 9415.6318, Valid Loss: 64.8191
Epoch [13501/30000], Step [1/1], Training Loss: 9211.5732, Valid Loss: 68.1143
Epoch [13601/30000], Step [1/1], Training Loss: 9864.6738, Valid Loss: 110.8381
Epoch [13701/30000], Step [1/1], Training Loss: 8840.5957, Valid Loss: 70.8667
Epoch [13801/30000], Step [1/1], Training Loss: 8570.5352, Valid Loss: 67.5048
Epoch [13901/30000], Step [1/1], Training Loss: 8375.0273, Valid Loss: 67.6476
Epoch [14001/30000], Step [1/1], Training Loss: 8190.5527, Valid Loss: 61.8667
Epoch [14101/30000], Step [1/1], Training Loss: 8009.3066, Valid Loss: 62.6762
Epoch [14201/30000], Step [1/1], Training Loss: 7834.9375, Valid Loss: 63.2191
Epoch [14301/30000], Step [1/1], Training Loss: 7662.8267, Valid Loss: 63.1810
Epoch [14401/30000], Step [1/1], Training Loss: 7496.4873, Valid Loss: 59.3143
Epoch [14501/30000], Step [1/1], Training Loss: 7333.8501, Valid Loss: 59.1333
Epoch [14601/30000], Step [1/1], Training Loss: 7174.3774, Valid Loss: 62.3429
Epoch [14701/30000], Step [1/1], Training Loss: 7020.4570, Valid Loss: 59.4667
Epoch [14801/30000], Step [1/1], Training Loss: 6867.7935, Valid Loss: 60.9524
Epoch [14901/30000], Step [1/1], Training Loss: 6721.1401, Valid Loss: 61.1429
Epoch [15001/30000], Step [1/1], Training Loss: 6560.8359, Valid Loss: 59.0191
Epoch [15101/30000], Step [1/1], Training Loss: 6415.8032, Valid Loss: 60.7048
Epoch [15201/30000], Step [1/1], Training Loss: 6275.6206, Valid Loss: 56.0286
Epoch [15301/30000], Step [1/1], Training Loss: 6138.8320, Valid Loss: 64.3619
Epoch [15401/30000], Step [1/1], Training Loss: 6005.6270, Valid Loss: 58.1905
Epoch [15501/30000], Step [1/1], Training Loss: 5876.4351, Valid Loss: 63.8476
Epoch [15601/30000], Step [1/1], Training Loss: 5749.8022, Valid Loss: 59.8571
Epoch [15701/30000], Step [1/1], Training Loss: 5626.0879, Valid Loss: 58.4286
Epoch [15801/30000], Step [1/1], Training Loss: 5505.6514, Valid Loss: 59.5810
Epoch [15901/30000], Step [1/1], Training Loss: 5387.8491, Valid Loss: 63.1905
Epoch [16001/30000], Step [1/1], Training Loss: 5274.3101, Valid Loss: 58.7143
Epoch [16101/30000], Step [1/1], Training Loss: 5162.9922, Valid Loss: 59.1619
Epoch [16201/30000], Step [1/1], Training Loss: 5054.4106, Valid Loss: 58.8762
Epoch [16301/30000], Step [1/1], Training Loss: 4948.8203, Valid Loss: 57.7619
Epoch [16401/30000], Step [1/1], Training Loss: 4846.2539, Valid Loss: 59.5429
Epoch [16501/30000], Step [1/1], Training Loss: 4746.8037, Valid Loss: 59.1524
Epoch [16601/30000], Step [1/1], Training Loss: 4650.4609, Valid Loss: 59.8381
Epoch [16701/30000], Step [1/1], Training Loss: 4556.9473, Valid Loss: 60.4190
Epoch [16801/30000], Step [1/1], Training Loss: 4823.2388, Valid Loss: 72.6190
Epoch [16901/30000], Step [1/1], Training Loss: 4145.7808, Valid Loss: 65.6095
Epoch [17001/30000], Step [1/1], Training Loss: 4039.4182, Valid Loss: 65.2190
Epoch [17101/30000], Step [1/1], Training Loss: 3936.5059, Valid Loss: 63.9810
Epoch [17201/30000], Step [1/1], Training Loss: 3837.6433, Valid Loss: 66.5524
Epoch [17301/30000], Step [1/1], Training Loss: 3742.3396, Valid Loss: 67.1333
Epoch [17401/30000], Step [1/1], Training Loss: 3650.4023, Valid Loss: 67.3143
Epoch [17501/30000], Step [1/1], Training Loss: 3560.1462, Valid Loss: 62.8762
Epoch [17601/30000], Step [1/1], Training Loss: 3472.4402, Valid Loss: 61.4667
Epoch [17701/30000], Step [1/1], Training Loss: 3386.0605, Valid Loss: 64.0476
Epoch [17801/30000], Step [1/1], Training Loss: 3302.0129, Valid Loss: 60.3333
Epoch [17901/30000], Step [1/1], Training Loss: 3219.8604, Valid Loss: 61.1143
Epoch [18001/30000], Step [1/1], Training Loss: 3140.1672, Valid Loss: 63.5333
Epoch [18101/30000], Step [1/1], Training Loss: 3062.4893, Valid Loss: 67.5905
Epoch [18201/30000], Step [1/1], Training Loss: 2986.6907, Valid Loss: 58.6476
Epoch [18301/30000], Step [1/1], Training Loss: 2912.6501, Valid Loss: 64.9048
Epoch [18401/30000], Step [1/1], Training Loss: 2840.6685, Valid Loss: 59.6286
Epoch [18501/30000], Step [1/1], Training Loss: 2770.5161, Valid Loss: 60.5143
Epoch [18601/30000], Step [1/1], Training Loss: 2701.2161, Valid Loss: 58.7810
Epoch [18701/30000], Step [1/1], Training Loss: 2633.9563, Valid Loss: 55.8000
Epoch [18801/30000], Step [1/1], Training Loss: 2567.9263, Valid Loss: 62.3524
Epoch [18901/30000], Step [1/1], Training Loss: 2503.1016, Valid Loss: 60.8286
Epoch [19001/30000], Step [1/1], Training Loss: 2439.9409, Valid Loss: 59.6857
Epoch [19101/30000], Step [1/1], Training Loss: 2378.2668, Valid Loss: 57.0571
Epoch [19201/30000], Step [1/1], Training Loss: 2317.7698, Valid Loss: 59.0191
Epoch [19301/30000], Step [1/1], Training Loss: 2259.7791, Valid Loss: 58.1810
Epoch [19401/30000], Step [1/1], Training Loss: 2202.0349, Valid Loss: 52.7714
Epoch [19501/30000], Step [1/1], Training Loss: 2146.7253, Valid Loss: 59.0571
Epoch [19601/30000], Step [1/1], Training Loss: 2092.6709, Valid Loss: 60.3714
Epoch [19701/30000], Step [1/1], Training Loss: 2040.0596, Valid Loss: 57.2476
Epoch [19801/30000], Step [1/1], Training Loss: 1989.2002, Valid Loss: 58.7905
Epoch [19901/30000], Step [1/1], Training Loss: 1939.9319, Valid Loss: 56.0571
Epoch [20001/30000], Step [1/1], Training Loss: 1892.1785, Valid Loss: 59.3714
Epoch [20101/30000], Step [1/1], Training Loss: 1845.8093, Valid Loss: 55.2286
Epoch [20201/30000], Step [1/1], Training Loss: 1801.0701, Valid Loss: 55.5810
Epoch [20301/30000], Step [1/1], Training Loss: 1757.7544, Valid Loss: 58.7524
Epoch [20401/30000], Step [1/1], Training Loss: 1716.2172, Valid Loss: 58.4762

[Epoch 25000] Rounded prediction: 
tensor([13., 17., 12., 13., 15., 16., 17., 13., 12., 12., 11.,  9., 11., 12.,
         9.,  6.,  7.,  7.,  8.,  9.,  3.,  7.,  8.,  9.,  5.,  3., 10., 10.,
         9.,  2., 10.,  4.,  7., 11.,  4.,  8.,  2., 10.,  8., 10.,  3., 19.,
        12.,  8.,  3., 12.,  7.,  8.,  7.,  7.,  9.,  8.,  6.,  4., 11.,  6.,
         1., 10., 13.,  5.,  7.,  7.,  7., 15.,  6.,  9.,  5., 10.,  5., 11.,
         8.,  8.,  0.,  8., 13.,  4.,  3., 15., 10., 14., 10., 10., 15., 17.,
        19., 12.,  6.,  5., 15.,  4.,  1., 16., 38., 33., 24., 28., 33., 28.,
        27., 34., 29., 14., 26., 22., 19.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [20501/30000], Step [1/1], Training Loss: 1676.1119, Valid Loss: 56.4476
Epoch [20601/30000], Step [1/1], Training Loss: 1637.1636, Valid Loss: 57.3048
Epoch [20701/30000], Step [1/1], Training Loss: 1599.5044, Valid Loss: 56.3238
Epoch [20801/30000], Step [1/1], Training Loss: 1563.2026, Valid Loss: 54.6095
Epoch [20901/30000], Step [1/1], Training Loss: 1527.7920, Valid Loss: 57.2191
Epoch [21001/30000], Step [1/1], Training Loss: 1493.5690, Valid Loss: 58.3429
Epoch [21101/30000], Step [1/1], Training Loss: 1460.4187, Valid Loss: 54.1905
Epoch [21201/30000], Step [1/1], Training Loss: 1428.1975, Valid Loss: 55.1619
Epoch [21301/30000], Step [1/1], Training Loss: 1396.8679, Valid Loss: 54.1619
Epoch [21401/30000], Step [1/1], Training Loss: 1366.4742, Valid Loss: 57.7333
Epoch [21501/30000], Step [1/1], Training Loss: 1336.5447, Valid Loss: 60.7714
Epoch [21601/30000], Step [1/1], Training Loss: 1307.4761, Valid Loss: 60.3333
Epoch [21701/30000], Step [1/1], Training Loss: 1279.3367, Valid Loss: 56.4762
Epoch [21801/30000], Step [1/1], Training Loss: 1251.7377, Valid Loss: 54.6286
Epoch [21901/30000], Step [1/1], Training Loss: 1225.2393, Valid Loss: 57.1619
Epoch [22001/30000], Step [1/1], Training Loss: 1199.0947, Valid Loss: 53.9524
Epoch [22101/30000], Step [1/1], Training Loss: 1173.9241, Valid Loss: 54.8952
Epoch [22201/30000], Step [1/1], Training Loss: 1149.0149, Valid Loss: 56.6095
Epoch [22301/30000], Step [1/1], Training Loss: 1124.4484, Valid Loss: 51.6190
Epoch [22401/30000], Step [1/1], Training Loss: 1100.2742, Valid Loss: 59.7810
Epoch [22501/30000], Step [1/1], Training Loss: 1076.5608, Valid Loss: 55.9905
Epoch [22601/30000], Step [1/1], Training Loss: 1053.0234, Valid Loss: 58.8571
Epoch [22701/30000], Step [1/1], Training Loss: 1029.8196, Valid Loss: 54.4381
Epoch [22801/30000], Step [1/1], Training Loss: 1006.8502, Valid Loss: 55.6000
Epoch [22901/30000], Step [1/1], Training Loss: 984.3364, Valid Loss: 58.3524
Epoch [23001/30000], Step [1/1], Training Loss: 962.2548, Valid Loss: 55.6571
Epoch [23101/30000], Step [1/1], Training Loss: 940.5003, Valid Loss: 58.3238
Epoch [23201/30000], Step [1/1], Training Loss: 919.3469, Valid Loss: 57.2000
Epoch [23301/30000], Step [1/1], Training Loss: 898.3876, Valid Loss: 58.7333
Epoch [23401/30000], Step [1/1], Training Loss: 878.0805, Valid Loss: 55.5905
Epoch [23501/30000], Step [1/1], Training Loss: 858.2622, Valid Loss: 57.9143
Epoch [23601/30000], Step [1/1], Training Loss: 838.8459, Valid Loss: 53.8000
Epoch [23701/30000], Step [1/1], Training Loss: 819.8785, Valid Loss: 56.2000
Epoch [23801/30000], Step [1/1], Training Loss: 801.4130, Valid Loss: 57.0476
Epoch [23901/30000], Step [1/1], Training Loss: 783.4528, Valid Loss: 56.1333
Epoch [24001/30000], Step [1/1], Training Loss: 766.0100, Valid Loss: 56.6571
Epoch [24101/30000], Step [1/1], Training Loss: 749.2387, Valid Loss: 57.2762
Epoch [24201/30000], Step [1/1], Training Loss: 732.7108, Valid Loss: 56.0952
Epoch [24301/30000], Step [1/1], Training Loss: 716.9464, Valid Loss: 54.1524
Epoch [24401/30000], Step [1/1], Training Loss: 701.3109, Valid Loss: 57.4381
Epoch [24501/30000], Step [1/1], Training Loss: 686.0765, Valid Loss: 57.6762
Epoch [24601/30000], Step [1/1], Training Loss: 671.0573, Valid Loss: 55.0857
Epoch [24701/30000], Step [1/1], Training Loss: 656.4296, Valid Loss: 57.5524
Epoch [24801/30000], Step [1/1], Training Loss: 642.1417, Valid Loss: 58.1905
Epoch [24901/30000], Step [1/1], Training Loss: 628.1074, Valid Loss: 57.8000
Epoch [25001/30000], Step [1/1], Training Loss: 614.1953, Valid Loss: 57.3238
Epoch [25101/30000], Step [1/1], Training Loss: 600.4398, Valid Loss: 55.7048
Epoch [25201/30000], Step [1/1], Training Loss: 586.8718, Valid Loss: 56.6190
Epoch [25301/30000], Step [1/1], Training Loss: 573.3436, Valid Loss: 55.2857
Epoch [25401/30000], Step [1/1], Training Loss: 560.2042, Valid Loss: 56.8190
Epoch [25501/30000], Step [1/1], Training Loss: 547.1443, Valid Loss: 55.5333
Epoch [25601/30000], Step [1/1], Training Loss: 565.3911, Valid Loss: 58.3048
Epoch [25701/30000], Step [1/1], Training Loss: 539.9433, Valid Loss: 61.5905
Epoch [25801/30000], Step [1/1], Training Loss: 527.8027, Valid Loss: 61.6667
Epoch [25901/30000], Step [1/1], Training Loss: 518.1566, Valid Loss: 60.6381
Epoch [26001/30000], Step [1/1], Training Loss: 509.2469, Valid Loss: 58.4762
Epoch [26101/30000], Step [1/1], Training Loss: 499.2439, Valid Loss: 59.0000
Epoch [26201/30000], Step [1/1], Training Loss: 490.7081, Valid Loss: 57.6571
Epoch [26301/30000], Step [1/1], Training Loss: 481.9966, Valid Loss: 67.1048
Epoch [26401/30000], Step [1/1], Training Loss: 472.9435, Valid Loss: 66.1905
Epoch [26501/30000], Step [1/1], Training Loss: 463.8427, Valid Loss: 62.7238
Epoch [26601/30000], Step [1/1], Training Loss: 455.4437, Valid Loss: 62.5524
Epoch [26701/30000], Step [1/1], Training Loss: 446.9134, Valid Loss: 62.4095
Epoch [26801/30000], Step [1/1], Training Loss: 437.6509, Valid Loss: 63.3619
Epoch [26901/30000], Step [1/1], Training Loss: 429.2762, Valid Loss: 62.6476
Epoch [27001/30000], Step [1/1], Training Loss: 420.8127, Valid Loss: 62.4952
Epoch [27101/30000], Step [1/1], Training Loss: 412.2734, Valid Loss: 64.3905
Epoch [27201/30000], Step [1/1], Training Loss: 404.0581, Valid Loss: 60.0286
Epoch [27301/30000], Step [1/1], Training Loss: 395.4314, Valid Loss: 63.5238
Epoch [27401/30000], Step [1/1], Training Loss: 387.5096, Valid Loss: 63.4762
Epoch [27501/30000], Step [1/1], Training Loss: 378.7061, Valid Loss: 65.9333
Epoch [27601/30000], Step [1/1], Training Loss: 370.1967, Valid Loss: 66.2095
Epoch [27701/30000], Step [1/1], Training Loss: 361.5301, Valid Loss: 67.8286
Epoch [27801/30000], Step [1/1], Training Loss: 353.0465, Valid Loss: 63.2476
Epoch [27901/30000], Step [1/1], Training Loss: 344.4789, Valid Loss: 61.1714
Epoch [28001/30000], Step [1/1], Training Loss: 335.8864, Valid Loss: 62.5238
Epoch [28101/30000], Step [1/1], Training Loss: 327.3145, Valid Loss: 64.3238
Epoch [28201/30000], Step [1/1], Training Loss: 318.8264, Valid Loss: 64.2571
Epoch [28301/30000], Step [1/1], Training Loss: 310.4399, Valid Loss: 63.5143
Epoch [28401/30000], Step [1/1], Training Loss: 301.7910, Valid Loss: 66.2952
Epoch [28501/30000], Step [1/1], Training Loss: 293.4894, Valid Loss: 64.3143
Epoch [28601/30000], Step [1/1], Training Loss: 285.0265, Valid Loss: 62.9810
Epoch [28701/30000], Step [1/1], Training Loss: 276.6754, Valid Loss: 63.7143
Epoch [28801/30000], Step [1/1], Training Loss: 268.4203, Valid Loss: 66.7524
Epoch [28901/30000], Step [1/1], Training Loss: 260.3232, Valid Loss: 62.5143
Epoch [29001/30000], Step [1/1], Training Loss: 252.3702, Valid Loss: 63.5048
Epoch [29101/30000], Step [1/1], Training Loss: 244.4118, Valid Loss: 64.6571
Epoch [29201/30000], Step [1/1], Training Loss: 236.4173, Valid Loss: 67.2952
Epoch [29301/30000], Step [1/1], Training Loss: 228.6207, Valid Loss: 66.6286
Epoch [29401/30000], Step [1/1], Training Loss: 221.0721, Valid Loss: 65.3238
Epoch [29501/30000], Step [1/1], Training Loss: 214.1671, Valid Loss: 64.6095
Epoch [29601/30000], Step [1/1], Training Loss: 206.0559, Valid Loss: 65.0952
Epoch [29701/30000], Step [1/1], Training Loss: 198.7435, Valid Loss: 65.9810
Epoch [29801/30000], Step [1/1], Training Loss: 191.6256, Valid Loss: 63.9048
Epoch [29901/30000], Step [1/1], Training Loss: 184.4533, Valid Loss: 66.1333

 End Time: 2021/04/19, 04:33:02




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=11 	hidden_size=512 	layers=3

Start Time = 2021/04/19, 04:37:27
##########################################################


[Epoch 0] Rounded prediction: 
tensor([1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1.],
       device='cuda:0')
Target: 
tensor([12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,  3.,
         7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9., 12.,
         4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,  2.,
         3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,  6.,
         8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,  8.,
         7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14., 10.,
         5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23., 29.,
        42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([ 6.,  9., 13., 10.,  9.,  8.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2., 30., 15.,
         3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 85., 60., 42., 11., 24.,
        12.,  0.,  0.,  6.,  1.,  3.], device='cuda:0')
Target: 
tensor([12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,  3.,
         7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9., 12.,
         4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,  2.,
         3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,  6.,
         8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,  8.,
         7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14., 10.,
         5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23., 29.,
        42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([ 6.,  8., 14., 10.,  7.,  9.,  6.,  3.,  3.,  2.,  2.,  0.,  2.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 15.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  5.,  0.,  7., 18.,  0.,
         0.,  0.,  3.,  2.,  1.,  0.,  0., 13., 41., 64., 25.,  0.,  1., 15.,
        26., 20., 21., 11.,  8., 10.], device='cuda:0')
Target: 
tensor([12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,  3.,
         7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9., 12.,
         4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,  2.,
         3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,  6.,
         8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,  8.,
         7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14., 10.,
         5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23., 29.,
        42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 130242.9219, Valid Loss: 235.2885
Epoch [101/30000], Step [1/1], Training Loss: 122844.6094, Valid Loss: 109.4904
Epoch [201/30000], Step [1/1], Training Loss: 120430.2734, Valid Loss: 192.2212
Epoch [301/30000], Step [1/1], Training Loss: 118157.1172, Valid Loss: 316.1635
Epoch [401/30000], Step [1/1], Training Loss: 115970.5234, Valid Loss: 490.1058
Epoch [501/30000], Step [1/1], Training Loss: 113862.2422, Valid Loss: 714.0481
Epoch [601/30000], Step [1/1], Training Loss: 111822.0469, Valid Loss: 987.9904
Epoch [701/30000], Step [1/1], Training Loss: 109841.9609, Valid Loss: 1311.9327
Epoch [801/30000], Step [1/1], Training Loss: 107920.9297, Valid Loss: 1685.8751
Epoch [901/30000], Step [1/1], Training Loss: 106055.0234, Valid Loss: 2021.0289
Epoch [1001/30000], Step [1/1], Training Loss: 104240.7812, Valid Loss: 2484.9712
Epoch [1101/30000], Step [1/1], Training Loss: 102472.0312, Valid Loss: 2073.8655
Epoch [1201/30000], Step [1/1], Training Loss: 100749.7812, Valid Loss: 2217.0481
Epoch [1301/30000], Step [1/1], Training Loss: 99074.3438, Valid Loss: 2330.8174
Epoch [1401/30000], Step [1/1], Training Loss: 97442.7734, Valid Loss: 2838.5962
Epoch [1501/30000], Step [1/1], Training Loss: 95855.8047, Valid Loss: 3441.6636
Epoch [1601/30000], Step [1/1], Training Loss: 94309.8906, Valid Loss: 3828.6636
Epoch [1701/30000], Step [1/1], Training Loss: 92806.6094, Valid Loss: 4376.5771
Epoch [1801/30000], Step [1/1], Training Loss: 91344.7891, Valid Loss: 4797.1348
Epoch [1901/30000], Step [1/1], Training Loss: 89922.4062, Valid Loss: 5242.5962
Epoch [2001/30000], Step [1/1], Training Loss: 88539.6953, Valid Loss: 5721.7310
Epoch [2101/30000], Step [1/1], Training Loss: 87196.9062, Valid Loss: 6294.3848
Epoch [2201/30000], Step [1/1], Training Loss: 85891.2344, Valid Loss: 6634.8848
Epoch [2301/30000], Step [1/1], Training Loss: 84621.3203, Valid Loss: 6857.9233
Epoch [2401/30000], Step [1/1], Training Loss: 82927.4688, Valid Loss: 2613.6541
Epoch [2501/30000], Step [1/1], Training Loss: 80482.5625, Valid Loss: 152.6346
Epoch [2601/30000], Step [1/1], Training Loss: 79011.7344, Valid Loss: 157.6635
Epoch [2701/30000], Step [1/1], Training Loss: 77576.5156, Valid Loss: 153.8462
Epoch [2801/30000], Step [1/1], Training Loss: 76109.8828, Valid Loss: 192.2885
Epoch [2901/30000], Step [1/1], Training Loss: 74703.9141, Valid Loss: 201.6154
Epoch [3001/30000], Step [1/1], Training Loss: 73351.6641, Valid Loss: 172.2692
Epoch [3101/30000], Step [1/1], Training Loss: 72029.0625, Valid Loss: 209.0865
Epoch [3201/30000], Step [1/1], Training Loss: 70736.9375, Valid Loss: 180.6923
Epoch [3301/30000], Step [1/1], Training Loss: 69479.8984, Valid Loss: 178.9231
Epoch [3401/30000], Step [1/1], Training Loss: 68249.1641, Valid Loss: 196.6827
Epoch [3501/30000], Step [1/1], Training Loss: 67045.2969, Valid Loss: 204.6154
Epoch [3601/30000], Step [1/1], Training Loss: 65874.0625, Valid Loss: 183.2981
Epoch [3701/30000], Step [1/1], Training Loss: 64727.7148, Valid Loss: 183.1731
Epoch [3801/30000], Step [1/1], Training Loss: 63654.6719, Valid Loss: 305.4231
Epoch [3901/30000], Step [1/1], Training Loss: 62517.6836, Valid Loss: 198.3654
Epoch [4001/30000], Step [1/1], Training Loss: 61444.5586, Valid Loss: 230.4231
Epoch [4101/30000], Step [1/1], Training Loss: 60396.2773, Valid Loss: 265.8846
Epoch [4201/30000], Step [1/1], Training Loss: 59372.6289, Valid Loss: 206.4808
Epoch [4301/30000], Step [1/1], Training Loss: 58373.9414, Valid Loss: 225.5481
Epoch [4401/30000], Step [1/1], Training Loss: 57398.9453, Valid Loss: 228.6442
Epoch [4501/30000], Step [1/1], Training Loss: 56445.5977, Valid Loss: 217.3269
Epoch [4601/30000], Step [1/1], Training Loss: 55519.2070, Valid Loss: 202.4808
Epoch [4701/30000], Step [1/1], Training Loss: 54611.0078, Valid Loss: 209.3365
Epoch [4801/30000], Step [1/1], Training Loss: 53726.4727, Valid Loss: 206.3942
Epoch [4901/30000], Step [1/1], Training Loss: 52864.3711, Valid Loss: 231.1827
Epoch [5001/30000], Step [1/1], Training Loss: 52024.0391, Valid Loss: 220.8846
Epoch [5101/30000], Step [1/1], Training Loss: 51206.6055, Valid Loss: 192.9808
Epoch [5201/30000], Step [1/1], Training Loss: 50409.9375, Valid Loss: 242.1539
Epoch [5301/30000], Step [1/1], Training Loss: 49635.0898, Valid Loss: 196.8750
Epoch [5401/30000], Step [1/1], Training Loss: 48880.0547, Valid Loss: 229.8942
Epoch [5501/30000], Step [1/1], Training Loss: 48146.0195, Valid Loss: 237.4231
Epoch [5601/30000], Step [1/1], Training Loss: 47435.5039, Valid Loss: 247.3942
Epoch [5701/30000], Step [1/1], Training Loss: 46287.0625, Valid Loss: 214.3750
Epoch [5801/30000], Step [1/1], Training Loss: 45283.6914, Valid Loss: 185.1827
Epoch [5901/30000], Step [1/1], Training Loss: 44386.2930, Valid Loss: 196.9231
Epoch [6001/30000], Step [1/1], Training Loss: 43580.8711, Valid Loss: 199.6731
Epoch [6101/30000], Step [1/1], Training Loss: 42716.6211, Valid Loss: 208.9231
Epoch [6201/30000], Step [1/1], Training Loss: 41962.4609, Valid Loss: 172.0962
Epoch [6301/30000], Step [1/1], Training Loss: 41102.9375, Valid Loss: 184.6923
Epoch [6401/30000], Step [1/1], Training Loss: 40372.5547, Valid Loss: 168.7885
Epoch [6501/30000], Step [1/1], Training Loss: 39595.1094, Valid Loss: 178.2404
Epoch [6601/30000], Step [1/1], Training Loss: 38892.7031, Valid Loss: 179.0769
Epoch [6701/30000], Step [1/1], Training Loss: 38204.2891, Valid Loss: 194.9327
Epoch [6801/30000], Step [1/1], Training Loss: 37534.8203, Valid Loss: 183.5192
Epoch [6901/30000], Step [1/1], Training Loss: 36881.0664, Valid Loss: 186.9519
Epoch [7001/30000], Step [1/1], Training Loss: 36243.9297, Valid Loss: 207.3077
Epoch [7101/30000], Step [1/1], Training Loss: 35556.6016, Valid Loss: 180.1346
Epoch [7201/30000], Step [1/1], Training Loss: 35536.0938, Valid Loss: 215.0577
Epoch [7301/30000], Step [1/1], Training Loss: 35314.3750, Valid Loss: 181.2115
Epoch [7401/30000], Step [1/1], Training Loss: 33963.0859, Valid Loss: 187.6250
Epoch [7501/30000], Step [1/1], Training Loss: 33236.9297, Valid Loss: 204.5000
Epoch [7601/30000], Step [1/1], Training Loss: 32479.1934, Valid Loss: 182.5962
Epoch [7701/30000], Step [1/1], Training Loss: 31980.6816, Valid Loss: 195.9327
Epoch [7801/30000], Step [1/1], Training Loss: 31310.8379, Valid Loss: 187.1635
Epoch [7901/30000], Step [1/1], Training Loss: 30625.4102, Valid Loss: 168.0096
Epoch [8001/30000], Step [1/1], Training Loss: 30438.1250, Valid Loss: 185.1827
Epoch [8101/30000], Step [1/1], Training Loss: 29266.5059, Valid Loss: 161.7019
Epoch [8201/30000], Step [1/1], Training Loss: 28634.9102, Valid Loss: 168.6058
Epoch [8301/30000], Step [1/1], Training Loss: 28030.7051, Valid Loss: 164.9135
Epoch [8401/30000], Step [1/1], Training Loss: 27316.2051, Valid Loss: 157.0865
Epoch [8501/30000], Step [1/1], Training Loss: 26746.4727, Valid Loss: 187.4135
Epoch [8601/30000], Step [1/1], Training Loss: 26197.5742, Valid Loss: 158.7789
Epoch [8701/30000], Step [1/1], Training Loss: 25670.5352, Valid Loss: 162.3077
Epoch [8801/30000], Step [1/1], Training Loss: 25168.5859, Valid Loss: 182.2500
Epoch [8901/30000], Step [1/1], Training Loss: 24656.3066, Valid Loss: 164.2308
Epoch [9001/30000], Step [1/1], Training Loss: 24171.3867, Valid Loss: 157.8750
Epoch [9101/30000], Step [1/1], Training Loss: 23692.3066, Valid Loss: 158.9615
Epoch [9201/30000], Step [1/1], Training Loss: 23225.8223, Valid Loss: 166.1731
Epoch [9301/30000], Step [1/1], Training Loss: 22772.3828, Valid Loss: 172.7692
Epoch [9401/30000], Step [1/1], Training Loss: 22324.3496, Valid Loss: 165.8269
Epoch [9501/30000], Step [1/1], Training Loss: 21888.6133, Valid Loss: 174.0481
Epoch [9601/30000], Step [1/1], Training Loss: 21464.7031, Valid Loss: 168.3173
Epoch [9701/30000], Step [1/1], Training Loss: 21049.2715, Valid Loss: 159.3750
Epoch [9801/30000], Step [1/1], Training Loss: 20644.2812, Valid Loss: 161.1827
Epoch [9901/30000], Step [1/1], Training Loss: 20252.2344, Valid Loss: 165.3750
Epoch [10001/30000], Step [1/1], Training Loss: 19868.3359, Valid Loss: 164.2404

[Epoch 15000] Rounded prediction: 
tensor([ 7.,  9., 15., 12., 10., 10.,  8.,  5.,  3.,  1.,  2.,  3.,  5.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 13.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  4.,  0.,  9., 12.,  0.,
         0.,  4.,  7.,  7.,  0.,  0.,  0.,  2., 42., 27.,  2., 11., 17., 30.,
        29., 26., 16., 20., 19., 11.], device='cuda:0')
Target: 
tensor([12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,  3.,
         7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9., 12.,
         4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,  2.,
         3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,  6.,
         8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,  8.,
         7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14., 10.,
         5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23., 29.,
        42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([ 6.,  9., 14., 12., 10., 11.,  8.,  4.,  5.,  4.,  1.,  3.,  3.,  1.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 11.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  9.,
         6.,  0.,  1.,  2.,  0.,  0.,  0.,  0.,  0.,  2.,  0., 13., 16.,  0.,
        11., 11.,  3.,  0.,  0.,  0.,  0.,  7., 50., 43., 14., 26., 15., 28.,
        31., 22., 18., 21., 13., 11.], device='cuda:0')
Target: 
tensor([12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,  3.,
         7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9., 12.,
         4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,  2.,
         3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,  6.,
         8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,  8.,
         7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14., 10.,
         5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23., 29.,
        42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [10101/30000], Step [1/1], Training Loss: 19488.1523, Valid Loss: 155.0289
Epoch [10201/30000], Step [1/1], Training Loss: 19045.7520, Valid Loss: 158.1442
Epoch [10301/30000], Step [1/1], Training Loss: 18669.9531, Valid Loss: 152.6923
Epoch [10401/30000], Step [1/1], Training Loss: 18748.8945, Valid Loss: 164.1250
Epoch [10501/30000], Step [1/1], Training Loss: 17979.9648, Valid Loss: 137.0673
Epoch [10601/30000], Step [1/1], Training Loss: 17614.9102, Valid Loss: 135.3077
Epoch [10701/30000], Step [1/1], Training Loss: 17164.1406, Valid Loss: 133.8750
Epoch [10801/30000], Step [1/1], Training Loss: 16800.6367, Valid Loss: 146.0096
Epoch [10901/30000], Step [1/1], Training Loss: 16454.6660, Valid Loss: 132.7212
Epoch [11001/30000], Step [1/1], Training Loss: 16116.9580, Valid Loss: 139.8558
Epoch [11101/30000], Step [1/1], Training Loss: 15784.5059, Valid Loss: 134.6923
Epoch [11201/30000], Step [1/1], Training Loss: 15465.1006, Valid Loss: 138.8558
Epoch [11301/30000], Step [1/1], Training Loss: 15152.9502, Valid Loss: 136.3846
Epoch [11401/30000], Step [1/1], Training Loss: 14846.8643, Valid Loss: 133.4904
Epoch [11501/30000], Step [1/1], Training Loss: 14553.1855, Valid Loss: 139.5865
Epoch [11601/30000], Step [1/1], Training Loss: 14258.5264, Valid Loss: 134.2789
Epoch [11701/30000], Step [1/1], Training Loss: 14051.3555, Valid Loss: 136.9808
Epoch [11801/30000], Step [1/1], Training Loss: 13523.1816, Valid Loss: 125.4423
Epoch [11901/30000], Step [1/1], Training Loss: 13182.6377, Valid Loss: 135.1827
Epoch [12001/30000], Step [1/1], Training Loss: 12894.6416, Valid Loss: 126.0865
Epoch [12101/30000], Step [1/1], Training Loss: 12612.8320, Valid Loss: 132.0769
Epoch [12201/30000], Step [1/1], Training Loss: 12341.7031, Valid Loss: 133.3750
Epoch [12301/30000], Step [1/1], Training Loss: 12073.2451, Valid Loss: 131.0673
Epoch [12401/30000], Step [1/1], Training Loss: 11814.3682, Valid Loss: 136.3269
Epoch [12501/30000], Step [1/1], Training Loss: 11559.7168, Valid Loss: 132.1827
Epoch [12601/30000], Step [1/1], Training Loss: 11312.5098, Valid Loss: 127.5192
Epoch [12701/30000], Step [1/1], Training Loss: 11076.4561, Valid Loss: 132.3750
Epoch [12801/30000], Step [1/1], Training Loss: 10837.6768, Valid Loss: 133.7692
Epoch [12901/30000], Step [1/1], Training Loss: 10896.2373, Valid Loss: 135.2692
Epoch [13001/30000], Step [1/1], Training Loss: 10392.7900, Valid Loss: 135.1539
Epoch [13101/30000], Step [1/1], Training Loss: 10167.9707, Valid Loss: 132.0000
Epoch [13201/30000], Step [1/1], Training Loss: 9931.5527, Valid Loss: 129.6058
Epoch [13301/30000], Step [1/1], Training Loss: 9680.7510, Valid Loss: 131.1635
Epoch [13401/30000], Step [1/1], Training Loss: 9465.9365, Valid Loss: 127.7404
Epoch [13501/30000], Step [1/1], Training Loss: 9254.6611, Valid Loss: 132.6154
Epoch [13601/30000], Step [1/1], Training Loss: 9050.7393, Valid Loss: 125.0481
Epoch [13701/30000], Step [1/1], Training Loss: 8852.4229, Valid Loss: 134.9712
Epoch [13801/30000], Step [1/1], Training Loss: 8656.0654, Valid Loss: 136.0289
Epoch [13901/30000], Step [1/1], Training Loss: 8464.9717, Valid Loss: 136.8654
Epoch [14001/30000], Step [1/1], Training Loss: 8280.4043, Valid Loss: 136.8173
Epoch [14101/30000], Step [1/1], Training Loss: 8097.9946, Valid Loss: 138.6442
Epoch [14201/30000], Step [1/1], Training Loss: 7923.6104, Valid Loss: 140.2981
Epoch [14301/30000], Step [1/1], Training Loss: 7751.5000, Valid Loss: 130.0385
Epoch [14401/30000], Step [1/1], Training Loss: 7585.2793, Valid Loss: 133.6539
Epoch [14501/30000], Step [1/1], Training Loss: 7422.4854, Valid Loss: 131.6250
Epoch [14601/30000], Step [1/1], Training Loss: 7263.5640, Valid Loss: 140.3365
Epoch [14701/30000], Step [1/1], Training Loss: 7109.2446, Valid Loss: 142.4904
Epoch [14801/30000], Step [1/1], Training Loss: 6958.2910, Valid Loss: 134.8365
Epoch [14901/30000], Step [1/1], Training Loss: 6811.6025, Valid Loss: 139.4808
Epoch [15001/30000], Step [1/1], Training Loss: 6655.5459, Valid Loss: 138.9327
Epoch [15101/30000], Step [1/1], Training Loss: 6453.6538, Valid Loss: 138.0481
Epoch [15201/30000], Step [1/1], Training Loss: 6309.1621, Valid Loss: 130.3173
Epoch [15301/30000], Step [1/1], Training Loss: 6157.1084, Valid Loss: 132.4904
Epoch [15401/30000], Step [1/1], Training Loss: 6020.9165, Valid Loss: 126.0289
Epoch [15501/30000], Step [1/1], Training Loss: 5882.4722, Valid Loss: 129.8942
Epoch [15601/30000], Step [1/1], Training Loss: 5750.9692, Valid Loss: 134.2308
Epoch [15701/30000], Step [1/1], Training Loss: 5622.4028, Valid Loss: 130.8846
Epoch [15801/30000], Step [1/1], Training Loss: 5497.7427, Valid Loss: 129.9808
Epoch [15901/30000], Step [1/1], Training Loss: 5375.1978, Valid Loss: 129.1635
Epoch [16001/30000], Step [1/1], Training Loss: 5256.3892, Valid Loss: 132.6923
Epoch [16101/30000], Step [1/1], Training Loss: 5139.9780, Valid Loss: 131.4231
Epoch [16201/30000], Step [1/1], Training Loss: 5027.3516, Valid Loss: 125.7596
Epoch [16301/30000], Step [1/1], Training Loss: 4919.1611, Valid Loss: 129.9135
Epoch [16401/30000], Step [1/1], Training Loss: 4811.2842, Valid Loss: 125.5192
Epoch [16501/30000], Step [1/1], Training Loss: 4707.9307, Valid Loss: 131.9904
Epoch [16601/30000], Step [1/1], Training Loss: 5166.8804, Valid Loss: 140.9231
Epoch [16701/30000], Step [1/1], Training Loss: 4404.0723, Valid Loss: 139.2212
Epoch [16801/30000], Step [1/1], Training Loss: 4282.8633, Valid Loss: 130.2019
Epoch [16901/30000], Step [1/1], Training Loss: 4176.2935, Valid Loss: 125.9615
Epoch [17001/30000], Step [1/1], Training Loss: 4073.4373, Valid Loss: 141.4231
Epoch [17101/30000], Step [1/1], Training Loss: 3971.6184, Valid Loss: 131.3558
Epoch [17201/30000], Step [1/1], Training Loss: 3872.9663, Valid Loss: 137.3750
Epoch [17301/30000], Step [1/1], Training Loss: 3778.1841, Valid Loss: 142.7308
Epoch [17401/30000], Step [1/1], Training Loss: 3688.6919, Valid Loss: 135.7212
Epoch [17501/30000], Step [1/1], Training Loss: 3596.1028, Valid Loss: 128.0192
Epoch [17601/30000], Step [1/1], Training Loss: 3509.2180, Valid Loss: 134.6250
Epoch [17701/30000], Step [1/1], Training Loss: 3424.2188, Valid Loss: 137.8462
Epoch [17801/30000], Step [1/1], Training Loss: 3340.8899, Valid Loss: 134.9519
Epoch [17901/30000], Step [1/1], Training Loss: 3259.0764, Valid Loss: 135.0577
Epoch [18001/30000], Step [1/1], Training Loss: 3181.1758, Valid Loss: 136.3077
Epoch [18101/30000], Step [1/1], Training Loss: 3106.3250, Valid Loss: 133.1539
Epoch [18201/30000], Step [1/1], Training Loss: 3026.8579, Valid Loss: 139.3269
Epoch [18301/30000], Step [1/1], Training Loss: 2953.7993, Valid Loss: 135.2692
Epoch [18401/30000], Step [1/1], Training Loss: 2883.3965, Valid Loss: 131.3558
Epoch [18501/30000], Step [1/1], Training Loss: 2813.3696, Valid Loss: 137.0000
Epoch [18601/30000], Step [1/1], Training Loss: 2745.7886, Valid Loss: 136.5385
Epoch [18701/30000], Step [1/1], Training Loss: 2676.5330, Valid Loss: 141.8750
Epoch [18801/30000], Step [1/1], Training Loss: 2606.3462, Valid Loss: 139.3558
Epoch [18901/30000], Step [1/1], Training Loss: 2541.0657, Valid Loss: 139.5577
Epoch [19001/30000], Step [1/1], Training Loss: 2476.4500, Valid Loss: 135.9231
Epoch [19101/30000], Step [1/1], Training Loss: 2413.4399, Valid Loss: 139.2308
Epoch [19201/30000], Step [1/1], Training Loss: 2352.3623, Valid Loss: 134.3269
Epoch [19301/30000], Step [1/1], Training Loss: 2292.6882, Valid Loss: 137.3269
Epoch [19401/30000], Step [1/1], Training Loss: 2234.5811, Valid Loss: 136.6346
Epoch [19501/30000], Step [1/1], Training Loss: 2178.5205, Valid Loss: 140.2019
Epoch [19601/30000], Step [1/1], Training Loss: 2124.0413, Valid Loss: 135.1827
Epoch [19701/30000], Step [1/1], Training Loss: 2070.0813, Valid Loss: 136.0096
Epoch [19801/30000], Step [1/1], Training Loss: 2018.5885, Valid Loss: 133.8173
Epoch [19901/30000], Step [1/1], Training Loss: 1968.1953, Valid Loss: 134.7212
Epoch [20001/30000], Step [1/1], Training Loss: 1919.8176, Valid Loss: 137.9135
Epoch [20101/30000], Step [1/1], Training Loss: 1872.4069, Valid Loss: 136.7404

[Epoch 25000] Rounded prediction: 
tensor([ 8., 11., 15., 12., 11., 10.,  9.,  4.,  1.,  0.,  0.,  0.,  1.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  5.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 11.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         1.,  0.,  0.,  0.,  0.,  0.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1., 14.,  0., 18., 15.,  0.,
         6.,  5.,  6.,  0.,  0.,  0.,  0., 15., 49., 36., 20., 34., 26., 41.,
        26., 19., 28., 16., 16., 11.], device='cuda:0')
Target: 
tensor([12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,  3.,
         7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9., 12.,
         4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,  2.,
         3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,  6.,
         8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,  8.,
         7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14., 10.,
         5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23., 29.,
        42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [20201/30000], Step [1/1], Training Loss: 1827.0853, Valid Loss: 132.0289
Epoch [20301/30000], Step [1/1], Training Loss: 1783.1838, Valid Loss: 134.9615
Epoch [20401/30000], Step [1/1], Training Loss: 1741.1536, Valid Loss: 131.5769
Epoch [20501/30000], Step [1/1], Training Loss: 1699.9290, Valid Loss: 137.3750
Epoch [20601/30000], Step [1/1], Training Loss: 1660.4092, Valid Loss: 129.6923
Epoch [20701/30000], Step [1/1], Training Loss: 1622.5332, Valid Loss: 133.3846
Epoch [20801/30000], Step [1/1], Training Loss: 1585.1165, Valid Loss: 133.4423
Epoch [20901/30000], Step [1/1], Training Loss: 1549.4487, Valid Loss: 132.0769
Epoch [21001/30000], Step [1/1], Training Loss: 1617.8363, Valid Loss: 129.0577
Epoch [21101/30000], Step [1/1], Training Loss: 1491.5562, Valid Loss: 137.3654
Epoch [21201/30000], Step [1/1], Training Loss: 1454.5951, Valid Loss: 132.9615
Epoch [21301/30000], Step [1/1], Training Loss: 1422.4062, Valid Loss: 140.7885
Epoch [21401/30000], Step [1/1], Training Loss: 1390.7800, Valid Loss: 137.6058
Epoch [21501/30000], Step [1/1], Training Loss: 1371.9464, Valid Loss: 134.2308
Epoch [21601/30000], Step [1/1], Training Loss: 1330.9985, Valid Loss: 140.2308
Epoch [21701/30000], Step [1/1], Training Loss: 1302.0886, Valid Loss: 143.2981
Epoch [21801/30000], Step [1/1], Training Loss: 1274.5768, Valid Loss: 134.5096
Epoch [21901/30000], Step [1/1], Training Loss: 1247.8870, Valid Loss: 139.1442
Epoch [22001/30000], Step [1/1], Training Loss: 1220.8783, Valid Loss: 136.1058
Epoch [22101/30000], Step [1/1], Training Loss: 1196.1266, Valid Loss: 143.2981
Epoch [22201/30000], Step [1/1], Training Loss: 1170.2623, Valid Loss: 136.1346
Epoch [22301/30000], Step [1/1], Training Loss: 1145.5420, Valid Loss: 137.1539
Epoch [22401/30000], Step [1/1], Training Loss: 1121.0764, Valid Loss: 142.5192
Epoch [22501/30000], Step [1/1], Training Loss: 1097.1538, Valid Loss: 145.0000
Epoch [22601/30000], Step [1/1], Training Loss: 1073.7423, Valid Loss: 139.3558
Epoch [22701/30000], Step [1/1], Training Loss: 1050.0392, Valid Loss: 135.2596
Epoch [22801/30000], Step [1/1], Training Loss: 1026.7030, Valid Loss: 142.4423
Epoch [22901/30000], Step [1/1], Training Loss: 1004.0167, Valid Loss: 142.0673
Epoch [23001/30000], Step [1/1], Training Loss: 981.3230, Valid Loss: 138.5962
Epoch [23101/30000], Step [1/1], Training Loss: 959.3165, Valid Loss: 138.5673
Epoch [23201/30000], Step [1/1], Training Loss: 937.4540, Valid Loss: 136.0192
Epoch [23301/30000], Step [1/1], Training Loss: 916.4292, Valid Loss: 138.1635
Epoch [23401/30000], Step [1/1], Training Loss: 895.4866, Valid Loss: 134.8365
Epoch [23501/30000], Step [1/1], Training Loss: 875.5314, Valid Loss: 142.7692
Epoch [23601/30000], Step [1/1], Training Loss: 855.5661, Valid Loss: 141.8173
Epoch [23701/30000], Step [1/1], Training Loss: 836.4765, Valid Loss: 139.5385
Epoch [23801/30000], Step [1/1], Training Loss: 817.9990, Valid Loss: 138.4423
Epoch [23901/30000], Step [1/1], Training Loss: 799.2042, Valid Loss: 143.9519
Epoch [24001/30000], Step [1/1], Training Loss: 781.4896, Valid Loss: 134.1346
Epoch [24101/30000], Step [1/1], Training Loss: 764.0581, Valid Loss: 135.9808
Epoch [24201/30000], Step [1/1], Training Loss: 747.5254, Valid Loss: 139.5769
Epoch [24301/30000], Step [1/1], Training Loss: 731.1824, Valid Loss: 133.0962
Epoch [24401/30000], Step [1/1], Training Loss: 715.2452, Valid Loss: 134.7885
Epoch [24501/30000], Step [1/1], Training Loss: 699.8307, Valid Loss: 137.8269
Epoch [24601/30000], Step [1/1], Training Loss: 685.4423, Valid Loss: 135.4519
Epoch [24701/30000], Step [1/1], Training Loss: 669.9991, Valid Loss: 133.7212
Epoch [24801/30000], Step [1/1], Training Loss: 655.3297, Valid Loss: 134.0000
Epoch [24901/30000], Step [1/1], Training Loss: 641.1008, Valid Loss: 135.3558
Epoch [25001/30000], Step [1/1], Training Loss: 626.8060, Valid Loss: 129.0577
Epoch [25101/30000], Step [1/1], Training Loss: 612.7238, Valid Loss: 139.2692
Epoch [25201/30000], Step [1/1], Training Loss: 598.9065, Valid Loss: 139.5096
Epoch [25301/30000], Step [1/1], Training Loss: 585.2980, Valid Loss: 133.2885
Epoch [25401/30000], Step [1/1], Training Loss: 571.6368, Valid Loss: 135.2019
Epoch [25501/30000], Step [1/1], Training Loss: 558.4291, Valid Loss: 132.7500
Epoch [25601/30000], Step [1/1], Training Loss: 545.4135, Valid Loss: 134.0577
Epoch [25701/30000], Step [1/1], Training Loss: 532.4616, Valid Loss: 133.6731
Epoch [25801/30000], Step [1/1], Training Loss: 519.6916, Valid Loss: 138.8654
Epoch [25901/30000], Step [1/1], Training Loss: 507.3076, Valid Loss: 130.2500
Epoch [26001/30000], Step [1/1], Training Loss: 495.0510, Valid Loss: 141.8077
Epoch [26101/30000], Step [1/1], Training Loss: 483.1186, Valid Loss: 135.6731
Epoch [26201/30000], Step [1/1], Training Loss: 471.5689, Valid Loss: 140.5769
Epoch [26301/30000], Step [1/1], Training Loss: 460.0396, Valid Loss: 138.8462
Epoch [26401/30000], Step [1/1], Training Loss: 448.9196, Valid Loss: 134.6058
Epoch [26501/30000], Step [1/1], Training Loss: 437.9819, Valid Loss: 141.1442
Epoch [26601/30000], Step [1/1], Training Loss: 427.3676, Valid Loss: 135.8750
Epoch [26701/30000], Step [1/1], Training Loss: 416.9035, Valid Loss: 143.4519
Epoch [26801/30000], Step [1/1], Training Loss: 406.9755, Valid Loss: 137.8077
Epoch [26901/30000], Step [1/1], Training Loss: 396.9754, Valid Loss: 139.2115
Epoch [27001/30000], Step [1/1], Training Loss: 387.1371, Valid Loss: 141.9808
Epoch [27101/30000], Step [1/1], Training Loss: 377.2979, Valid Loss: 137.0192
Epoch [27201/30000], Step [1/1], Training Loss: 367.3519, Valid Loss: 137.8654
Epoch [27301/30000], Step [1/1], Training Loss: 357.4357, Valid Loss: 141.4519
Epoch [27401/30000], Step [1/1], Training Loss: 347.7206, Valid Loss: 144.2692
Epoch [27501/30000], Step [1/1], Training Loss: 338.2267, Valid Loss: 139.6635
Epoch [27601/30000], Step [1/1], Training Loss: 328.5890, Valid Loss: 139.1250
Epoch [27701/30000], Step [1/1], Training Loss: 319.1296, Valid Loss: 142.6923
Epoch [27801/30000], Step [1/1], Training Loss: 309.8413, Valid Loss: 142.0096
Epoch [27901/30000], Step [1/1], Training Loss: 300.5253, Valid Loss: 137.7885
Epoch [28001/30000], Step [1/1], Training Loss: 291.4204, Valid Loss: 134.5289
Epoch [28101/30000], Step [1/1], Training Loss: 282.5735, Valid Loss: 131.9327
Epoch [28201/30000], Step [1/1], Training Loss: 273.6365, Valid Loss: 138.3750
Epoch [28301/30000], Step [1/1], Training Loss: 264.9641, Valid Loss: 136.7212
Epoch [28401/30000], Step [1/1], Training Loss: 256.2998, Valid Loss: 134.5096
Epoch [28501/30000], Step [1/1], Training Loss: 247.8744, Valid Loss: 135.3654
Epoch [28601/30000], Step [1/1], Training Loss: 239.5332, Valid Loss: 136.1250
Epoch [28701/30000], Step [1/1], Training Loss: 231.2697, Valid Loss: 137.7404
Epoch [28801/30000], Step [1/1], Training Loss: 223.3373, Valid Loss: 131.0096
Epoch [28901/30000], Step [1/1], Training Loss: 215.4421, Valid Loss: 139.8654
Epoch [29001/30000], Step [1/1], Training Loss: 207.7820, Valid Loss: 132.1346
Epoch [29101/30000], Step [1/1], Training Loss: 200.5384, Valid Loss: 137.7885
Epoch [29201/30000], Step [1/1], Training Loss: 192.7348, Valid Loss: 132.4327
Epoch [29301/30000], Step [1/1], Training Loss: 185.4914, Valid Loss: 137.3173
Epoch [29401/30000], Step [1/1], Training Loss: 178.4282, Valid Loss: 133.7596
Epoch [29501/30000], Step [1/1], Training Loss: 171.3667, Valid Loss: 137.1827
Epoch [29601/30000], Step [1/1], Training Loss: 164.5401, Valid Loss: 133.9519
Epoch [29701/30000], Step [1/1], Training Loss: 157.9546, Valid Loss: 139.9423
Epoch [29801/30000], Step [1/1], Training Loss: 151.4816, Valid Loss: 133.1346
Epoch [29901/30000], Step [1/1], Training Loss: 145.1565, Valid Loss: 133.8558

 End Time: 2021/04/19, 04:47:33




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=11 	hidden_size=512 	layers=3

Start Time = 2021/04/19, 04:47:33
##########################################################


[Epoch 0] Rounded prediction: 
tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],
       device='cuda:0')
Target: 
tensor([12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,  3.,
         7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9., 12.,
         4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,  2.,
         3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,  6.,
         8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,  8.,
         7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14., 10.,
         5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23., 29.,
        42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([ 8., 14., 15., 10.,  9., 12.,  7.,  2.,  4.,  5.,  6.,  0.,  7.,  7.,
         2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         1.,  0.,  0.,  0.,  3.,  0.,  0.,  0., 30., 51., 29., 33., 31., 23.,
        22., 18., 24., 18.,  7., 15.], device='cuda:0')
Target: 
tensor([12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,  3.,
         7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9., 12.,
         4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,  2.,
         3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,  6.,
         8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,  8.,
         7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14., 10.,
         5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23., 29.,
        42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([11., 18., 16.,  9.,  9., 13.,  9.,  7.,  6., 10.,  8., 10.,  9.,  8.,
         2.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  8.,
        10.,  2.,  2.,  5.,  5.,  0.,  0.,  0.,  5., 12., 25., 34., 25., 20.,
        23., 22., 27., 18., 14., 19.], device='cuda:0')
Target: 
tensor([12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,  3.,
         7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9., 12.,
         4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,  2.,
         3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,  6.,
         8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,  8.,
         7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14., 10.,
         5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23., 29.,
        42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 130246.9375, Valid Loss: 240.1154
Epoch [101/30000], Step [1/1], Training Loss: 122555.4844, Valid Loss: 118.2789
Epoch [201/30000], Step [1/1], Training Loss: 120141.9375, Valid Loss: 192.2212
Epoch [301/30000], Step [1/1], Training Loss: 117871.1328, Valid Loss: 316.1635
Epoch [401/30000], Step [1/1], Training Loss: 115692.7734, Valid Loss: 530.8942
Epoch [501/30000], Step [1/1], Training Loss: 113588.6250, Valid Loss: 764.8365
Epoch [601/30000], Step [1/1], Training Loss: 111552.7031, Valid Loss: 1030.3077
Epoch [701/30000], Step [1/1], Training Loss: 109578.3281, Valid Loss: 1311.9327
Epoch [801/30000], Step [1/1], Training Loss: 107661.9297, Valid Loss: 1685.8751
Epoch [901/30000], Step [1/1], Training Loss: 105801.5000, Valid Loss: 2109.8174
Epoch [1001/30000], Step [1/1], Training Loss: 103990.8906, Valid Loss: 2575.4136
Epoch [1101/30000], Step [1/1], Training Loss: 102226.3438, Valid Loss: 1802.0865
Epoch [1201/30000], Step [1/1], Training Loss: 100508.9609, Valid Loss: 1797.1731
Epoch [1301/30000], Step [1/1], Training Loss: 98838.6172, Valid Loss: 2168.2019
Epoch [1401/30000], Step [1/1], Training Loss: 97211.2891, Valid Loss: 2546.0579
Epoch [1501/30000], Step [1/1], Training Loss: 95629.8672, Valid Loss: 2823.9424
Epoch [1601/30000], Step [1/1], Training Loss: 94089.1172, Valid Loss: 3373.5771
Epoch [1701/30000], Step [1/1], Training Loss: 92591.4531, Valid Loss: 3892.4905
Epoch [1801/30000], Step [1/1], Training Loss: 90449.9688, Valid Loss: 440.8269
Epoch [1901/30000], Step [1/1], Training Loss: 88784.5078, Valid Loss: 218.3462
Epoch [2001/30000], Step [1/1], Training Loss: 87173.9609, Valid Loss: 213.4327
Epoch [2101/30000], Step [1/1], Training Loss: 85606.5391, Valid Loss: 212.9808
Epoch [2201/30000], Step [1/1], Training Loss: 84075.3438, Valid Loss: 252.5289
Epoch [2301/30000], Step [1/1], Training Loss: 82581.7656, Valid Loss: 186.6923
Epoch [2401/30000], Step [1/1], Training Loss: 81116.5391, Valid Loss: 269.4904
Epoch [2501/30000], Step [1/1], Training Loss: 79639.9375, Valid Loss: 249.0385
Epoch [2601/30000], Step [1/1], Training Loss: 78218.3672, Valid Loss: 231.7019
Epoch [2701/30000], Step [1/1], Training Loss: 76825.7969, Valid Loss: 162.1154
Epoch [2801/30000], Step [1/1], Training Loss: 75468.7734, Valid Loss: 212.0769
Epoch [2901/30000], Step [1/1], Training Loss: 74138.1719, Valid Loss: 177.9808
Epoch [3001/30000], Step [1/1], Training Loss: 72834.0625, Valid Loss: 189.3462
Epoch [3101/30000], Step [1/1], Training Loss: 71557.4453, Valid Loss: 201.9712
Epoch [3201/30000], Step [1/1], Training Loss: 70306.3828, Valid Loss: 207.4808
Epoch [3301/30000], Step [1/1], Training Loss: 69081.6719, Valid Loss: 190.7789
Epoch [3401/30000], Step [1/1], Training Loss: 67896.0312, Valid Loss: 198.0769
Epoch [3501/30000], Step [1/1], Training Loss: 66714.3828, Valid Loss: 157.0577
Epoch [3601/30000], Step [1/1], Training Loss: 65560.8047, Valid Loss: 187.4327
Epoch [3701/30000], Step [1/1], Training Loss: 64434.1055, Valid Loss: 175.9808
Epoch [3801/30000], Step [1/1], Training Loss: 63330.9414, Valid Loss: 191.3173
Epoch [3901/30000], Step [1/1], Training Loss: 62253.6875, Valid Loss: 174.8173
Epoch [4001/30000], Step [1/1], Training Loss: 61197.8750, Valid Loss: 188.4231
Epoch [4101/30000], Step [1/1], Training Loss: 60167.8516, Valid Loss: 173.7981
Epoch [4201/30000], Step [1/1], Training Loss: 59141.2773, Valid Loss: 159.3173
Epoch [4301/30000], Step [1/1], Training Loss: 58149.4805, Valid Loss: 169.3462
Epoch [4401/30000], Step [1/1], Training Loss: 57243.7969, Valid Loss: 170.3750
Epoch [4501/30000], Step [1/1], Training Loss: 56194.2852, Valid Loss: 168.0769
Epoch [4601/30000], Step [1/1], Training Loss: 55222.0000, Valid Loss: 151.9327
Epoch [4701/30000], Step [1/1], Training Loss: 54221.2773, Valid Loss: 151.8846
Epoch [4801/30000], Step [1/1], Training Loss: 53203.9531, Valid Loss: 148.7404
Epoch [4901/30000], Step [1/1], Training Loss: 52255.9766, Valid Loss: 154.8846
Epoch [5001/30000], Step [1/1], Training Loss: 51341.3203, Valid Loss: 150.4231
Epoch [5101/30000], Step [1/1], Training Loss: 50455.3047, Valid Loss: 150.6346
Epoch [5201/30000], Step [1/1], Training Loss: 49583.5586, Valid Loss: 156.1058
Epoch [5301/30000], Step [1/1], Training Loss: 48725.8086, Valid Loss: 155.5096
Epoch [5401/30000], Step [1/1], Training Loss: 47869.4531, Valid Loss: 155.2981
Epoch [5501/30000], Step [1/1], Training Loss: 47051.6836, Valid Loss: 150.5673
Epoch [5601/30000], Step [1/1], Training Loss: 46250.0078, Valid Loss: 160.0673
Epoch [5701/30000], Step [1/1], Training Loss: 45463.9023, Valid Loss: 148.7212
Epoch [5801/30000], Step [1/1], Training Loss: 44704.3828, Valid Loss: 148.7885
Epoch [5901/30000], Step [1/1], Training Loss: 45105.2461, Valid Loss: 167.7115
Epoch [6001/30000], Step [1/1], Training Loss: 43162.9141, Valid Loss: 176.8558
Epoch [6101/30000], Step [1/1], Training Loss: 42363.2188, Valid Loss: 145.9519
Epoch [6201/30000], Step [1/1], Training Loss: 41634.2617, Valid Loss: 151.8846
Epoch [6301/30000], Step [1/1], Training Loss: 40805.5938, Valid Loss: 158.3750
Epoch [6401/30000], Step [1/1], Training Loss: 40071.3984, Valid Loss: 149.4231
Epoch [6501/30000], Step [1/1], Training Loss: 39357.8867, Valid Loss: 147.4423
Epoch [6601/30000], Step [1/1], Training Loss: 38648.2812, Valid Loss: 146.9135
Epoch [6701/30000], Step [1/1], Training Loss: 37941.0352, Valid Loss: 143.4712
Epoch [6801/30000], Step [1/1], Training Loss: 37269.7422, Valid Loss: 151.3558
Epoch [6901/30000], Step [1/1], Training Loss: 36583.6836, Valid Loss: 150.3942
Epoch [7001/30000], Step [1/1], Training Loss: 35835.1758, Valid Loss: 161.2404
Epoch [7101/30000], Step [1/1], Training Loss: 35048.1914, Valid Loss: 151.7789
Epoch [7201/30000], Step [1/1], Training Loss: 34365.1758, Valid Loss: 154.2692
Epoch [7301/30000], Step [1/1], Training Loss: 33712.3359, Valid Loss: 149.0673
Epoch [7401/30000], Step [1/1], Training Loss: 33118.3633, Valid Loss: 142.5000
Epoch [7501/30000], Step [1/1], Training Loss: 32476.1582, Valid Loss: 146.5769
Epoch [7601/30000], Step [1/1], Training Loss: 31878.4668, Valid Loss: 152.0192
Epoch [7701/30000], Step [1/1], Training Loss: 31343.8223, Valid Loss: 154.4615
Epoch [7801/30000], Step [1/1], Training Loss: 30801.7754, Valid Loss: 150.3462
Epoch [7901/30000], Step [1/1], Training Loss: 30229.4727, Valid Loss: 149.2212
Epoch [8001/30000], Step [1/1], Training Loss: 29682.6172, Valid Loss: 152.2692
Epoch [8101/30000], Step [1/1], Training Loss: 29149.7500, Valid Loss: 152.8750
Epoch [8201/30000], Step [1/1], Training Loss: 28627.9082, Valid Loss: 148.3942
Epoch [8301/30000], Step [1/1], Training Loss: 28118.1602, Valid Loss: 148.2212
Epoch [8401/30000], Step [1/1], Training Loss: 27622.0586, Valid Loss: 155.0096
Epoch [8501/30000], Step [1/1], Training Loss: 27136.2676, Valid Loss: 147.9135
Epoch [8601/30000], Step [1/1], Training Loss: 26662.6055, Valid Loss: 150.4519
Epoch [8701/30000], Step [1/1], Training Loss: 26201.5156, Valid Loss: 151.0000
Epoch [8801/30000], Step [1/1], Training Loss: 25751.1641, Valid Loss: 151.7596
Epoch [8901/30000], Step [1/1], Training Loss: 25310.2754, Valid Loss: 151.8173
Epoch [9001/30000], Step [1/1], Training Loss: 24881.7246, Valid Loss: 154.3558
Epoch [9101/30000], Step [1/1], Training Loss: 24462.6895, Valid Loss: 146.5096
Epoch [9201/30000], Step [1/1], Training Loss: 23967.2773, Valid Loss: 147.9712
Epoch [9301/30000], Step [1/1], Training Loss: 23452.1348, Valid Loss: 138.9423
Epoch [9401/30000], Step [1/1], Training Loss: 23030.9316, Valid Loss: 134.5385
Epoch [9501/30000], Step [1/1], Training Loss: 22629.8594, Valid Loss: 146.3942
Epoch [9601/30000], Step [1/1], Training Loss: 22240.0664, Valid Loss: 143.5096
Epoch [9701/30000], Step [1/1], Training Loss: 21869.7539, Valid Loss: 139.6058
Epoch [9801/30000], Step [1/1], Training Loss: 21473.2363, Valid Loss: 140.6058
Epoch [9901/30000], Step [1/1], Training Loss: 21110.8848, Valid Loss: 143.2981
Epoch [10001/30000], Step [1/1], Training Loss: 20759.0352, Valid Loss: 141.0096

[Epoch 15000] Rounded prediction: 
tensor([12., 19., 17., 13., 14., 17., 14., 12., 12., 14., 13., 17., 15., 14.,
        12., 10.,  4.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         4.,  0.,  2.,  2.,  5.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  5.,  9.,
         9., 10.,  8., 13., 12.,  8.,  0.,  5.,  6.,  8.,  8., 20., 18., 19.,
        18., 20., 37., 15.,  7., 21.], device='cuda:0')
Target: 
tensor([12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,  3.,
         7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9., 12.,
         4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,  2.,
         3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,  6.,
         8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,  8.,
         7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14., 10.,
         5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23., 29.,
        42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([12., 20., 20., 20., 18., 21., 18., 15., 17., 17., 18., 23., 22., 19.,
        18., 17., 16., 10.,  6.,  5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  5.,
        14., 11., 12., 18., 15.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 10.,
        11.,  8., 10., 16., 18.,  6.,  0., 12., 10.,  2., 13., 25., 20., 21.,
        18., 24., 33., 26., 14., 23.], device='cuda:0')
Target: 
tensor([12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,  3.,
         7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9., 12.,
         4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,  2.,
         3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,  6.,
         8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,  8.,
         7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14., 10.,
         5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23., 29.,
        42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [10101/30000], Step [1/1], Training Loss: 20770.0996, Valid Loss: 139.3077
Epoch [10201/30000], Step [1/1], Training Loss: 19909.0352, Valid Loss: 143.8269
Epoch [10301/30000], Step [1/1], Training Loss: 18925.7559, Valid Loss: 129.4039
Epoch [10401/30000], Step [1/1], Training Loss: 18459.8750, Valid Loss: 127.9327
Epoch [10501/30000], Step [1/1], Training Loss: 18043.5898, Valid Loss: 128.1635
Epoch [10601/30000], Step [1/1], Training Loss: 17665.9883, Valid Loss: 135.3654
Epoch [10701/30000], Step [1/1], Training Loss: 17273.8828, Valid Loss: 125.4808
Epoch [10801/30000], Step [1/1], Training Loss: 16920.3867, Valid Loss: 130.2404
Epoch [10901/30000], Step [1/1], Training Loss: 16564.7578, Valid Loss: 135.5096
Epoch [11001/30000], Step [1/1], Training Loss: 16214.3096, Valid Loss: 135.4615
Epoch [11101/30000], Step [1/1], Training Loss: 15878.8408, Valid Loss: 140.5962
Epoch [11201/30000], Step [1/1], Training Loss: 15551.5176, Valid Loss: 141.2212
Epoch [11301/30000], Step [1/1], Training Loss: 15231.9980, Valid Loss: 141.3558
Epoch [11401/30000], Step [1/1], Training Loss: 14912.2393, Valid Loss: 135.6923
Epoch [11501/30000], Step [1/1], Training Loss: 14599.9707, Valid Loss: 142.1539
Epoch [11601/30000], Step [1/1], Training Loss: 14168.2598, Valid Loss: 124.9135
Epoch [11701/30000], Step [1/1], Training Loss: 13787.0410, Valid Loss: 125.8077
Epoch [11801/30000], Step [1/1], Training Loss: 13483.2959, Valid Loss: 140.7019
Epoch [11901/30000], Step [1/1], Training Loss: 13178.9023, Valid Loss: 133.2692
Epoch [12001/30000], Step [1/1], Training Loss: 12890.0439, Valid Loss: 133.8462
Epoch [12101/30000], Step [1/1], Training Loss: 12608.3652, Valid Loss: 136.0385
Epoch [12201/30000], Step [1/1], Training Loss: 12331.3203, Valid Loss: 137.2981
Epoch [12301/30000], Step [1/1], Training Loss: 12061.0977, Valid Loss: 139.7789
Epoch [12401/30000], Step [1/1], Training Loss: 11802.6230, Valid Loss: 135.1346
Epoch [12501/30000], Step [1/1], Training Loss: 11543.4609, Valid Loss: 144.2308
Epoch [12601/30000], Step [1/1], Training Loss: 11292.1309, Valid Loss: 135.0769
Epoch [12701/30000], Step [1/1], Training Loss: 11030.2012, Valid Loss: 137.9039
Epoch [12801/30000], Step [1/1], Training Loss: 10787.5078, Valid Loss: 133.6539
Epoch [12901/30000], Step [1/1], Training Loss: 10549.1094, Valid Loss: 138.2500
Epoch [13001/30000], Step [1/1], Training Loss: 10326.2715, Valid Loss: 136.3462
Epoch [13101/30000], Step [1/1], Training Loss: 10252.8652, Valid Loss: 137.6058
Epoch [13201/30000], Step [1/1], Training Loss: 9943.9639, Valid Loss: 137.6827
Epoch [13301/30000], Step [1/1], Training Loss: 9681.7363, Valid Loss: 153.7404
Epoch [13401/30000], Step [1/1], Training Loss: 9434.1973, Valid Loss: 148.8365
Epoch [13501/30000], Step [1/1], Training Loss: 9217.9404, Valid Loss: 144.7019
Epoch [13601/30000], Step [1/1], Training Loss: 9038.4707, Valid Loss: 140.1250
Epoch [13701/30000], Step [1/1], Training Loss: 8806.7373, Valid Loss: 143.7789
Epoch [13801/30000], Step [1/1], Training Loss: 8607.9678, Valid Loss: 153.7019
Epoch [13901/30000], Step [1/1], Training Loss: 8412.2783, Valid Loss: 157.9808
Epoch [14001/30000], Step [1/1], Training Loss: 8222.8262, Valid Loss: 151.2981
Epoch [14101/30000], Step [1/1], Training Loss: 8038.5068, Valid Loss: 139.2789
Epoch [14201/30000], Step [1/1], Training Loss: 7858.9116, Valid Loss: 140.2308
Epoch [14301/30000], Step [1/1], Training Loss: 7683.2534, Valid Loss: 143.7885
Epoch [14401/30000], Step [1/1], Training Loss: 7511.4053, Valid Loss: 151.2789
Epoch [14501/30000], Step [1/1], Training Loss: 7344.8071, Valid Loss: 156.0865
Epoch [14601/30000], Step [1/1], Training Loss: 7179.0166, Valid Loss: 135.2692
Epoch [14701/30000], Step [1/1], Training Loss: 7019.4146, Valid Loss: 143.4135
Epoch [14801/30000], Step [1/1], Training Loss: 6862.9497, Valid Loss: 142.8173
Epoch [14901/30000], Step [1/1], Training Loss: 6710.5249, Valid Loss: 138.6154
Epoch [15001/30000], Step [1/1], Training Loss: 6558.9272, Valid Loss: 146.0577
Epoch [15101/30000], Step [1/1], Training Loss: 6414.8296, Valid Loss: 146.6442
Epoch [15201/30000], Step [1/1], Training Loss: 6273.6055, Valid Loss: 146.3750
Epoch [15301/30000], Step [1/1], Training Loss: 6134.7881, Valid Loss: 147.4712
Epoch [15401/30000], Step [1/1], Training Loss: 5999.2490, Valid Loss: 133.1731
Epoch [15501/30000], Step [1/1], Training Loss: 5872.8706, Valid Loss: 137.2692
Epoch [15601/30000], Step [1/1], Training Loss: 5740.2095, Valid Loss: 143.9231
Epoch [15701/30000], Step [1/1], Training Loss: 5615.1079, Valid Loss: 135.0192
Epoch [15801/30000], Step [1/1], Training Loss: 5454.3545, Valid Loss: 144.6827
Epoch [15901/30000], Step [1/1], Training Loss: 5326.4150, Valid Loss: 128.7308
Epoch [16001/30000], Step [1/1], Training Loss: 5204.1401, Valid Loss: 136.2500
Epoch [16101/30000], Step [1/1], Training Loss: 5083.4658, Valid Loss: 131.3750
Epoch [16201/30000], Step [1/1], Training Loss: 4967.7686, Valid Loss: 135.2500
Epoch [16301/30000], Step [1/1], Training Loss: 4851.1797, Valid Loss: 136.5577
Epoch [16401/30000], Step [1/1], Training Loss: 4727.1665, Valid Loss: 131.4231
Epoch [16501/30000], Step [1/1], Training Loss: 7755.9966, Valid Loss: 139.6250
Epoch [16601/30000], Step [1/1], Training Loss: 4536.4883, Valid Loss: 156.3942
Epoch [16701/30000], Step [1/1], Training Loss: 4370.5776, Valid Loss: 146.9904
Epoch [16801/30000], Step [1/1], Training Loss: 4257.5464, Valid Loss: 155.3846
Epoch [16901/30000], Step [1/1], Training Loss: 4151.6582, Valid Loss: 146.7404
Epoch [17001/30000], Step [1/1], Training Loss: 4048.9490, Valid Loss: 154.6923
Epoch [17101/30000], Step [1/1], Training Loss: 3948.8694, Valid Loss: 152.2885
Epoch [17201/30000], Step [1/1], Training Loss: 3852.5928, Valid Loss: 143.2019
Epoch [17301/30000], Step [1/1], Training Loss: 3758.5044, Valid Loss: 142.4615
Epoch [17401/30000], Step [1/1], Training Loss: 3666.6582, Valid Loss: 141.3173
Epoch [17501/30000], Step [1/1], Training Loss: 3577.6838, Valid Loss: 133.4904
Epoch [17601/30000], Step [1/1], Training Loss: 3490.3867, Valid Loss: 132.0000
Epoch [17701/30000], Step [1/1], Training Loss: 3403.8232, Valid Loss: 146.3558
Epoch [17801/30000], Step [1/1], Training Loss: 3322.4255, Valid Loss: 139.1154
Epoch [17901/30000], Step [1/1], Training Loss: 3241.3315, Valid Loss: 135.6827
Epoch [18001/30000], Step [1/1], Training Loss: 3160.8074, Valid Loss: 142.3173
Epoch [18101/30000], Step [1/1], Training Loss: 3085.0015, Valid Loss: 127.2212
Epoch [18201/30000], Step [1/1], Training Loss: 3009.3894, Valid Loss: 137.1539
Epoch [18301/30000], Step [1/1], Training Loss: 2935.6194, Valid Loss: 125.3846
Epoch [18401/30000], Step [1/1], Training Loss: 2863.4434, Valid Loss: 130.0481
Epoch [18501/30000], Step [1/1], Training Loss: 2793.6931, Valid Loss: 133.7500
Epoch [18601/30000], Step [1/1], Training Loss: 2724.8379, Valid Loss: 134.3269
Epoch [18701/30000], Step [1/1], Training Loss: 2658.1550, Valid Loss: 132.4231
Epoch [18801/30000], Step [1/1], Training Loss: 2592.0305, Valid Loss: 132.2789
Epoch [18901/30000], Step [1/1], Training Loss: 2526.2466, Valid Loss: 124.5962
Epoch [19001/30000], Step [1/1], Training Loss: 2463.4226, Valid Loss: 133.1827
Epoch [19101/30000], Step [1/1], Training Loss: 2402.4709, Valid Loss: 139.3942
Epoch [19201/30000], Step [1/1], Training Loss: 2341.7698, Valid Loss: 136.9135
Epoch [19301/30000], Step [1/1], Training Loss: 2281.8159, Valid Loss: 130.3942
Epoch [19401/30000], Step [1/1], Training Loss: 2225.5015, Valid Loss: 134.9808
Epoch [19501/30000], Step [1/1], Training Loss: 2168.3965, Valid Loss: 134.2789
Epoch [19601/30000], Step [1/1], Training Loss: 2114.5879, Valid Loss: 139.1346
Epoch [19701/30000], Step [1/1], Training Loss: 2061.4871, Valid Loss: 133.3365
Epoch [19801/30000], Step [1/1], Training Loss: 2010.6307, Valid Loss: 138.5000
Epoch [19901/30000], Step [1/1], Training Loss: 1960.3792, Valid Loss: 135.6154
Epoch [20001/30000], Step [1/1], Training Loss: 1912.6614, Valid Loss: 136.6923
Epoch [20101/30000], Step [1/1], Training Loss: 1865.2875, Valid Loss: 133.5577

[Epoch 25000] Rounded prediction: 
tensor([10., 15., 16., 18., 16., 18., 15., 12., 11., 12., 13., 14., 16., 16.,
        16., 15., 16., 16., 22., 17., 11.,  6., 13.,  0.,  1., 11.,  6.,  0.,
         0.,  0.,  0.,  0.,  3.,  2.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,
         0.,  0.,  0.,  1.,  4.,  5.,  6.,  5.,  9.,  5.,  2.,  0.,  2.,  0.,
         0.,  6.,  3.,  0.,  0.,  1.,  2.,  6.,  7.,  3.,  4.,  0.,  2., 12.,
        15., 16., 16., 27., 19.,  6., 11.,  3., 10.,  5.,  9.,  9.,  9., 11.,
        14., 15., 13., 16., 17.,  9., 10.,  3.,  4.,  0.,  4., 17., 12., 16.,
        17., 13., 27., 17., 12., 20.], device='cuda:0')
Target: 
tensor([12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,  3.,
         7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9., 12.,
         4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,  2.,
         3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,  6.,
         8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,  8.,
         7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14., 10.,
         5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23., 29.,
        42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [20201/30000], Step [1/1], Training Loss: 1820.6696, Valid Loss: 139.2885
Epoch [20301/30000], Step [1/1], Training Loss: 1776.4913, Valid Loss: 139.7212
Epoch [20401/30000], Step [1/1], Training Loss: 1734.7952, Valid Loss: 132.8173
Epoch [20501/30000], Step [1/1], Training Loss: 1694.1421, Valid Loss: 139.2019
Epoch [20601/30000], Step [1/1], Training Loss: 1655.2480, Valid Loss: 136.7981
Epoch [20701/30000], Step [1/1], Training Loss: 1617.4642, Valid Loss: 137.9327
Epoch [20801/30000], Step [1/1], Training Loss: 1580.6213, Valid Loss: 137.3173
Epoch [20901/30000], Step [1/1], Training Loss: 1544.6803, Valid Loss: 138.7981
Epoch [21001/30000], Step [1/1], Training Loss: 1510.3403, Valid Loss: 135.4519
Epoch [21101/30000], Step [1/1], Training Loss: 1476.9357, Valid Loss: 140.8750
Epoch [21201/30000], Step [1/1], Training Loss: 1444.3865, Valid Loss: 137.0481
Epoch [21301/30000], Step [1/1], Training Loss: 1412.3429, Valid Loss: 135.9615
Epoch [21401/30000], Step [1/1], Training Loss: 1382.0187, Valid Loss: 140.2212
Epoch [21501/30000], Step [1/1], Training Loss: 1351.7717, Valid Loss: 134.4135
Epoch [21601/30000], Step [1/1], Training Loss: 1322.1428, Valid Loss: 139.1058
Epoch [21701/30000], Step [1/1], Training Loss: 1294.1346, Valid Loss: 135.8462
Epoch [21801/30000], Step [1/1], Training Loss: 1266.0944, Valid Loss: 143.0192
Epoch [21901/30000], Step [1/1], Training Loss: 1239.1664, Valid Loss: 134.7115
Epoch [22001/30000], Step [1/1], Training Loss: 1212.8783, Valid Loss: 139.0000
Epoch [22101/30000], Step [1/1], Training Loss: 1187.7091, Valid Loss: 135.2500
Epoch [22201/30000], Step [1/1], Training Loss: 1162.3019, Valid Loss: 141.0000
Epoch [22301/30000], Step [1/1], Training Loss: 1137.7198, Valid Loss: 144.2789
Epoch [22401/30000], Step [1/1], Training Loss: 1113.1929, Valid Loss: 138.4423
Epoch [22501/30000], Step [1/1], Training Loss: 1088.9808, Valid Loss: 143.3269
Epoch [22601/30000], Step [1/1], Training Loss: 1065.2061, Valid Loss: 137.3462
Epoch [22701/30000], Step [1/1], Training Loss: 1041.7279, Valid Loss: 141.7212
Epoch [22801/30000], Step [1/1], Training Loss: 1018.5392, Valid Loss: 139.0096
Epoch [22901/30000], Step [1/1], Training Loss: 995.9378, Valid Loss: 138.2115
Epoch [23001/30000], Step [1/1], Training Loss: 973.4117, Valid Loss: 142.9615
Epoch [23101/30000], Step [1/1], Training Loss: 951.4996, Valid Loss: 143.0962
Epoch [23201/30000], Step [1/1], Training Loss: 930.1059, Valid Loss: 146.3365
Epoch [23301/30000], Step [1/1], Training Loss: 908.9147, Valid Loss: 145.0000
Epoch [23401/30000], Step [1/1], Training Loss: 888.1441, Valid Loss: 143.8750
Epoch [23501/30000], Step [1/1], Training Loss: 868.2502, Valid Loss: 144.9904
Epoch [23601/30000], Step [1/1], Training Loss: 848.3755, Valid Loss: 142.2212
Epoch [23701/30000], Step [1/1], Training Loss: 829.3466, Valid Loss: 139.2500
Epoch [23801/30000], Step [1/1], Training Loss: 810.5590, Valid Loss: 142.1154
Epoch [23901/30000], Step [1/1], Training Loss: 792.5522, Valid Loss: 146.3077
Epoch [24001/30000], Step [1/1], Training Loss: 8010.5493, Valid Loss: 162.7596
Epoch [24101/30000], Step [1/1], Training Loss: 796.7176, Valid Loss: 105.1731
Epoch [24201/30000], Step [1/1], Training Loss: 758.3984, Valid Loss: 116.0385
Epoch [24301/30000], Step [1/1], Training Loss: 741.5499, Valid Loss: 114.4231
Epoch [24401/30000], Step [1/1], Training Loss: 726.3486, Valid Loss: 120.7212
Epoch [24501/30000], Step [1/1], Training Loss: 712.6380, Valid Loss: 113.1923
Epoch [24601/30000], Step [1/1], Training Loss: 699.2814, Valid Loss: 120.2596
Epoch [24701/30000], Step [1/1], Training Loss: 686.0797, Valid Loss: 113.1250
Epoch [24801/30000], Step [1/1], Training Loss: 672.6002, Valid Loss: 116.3365
Epoch [24901/30000], Step [1/1], Training Loss: 659.0207, Valid Loss: 113.9327
Epoch [25001/30000], Step [1/1], Training Loss: 646.0084, Valid Loss: 120.2692
Epoch [25101/30000], Step [1/1], Training Loss: 632.7233, Valid Loss: 106.1442
Epoch [25201/30000], Step [1/1], Training Loss: 620.2390, Valid Loss: 119.8269
Epoch [25301/30000], Step [1/1], Training Loss: 607.8242, Valid Loss: 117.9423
Epoch [25401/30000], Step [1/1], Training Loss: 595.1097, Valid Loss: 122.8077
Epoch [25501/30000], Step [1/1], Training Loss: 582.6393, Valid Loss: 121.8654
Epoch [25601/30000], Step [1/1], Training Loss: 570.1877, Valid Loss: 128.2019
Epoch [25701/30000], Step [1/1], Training Loss: 558.1678, Valid Loss: 111.9904
Epoch [25801/30000], Step [1/1], Training Loss: 545.4995, Valid Loss: 117.1154
Epoch [25901/30000], Step [1/1], Training Loss: 533.1448, Valid Loss: 121.4039
Epoch [26001/30000], Step [1/1], Training Loss: 520.9807, Valid Loss: 124.7212
Epoch [26101/30000], Step [1/1], Training Loss: 509.2754, Valid Loss: 124.4327
Epoch [26201/30000], Step [1/1], Training Loss: 497.2810, Valid Loss: 130.3654
Epoch [26301/30000], Step [1/1], Training Loss: 486.4286, Valid Loss: 125.9519
Epoch [26401/30000], Step [1/1], Training Loss: 474.9901, Valid Loss: 119.2500
Epoch [26501/30000], Step [1/1], Training Loss: 463.4054, Valid Loss: 118.1442
Epoch [26601/30000], Step [1/1], Training Loss: 452.8086, Valid Loss: 115.1731
Epoch [26701/30000], Step [1/1], Training Loss: 442.0176, Valid Loss: 116.4519
Epoch [26801/30000], Step [1/1], Training Loss: 431.6646, Valid Loss: 119.9039
Epoch [26901/30000], Step [1/1], Training Loss: 421.2779, Valid Loss: 118.1442
Epoch [27001/30000], Step [1/1], Training Loss: 411.2509, Valid Loss: 125.1923
Epoch [27101/30000], Step [1/1], Training Loss: 401.9988, Valid Loss: 123.2308
Epoch [27201/30000], Step [1/1], Training Loss: 392.2253, Valid Loss: 131.6539
Epoch [27301/30000], Step [1/1], Training Loss: 382.1850, Valid Loss: 129.7981
Epoch [27401/30000], Step [1/1], Training Loss: 372.6825, Valid Loss: 125.2115
Epoch [27501/30000], Step [1/1], Training Loss: 362.9077, Valid Loss: 126.9039
Epoch [27601/30000], Step [1/1], Training Loss: 353.3949, Valid Loss: 119.2308
Epoch [27701/30000], Step [1/1], Training Loss: 343.7098, Valid Loss: 119.3654
Epoch [27801/30000], Step [1/1], Training Loss: 334.1798, Valid Loss: 123.1154
Epoch [27901/30000], Step [1/1], Training Loss: 325.0955, Valid Loss: 126.7212
Epoch [28001/30000], Step [1/1], Training Loss: 315.5474, Valid Loss: 136.2404
Epoch [28101/30000], Step [1/1], Training Loss: 306.3977, Valid Loss: 128.4808
Epoch [28201/30000], Step [1/1], Training Loss: 297.3373, Valid Loss: 146.9904
Epoch [28301/30000], Step [1/1], Training Loss: 288.1949, Valid Loss: 131.7692
Epoch [28401/30000], Step [1/1], Training Loss: 279.3855, Valid Loss: 117.2404
Epoch [28501/30000], Step [1/1], Training Loss: 270.7356, Valid Loss: 119.0577
Epoch [28601/30000], Step [1/1], Training Loss: 262.0520, Valid Loss: 139.5289
Epoch [28701/30000], Step [1/1], Training Loss: 253.5492, Valid Loss: 131.5192
Epoch [28801/30000], Step [1/1], Training Loss: 245.1918, Valid Loss: 125.3558
Epoch [28901/30000], Step [1/1], Training Loss: 236.8643, Valid Loss: 127.5865
Epoch [29001/30000], Step [1/1], Training Loss: 228.7694, Valid Loss: 134.2019
Epoch [29101/30000], Step [1/1], Training Loss: 220.8795, Valid Loss: 127.4423
Epoch [29201/30000], Step [1/1], Training Loss: 213.0053, Valid Loss: 143.4615
Epoch [29301/30000], Step [1/1], Training Loss: 205.6012, Valid Loss: 128.1635
Epoch [29401/30000], Step [1/1], Training Loss: 197.8661, Valid Loss: 134.7981
Epoch [29501/30000], Step [1/1], Training Loss: 190.5303, Valid Loss: 137.6346
Epoch [29601/30000], Step [1/1], Training Loss: 183.2829, Valid Loss: 133.6058
Epoch [29701/30000], Step [1/1], Training Loss: 176.4455, Valid Loss: 131.5481
Epoch [29801/30000], Step [1/1], Training Loss: 169.3899, Valid Loss: 120.1154
Epoch [29901/30000], Step [1/1], Training Loss: 162.7841, Valid Loss: 134.2692

 End Time: 2021/04/19, 04:57:59




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=11 	hidden_size=1024 	layers=3

Start Time = 2021/04/19, 13:52:11
##########################################################


[Epoch 0] Rounded prediction: 
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       device='cuda:0')
Target: 
tensor([12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,  3.,
         7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9., 12.,
         4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,  2.,
         3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,  6.,
         8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,  8.,
         7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14., 10.,
         5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23., 29.,
        42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([ 9.,  9., 12., 16., 15., 18., 19., 16., 23., 21., 22.,  0., 24.,  1.,
        26., 28.,  0., 28., 18., 23.,  0.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 14.,  5.,  0.,  0.,  1.,  0.,
        12.,  0.,  0.,  0.,  0.,  0.,  3., 23., 26.,  0., 36., 25.,  0., 31.,
        59., 42., 42.,  0.,  0.,  2.], device='cuda:0')
Target: 
tensor([12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,  3.,
         7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9., 12.,
         4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,  2.,
         3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,  6.,
         8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,  8.,
         7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14., 10.,
         5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23., 29.,
        42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([ 7.,  7.,  9., 11., 15., 15., 12., 17., 18., 23., 23., 25., 25., 30.,
        29., 32., 26., 26., 28., 26.,  8., 16.,  0.,  1.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  6.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0.,  0., 20.,  8.,  0., 22.,  0.,  4.,  0., 24.,
         0.,  0.,  0.,  0.,  0.,  0.,  7., 11., 49., 67., 68., 90., 55.,  0.,
         1., 17., 40.,  0.,  0.,  7.], device='cuda:0')
Target: 
tensor([12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,  3.,
         7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9., 12.,
         4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,  2.,
         3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,  6.,
         8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,  8.,
         7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14., 10.,
         5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23., 29.,
        42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 130278.6484, Valid Loss: 224.6731
Epoch [101/30000], Step [1/1], Training Loss: 118656.4062, Valid Loss: 287.3750
Epoch [201/30000], Step [1/1], Training Loss: 114231.1172, Valid Loss: 665.2596
Epoch [301/30000], Step [1/1], Training Loss: 110131.5078, Valid Loss: 1243.1443
Epoch [401/30000], Step [1/1], Training Loss: 106291.4688, Valid Loss: 2021.0289
Epoch [501/30000], Step [1/1], Training Loss: 102681.7812, Valid Loss: 2803.7310
Epoch [601/30000], Step [1/1], Training Loss: 99269.0938, Valid Loss: 1549.4039
Epoch [701/30000], Step [1/1], Training Loss: 96050.8984, Valid Loss: 2313.0579
Epoch [801/30000], Step [1/1], Training Loss: 92415.2109, Valid Loss: 2019.1636
Epoch [901/30000], Step [1/1], Training Loss: 89171.4062, Valid Loss: 3769.3271
Epoch [1001/30000], Step [1/1], Training Loss: 86067.2500, Valid Loss: 2764.0769
Epoch [1101/30000], Step [1/1], Training Loss: 83089.0312, Valid Loss: 1640.1058
Epoch [1201/30000], Step [1/1], Training Loss: 80198.5391, Valid Loss: 1048.0865
Epoch [1301/30000], Step [1/1], Training Loss: 77456.7266, Valid Loss: 607.7981
Epoch [1401/30000], Step [1/1], Training Loss: 74840.3750, Valid Loss: 860.5096
Epoch [1501/30000], Step [1/1], Training Loss: 72323.4375, Valid Loss: 407.8750
Epoch [1601/30000], Step [1/1], Training Loss: 69919.4219, Valid Loss: 517.1827
Epoch [1701/30000], Step [1/1], Training Loss: 67624.8438, Valid Loss: 496.9135
Epoch [1801/30000], Step [1/1], Training Loss: 65429.3125, Valid Loss: 594.4231
Epoch [1901/30000], Step [1/1], Training Loss: 63350.3438, Valid Loss: 586.2500
Epoch [2001/30000], Step [1/1], Training Loss: 61309.6992, Valid Loss: 707.7885
Epoch [2101/30000], Step [1/1], Training Loss: 59384.7539, Valid Loss: 570.9231
Epoch [2201/30000], Step [1/1], Training Loss: 57521.6953, Valid Loss: 767.1731
Epoch [2301/30000], Step [1/1], Training Loss: 55687.8008, Valid Loss: 898.2693
Epoch [2401/30000], Step [1/1], Training Loss: 53965.4141, Valid Loss: 981.9039
Epoch [2501/30000], Step [1/1], Training Loss: 52313.3789, Valid Loss: 961.3365
Epoch [2601/30000], Step [1/1], Training Loss: 50632.6719, Valid Loss: 854.2789
Epoch [2701/30000], Step [1/1], Training Loss: 49065.1133, Valid Loss: 923.8654
Epoch [2801/30000], Step [1/1], Training Loss: 47446.4180, Valid Loss: 589.1827
Epoch [2901/30000], Step [1/1], Training Loss: 45956.7344, Valid Loss: 698.3558
Epoch [3001/30000], Step [1/1], Training Loss: 44527.3633, Valid Loss: 282.9327
Epoch [3101/30000], Step [1/1], Training Loss: 43134.3633, Valid Loss: 191.4904
Epoch [3201/30000], Step [1/1], Training Loss: 41776.4727, Valid Loss: 306.9039
Epoch [3301/30000], Step [1/1], Training Loss: 40336.7266, Valid Loss: 451.8077
Epoch [3401/30000], Step [1/1], Training Loss: 39076.1250, Valid Loss: 304.2019
Epoch [3501/30000], Step [1/1], Training Loss: 37983.2031, Valid Loss: 450.9519
Epoch [3601/30000], Step [1/1], Training Loss: 38424.0391, Valid Loss: 411.8654
Epoch [3701/30000], Step [1/1], Training Loss: 35327.1289, Valid Loss: 300.5577
Epoch [3801/30000], Step [1/1], Training Loss: 34083.2773, Valid Loss: 578.6827
Epoch [3901/30000], Step [1/1], Training Loss: 32968.4922, Valid Loss: 551.2115
Epoch [4001/30000], Step [1/1], Training Loss: 31877.2676, Valid Loss: 549.4039
Epoch [4101/30000], Step [1/1], Training Loss: 30766.3926, Valid Loss: 318.5962
Epoch [4201/30000], Step [1/1], Training Loss: 29754.1992, Valid Loss: 310.9327
Epoch [4301/30000], Step [1/1], Training Loss: 28822.4980, Valid Loss: 514.0096
Epoch [4401/30000], Step [1/1], Training Loss: 27864.8965, Valid Loss: 539.0962
Epoch [4501/30000], Step [1/1], Training Loss: 26975.4219, Valid Loss: 352.1635
Epoch [4601/30000], Step [1/1], Training Loss: 26123.3438, Valid Loss: 303.6250
Epoch [4701/30000], Step [1/1], Training Loss: 25298.2969, Valid Loss: 322.1635
Epoch [4801/30000], Step [1/1], Training Loss: 24515.6387, Valid Loss: 222.8846
Epoch [4901/30000], Step [1/1], Training Loss: 23769.4512, Valid Loss: 252.2500
Epoch [5001/30000], Step [1/1], Training Loss: 23060.3008, Valid Loss: 196.1058
Epoch [5101/30000], Step [1/1], Training Loss: 22789.8926, Valid Loss: 236.2115
Epoch [5201/30000], Step [1/1], Training Loss: 21699.6973, Valid Loss: 227.6154
Epoch [5301/30000], Step [1/1], Training Loss: 20815.2324, Valid Loss: 256.9135
Epoch [5401/30000], Step [1/1], Training Loss: 20287.2539, Valid Loss: 259.0769
Epoch [5501/30000], Step [1/1], Training Loss: 19239.9102, Valid Loss: 245.6058
Epoch [5601/30000], Step [1/1], Training Loss: 18535.5684, Valid Loss: 268.2885
Epoch [5701/30000], Step [1/1], Training Loss: 17836.0215, Valid Loss: 248.2789
Epoch [5801/30000], Step [1/1], Training Loss: 17193.8418, Valid Loss: 296.7885
Epoch [5901/30000], Step [1/1], Training Loss: 16584.9707, Valid Loss: 292.9135
Epoch [6001/30000], Step [1/1], Training Loss: 15984.7158, Valid Loss: 310.7212
Epoch [6101/30000], Step [1/1], Training Loss: 15411.8701, Valid Loss: 264.2789
Epoch [6201/30000], Step [1/1], Training Loss: 14862.6875, Valid Loss: 262.5192
Epoch [6301/30000], Step [1/1], Training Loss: 14451.5264, Valid Loss: 255.3365
Epoch [6401/30000], Step [1/1], Training Loss: 13842.4932, Valid Loss: 302.0385
Epoch [6501/30000], Step [1/1], Training Loss: 13350.8525, Valid Loss: 283.1346
Epoch [6601/30000], Step [1/1], Training Loss: 12881.3828, Valid Loss: 291.4231
Epoch [6701/30000], Step [1/1], Training Loss: 12426.2256, Valid Loss: 303.7693
Epoch [6801/30000], Step [1/1], Training Loss: 12090.7520, Valid Loss: 253.4327
Epoch [6901/30000], Step [1/1], Training Loss: 11640.4561, Valid Loss: 224.0385
Epoch [7001/30000], Step [1/1], Training Loss: 11176.7744, Valid Loss: 239.5577
Epoch [7101/30000], Step [1/1], Training Loss: 10783.2148, Valid Loss: 276.3365
Epoch [7201/30000], Step [1/1], Training Loss: 10402.3848, Valid Loss: 256.8558
Epoch [7301/30000], Step [1/1], Training Loss: 10037.6240, Valid Loss: 268.4327
Epoch [7401/30000], Step [1/1], Training Loss: 9688.8057, Valid Loss: 292.1635
Epoch [7501/30000], Step [1/1], Training Loss: 9307.3945, Valid Loss: 277.4615
Epoch [7601/30000], Step [1/1], Training Loss: 8970.0254, Valid Loss: 282.5962
Epoch [7701/30000], Step [1/1], Training Loss: 8685.2383, Valid Loss: 278.0000
Epoch [7801/30000], Step [1/1], Training Loss: 8932.5977, Valid Loss: 279.9231
Epoch [7901/30000], Step [1/1], Training Loss: 8075.4014, Valid Loss: 251.3750
Epoch [8001/30000], Step [1/1], Training Loss: 7784.7080, Valid Loss: 273.5096
Epoch [8101/30000], Step [1/1], Training Loss: 7469.7085, Valid Loss: 266.1827
Epoch [8201/30000], Step [1/1], Training Loss: 7197.5176, Valid Loss: 311.1443
Epoch [8301/30000], Step [1/1], Training Loss: 6939.2563, Valid Loss: 257.0385
Epoch [8401/30000], Step [1/1], Training Loss: 6688.2632, Valid Loss: 302.7308
Epoch [8501/30000], Step [1/1], Training Loss: 6429.8643, Valid Loss: 296.6827
Epoch [8601/30000], Step [1/1], Training Loss: 6196.8530, Valid Loss: 259.6250
Epoch [8701/30000], Step [1/1], Training Loss: 5973.9385, Valid Loss: 277.0577
Epoch [8801/30000], Step [1/1], Training Loss: 5762.0820, Valid Loss: 282.6058
Epoch [8901/30000], Step [1/1], Training Loss: 5559.0317, Valid Loss: 259.5481
Epoch [9001/30000], Step [1/1], Training Loss: 5361.9253, Valid Loss: 224.0000
Epoch [9101/30000], Step [1/1], Training Loss: 5175.0718, Valid Loss: 299.6154
Epoch [9201/30000], Step [1/1], Training Loss: 5000.7271, Valid Loss: 254.3942
Epoch [9301/30000], Step [1/1], Training Loss: 4827.8237, Valid Loss: 280.5481
Epoch [9401/30000], Step [1/1], Training Loss: 4665.7544, Valid Loss: 261.1346
Epoch [9501/30000], Step [1/1], Training Loss: 4508.3486, Valid Loss: 314.5577
Epoch [9601/30000], Step [1/1], Training Loss: 4359.1304, Valid Loss: 296.1154
Epoch [9701/30000], Step [1/1], Training Loss: 4217.8276, Valid Loss: 315.2885
Epoch [9801/30000], Step [1/1], Training Loss: 4083.9668, Valid Loss: 285.6058
Epoch [9901/30000], Step [1/1], Training Loss: 3957.4124, Valid Loss: 299.7789
Epoch [10001/30000], Step [1/1], Training Loss: 3837.2517, Valid Loss: 282.7115
Epoch [10101/30000], Step [1/1], Training Loss: 3723.4666, Valid Loss: 240.1442

[Epoch 15000] Rounded prediction: 
tensor([  9.,  10.,   8.,   8.,   9.,  12.,  10.,  13.,  12.,  16.,  14.,  24.,
         25.,  28.,  31.,  31.,  28.,  39.,  37.,  17.,  24.,   0.,   0.,  24.,
         17.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,
          0.,   0.,   0.,   0.,   0.,  23.,   0.,  31.,  15.,   0.,  48.,  40.,
          0.,   0.,   0.,   0.,   0.,   0.,   3.,  22.,  59.,  69.,  93., 119.,
         34.,   0.,   0.,  23.,   0.,   0.,   3.,   7.], device='cuda:0')
Target: 
tensor([12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,  3.,
         7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9., 12.,
         4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,  2.,
         3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,  6.,
         8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,  8.,
         7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14., 10.,
         5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23., 29.,
        42., 22., 17., 38., 45., 30.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([  5.,   6.,   6.,  11.,  10.,  12.,  13.,  15.,  21.,  24.,  26.,  29.,
         33.,  28.,  36.,  42.,  41.,  18.,  41.,  46.,   0.,  24.,   0.,   7.,
          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,
          0.,   0.,   0.,   0.,   0.,   0.,   3.,   0.,   0.,   0.,   0.,   0.,
          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
          0.,   0.,   0.,   0.,  33.,   1.,   0.,   0.,  15.,   0.,   0.,  52.,
          4.,   0.,   0.,   0.,   0.,  23.,   0.,  77.,  72.,  88., 125., 102.,
         59.,   0.,   0.,   0.,  22.,   7.,   1.,  13.], device='cuda:0')
Target: 
tensor([12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,  3.,
         7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9., 12.,
         4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,  2.,
         3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,  6.,
         8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,  8.,
         7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14., 10.,
         5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23., 29.,
        42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [10201/30000], Step [1/1], Training Loss: 3615.8164, Valid Loss: 299.9904
Epoch [10301/30000], Step [1/1], Training Loss: 3510.3733, Valid Loss: 297.8750
Epoch [10401/30000], Step [1/1], Training Loss: 3411.5310, Valid Loss: 261.5673
Epoch [10501/30000], Step [1/1], Training Loss: 3317.9180, Valid Loss: 319.4231
Epoch [10601/30000], Step [1/1], Training Loss: 3229.5137, Valid Loss: 314.6058
Epoch [10701/30000], Step [1/1], Training Loss: 3145.1821, Valid Loss: 294.4231
Epoch [10801/30000], Step [1/1], Training Loss: 3065.1306, Valid Loss: 330.2404
Epoch [10901/30000], Step [1/1], Training Loss: 2988.1726, Valid Loss: 326.1827
Epoch [11001/30000], Step [1/1], Training Loss: 2830.7336, Valid Loss: 266.7019
Epoch [11101/30000], Step [1/1], Training Loss: 2996.1255, Valid Loss: 269.1635
Epoch [11201/30000], Step [1/1], Training Loss: 2566.1277, Valid Loss: 333.4808
Epoch [11301/30000], Step [1/1], Training Loss: 2469.9949, Valid Loss: 377.6443
Epoch [11401/30000], Step [1/1], Training Loss: 2196.4895, Valid Loss: 333.7693
Epoch [11501/30000], Step [1/1], Training Loss: 2100.2793, Valid Loss: 367.3846
Epoch [11601/30000], Step [1/1], Training Loss: 2011.3768, Valid Loss: 367.5000
Epoch [11701/30000], Step [1/1], Training Loss: 1934.8585, Valid Loss: 310.6346
Epoch [11801/30000], Step [1/1], Training Loss: 1849.8407, Valid Loss: 317.6154
Epoch [11901/30000], Step [1/1], Training Loss: 1775.3630, Valid Loss: 335.9135
Epoch [12001/30000], Step [1/1], Training Loss: 1706.9988, Valid Loss: 358.0769
Epoch [12101/30000], Step [1/1], Training Loss: 1641.5967, Valid Loss: 392.6731
Epoch [12201/30000], Step [1/1], Training Loss: 1581.8105, Valid Loss: 380.7500
Epoch [12301/30000], Step [1/1], Training Loss: 1524.1582, Valid Loss: 386.8173
Epoch [12401/30000], Step [1/1], Training Loss: 1469.1647, Valid Loss: 363.5193
Epoch [12501/30000], Step [1/1], Training Loss: 1419.1597, Valid Loss: 336.9135
Epoch [12601/30000], Step [1/1], Training Loss: 1370.3654, Valid Loss: 406.3077
Epoch [12701/30000], Step [1/1], Training Loss: 1322.5553, Valid Loss: 336.4904
Epoch [12801/30000], Step [1/1], Training Loss: 1278.0105, Valid Loss: 335.3846
Epoch [12901/30000], Step [1/1], Training Loss: 1236.2198, Valid Loss: 345.5000
Epoch [13001/30000], Step [1/1], Training Loss: 1195.7771, Valid Loss: 426.1923
Epoch [13101/30000], Step [1/1], Training Loss: 1156.4536, Valid Loss: 382.6443
Epoch [13201/30000], Step [1/1], Training Loss: 1118.2565, Valid Loss: 458.7019
Epoch [13301/30000], Step [1/1], Training Loss: 1081.1183, Valid Loss: 343.2596
Epoch [13401/30000], Step [1/1], Training Loss: 1044.9395, Valid Loss: 349.6250
Epoch [13501/30000], Step [1/1], Training Loss: 1009.6539, Valid Loss: 418.0000
Epoch [13601/30000], Step [1/1], Training Loss: 975.2420, Valid Loss: 484.1250
Epoch [13701/30000], Step [1/1], Training Loss: 941.3839, Valid Loss: 354.3943
Epoch [13801/30000], Step [1/1], Training Loss: 909.3521, Valid Loss: 417.5962
Epoch [13901/30000], Step [1/1], Training Loss: 878.2644, Valid Loss: 326.3077
Epoch [14001/30000], Step [1/1], Training Loss: 847.4600, Valid Loss: 477.7115
Epoch [14101/30000], Step [1/1], Training Loss: 818.7862, Valid Loss: 389.0673
Epoch [14201/30000], Step [1/1], Training Loss: 791.3876, Valid Loss: 457.0193
Epoch [14301/30000], Step [1/1], Training Loss: 765.2088, Valid Loss: 425.9712
Epoch [14401/30000], Step [1/1], Training Loss: 739.1028, Valid Loss: 440.2404
Epoch [14501/30000], Step [1/1], Training Loss: 715.0878, Valid Loss: 414.3846
Epoch [14601/30000], Step [1/1], Training Loss: 692.4666, Valid Loss: 324.0577
Epoch [14701/30000], Step [1/1], Training Loss: 669.3188, Valid Loss: 406.6154
Epoch [14801/30000], Step [1/1], Training Loss: 647.2690, Valid Loss: 370.9327
Epoch [14901/30000], Step [1/1], Training Loss: 625.8985, Valid Loss: 479.0865
Epoch [15001/30000], Step [1/1], Training Loss: 604.8512, Valid Loss: 357.0673
Epoch [15101/30000], Step [1/1], Training Loss: 584.1436, Valid Loss: 389.8558
Epoch [15201/30000], Step [1/1], Training Loss: 564.0206, Valid Loss: 384.8943
Epoch [15301/30000], Step [1/1], Training Loss: 543.8740, Valid Loss: 415.9423
Epoch [15401/30000], Step [1/1], Training Loss: 524.7015, Valid Loss: 429.3750
Epoch [15501/30000], Step [1/1], Training Loss: 505.4061, Valid Loss: 306.7693
Epoch [15601/30000], Step [1/1], Training Loss: 487.4221, Valid Loss: 370.7981
Epoch [15701/30000], Step [1/1], Training Loss: 469.4757, Valid Loss: 375.7981
Epoch [15801/30000], Step [1/1], Training Loss: 452.0901, Valid Loss: 419.7212
Epoch [15901/30000], Step [1/1], Training Loss: 435.7003, Valid Loss: 459.2789
Epoch [16001/30000], Step [1/1], Training Loss: 419.5942, Valid Loss: 403.5577
Epoch [16101/30000], Step [1/1], Training Loss: 404.1342, Valid Loss: 416.5096
Epoch [16201/30000], Step [1/1], Training Loss: 389.2304, Valid Loss: 458.1827
Epoch [16301/30000], Step [1/1], Training Loss: 374.0959, Valid Loss: 406.1635
Epoch [16401/30000], Step [1/1], Training Loss: 358.9519, Valid Loss: 467.2308
Epoch [16501/30000], Step [1/1], Training Loss: 344.1074, Valid Loss: 392.3750
Epoch [16601/30000], Step [1/1], Training Loss: 329.3210, Valid Loss: 387.5962
Epoch [16701/30000], Step [1/1], Training Loss: 315.3626, Valid Loss: 371.5385
Epoch [16801/30000], Step [1/1], Training Loss: 300.5147, Valid Loss: 426.8365
Epoch [16901/30000], Step [1/1], Training Loss: 286.4368, Valid Loss: 468.4904
Epoch [17001/30000], Step [1/1], Training Loss: 272.6285, Valid Loss: 413.2596
Epoch [17101/30000], Step [1/1], Training Loss: 258.9352, Valid Loss: 333.3558
Epoch [17201/30000], Step [1/1], Training Loss: 245.7520, Valid Loss: 390.5962
Epoch [17301/30000], Step [1/1], Training Loss: 232.8027, Valid Loss: 434.6443
Epoch [17401/30000], Step [1/1], Training Loss: 220.1848, Valid Loss: 417.6635
Epoch [17501/30000], Step [1/1], Training Loss: 207.9428, Valid Loss: 405.5096
Epoch [17601/30000], Step [1/1], Training Loss: 196.1395, Valid Loss: 406.4519
Epoch [17701/30000], Step [1/1], Training Loss: 184.4031, Valid Loss: 406.9712
Epoch [17801/30000], Step [1/1], Training Loss: 173.1782, Valid Loss: 398.1250
Epoch [17901/30000], Step [1/1], Training Loss: 162.2753, Valid Loss: 466.7500
Epoch [18001/30000], Step [1/1], Training Loss: 151.8879, Valid Loss: 404.4039
Epoch [18101/30000], Step [1/1], Training Loss: 141.8086, Valid Loss: 467.0289
Epoch [18201/30000], Step [1/1], Training Loss: 132.2057, Valid Loss: 404.4327
Epoch [18301/30000], Step [1/1], Training Loss: 122.9904, Valid Loss: 432.3462
Epoch [18401/30000], Step [1/1], Training Loss: 114.1830, Valid Loss: 384.7019
Epoch [18501/30000], Step [1/1], Training Loss: 105.6348, Valid Loss: 401.3750
Epoch [18601/30000], Step [1/1], Training Loss: 97.5186, Valid Loss: 397.0000
Epoch [18701/30000], Step [1/1], Training Loss: 90.0780, Valid Loss: 406.0289
Epoch [18801/30000], Step [1/1], Training Loss: 82.4592, Valid Loss: 434.4904
Epoch [18901/30000], Step [1/1], Training Loss: 75.6295, Valid Loss: 465.2404
Epoch [19001/30000], Step [1/1], Training Loss: 69.0880, Valid Loss: 402.7308
Epoch [19101/30000], Step [1/1], Training Loss: 62.9258, Valid Loss: 426.9135
Epoch [19201/30000], Step [1/1], Training Loss: 57.1404, Valid Loss: 377.8269
Epoch [19301/30000], Step [1/1], Training Loss: 51.7859, Valid Loss: 442.9712
Epoch [19401/30000], Step [1/1], Training Loss: 46.6672, Valid Loss: 438.0289
Epoch [19501/30000], Step [1/1], Training Loss: 41.9338, Valid Loss: 352.8173
Epoch [19601/30000], Step [1/1], Training Loss: 37.6146, Valid Loss: 371.7212
Epoch [19701/30000], Step [1/1], Training Loss: 33.6614, Valid Loss: 376.8077
Epoch [19801/30000], Step [1/1], Training Loss: 29.9579, Valid Loss: 452.4423
Epoch [19901/30000], Step [1/1], Training Loss: 26.5202, Valid Loss: 523.3846
Epoch [20001/30000], Step [1/1], Training Loss: 23.3378, Valid Loss: 474.5289
Epoch [20101/30000], Step [1/1], Training Loss: 20.3860, Valid Loss: 472.8943
Epoch [20201/30000], Step [1/1], Training Loss: 17.7511, Valid Loss: 395.5000
Epoch [20301/30000], Step [1/1], Training Loss: 15.5893, Valid Loss: 395.2019
Epoch [20401/30000], Step [1/1], Training Loss: 13.4030, Valid Loss: 492.6250

[Epoch 25000] Rounded prediction: 
tensor([ 10.,  10.,  13.,  15.,  15.,  17.,  16.,  17.,  16.,  19.,  18.,  23.,
         25.,  28.,  32.,  27.,  41.,  38.,  35.,  35.,   0.,  19.,  32.,   0.,
          3.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
          0.,   0.,   0.,   0.,   9.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
          0.,  13.,   0.,  27.,   3.,  29.,  23.,  44.,   0.,   0.,  59.,  66.,
          0.,   0.,   0.,   0.,   0.,  12.,   0.,  87., 100., 105., 141., 133.,
          4.,   0.,   0.,  22.,   0.,  33.,  33.,  17.], device='cuda:0')
Target: 
tensor([12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,  3.,
         7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9., 12.,
         4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,  2.,
         3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,  6.,
         8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,  8.,
         7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14., 10.,
         5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23., 29.,
        42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [20501/30000], Step [1/1], Training Loss: 11.5086, Valid Loss: 420.9231
Epoch [20601/30000], Step [1/1], Training Loss: 9.8070, Valid Loss: 377.8077
Epoch [20701/30000], Step [1/1], Training Loss: 8.4478, Valid Loss: 417.4615
Epoch [20801/30000], Step [1/1], Training Loss: 7.0973, Valid Loss: 435.3943
Epoch [20901/30000], Step [1/1], Training Loss: 5.9185, Valid Loss: 447.4327
Epoch [21001/30000], Step [1/1], Training Loss: 4.9302, Valid Loss: 404.8558
Epoch [21101/30000], Step [1/1], Training Loss: 4.1199, Valid Loss: 384.6923
Epoch [21201/30000], Step [1/1], Training Loss: 3.3208, Valid Loss: 430.3269
Epoch [21301/30000], Step [1/1], Training Loss: 2.8369, Valid Loss: 452.8654
Epoch [21401/30000], Step [1/1], Training Loss: 2.2394, Valid Loss: 448.9519
Epoch [21501/30000], Step [1/1], Training Loss: 1.8151, Valid Loss: 451.2019
Epoch [21601/30000], Step [1/1], Training Loss: 1.6206, Valid Loss: 427.8365
Epoch [21701/30000], Step [1/1], Training Loss: 143.9781, Valid Loss: 830.4231
Epoch [21801/30000], Step [1/1], Training Loss: 11.9787, Valid Loss: 595.1442
Epoch [21901/30000], Step [1/1], Training Loss: 6.5136, Valid Loss: 511.8269
Epoch [22001/30000], Step [1/1], Training Loss: 5.3917, Valid Loss: 618.5192
Epoch [22101/30000], Step [1/1], Training Loss: 3.9284, Valid Loss: 658.9231
Epoch [22201/30000], Step [1/1], Training Loss: 3.3307, Valid Loss: 678.6250
Epoch [22301/30000], Step [1/1], Training Loss: 2.9759, Valid Loss: 501.4904
Epoch [22401/30000], Step [1/1], Training Loss: 3.9223, Valid Loss: 663.6827
Epoch [22501/30000], Step [1/1], Training Loss: 2.6125, Valid Loss: 805.3654
Epoch [22601/30000], Step [1/1], Training Loss: 2.8569, Valid Loss: 788.0193
Epoch [22701/30000], Step [1/1], Training Loss: 2.6730, Valid Loss: 699.7308
Epoch [22801/30000], Step [1/1], Training Loss: 2.1268, Valid Loss: 637.5962
Epoch [22901/30000], Step [1/1], Training Loss: 2.0017, Valid Loss: 681.1058
Epoch [23001/30000], Step [1/1], Training Loss: 1.9256, Valid Loss: 740.1443
Epoch [23101/30000], Step [1/1], Training Loss: 1.8335, Valid Loss: 696.0962
Epoch [23201/30000], Step [1/1], Training Loss: 1.5563, Valid Loss: 580.6058
Epoch [23301/30000], Step [1/1], Training Loss: 1.6177, Valid Loss: 655.9808
Epoch [23401/30000], Step [1/1], Training Loss: 1.3272, Valid Loss: 525.1058
Epoch [23501/30000], Step [1/1], Training Loss: 1.3578, Valid Loss: 639.8654
Epoch [23601/30000], Step [1/1], Training Loss: 1.2708, Valid Loss: 710.4327
Epoch [23701/30000], Step [1/1], Training Loss: 1.1439, Valid Loss: 639.5962
Epoch [23801/30000], Step [1/1], Training Loss: 1.2329, Valid Loss: 587.6923
Epoch [23901/30000], Step [1/1], Training Loss: 1.1362, Valid Loss: 667.5289
Epoch [24001/30000], Step [1/1], Training Loss: 0.8492, Valid Loss: 701.0673
Epoch [24101/30000], Step [1/1], Training Loss: 0.8269, Valid Loss: 719.9520
Epoch [24201/30000], Step [1/1], Training Loss: 0.8981, Valid Loss: 614.3846
Epoch [24301/30000], Step [1/1], Training Loss: 0.8950, Valid Loss: 754.0385
Epoch [24401/30000], Step [1/1], Training Loss: 0.7531, Valid Loss: 644.9231
Epoch [24501/30000], Step [1/1], Training Loss: 0.6638, Valid Loss: 641.7789
Epoch [24601/30000], Step [1/1], Training Loss: 0.5591, Valid Loss: 632.4327
Epoch [24701/30000], Step [1/1], Training Loss: 0.5623, Valid Loss: 527.7596
Epoch [24801/30000], Step [1/1], Training Loss: 0.5293, Valid Loss: 580.0000
Epoch [24901/30000], Step [1/1], Training Loss: 0.5812, Valid Loss: 579.6731
Epoch [25001/30000], Step [1/1], Training Loss: 0.4725, Valid Loss: 593.6635
Epoch [25101/30000], Step [1/1], Training Loss: 0.4355, Valid Loss: 568.3173
Epoch [25201/30000], Step [1/1], Training Loss: 0.5852, Valid Loss: 527.1154
Epoch [25301/30000], Step [1/1], Training Loss: 0.4767, Valid Loss: 494.4423
Epoch [25401/30000], Step [1/1], Training Loss: 0.5037, Valid Loss: 541.1827
Epoch [25501/30000], Step [1/1], Training Loss: 0.3840, Valid Loss: 665.3365
Epoch [25601/30000], Step [1/1], Training Loss: 0.3321, Valid Loss: 596.8173
Epoch [25701/30000], Step [1/1], Training Loss: 0.3337, Valid Loss: 597.2308
Epoch [25801/30000], Step [1/1], Training Loss: 0.4082, Valid Loss: 612.7692
Epoch [25901/30000], Step [1/1], Training Loss: 0.2884, Valid Loss: 587.8270
Epoch [26001/30000], Step [1/1], Training Loss: 0.3915, Valid Loss: 656.6923
Epoch [26101/30000], Step [1/1], Training Loss: 0.2959, Valid Loss: 522.6154
Epoch [26201/30000], Step [1/1], Training Loss: 0.3737, Valid Loss: 562.0192
Epoch [26301/30000], Step [1/1], Training Loss: 0.3463, Valid Loss: 526.4231
Epoch [26401/30000], Step [1/1], Training Loss: 0.3034, Valid Loss: 598.1154
Epoch [26501/30000], Step [1/1], Training Loss: 0.3757, Valid Loss: 532.8462
Epoch [26601/30000], Step [1/1], Training Loss: 0.2670, Valid Loss: 653.9327
Epoch [26701/30000], Step [1/1], Training Loss: 0.3414, Valid Loss: 519.9712
Epoch [26801/30000], Step [1/1], Training Loss: 0.3076, Valid Loss: 510.1250
Epoch [26901/30000], Step [1/1], Training Loss: 0.2813, Valid Loss: 575.6635
Epoch [27001/30000], Step [1/1], Training Loss: 0.2142, Valid Loss: 523.1058
Epoch [27101/30000], Step [1/1], Training Loss: 0.2438, Valid Loss: 418.9423
Epoch [27201/30000], Step [1/1], Training Loss: 0.2339, Valid Loss: 571.0962
Epoch [27301/30000], Step [1/1], Training Loss: 0.1716, Valid Loss: 525.7789
Epoch [27401/30000], Step [1/1], Training Loss: 0.2743, Valid Loss: 487.1250
Epoch [27501/30000], Step [1/1], Training Loss: 0.2320, Valid Loss: 509.5096
Epoch [27601/30000], Step [1/1], Training Loss: 0.2041, Valid Loss: 463.2308
Epoch [27701/30000], Step [1/1], Training Loss: 0.2593, Valid Loss: 486.7500
Epoch [27801/30000], Step [1/1], Training Loss: 0.2193, Valid Loss: 450.5289
Epoch [27901/30000], Step [1/1], Training Loss: 0.2038, Valid Loss: 475.8173
Epoch [28001/30000], Step [1/1], Training Loss: 0.2170, Valid Loss: 448.2885
Epoch [28101/30000], Step [1/1], Training Loss: 0.2675, Valid Loss: 397.8462
Epoch [28201/30000], Step [1/1], Training Loss: 0.1634, Valid Loss: 426.6443
Epoch [28301/30000], Step [1/1], Training Loss: 0.3167, Valid Loss: 367.7212
Epoch [28401/30000], Step [1/1], Training Loss: 0.1850, Valid Loss: 383.7115
Epoch [28501/30000], Step [1/1], Training Loss: 0.2293, Valid Loss: 390.8077
Epoch [28601/30000], Step [1/1], Training Loss: 0.2400, Valid Loss: 515.7020
Epoch [28701/30000], Step [1/1], Training Loss: 0.3382, Valid Loss: 455.3365
Epoch [28801/30000], Step [1/1], Training Loss: 0.1565, Valid Loss: 465.7596
Epoch [28901/30000], Step [1/1], Training Loss: 0.1584, Valid Loss: 400.1923
Epoch [29001/30000], Step [1/1], Training Loss: 0.1902, Valid Loss: 416.6827
Epoch [29101/30000], Step [1/1], Training Loss: 0.2961, Valid Loss: 393.5769
Epoch [29201/30000], Step [1/1], Training Loss: 0.1763, Valid Loss: 440.1539
Epoch [29301/30000], Step [1/1], Training Loss: 0.2094, Valid Loss: 377.0000
Epoch [29401/30000], Step [1/1], Training Loss: 0.1434, Valid Loss: 341.7115
Epoch [29501/30000], Step [1/1], Training Loss: 0.1404, Valid Loss: 329.8462
Epoch [29601/30000], Step [1/1], Training Loss: 0.1347, Valid Loss: 359.1346
Epoch [29701/30000], Step [1/1], Training Loss: 0.1354, Valid Loss: 363.8750
Epoch [29801/30000], Step [1/1], Training Loss: 0.1507, Valid Loss: 394.3077
Epoch [29901/30000], Step [1/1], Training Loss: 0.1430, Valid Loss: 302.5865

 End Time: 2021/04/19, 14:16:33




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=11 	hidden_size=1024 	layers=3

Start Time = 2021/04/19, 14:16:34
##########################################################


[Epoch 0] Rounded prediction: 
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       device='cuda:0')
Target: 
tensor([12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,  3.,
         7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9., 12.,
         4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,  2.,
         3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,  6.,
         8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,  8.,
         7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14., 10.,
         5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23., 29.,
        42., 22., 17., 38., 45., 30.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 130262.6797, Valid Loss: 219.4135
Epoch [101/30000], Step [1/1], Training Loss: 118526.5234, Valid Loss: 287.3750
Epoch [201/30000], Step [1/1], Training Loss: 114107.5938, Valid Loss: 665.2596
Epoch [301/30000], Step [1/1], Training Loss: 110016.9219, Valid Loss: 1243.1443
Epoch [401/30000], Step [1/1], Training Loss: 106185.5312, Valid Loss: 2021.0289
Epoch [501/30000], Step [1/1], Training Loss: 102581.6562, Valid Loss: 2880.6731
Epoch [601/30000], Step [1/1], Training Loss: 99173.1484, Valid Loss: 1783.1731
Epoch [701/30000], Step [1/1], Training Loss: 95959.7344, Valid Loss: 2489.8462
Epoch [801/30000], Step [1/1], Training Loss: 92930.1250, Valid Loss: 3686.9231
Epoch [901/30000], Step [1/1], Training Loss: 89214.4062, Valid Loss: 2142.5674
Epoch [1001/30000], Step [1/1], Training Loss: 86078.9219, Valid Loss: 3579.7212
Epoch [1101/30000], Step [1/1], Training Loss: 83091.8281, Valid Loss: 2246.4424
Epoch [1201/30000], Step [1/1], Training Loss: 80200.9922, Valid Loss: 748.1827
Epoch [1301/30000], Step [1/1], Training Loss: 77430.6875, Valid Loss: 985.8462
Epoch [1401/30000], Step [1/1], Training Loss: 74805.2188, Valid Loss: 978.4039
Epoch [1501/30000], Step [1/1], Training Loss: 72291.3906, Valid Loss: 798.1443
Epoch [1601/30000], Step [1/1], Training Loss: 69904.2500, Valid Loss: 1192.5289
Epoch [1701/30000], Step [1/1], Training Loss: 67576.2188, Valid Loss: 1115.7405
Epoch [1801/30000], Step [1/1], Training Loss: 65368.5078, Valid Loss: 889.2308
Epoch [1901/30000], Step [1/1], Training Loss: 63266.0469, Valid Loss: 1096.1731
Epoch [2001/30000], Step [1/1], Training Loss: 61276.6953, Valid Loss: 1570.6250
Epoch [2101/30000], Step [1/1], Training Loss: 59329.8398, Valid Loss: 729.5000
Epoch [2201/30000], Step [1/1], Training Loss: 57390.3828, Valid Loss: 1349.8750
Epoch [2301/30000], Step [1/1], Training Loss: 55583.3359, Valid Loss: 1418.4039
Epoch [2401/30000], Step [1/1], Training Loss: 53861.7383, Valid Loss: 1471.1539
Epoch [2501/30000], Step [1/1], Training Loss: 52217.8789, Valid Loss: 1358.5193
Epoch [2601/30000], Step [1/1], Training Loss: 50640.4805, Valid Loss: 1238.9520
Epoch [2701/30000], Step [1/1], Training Loss: 49138.7031, Valid Loss: 1471.2886
Epoch [2801/30000], Step [1/1], Training Loss: 47532.2930, Valid Loss: 1483.3655
Epoch [2901/30000], Step [1/1], Training Loss: 45990.3633, Valid Loss: 1218.6058
Epoch [3001/30000], Step [1/1], Training Loss: 44569.1641, Valid Loss: 1255.0289
Epoch [3101/30000], Step [1/1], Training Loss: 43199.7891, Valid Loss: 492.8173
Epoch [3201/30000], Step [1/1], Training Loss: 41746.2656, Valid Loss: 714.7115
Epoch [3301/30000], Step [1/1], Training Loss: 40393.8203, Valid Loss: 616.9327
Epoch [3401/30000], Step [1/1], Training Loss: 39027.9688, Valid Loss: 598.1442
Epoch [3501/30000], Step [1/1], Training Loss: 37880.7891, Valid Loss: 862.9231
Epoch [3601/30000], Step [1/1], Training Loss: 36545.8984, Valid Loss: 540.0385
Epoch [3701/30000], Step [1/1], Training Loss: 35415.9258, Valid Loss: 379.9135
Epoch [3801/30000], Step [1/1], Training Loss: 34334.5391, Valid Loss: 393.6346
Epoch [3901/30000], Step [1/1], Training Loss: 33301.0352, Valid Loss: 437.8365
Epoch [4001/30000], Step [1/1], Training Loss: 32307.8516, Valid Loss: 496.0962
Epoch [4101/30000], Step [1/1], Training Loss: 31353.2383, Valid Loss: 535.1346




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=11 	hidden_size=256 	layers=3

Start Time = 2021/04/19, 15:34:27
##########################################################


[Epoch 0] Rounded prediction: 
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([129., 129., 129., 129., 129., 129., 129., 129., 129., 129., 129., 129.,
        129., 129., 129., 129.,  81., 127.,  94., 101., 105.,  79.,  82.,  83.,
         68.,  50.,  43.,  64.,  58.,  50.,  61.,  52.,  47.,  53.,  51.,  46.,
         47.,  49.,  37.,  42.,  57.,  60.,  61.,  52.,  43.,  42.,  44.,  46.,
         49.,  49.,  49.,  59.,  56.,  63.,  56.,  51.,  46.,  52.,  67.,  46.,
         52.,  50.,  53.,  57.,  53.,  62.,  77.,  63.,  73.,  70.,  72.,  72.,
         76.,  82.,  63.,  74.,  69.,  65.,  68.,  74.,  73.,  77.,  72.,  84.,
         70.,  82., 107., 107.,  87.,  72., 129.,  82.,  71.,  72.,  81.,  82.,
         81.,  85.,  67.,  70.,  70.,  75., 104.,  94.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 130267.4297, Valid Loss: 232.5673
Epoch [101/30000], Step [1/1], Training Loss: 125434.7266, Valid Loss: 95.0673
Epoch [201/30000], Step [1/1], Training Loss: 124087.6875, Valid Loss: 92.8173
Epoch [301/30000], Step [1/1], Training Loss: 122850.2344, Valid Loss: 108.5673
Epoch [401/30000], Step [1/1], Training Loss: 121655.3359, Valid Loss: 142.3173
Epoch [501/30000], Step [1/1], Training Loss: 120499.8594, Valid Loss: 174.8173
Epoch [601/30000], Step [1/1], Training Loss: 119368.1953, Valid Loss: 238.5673
Epoch [701/30000], Step [1/1], Training Loss: 118256.0469, Valid Loss: 291.0673
Epoch [801/30000], Step [1/1], Training Loss: 117163.5547, Valid Loss: 384.8173
Epoch [901/30000], Step [1/1], Training Loss: 116087.7891, Valid Loss: 496.5673
Epoch [1001/30000], Step [1/1], Training Loss: 115029.5625, Valid Loss: 581.0673
Epoch [1101/30000], Step [1/1], Training Loss: 113986.8203, Valid Loss: 722.8173
Epoch [1201/30000], Step [1/1], Training Loss: 112958.7578, Valid Loss: 827.3173
Epoch [1301/30000], Step [1/1], Training Loss: 111945.7812, Valid Loss: 939.8173
Epoch [1401/30000], Step [1/1], Training Loss: 110948.3750, Valid Loss: 1123.5674
Epoch [1501/30000], Step [1/1], Training Loss: 109962.9219, Valid Loss: 1256.0674
Epoch [1601/30000], Step [1/1], Training Loss: 108991.1094, Valid Loss: 1469.8174
Epoch [1701/30000], Step [1/1], Training Loss: 108031.9844, Valid Loss: 1622.3174
Epoch [1801/30000], Step [1/1], Training Loss: 107084.8906, Valid Loss: 1866.0674
Epoch [1901/30000], Step [1/1], Training Loss: 106151.6797, Valid Loss: 2038.5674
Epoch [2001/30000], Step [1/1], Training Loss: 105228.5469, Valid Loss: 2312.3174
Epoch [2101/30000], Step [1/1], Training Loss: 104317.0234, Valid Loss: 2504.8174
Epoch [2201/30000], Step [1/1], Training Loss: 103417.7500, Valid Loss: 2705.3174
Epoch [2301/30000], Step [1/1], Training Loss: 102525.2578, Valid Loss: 1912.4905
Epoch [2401/30000], Step [1/1], Training Loss: 101642.6719, Valid Loss: 1830.8270
Epoch [2501/30000], Step [1/1], Training Loss: 100770.5078, Valid Loss: 1923.2212
Epoch [2601/30000], Step [1/1], Training Loss: 99909.2500, Valid Loss: 2215.2117
Epoch [2701/30000], Step [1/1], Training Loss: 99058.1562, Valid Loss: 2524.9041
Epoch [2801/30000], Step [1/1], Training Loss: 98218.2109, Valid Loss: 2803.0000
Epoch [2901/30000], Step [1/1], Training Loss: 97386.9609, Valid Loss: 3245.0481
Epoch [3001/30000], Step [1/1], Training Loss: 96564.8281, Valid Loss: 3485.8752
Epoch [3101/30000], Step [1/1], Training Loss: 95755.6328, Valid Loss: 3751.3271
Epoch [3201/30000], Step [1/1], Training Loss: 94953.9375, Valid Loss: 3938.0291
Epoch [3301/30000], Step [1/1], Training Loss: 94164.6875, Valid Loss: 4183.5771
Epoch [3401/30000], Step [1/1], Training Loss: 93381.9609, Valid Loss: 4665.7598
Epoch [3501/30000], Step [1/1], Training Loss: 92611.5391, Valid Loss: 4844.2021
Epoch [3601/30000], Step [1/1], Training Loss: 91851.5859, Valid Loss: 5128.5288
Epoch [3701/30000], Step [1/1], Training Loss: 91098.2188, Valid Loss: 5577.2212
Epoch [3801/30000], Step [1/1], Training Loss: 90353.2031, Valid Loss: 5820.8848
Epoch [3901/30000], Step [1/1], Training Loss: 89619.6641, Valid Loss: 5815.0098
Epoch [4001/30000], Step [1/1], Training Loss: 88895.5859, Valid Loss: 6036.6250
Epoch [4101/30000], Step [1/1], Training Loss: 88180.4062, Valid Loss: 6591.7212
Epoch [4201/30000], Step [1/1], Training Loss: 87475.6875, Valid Loss: 6959.5674
Epoch [4301/30000], Step [1/1], Training Loss: 86779.4453, Valid Loss: 7102.8560
Epoch [4401/30000], Step [1/1], Training Loss: 86090.1797, Valid Loss: 7299.1348
Epoch [4501/30000], Step [1/1], Training Loss: 85410.9297, Valid Loss: 7765.4907
Epoch [4601/30000], Step [1/1], Training Loss: 84742.8906, Valid Loss: 7879.4810
Epoch [4701/30000], Step [1/1], Training Loss: 84080.1016, Valid Loss: 8309.3564
Epoch [4801/30000], Step [1/1], Training Loss: 83429.7891, Valid Loss: 8295.6641
Epoch [4901/30000], Step [1/1], Training Loss: 82785.3438, Valid Loss: 8138.1636
Epoch [5001/30000], Step [1/1], Training Loss: 82137.6016, Valid Loss: 5069.6924
Epoch [5101/30000], Step [1/1], Training Loss: 81506.1016, Valid Loss: 4847.0674
Epoch [5201/30000], Step [1/1], Training Loss: 80884.2969, Valid Loss: 4857.0581
Epoch [5301/30000], Step [1/1], Training Loss: 80272.5938, Valid Loss: 4985.4331
Epoch [5401/30000], Step [1/1], Training Loss: 79669.7891, Valid Loss: 4970.6538
Epoch [5501/30000], Step [1/1], Training Loss: 79073.9766, Valid Loss: 4960.5195
Epoch [5601/30000], Step [1/1], Training Loss: 78488.2188, Valid Loss: 4996.9619
Epoch [5701/30000], Step [1/1], Training Loss: 77911.4219, Valid Loss: 5187.4136
Epoch [5801/30000], Step [1/1], Training Loss: 77343.0000, Valid Loss: 5239.2983
Epoch [5901/30000], Step [1/1], Training Loss: 76782.5625, Valid Loss: 5321.0000




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=11 	hidden_size=512 	layers=3

Start Time = 2021/04/19, 15:40:36
##########################################################


[Epoch 0] Rounded prediction: 
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],
       device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([18., 16., 17.,  6.,  7.,  8.,  7.,  6.,  6.,  0.,  0.,  0.,  0.,  0.,
         0.,  0.,  0.,  0.,  0., 10., 15., 19., 23., 17.,  3.,  3.,  2.,  5.,
         5.,  7.,  5.,  1.,  0.,  6.,  6.,  2.,  3.,  0.,  0.,  3., 19., 18.,
        14.,  5.,  2.,  0.,  1.,  2.,  1.,  0.,  0.,  3.,  5., 14., 13.,  5.,
         4.,  2.,  5.,  3.,  5.,  8.,  6.,  5., 12., 10., 13., 17., 15., 10.,
         2.,  6.,  4.,  0.,  1.,  9., 29., 37., 34., 37., 30., 31., 36., 47.,
        50., 12.,  0.,  0.,  0.,  0., 14., 44., 62., 57., 45., 40., 29., 42.,
        63., 43., 37., 43., 43., 35.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([14., 25., 21., 22., 19., 16., 19., 12., 21.,  9., 20., 23., 14., 16.,
        13.,  9., 24., 65., 97., 63., 67., 69., 14., 10.,  4.,  1.,  0.,  4.,
         0.,  3.,  4.,  6.,  1.,  0.,  1.,  0.,  0.,  2.,  0.,  0., 13., 18.,
        12., 10.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 12.,  7.,  7.,
         5.,  3.,  1.,  0.,  1.,  3.,  5.,  3.,  2.,  6., 10., 11., 16., 14.,
         3.,  0.,  0.,  0.,  0.,  0., 11., 28., 20., 25., 23., 23., 25., 23.,
        17.,  9.,  0.,  0.,  0.,  0.,  1., 36., 44., 57., 37., 31., 41., 42.,
        39., 41., 41., 40., 38., 16.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 130241.8438, Valid Loss: 231.0000
Epoch [101/30000], Step [1/1], Training Loss: 122719.2656, Valid Loss: 108.5673
Epoch [201/30000], Step [1/1], Training Loss: 120303.5312, Valid Loss: 194.0673
Epoch [301/30000], Step [1/1], Training Loss: 118029.6406, Valid Loss: 320.3173
Epoch [401/30000], Step [1/1], Training Loss: 115846.3359, Valid Loss: 496.5673
Epoch [501/30000], Step [1/1], Training Loss: 113737.1406, Valid Loss: 722.8173
Epoch [601/30000], Step [1/1], Training Loss: 111697.1719, Valid Loss: 999.0673
Epoch [701/30000], Step [1/1], Training Loss: 109718.2500, Valid Loss: 1325.3174
Epoch [801/30000], Step [1/1], Training Loss: 107795.1328, Valid Loss: 1701.5674
Epoch [901/30000], Step [1/1], Training Loss: 105929.0391, Valid Loss: 2127.8174
Epoch [1001/30000], Step [1/1], Training Loss: 104113.0859, Valid Loss: 2487.7117
Epoch [1101/30000], Step [1/1], Training Loss: 102344.6406, Valid Loss: 1661.7693
Epoch [1201/30000], Step [1/1], Training Loss: 100620.0312, Valid Loss: 1828.6636
Epoch [1301/30000], Step [1/1], Training Loss: 98945.6484, Valid Loss: 1942.5096
Epoch [1401/30000], Step [1/1], Training Loss: 97311.3828, Valid Loss: 2141.2981
Epoch [1501/30000], Step [1/1], Training Loss: 95721.4609, Valid Loss: 2353.7598
Epoch [1601/30000], Step [1/1], Training Loss: 94174.6875, Valid Loss: 2456.2405
Epoch [1701/30000], Step [1/1], Training Loss: 92670.4609, Valid Loss: 2706.9424
Epoch [1801/30000], Step [1/1], Training Loss: 91207.1172, Valid Loss: 3049.1636
Epoch [1901/30000], Step [1/1], Training Loss: 89780.6953, Valid Loss: 3454.9617
Epoch [2001/30000], Step [1/1], Training Loss: 88394.4453, Valid Loss: 3941.0291
Epoch [2101/30000], Step [1/1], Training Loss: 87047.8828, Valid Loss: 4201.1250
Epoch [2201/30000], Step [1/1], Training Loss: 85739.3047, Valid Loss: 4325.6733
Epoch [2301/30000], Step [1/1], Training Loss: 84466.6562, Valid Loss: 4637.7788
Epoch [2401/30000], Step [1/1], Training Loss: 83231.3203, Valid Loss: 4813.8369
Epoch [2501/30000], Step [1/1], Training Loss: 82022.5938, Valid Loss: 3711.4136
Epoch [2601/30000], Step [1/1], Training Loss: 80845.4062, Valid Loss: 2797.8750
Epoch [2701/30000], Step [1/1], Training Loss: 79709.2188, Valid Loss: 3077.8079
Epoch [2801/30000], Step [1/1], Training Loss: 78605.7188, Valid Loss: 3285.6731
Epoch [2901/30000], Step [1/1], Training Loss: 77538.2344, Valid Loss: 3273.8271
Epoch [3001/30000], Step [1/1], Training Loss: 76501.4453, Valid Loss: 3337.2981
Epoch [3101/30000], Step [1/1], Training Loss: 75498.1562, Valid Loss: 3502.2886
Epoch [3201/30000], Step [1/1], Training Loss: 74525.9766, Valid Loss: 3595.8560
Epoch [3301/30000], Step [1/1], Training Loss: 73586.1172, Valid Loss: 3883.0579
Epoch [3401/30000], Step [1/1], Training Loss: 72676.0391, Valid Loss: 4071.2886
Epoch [3501/30000], Step [1/1], Training Loss: 71798.1641, Valid Loss: 4048.0291
Epoch [3601/30000], Step [1/1], Training Loss: 70947.4531, Valid Loss: 4155.0576
Epoch [3701/30000], Step [1/1], Training Loss: 70125.1797, Valid Loss: 4392.2310
Epoch [3801/30000], Step [1/1], Training Loss: 69335.3672, Valid Loss: 4895.0771
Epoch [3901/30000], Step [1/1], Training Loss: 68571.5078, Valid Loss: 4810.3081
Epoch [4001/30000], Step [1/1], Training Loss: 67837.4375, Valid Loss: 5312.1348
Epoch [4101/30000], Step [1/1], Training Loss: 67130.6875, Valid Loss: 5268.3848
Epoch [4201/30000], Step [1/1], Training Loss: 66451.1719, Valid Loss: 5705.6250
Epoch [4301/30000], Step [1/1], Training Loss: 65800.0000, Valid Loss: 5793.6831
Epoch [4401/30000], Step [1/1], Training Loss: 65173.8516, Valid Loss: 5903.8462
Epoch [4501/30000], Step [1/1], Training Loss: 64573.2773, Valid Loss: 6424.2119
Epoch [4601/30000], Step [1/1], Training Loss: 64000.3438, Valid Loss: 6620.9907
Epoch [4701/30000], Step [1/1], Training Loss: 63451.3867, Valid Loss: 6707.4907
Epoch [4801/30000], Step [1/1], Training Loss: 56121.8008, Valid Loss: 403.9615
Epoch [4901/30000], Step [1/1], Training Loss: 54867.3789, Valid Loss: 189.0481
Epoch [5001/30000], Step [1/1], Training Loss: 53788.6836, Valid Loss: 152.7115
Epoch [5101/30000], Step [1/1], Training Loss: 52539.3828, Valid Loss: 167.2981
Epoch [5201/30000], Step [1/1], Training Loss: 51397.7188, Valid Loss: 188.6539
Epoch [5301/30000], Step [1/1], Training Loss: 50378.3750, Valid Loss: 145.0289
Epoch [5401/30000], Step [1/1], Training Loss: 49347.6602, Valid Loss: 140.8846
Epoch [5501/30000], Step [1/1], Training Loss: 48414.9648, Valid Loss: 155.6058
Epoch [5601/30000], Step [1/1], Training Loss: 47478.3359, Valid Loss: 155.9519
Epoch [5701/30000], Step [1/1], Training Loss: 46506.2188, Valid Loss: 182.0481
Epoch [5801/30000], Step [1/1], Training Loss: 45616.0586, Valid Loss: 130.5577
Epoch [5901/30000], Step [1/1], Training Loss: 44719.1602, Valid Loss: 127.2308
Epoch [6001/30000], Step [1/1], Training Loss: 43862.5781, Valid Loss: 156.1250
Epoch [6101/30000], Step [1/1], Training Loss: 43151.5078, Valid Loss: 142.8846
Epoch [6201/30000], Step [1/1], Training Loss: 42369.8672, Valid Loss: 128.2212
Epoch [6301/30000], Step [1/1], Training Loss: 41655.5977, Valid Loss: 131.2404
Epoch [6401/30000], Step [1/1], Training Loss: 41420.5508, Valid Loss: 136.7404
Epoch [6501/30000], Step [1/1], Training Loss: 40121.0352, Valid Loss: 136.7500
Epoch [6601/30000], Step [1/1], Training Loss: 39304.1016, Valid Loss: 145.6731
Epoch [6701/30000], Step [1/1], Training Loss: 38706.9258, Valid Loss: 164.3462
Epoch [6801/30000], Step [1/1], Training Loss: 37862.6875, Valid Loss: 200.0577
Epoch [6901/30000], Step [1/1], Training Loss: 38579.5586, Valid Loss: 161.3269
Epoch [7001/30000], Step [1/1], Training Loss: 36364.1641, Valid Loss: 170.1635
Epoch [7101/30000], Step [1/1], Training Loss: 35723.1719, Valid Loss: 142.3462
Epoch [7201/30000], Step [1/1], Training Loss: 35276.2578, Valid Loss: 153.2404
Epoch [7301/30000], Step [1/1], Training Loss: 34338.2773, Valid Loss: 130.8558
Epoch [7401/30000], Step [1/1], Training Loss: 33610.5977, Valid Loss: 156.0385
Epoch [7501/30000], Step [1/1], Training Loss: 32965.4023, Valid Loss: 150.4904
Epoch [7601/30000], Step [1/1], Training Loss: 32653.6855, Valid Loss: 131.5481
Epoch [7701/30000], Step [1/1], Training Loss: 31785.0293, Valid Loss: 182.5481
Epoch [7801/30000], Step [1/1], Training Loss: 31166.8926, Valid Loss: 195.7212
Epoch [7901/30000], Step [1/1], Training Loss: 30364.6992, Valid Loss: 169.1154
Epoch [8001/30000], Step [1/1], Training Loss: 29692.5625, Valid Loss: 161.7212
Epoch [8101/30000], Step [1/1], Training Loss: 29093.7734, Valid Loss: 162.6539
Epoch [8201/30000], Step [1/1], Training Loss: 28495.3926, Valid Loss: 157.1154
Epoch [8301/30000], Step [1/1], Training Loss: 27942.2246, Valid Loss: 164.7981
Epoch [8401/30000], Step [1/1], Training Loss: 27401.1191, Valid Loss: 141.3269
Epoch [8501/30000], Step [1/1], Training Loss: 26867.8848, Valid Loss: 153.4712
Epoch [8601/30000], Step [1/1], Training Loss: 26335.3750, Valid Loss: 220.3462
Epoch [8701/30000], Step [1/1], Training Loss: 25824.7324, Valid Loss: 181.5673
Epoch [8801/30000], Step [1/1], Training Loss: 25358.2422, Valid Loss: 248.1154
Epoch [8901/30000], Step [1/1], Training Loss: 24860.1523, Valid Loss: 234.3558
Epoch [9001/30000], Step [1/1], Training Loss: 24387.5293, Valid Loss: 238.7500
Epoch [9101/30000], Step [1/1], Training Loss: 23923.8301, Valid Loss: 236.0385
Epoch [9201/30000], Step [1/1], Training Loss: 23467.1191, Valid Loss: 318.5481
Epoch [9301/30000], Step [1/1], Training Loss: 23235.3223, Valid Loss: 282.4808
Epoch [9401/30000], Step [1/1], Training Loss: 22624.9316, Valid Loss: 212.8654
Epoch [9501/30000], Step [1/1], Training Loss: 22195.5781, Valid Loss: 296.7596
Epoch [9601/30000], Step [1/1], Training Loss: 21751.2422, Valid Loss: 400.1250
Epoch [9701/30000], Step [1/1], Training Loss: 21283.5371, Valid Loss: 402.4423
Epoch [9801/30000], Step [1/1], Training Loss: 20785.5078, Valid Loss: 395.8750
Epoch [9901/30000], Step [1/1], Training Loss: 20446.2324, Valid Loss: 248.3750
Epoch [10001/30000], Step [1/1], Training Loss: 20005.8418, Valid Loss: 312.2693

[Epoch 15000] Rounded prediction: 
tensor([ 14.,  26.,  22.,  21.,  26.,  25.,  22.,  27.,  21.,  23.,  26.,  29.,
         27.,  22.,  19.,  27.,  57., 110., 158., 184., 171., 104.,  96.,  27.,
         11.,   6.,   7.,   9.,   8.,  10.,  11.,   9.,   7.,   7.,   6.,   8.,
          7.,   6.,   5.,   5.,  17.,  17.,  13.,  11.,   9.,   6.,   5.,   7.,
         11.,  12.,  10.,   6.,   7.,  13.,  13.,   9.,  10.,   7.,   5.,   7.,
          7.,  11.,  10.,  10.,   8.,  14.,  14.,  17.,  19.,  20.,  12.,  17.,
         13.,  19.,   7.,  10.,  18.,  24.,  23.,  28.,  29.,  25.,  27.,  24.,
         18.,  17.,  27.,  34.,   9.,   5.,  33.,  52.,  48., 132.,  74.,  34.,
         35.,  41.,  43.,  39.,  43.,  36.,  37.,  42.], device='cuda:0')
Target: 
tensor([ 6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,  9.,
         3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,  9.,
        12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11., 12.,
         2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,  4.,
         6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,  8.,
         8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13., 14.,
        10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33., 23.,
        29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [10101/30000], Step [1/1], Training Loss: 19606.9863, Valid Loss: 457.9519
Epoch [10201/30000], Step [1/1], Training Loss: 19198.0117, Valid Loss: 321.9135
Epoch [10301/30000], Step [1/1], Training Loss: 18689.4414, Valid Loss: 398.0865
Epoch [10401/30000], Step [1/1], Training Loss: 18308.7402, Valid Loss: 325.4135
Epoch [10501/30000], Step [1/1], Training Loss: 17939.9805, Valid Loss: 442.8365
Epoch [10601/30000], Step [1/1], Training Loss: 17580.8438, Valid Loss: 376.9904
Epoch [10701/30000], Step [1/1], Training Loss: 17229.6016, Valid Loss: 377.7115
Epoch [10801/30000], Step [1/1], Training Loss: 16866.7383, Valid Loss: 413.0385
Epoch [10901/30000], Step [1/1], Training Loss: 17056.3184, Valid Loss: 345.7212
Epoch [11001/30000], Step [1/1], Training Loss: 16287.0410, Valid Loss: 546.2020
Epoch [11101/30000], Step [1/1], Training Loss: 15900.8115, Valid Loss: 468.8462
Epoch [11201/30000], Step [1/1], Training Loss: 15576.5732, Valid Loss: 778.6731
Epoch [11301/30000], Step [1/1], Training Loss: 15253.1865, Valid Loss: 674.0673
Epoch [11401/30000], Step [1/1], Training Loss: 14950.3916, Valid Loss: 618.4712
Epoch [11501/30000], Step [1/1], Training Loss: 14654.2383, Valid Loss: 441.4808
Epoch [11601/30000], Step [1/1], Training Loss: 14371.1777, Valid Loss: 646.1250
Epoch [11701/30000], Step [1/1], Training Loss: 14078.7490, Valid Loss: 636.8270
Epoch [11801/30000], Step [1/1], Training Loss: 13809.8818, Valid Loss: 671.6058
Epoch [11901/30000], Step [1/1], Training Loss: 13541.0479, Valid Loss: 626.2020
Epoch [12001/30000], Step [1/1], Training Loss: 13278.4502, Valid Loss: 746.9904
Epoch [12101/30000], Step [1/1], Training Loss: 13143.6338, Valid Loss: 517.7596
Epoch [12201/30000], Step [1/1], Training Loss: 12460.1484, Valid Loss: 704.3365
Epoch [12301/30000], Step [1/1], Training Loss: 12185.4170, Valid Loss: 846.9135
Epoch [12401/30000], Step [1/1], Training Loss: 11919.3135, Valid Loss: 845.3558
Epoch [12501/30000], Step [1/1], Training Loss: 11697.6865, Valid Loss: 753.0385
Epoch [12601/30000], Step [1/1], Training Loss: 11419.7373, Valid Loss: 1167.5962
Epoch [12701/30000], Step [1/1], Training Loss: 11179.5596, Valid Loss: 1200.7981
Epoch [12801/30000], Step [1/1], Training Loss: 10944.3105, Valid Loss: 1394.8655
Epoch [12901/30000], Step [1/1], Training Loss: 10714.0918, Valid Loss: 1453.0770
Epoch [13001/30000], Step [1/1], Training Loss: 10495.4023, Valid Loss: 1412.2789
Epoch [13101/30000], Step [1/1], Training Loss: 10274.2207, Valid Loss: 1336.2115
Epoch [13201/30000], Step [1/1], Training Loss: 10061.2588, Valid Loss: 1319.7981
Epoch [13301/30000], Step [1/1], Training Loss: 9854.8184, Valid Loss: 1384.5193
Epoch [13401/30000], Step [1/1], Training Loss: 9653.3799, Valid Loss: 1413.6539
Epoch [13501/30000], Step [1/1], Training Loss: 9456.1982, Valid Loss: 1156.9424
Epoch [13601/30000], Step [1/1], Training Loss: 9264.9209, Valid Loss: 1515.0193
Epoch [13701/30000], Step [1/1], Training Loss: 9077.7617, Valid Loss: 1257.7020
Epoch [13801/30000], Step [1/1], Training Loss: 8897.5557, Valid Loss: 1477.5096
Epoch [13901/30000], Step [1/1], Training Loss: 8715.3340, Valid Loss: 1358.0770
Epoch [14001/30000], Step [1/1], Training Loss: 8829.8633, Valid Loss: 1553.6346
Epoch [14101/30000], Step [1/1], Training Loss: 8406.5488, Valid Loss: 1787.2981
Epoch [14201/30000], Step [1/1], Training Loss: 8219.4863, Valid Loss: 1643.6539
Epoch [14301/30000], Step [1/1], Training Loss: 8050.1357, Valid Loss: 1510.7981
Epoch [14401/30000], Step [1/1], Training Loss: 7889.4707, Valid Loss: 1239.4327
Epoch [14501/30000], Step [1/1], Training Loss: 7724.7642, Valid Loss: 1246.6827
Epoch [14601/30000], Step [1/1], Training Loss: 7400.7114, Valid Loss: 1436.5193
Epoch [14701/30000], Step [1/1], Training Loss: 7168.6069, Valid Loss: 1459.0577
Epoch [14801/30000], Step [1/1], Training Loss: 6963.1011, Valid Loss: 1165.0962
Epoch [14901/30000], Step [1/1], Training Loss: 6785.6860, Valid Loss: 1477.5865
Epoch [15001/30000], Step [1/1], Training Loss: 6617.9990, Valid Loss: 1287.4520
Epoch [15101/30000], Step [1/1], Training Loss: 6551.9531, Valid Loss: 1379.9135
Epoch [15201/30000], Step [1/1], Training Loss: 6311.8643, Valid Loss: 1246.3750
Epoch [15301/30000], Step [1/1], Training Loss: 6149.6621, Valid Loss: 1323.9327
Epoch [15401/30000], Step [1/1], Training Loss: 5997.5127, Valid Loss: 1647.9136
Epoch [15501/30000], Step [1/1], Training Loss: 5850.9883, Valid Loss: 1252.0770
Epoch [15601/30000], Step [1/1], Training Loss: 5711.4722, Valid Loss: 1515.6924
Epoch [15701/30000], Step [1/1], Training Loss: 5571.7251, Valid Loss: 1636.6924
Epoch [15801/30000], Step [1/1], Training Loss: 5437.8701, Valid Loss: 1534.1155
Epoch [15901/30000], Step [1/1], Training Loss: 5302.7817, Valid Loss: 1688.1346
Epoch [16001/30000], Step [1/1], Training Loss: 5174.1138, Valid Loss: 1426.8174
Epoch [16101/30000], Step [1/1], Training Loss: 5049.1045, Valid Loss: 1552.5000
Epoch [16201/30000], Step [1/1], Training Loss: 4924.4580, Valid Loss: 1614.6250
Epoch [16301/30000], Step [1/1], Training Loss: 4805.1260, Valid Loss: 1528.0865
Epoch [16401/30000], Step [1/1], Training Loss: 4686.5654, Valid Loss: 1595.1731
Epoch [16501/30000], Step [1/1], Training Loss: 4575.2451, Valid Loss: 1446.3270
Epoch [16601/30000], Step [1/1], Training Loss: 4461.0698, Valid Loss: 1776.6346
Epoch [16701/30000], Step [1/1], Training Loss: 4353.6421, Valid Loss: 1787.9905
Epoch [16801/30000], Step [1/1], Training Loss: 4246.9917, Valid Loss: 1447.2981
Epoch [16901/30000], Step [1/1], Training Loss: 4144.4951, Valid Loss: 1809.8558
Epoch [17001/30000], Step [1/1], Training Loss: 4044.1597, Valid Loss: 1580.4520
Epoch [17101/30000], Step [1/1], Training Loss: 3945.9121, Valid Loss: 1788.5193
Epoch [17201/30000], Step [1/1], Training Loss: 3851.9438, Valid Loss: 1490.2405
Epoch [17301/30000], Step [1/1], Training Loss: 3759.7358, Valid Loss: 1422.0481
Epoch [17401/30000], Step [1/1], Training Loss: 3671.5388, Valid Loss: 1626.8365
Epoch [17501/30000], Step [1/1], Training Loss: 3580.4907, Valid Loss: 1430.5865
Epoch [17601/30000], Step [1/1], Training Loss: 3494.1917, Valid Loss: 1463.7020
Epoch [17701/30000], Step [1/1], Training Loss: 3409.7378, Valid Loss: 1591.8174
Epoch [17801/30000], Step [1/1], Training Loss: 3328.7817, Valid Loss: 1614.2789
Epoch [17901/30000], Step [1/1], Training Loss: 3246.9497, Valid Loss: 1598.2500
Epoch [18001/30000], Step [1/1], Training Loss: 3170.8462, Valid Loss: 1408.9039
Epoch [18101/30000], Step [1/1], Training Loss: 3090.2349, Valid Loss: 1691.7789
Epoch [18201/30000], Step [1/1], Training Loss: 3015.4434, Valid Loss: 1522.5481
Epoch [18301/30000], Step [1/1], Training Loss: 2942.2698, Valid Loss: 1426.7596
Epoch [18401/30000], Step [1/1], Training Loss: 2870.3188, Valid Loss: 1647.8077
Epoch [18501/30000], Step [1/1], Training Loss: 2803.6077, Valid Loss: 1592.4615
Epoch [18601/30000], Step [1/1], Training Loss: 2732.2817, Valid Loss: 1610.2886
Epoch [18701/30000], Step [1/1], Training Loss: 2664.3721, Valid Loss: 1629.1250




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=512 	layers=3

Start Time = 2021/04/19, 15:47:11
##########################################################


[Epoch 0] Rounded prediction: 
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([24., 22., 26., 21., 25., 22., 20., 22., 19., 21., 21., 20., 22., 21.,
        20., 15., 16., 17., 12., 16., 15., 17., 17., 19., 18., 14., 15., 14.,
        16., 16., 17., 15., 12., 15., 13., 14., 13., 14., 11., 15., 12., 21.,
        22., 21., 16., 13., 12., 14., 13., 13., 13., 14., 17., 14., 21., 19.,
        15., 14., 15., 15., 14., 17., 13., 16., 14., 18., 16., 18., 16., 20.,
        18., 20., 16., 17., 19., 18., 16., 27., 21., 22., 22., 20., 31., 22.,
        23., 22., 24., 30., 27., 17., 22., 34., 36., 41., 38., 23., 29., 32.,
        33., 37., 41., 35., 35., 37., 44.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([20., 22., 29., 18., 21., 20., 17., 20., 17., 21., 17., 21., 24., 18.,
        19., 14., 18., 17., 11., 16., 10., 18., 18., 15., 21., 14., 15., 12.,
        16., 14., 17., 17., 15., 14., 10., 17., 14., 14., 12., 14.,  9., 26.,
        21., 21., 18., 13., 12., 12., 15., 15., 14., 14., 14., 17., 22., 17.,
        14., 17., 11., 14., 15., 16., 16., 17., 14., 19., 14., 21., 13., 23.,
        17., 16., 16., 18., 19., 15., 17., 33., 21., 22., 21., 23., 30., 28.,
        22., 20., 25., 26., 23., 13., 25., 40., 43., 44., 38., 28., 29., 34.,
        32., 34., 35., 42., 29., 28., 44.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128674.8984, Valid Loss: 231.3048
Epoch [101/30000], Step [1/1], Training Loss: 121266.5859, Valid Loss: 107.8762
Epoch [201/30000], Step [1/1], Training Loss: 118873.1328, Valid Loss: 193.5905
Epoch [301/30000], Step [1/1], Training Loss: 116621.5469, Valid Loss: 320.0191
Epoch [401/30000], Step [1/1], Training Loss: 114462.0000, Valid Loss: 496.4476
Epoch [501/30000], Step [1/1], Training Loss: 112375.2109, Valid Loss: 722.8762
Epoch [601/30000], Step [1/1], Training Loss: 110355.1641, Valid Loss: 999.3048
Epoch [701/30000], Step [1/1], Training Loss: 108397.0234, Valid Loss: 1325.7334
Epoch [801/30000], Step [1/1], Training Loss: 106494.9844, Valid Loss: 1702.1620
Epoch [901/30000], Step [1/1], Training Loss: 104647.9141, Valid Loss: 2128.5906
Epoch [1001/30000], Step [1/1], Training Loss: 102851.3594, Valid Loss: 2492.2764
Epoch [1101/30000], Step [1/1], Training Loss: 101097.8594, Valid Loss: 1573.6191
Epoch [1201/30000], Step [1/1], Training Loss: 99392.0703, Valid Loss: 1893.2001
Epoch [1301/30000], Step [1/1], Training Loss: 97729.3281, Valid Loss: 2601.9714
Epoch [1401/30000], Step [1/1], Training Loss: 96113.8594, Valid Loss: 3179.1716
Epoch [1501/30000], Step [1/1], Training Loss: 94538.1719, Valid Loss: 3736.1050
Epoch [1601/30000], Step [1/1], Training Loss: 93004.9453, Valid Loss: 3526.9622
Epoch [1701/30000], Step [1/1], Training Loss: 91511.0547, Valid Loss: 3993.1050
Epoch [1801/30000], Step [1/1], Training Loss: 90056.4922, Valid Loss: 3833.1050
Epoch [1901/30000], Step [1/1], Training Loss: 88642.5469, Valid Loss: 4185.0669
Epoch [2001/30000], Step [1/1], Training Loss: 87267.3281, Valid Loss: 4209.4858
Epoch [2101/30000], Step [1/1], Training Loss: 85928.0625, Valid Loss: 4297.2476
Epoch [2201/30000], Step [1/1], Training Loss: 84629.3359, Valid Loss: 4120.7432
Epoch [2301/30000], Step [1/1], Training Loss: 83363.2031, Valid Loss: 4442.9429
Epoch [2401/30000], Step [1/1], Training Loss: 82134.8516, Valid Loss: 4183.3906
Epoch [2501/30000], Step [1/1], Training Loss: 79433.0234, Valid Loss: 278.8953
Epoch [2601/30000], Step [1/1], Training Loss: 77896.3984, Valid Loss: 215.5333
Epoch [2701/30000], Step [1/1], Training Loss: 76452.0078, Valid Loss: 171.0000
Epoch [2801/30000], Step [1/1], Training Loss: 75048.6953, Valid Loss: 151.8571
Epoch [2901/30000], Step [1/1], Training Loss: 73687.4453, Valid Loss: 205.9048
Epoch [3001/30000], Step [1/1], Training Loss: 72364.1484, Valid Loss: 197.8762
Epoch [3101/30000], Step [1/1], Training Loss: 71060.6094, Valid Loss: 228.7429
Epoch [3201/30000], Step [1/1], Training Loss: 69791.4688, Valid Loss: 218.1810
Epoch [3301/30000], Step [1/1], Training Loss: 68558.1641, Valid Loss: 202.5714
Epoch [3401/30000], Step [1/1], Training Loss: 67346.0859, Valid Loss: 213.0191
Epoch [3501/30000], Step [1/1], Training Loss: 66162.0703, Valid Loss: 209.1810
Epoch [3601/30000], Step [1/1], Training Loss: 65004.9297, Valid Loss: 188.9143
Epoch [3701/30000], Step [1/1], Training Loss: 63875.9141, Valid Loss: 184.4286
Epoch [3801/30000], Step [1/1], Training Loss: 62769.6016, Valid Loss: 190.8762
Epoch [3901/30000], Step [1/1], Training Loss: 61686.5234, Valid Loss: 170.1429
Epoch [4001/30000], Step [1/1], Training Loss: 60634.3164, Valid Loss: 185.7143
Epoch [4101/30000], Step [1/1], Training Loss: 59584.6836, Valid Loss: 201.0571
Epoch [4201/30000], Step [1/1], Training Loss: 58540.4414, Valid Loss: 165.7714
Epoch [4301/30000], Step [1/1], Training Loss: 57486.2344, Valid Loss: 138.1143
Epoch [4401/30000], Step [1/1], Training Loss: 56474.0312, Valid Loss: 157.5143
Epoch [4501/30000], Step [1/1], Training Loss: 55488.9688, Valid Loss: 118.5143
Epoch [4601/30000], Step [1/1], Training Loss: 54513.8203, Valid Loss: 111.1619
Epoch [4701/30000], Step [1/1], Training Loss: 53570.2539, Valid Loss: 127.0762
Epoch [4801/30000], Step [1/1], Training Loss: 52651.5039, Valid Loss: 137.7810
Epoch [4901/30000], Step [1/1], Training Loss: 51745.7500, Valid Loss: 140.8190
Epoch [5001/30000], Step [1/1], Training Loss: 50859.4766, Valid Loss: 112.8000
Epoch [5101/30000], Step [1/1], Training Loss: 49971.9805, Valid Loss: 125.3333
Epoch [5201/30000], Step [1/1], Training Loss: 48975.6875, Valid Loss: 101.1524
Epoch [5301/30000], Step [1/1], Training Loss: 48113.4688, Valid Loss: 110.7238
Epoch [5401/30000], Step [1/1], Training Loss: 47273.0273, Valid Loss: 122.7238
Epoch [5501/30000], Step [1/1], Training Loss: 46456.6055, Valid Loss: 96.9143
Epoch [5601/30000], Step [1/1], Training Loss: 45643.1914, Valid Loss: 117.3905
Epoch [5701/30000], Step [1/1], Training Loss: 44823.3750, Valid Loss: 123.1143
Epoch [5801/30000], Step [1/1], Training Loss: 44027.6289, Valid Loss: 104.7714
Epoch [5901/30000], Step [1/1], Training Loss: 43219.9805, Valid Loss: 115.5333
Epoch [6001/30000], Step [1/1], Training Loss: 42361.0234, Valid Loss: 118.9810
Epoch [6101/30000], Step [1/1], Training Loss: 41474.8398, Valid Loss: 114.0952
Epoch [6201/30000], Step [1/1], Training Loss: 40711.5117, Valid Loss: 106.0476
Epoch [6301/30000], Step [1/1], Training Loss: 39969.5234, Valid Loss: 127.8857
Epoch [6401/30000], Step [1/1], Training Loss: 39288.2227, Valid Loss: 120.0571
Epoch [6501/30000], Step [1/1], Training Loss: 38509.1797, Valid Loss: 114.5333
Epoch [6601/30000], Step [1/1], Training Loss: 37801.5000, Valid Loss: 105.7048
Epoch [6701/30000], Step [1/1], Training Loss: 37118.6172, Valid Loss: 102.7333
Epoch [6801/30000], Step [1/1], Training Loss: 36451.0742, Valid Loss: 97.9714
Epoch [6901/30000], Step [1/1], Training Loss: 35799.0469, Valid Loss: 114.0286
Epoch [7001/30000], Step [1/1], Training Loss: 35162.2969, Valid Loss: 108.8095
Epoch [7101/30000], Step [1/1], Training Loss: 34527.7344, Valid Loss: 115.9048
Epoch [7201/30000], Step [1/1], Training Loss: 33985.9336, Valid Loss: 126.5333
Epoch [7301/30000], Step [1/1], Training Loss: 33226.0078, Valid Loss: 130.2095
Epoch [7401/30000], Step [1/1], Training Loss: 32684.4824, Valid Loss: 99.5429
Epoch [7501/30000], Step [1/1], Training Loss: 31974.0000, Valid Loss: 116.4000
Epoch [7601/30000], Step [1/1], Training Loss: 31361.1309, Valid Loss: 129.7143
Epoch [7701/30000], Step [1/1], Training Loss: 30762.8477, Valid Loss: 126.1810
Epoch [7801/30000], Step [1/1], Training Loss: 30167.0293, Valid Loss: 129.0952
Epoch [7901/30000], Step [1/1], Training Loss: 29588.3574, Valid Loss: 130.8571
Epoch [8001/30000], Step [1/1], Training Loss: 29075.4883, Valid Loss: 144.4667
Epoch [8101/30000], Step [1/1], Training Loss: 28473.1914, Valid Loss: 137.7429
Epoch [8201/30000], Step [1/1], Training Loss: 27928.8301, Valid Loss: 127.7905
Epoch [8301/30000], Step [1/1], Training Loss: 27395.6152, Valid Loss: 119.8476
Epoch [8401/30000], Step [1/1], Training Loss: 26876.0625, Valid Loss: 120.7048
Epoch [8501/30000], Step [1/1], Training Loss: 26364.7012, Valid Loss: 122.0571
Epoch [8601/30000], Step [1/1], Training Loss: 25865.3438, Valid Loss: 118.7524
Epoch [8701/30000], Step [1/1], Training Loss: 25374.0566, Valid Loss: 123.2000
Epoch [8801/30000], Step [1/1], Training Loss: 24898.0684, Valid Loss: 128.0000
Epoch [8901/30000], Step [1/1], Training Loss: 24411.5664, Valid Loss: 112.6952
Epoch [9001/30000], Step [1/1], Training Loss: 23919.6465, Valid Loss: 129.7905
Epoch [9101/30000], Step [1/1], Training Loss: 23438.5605, Valid Loss: 112.5143
Epoch [9201/30000], Step [1/1], Training Loss: 22970.8281, Valid Loss: 110.4191
Epoch [9301/30000], Step [1/1], Training Loss: 22503.7012, Valid Loss: 110.5333
Epoch [9401/30000], Step [1/1], Training Loss: 22040.2617, Valid Loss: 116.6952
Epoch [9501/30000], Step [1/1], Training Loss: 21602.1055, Valid Loss: 111.0857
Epoch [9601/30000], Step [1/1], Training Loss: 21158.8965, Valid Loss: 109.3238
Epoch [9701/30000], Step [1/1], Training Loss: 20733.4023, Valid Loss: 113.1714
Epoch [9801/30000], Step [1/1], Training Loss: 20321.4219, Valid Loss: 110.7524
Epoch [9901/30000], Step [1/1], Training Loss: 19898.0000, Valid Loss: 110.6857
Epoch [10001/30000], Step [1/1], Training Loss: 19497.5996, Valid Loss: 114.2476

[Epoch 15000] Rounded prediction: 
tensor([17., 20., 27., 19., 19., 21., 17., 21., 16., 21., 18., 21., 21., 18.,
        20., 19., 17., 18., 14., 17., 17., 20., 19., 20., 20., 11., 16., 15.,
        17., 15., 20., 15., 11., 17., 14., 17., 14., 14., 12., 15., 12., 31.,
        18., 20., 15., 12., 13., 15., 15., 16., 14., 16., 19., 17., 25., 17.,
        11., 17., 13., 16., 16., 18., 16., 20., 16., 22., 17., 23., 18., 24.,
        19., 19., 19., 20., 20., 22., 20., 32., 22., 25., 26., 25., 32., 32.,
        24., 23., 24., 24., 22., 18., 26., 39., 43., 45., 38., 33., 30., 34.,
        32., 34., 33., 42., 30., 27., 41.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([23., 26., 30., 20., 23., 26., 17., 28., 21., 29., 25., 29., 35., 25.,
        30., 24., 24., 21., 16., 21., 18., 22., 20., 22., 21., 12., 17., 17.,
        18., 15., 22., 16., 12., 18., 15., 18., 15., 16., 14., 16., 13., 35.,
        18., 21., 16., 13., 14., 16., 17., 18., 17., 18., 20., 19., 27., 19.,
        12., 18., 15., 18., 17., 20., 19., 21., 18., 23., 21., 22., 20., 26.,
        22., 22., 22., 25., 27., 23., 23., 35., 24., 24., 29., 25., 33., 37.,
        26., 27., 30., 33., 29., 22., 31., 43., 45., 44., 39., 36., 35., 39.,
        37., 40., 38., 44., 36., 26., 44.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [10101/30000], Step [1/1], Training Loss: 19109.3398, Valid Loss: 111.1524
Epoch [10201/30000], Step [1/1], Training Loss: 18889.6055, Valid Loss: 90.0381
Epoch [10301/30000], Step [1/1], Training Loss: 18373.2715, Valid Loss: 101.8000
Epoch [10401/30000], Step [1/1], Training Loss: 18001.1348, Valid Loss: 102.4476
Epoch [10501/30000], Step [1/1], Training Loss: 17640.3105, Valid Loss: 96.5238
Epoch [10601/30000], Step [1/1], Training Loss: 17281.4375, Valid Loss: 97.2571
Epoch [10701/30000], Step [1/1], Training Loss: 16940.7910, Valid Loss: 99.0571
Epoch [10801/30000], Step [1/1], Training Loss: 16586.6172, Valid Loss: 100.2000
Epoch [10901/30000], Step [1/1], Training Loss: 16255.0742, Valid Loss: 100.3333
Epoch [11001/30000], Step [1/1], Training Loss: 15928.4170, Valid Loss: 99.1524
Epoch [11101/30000], Step [1/1], Training Loss: 15607.2100, Valid Loss: 102.1905
Epoch [11201/30000], Step [1/1], Training Loss: 15296.5078, Valid Loss: 101.8000
Epoch [11301/30000], Step [1/1], Training Loss: 14991.7344, Valid Loss: 104.9238
Epoch [11401/30000], Step [1/1], Training Loss: 14694.1260, Valid Loss: 102.4667
Epoch [11501/30000], Step [1/1], Training Loss: 14410.0947, Valid Loss: 112.9333
Epoch [11601/30000], Step [1/1], Training Loss: 14124.4229, Valid Loss: 113.0381
Epoch [11701/30000], Step [1/1], Training Loss: 13848.1182, Valid Loss: 111.4000
Epoch [11801/30000], Step [1/1], Training Loss: 13579.4277, Valid Loss: 104.2191
Epoch [11901/30000], Step [1/1], Training Loss: 13313.6436, Valid Loss: 108.3905
Epoch [12001/30000], Step [1/1], Training Loss: 13054.8281, Valid Loss: 105.4095
Epoch [12101/30000], Step [1/1], Training Loss: 13057.6982, Valid Loss: 188.7048
Epoch [12201/30000], Step [1/1], Training Loss: 12665.7910, Valid Loss: 109.3238
Epoch [12301/30000], Step [1/1], Training Loss: 12301.0615, Valid Loss: 112.6857
Epoch [12401/30000], Step [1/1], Training Loss: 12086.6250, Valid Loss: 103.2286
Epoch [12501/30000], Step [1/1], Training Loss: 11839.7480, Valid Loss: 103.4191
Epoch [12601/30000], Step [1/1], Training Loss: 11583.8516, Valid Loss: 106.2762
Epoch [12701/30000], Step [1/1], Training Loss: 11354.1865, Valid Loss: 108.2000
Epoch [12801/30000], Step [1/1], Training Loss: 11129.1064, Valid Loss: 101.0381
Epoch [12901/30000], Step [1/1], Training Loss: 10910.6465, Valid Loss: 104.7714
Epoch [13001/30000], Step [1/1], Training Loss: 10692.3027, Valid Loss: 104.6095
Epoch [13101/30000], Step [1/1], Training Loss: 10486.6943, Valid Loss: 103.4952
Epoch [13201/30000], Step [1/1], Training Loss: 10048.8115, Valid Loss: 130.8095
Epoch [13301/30000], Step [1/1], Training Loss: 9897.1943, Valid Loss: 158.1238
Epoch [13401/30000], Step [1/1], Training Loss: 9607.9473, Valid Loss: 135.5333
Epoch [13501/30000], Step [1/1], Training Loss: 9360.9541, Valid Loss: 132.4286
Epoch [13601/30000], Step [1/1], Training Loss: 9145.7354, Valid Loss: 130.3714
Epoch [13701/30000], Step [1/1], Training Loss: 8935.8047, Valid Loss: 129.8286
Epoch [13801/30000], Step [1/1], Training Loss: 8735.5615, Valid Loss: 122.8476
Epoch [13901/30000], Step [1/1], Training Loss: 8635.5117, Valid Loss: 161.0857
Epoch [14001/30000], Step [1/1], Training Loss: 8315.9346, Valid Loss: 130.3333
Epoch [14101/30000], Step [1/1], Training Loss: 8111.3379, Valid Loss: 131.6381
Epoch [14201/30000], Step [1/1], Training Loss: 7917.0972, Valid Loss: 129.6572
Epoch [14301/30000], Step [1/1], Training Loss: 7720.8623, Valid Loss: 123.6762
Epoch [14401/30000], Step [1/1], Training Loss: 7525.7979, Valid Loss: 125.1714
Epoch [14501/30000], Step [1/1], Training Loss: 7320.5005, Valid Loss: 124.8952
Epoch [14601/30000], Step [1/1], Training Loss: 7134.6562, Valid Loss: 129.4000
Epoch [14701/30000], Step [1/1], Training Loss: 6965.4805, Valid Loss: 126.0762
Epoch [14801/30000], Step [1/1], Training Loss: 6802.5063, Valid Loss: 130.0095
Epoch [14901/30000], Step [1/1], Training Loss: 6642.5161, Valid Loss: 123.5524
Epoch [15001/30000], Step [1/1], Training Loss: 6489.4580, Valid Loss: 129.0857
Epoch [15101/30000], Step [1/1], Training Loss: 6338.9600, Valid Loss: 130.4381
Epoch [15201/30000], Step [1/1], Training Loss: 6192.2539, Valid Loss: 130.5619
Epoch [15301/30000], Step [1/1], Training Loss: 6049.0674, Valid Loss: 128.7048
Epoch [15401/30000], Step [1/1], Training Loss: 5908.8687, Valid Loss: 123.6857
Epoch [15501/30000], Step [1/1], Training Loss: 5772.9443, Valid Loss: 123.8667
Epoch [15601/30000], Step [1/1], Training Loss: 5641.3394, Valid Loss: 124.0000
Epoch [15701/30000], Step [1/1], Training Loss: 5512.6299, Valid Loss: 120.9048
Epoch [15801/30000], Step [1/1], Training Loss: 5386.8892, Valid Loss: 128.4286
Epoch [15901/30000], Step [1/1], Training Loss: 5262.7568, Valid Loss: 126.8571
Epoch [16001/30000], Step [1/1], Training Loss: 5141.3340, Valid Loss: 122.7143
Epoch [16101/30000], Step [1/1], Training Loss: 5024.4189, Valid Loss: 119.2857
Epoch [16201/30000], Step [1/1], Training Loss: 4908.2144, Valid Loss: 127.1714
Epoch [16301/30000], Step [1/1], Training Loss: 4738.7349, Valid Loss: 114.4095
Epoch [16401/30000], Step [1/1], Training Loss: 4621.2256, Valid Loss: 115.9905
Epoch [16501/30000], Step [1/1], Training Loss: 4506.9277, Valid Loss: 121.6572
Epoch [16601/30000], Step [1/1], Training Loss: 5347.6919, Valid Loss: 161.6095
Epoch [16701/30000], Step [1/1], Training Loss: 4367.0615, Valid Loss: 185.2476
Epoch [16801/30000], Step [1/1], Training Loss: 4209.4844, Valid Loss: 199.7429
Epoch [16901/30000], Step [1/1], Training Loss: 4098.7007, Valid Loss: 189.0476
Epoch [17001/30000], Step [1/1], Training Loss: 3997.5815, Valid Loss: 184.2191
Epoch [17101/30000], Step [1/1], Training Loss: 3900.6677, Valid Loss: 196.0762
Epoch [17201/30000], Step [1/1], Training Loss: 3805.7600, Valid Loss: 194.6667
Epoch [17301/30000], Step [1/1], Training Loss: 3713.5293, Valid Loss: 194.8381
Epoch [17401/30000], Step [1/1], Training Loss: 3622.2966, Valid Loss: 192.2572
Epoch [17501/30000], Step [1/1], Training Loss: 3534.5076, Valid Loss: 200.6762
Epoch [17601/30000], Step [1/1], Training Loss: 3449.9121, Valid Loss: 194.4667
Epoch [17701/30000], Step [1/1], Training Loss: 3364.3281, Valid Loss: 187.8286
Epoch [17801/30000], Step [1/1], Training Loss: 3283.6133, Valid Loss: 195.5238
Epoch [17901/30000], Step [1/1], Training Loss: 3202.9827, Valid Loss: 195.7714
Epoch [18001/30000], Step [1/1], Training Loss: 3124.5520, Valid Loss: 196.2857
Epoch [18101/30000], Step [1/1], Training Loss: 3048.9729, Valid Loss: 203.3333
Epoch [18201/30000], Step [1/1], Training Loss: 2974.4143, Valid Loss: 200.2857
Epoch [18301/30000], Step [1/1], Training Loss: 2902.6614, Valid Loss: 206.5238
Epoch [18401/30000], Step [1/1], Training Loss: 2831.4346, Valid Loss: 202.2381
Epoch [18501/30000], Step [1/1], Training Loss: 2762.5813, Valid Loss: 207.9429
Epoch [18601/30000], Step [1/1], Training Loss: 2694.4397, Valid Loss: 203.8952
Epoch [18701/30000], Step [1/1], Training Loss: 2628.2517, Valid Loss: 208.6572
Epoch [18801/30000], Step [1/1], Training Loss: 2562.4858, Valid Loss: 200.2762
Epoch [18901/30000], Step [1/1], Training Loss: 2498.2864, Valid Loss: 216.8857
Epoch [19001/30000], Step [1/1], Training Loss: 2435.8455, Valid Loss: 196.5619
Epoch [19101/30000], Step [1/1], Training Loss: 2374.8162, Valid Loss: 202.6381
Epoch [19201/30000], Step [1/1], Training Loss: 2315.2632, Valid Loss: 207.4191
Epoch [19301/30000], Step [1/1], Training Loss: 2256.7969, Valid Loss: 214.4000
Epoch [19401/30000], Step [1/1], Training Loss: 2200.0645, Valid Loss: 207.9143
Epoch [19501/30000], Step [1/1], Training Loss: 2145.8977, Valid Loss: 221.7619
Epoch [19601/30000], Step [1/1], Training Loss: 2091.2866, Valid Loss: 204.9143
Epoch [19701/30000], Step [1/1], Training Loss: 2038.9076, Valid Loss: 208.6572
Epoch [19801/30000], Step [1/1], Training Loss: 1988.4139, Valid Loss: 202.9810
Epoch [19901/30000], Step [1/1], Training Loss: 1939.1764, Valid Loss: 202.4095
Epoch [20001/30000], Step [1/1], Training Loss: 1891.5142, Valid Loss: 203.7524
Epoch [20101/30000], Step [1/1], Training Loss: 1845.2373, Valid Loss: 216.0476

[Epoch 25000] Rounded prediction: 
tensor([22., 29., 32., 21., 25., 25., 22., 27., 23., 30., 26., 31., 31., 26.,
        28., 22., 24., 18., 17., 18., 17., 19., 17., 19., 20., 11., 14., 16.,
        16., 13., 20., 15., 12., 14., 15., 15., 14., 13., 13., 13., 11., 32.,
        17., 19., 14., 11., 12., 14., 15., 17., 15., 17., 18., 17., 24., 18.,
        11., 16., 12., 15., 16., 16., 18., 18., 16., 21., 19., 19., 18., 26.,
        20., 19., 21., 23., 25., 21., 22., 33., 22., 22., 27., 23., 32., 36.,
        23., 25., 29., 34., 28., 22., 30., 41., 47., 44., 41., 36., 34., 43.,
        44., 40., 39., 55., 37., 30., 45.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [20201/30000], Step [1/1], Training Loss: 1800.3868, Valid Loss: 213.0762
Epoch [20301/30000], Step [1/1], Training Loss: 1757.7322, Valid Loss: 200.2667
Epoch [20401/30000], Step [1/1], Training Loss: 1715.6421, Valid Loss: 202.6857
Epoch [20501/30000], Step [1/1], Training Loss: 1675.8158, Valid Loss: 207.6762
Epoch [20601/30000], Step [1/1], Training Loss: 1637.2202, Valid Loss: 213.2857
Epoch [20701/30000], Step [1/1], Training Loss: 1599.5157, Valid Loss: 219.2667
Epoch [20801/30000], Step [1/1], Training Loss: 1563.4458, Valid Loss: 207.5905
Epoch [20901/30000], Step [1/1], Training Loss: 1528.1176, Valid Loss: 211.1429
Epoch [21001/30000], Step [1/1], Training Loss: 1493.6151, Valid Loss: 198.0286
Epoch [21101/30000], Step [1/1], Training Loss: 1460.7018, Valid Loss: 204.0667
Epoch [21201/30000], Step [1/1], Training Loss: 1428.5969, Valid Loss: 211.7048
Epoch [21301/30000], Step [1/1], Training Loss: 1397.5079, Valid Loss: 210.2572
Epoch [21401/30000], Step [1/1], Training Loss: 1366.5615, Valid Loss: 206.0191
Epoch [21501/30000], Step [1/1], Training Loss: 1336.6631, Valid Loss: 215.0952
Epoch [21601/30000], Step [1/1], Training Loss: 1307.9465, Valid Loss: 200.2286
Epoch [21701/30000], Step [1/1], Training Loss: 1279.5579, Valid Loss: 206.5524
Epoch [21801/30000], Step [1/1], Training Loss: 1253.0056, Valid Loss: 191.5524
Epoch [21901/30000], Step [1/1], Training Loss: 1225.7993, Valid Loss: 196.2191
Epoch [22001/30000], Step [1/1], Training Loss: 1199.5016, Valid Loss: 191.6953
Epoch [22101/30000], Step [1/1], Training Loss: 1174.2479, Valid Loss: 196.5714
Epoch [22201/30000], Step [1/1], Training Loss: 1149.4502, Valid Loss: 202.8191
Epoch [22301/30000], Step [1/1], Training Loss: 1124.8840, Valid Loss: 191.1429
Epoch [22401/30000], Step [1/1], Training Loss: 1100.9983, Valid Loss: 195.5333
Epoch [22501/30000], Step [1/1], Training Loss: 1077.4380, Valid Loss: 197.4762
Epoch [22601/30000], Step [1/1], Training Loss: 1053.6030, Valid Loss: 198.6762
Epoch [22701/30000], Step [1/1], Training Loss: 1030.3748, Valid Loss: 202.1429
Epoch [22801/30000], Step [1/1], Training Loss: 1007.6080, Valid Loss: 193.8857
Epoch [22901/30000], Step [1/1], Training Loss: 985.3640, Valid Loss: 198.0000
Epoch [23001/30000], Step [1/1], Training Loss: 962.9121, Valid Loss: 191.3619
Epoch [23101/30000], Step [1/1], Training Loss: 1044.9124, Valid Loss: 140.3429
Epoch [23201/30000], Step [1/1], Training Loss: 936.7210, Valid Loss: 199.5048
Epoch [23301/30000], Step [1/1], Training Loss: 907.1964, Valid Loss: 194.0381
Epoch [23401/30000], Step [1/1], Training Loss: 887.8440, Valid Loss: 192.5619
Epoch [23501/30000], Step [1/1], Training Loss: 868.8633, Valid Loss: 182.0762
Epoch [23601/30000], Step [1/1], Training Loss: 848.6644, Valid Loss: 171.2000
Epoch [23701/30000], Step [1/1], Training Loss: 829.9277, Valid Loss: 182.2572
Epoch [23801/30000], Step [1/1], Training Loss: 812.4420, Valid Loss: 186.0286
Epoch [23901/30000], Step [1/1], Training Loss: 794.1775, Valid Loss: 180.8476
Epoch [24001/30000], Step [1/1], Training Loss: 777.0976, Valid Loss: 176.9619
Epoch [24101/30000], Step [1/1], Training Loss: 760.0872, Valid Loss: 176.7429
Epoch [24201/30000], Step [1/1], Training Loss: 743.9240, Valid Loss: 184.5810
Epoch [24301/30000], Step [1/1], Training Loss: 728.1870, Valid Loss: 180.2762
Epoch [24401/30000], Step [1/1], Training Loss: 712.9646, Valid Loss: 188.2476
Epoch [24501/30000], Step [1/1], Training Loss: 697.9833, Valid Loss: 175.4476
Epoch [24601/30000], Step [1/1], Training Loss: 683.9279, Valid Loss: 182.4762
Epoch [24701/30000], Step [1/1], Training Loss: 669.7089, Valid Loss: 182.5143
Epoch [24801/30000], Step [1/1], Training Loss: 656.1035, Valid Loss: 175.6381
Epoch [24901/30000], Step [1/1], Training Loss: 643.0866, Valid Loss: 182.4572
Epoch [25001/30000], Step [1/1], Training Loss: 630.3188, Valid Loss: 187.1905
Epoch [25101/30000], Step [1/1], Training Loss: 614.6079, Valid Loss: 178.3238
Epoch [25201/30000], Step [1/1], Training Loss: 600.7525, Valid Loss: 177.3810
Epoch [25301/30000], Step [1/1], Training Loss: 586.8929, Valid Loss: 181.4191
Epoch [25401/30000], Step [1/1], Training Loss: 574.1322, Valid Loss: 181.2000
Epoch [25501/30000], Step [1/1], Training Loss: 560.6107, Valid Loss: 185.8476
Epoch [25601/30000], Step [1/1], Training Loss: 547.4321, Valid Loss: 192.0476
Epoch [25701/30000], Step [1/1], Training Loss: 534.5900, Valid Loss: 186.7048
Epoch [25801/30000], Step [1/1], Training Loss: 521.9759, Valid Loss: 178.7524
Epoch [25901/30000], Step [1/1], Training Loss: 509.5968, Valid Loss: 183.8095
Epoch [26001/30000], Step [1/1], Training Loss: 497.4277, Valid Loss: 173.2000
Epoch [26101/30000], Step [1/1], Training Loss: 485.3151, Valid Loss: 186.6857
Epoch [26201/30000], Step [1/1], Training Loss: 473.7729, Valid Loss: 183.2381
Epoch [26301/30000], Step [1/1], Training Loss: 462.5177, Valid Loss: 181.0952
Epoch [26401/30000], Step [1/1], Training Loss: 451.2736, Valid Loss: 179.6286
Epoch [26501/30000], Step [1/1], Training Loss: 440.1316, Valid Loss: 179.6667
Epoch [26601/30000], Step [1/1], Training Loss: 429.6602, Valid Loss: 177.4952
Epoch [26701/30000], Step [1/1], Training Loss: 419.2732, Valid Loss: 190.9524
Epoch [26801/30000], Step [1/1], Training Loss: 408.8790, Valid Loss: 179.6000
Epoch [26901/30000], Step [1/1], Training Loss: 399.2980, Valid Loss: 174.8286
Epoch [27001/30000], Step [1/1], Training Loss: 389.5186, Valid Loss: 179.6953
Epoch [27101/30000], Step [1/1], Training Loss: 379.6054, Valid Loss: 182.2286
Epoch [27201/30000], Step [1/1], Training Loss: 378.8496, Valid Loss: 162.6762
Epoch [27301/30000], Step [1/1], Training Loss: 360.3336, Valid Loss: 192.1810
Epoch [27401/30000], Step [1/1], Training Loss: 350.8587, Valid Loss: 189.8857
Epoch [27501/30000], Step [1/1], Training Loss: 340.9987, Valid Loss: 185.7238
Epoch [27601/30000], Step [1/1], Training Loss: 331.5042, Valid Loss: 183.7619
Epoch [27701/30000], Step [1/1], Training Loss: 322.1593, Valid Loss: 180.1333
Epoch [27801/30000], Step [1/1], Training Loss: 313.0335, Valid Loss: 185.7429
Epoch [27901/30000], Step [1/1], Training Loss: 303.7861, Valid Loss: 180.3810
Epoch [28001/30000], Step [1/1], Training Loss: 294.5756, Valid Loss: 181.0381
Epoch [28101/30000], Step [1/1], Training Loss: 285.6254, Valid Loss: 183.0381
Epoch [28201/30000], Step [1/1], Training Loss: 276.8674, Valid Loss: 179.7524
Epoch [28301/30000], Step [1/1], Training Loss: 268.4193, Valid Loss: 176.4286
Epoch [28401/30000], Step [1/1], Training Loss: 259.6257, Valid Loss: 178.6000
Epoch [28501/30000], Step [1/1], Training Loss: 251.0631, Valid Loss: 181.9048
Epoch [28601/30000], Step [1/1], Training Loss: 243.0280, Valid Loss: 172.5333
Epoch [28701/30000], Step [1/1], Training Loss: 234.5257, Valid Loss: 176.1143
Epoch [28801/30000], Step [1/1], Training Loss: 226.5785, Valid Loss: 175.5619
Epoch [28901/30000], Step [1/1], Training Loss: 218.6633, Valid Loss: 174.2000
Epoch [29001/30000], Step [1/1], Training Loss: 211.0685, Valid Loss: 186.0191
Epoch [29101/30000], Step [1/1], Training Loss: 203.5605, Valid Loss: 179.0000
Epoch [29201/30000], Step [1/1], Training Loss: 196.1869, Valid Loss: 195.0476
Epoch [29301/30000], Step [1/1], Training Loss: 188.7081, Valid Loss: 181.4476
Epoch [29401/30000], Step [1/1], Training Loss: 181.4857, Valid Loss: 175.0571
Epoch [29501/30000], Step [1/1], Training Loss: 174.7502, Valid Loss: 173.0667
Epoch [29601/30000], Step [1/1], Training Loss: 167.7033, Valid Loss: 170.6381
Epoch [29701/30000], Step [1/1], Training Loss: 161.1671, Valid Loss: 160.8095
Epoch [29801/30000], Step [1/1], Training Loss: 154.6201, Valid Loss: 167.6762
Epoch [29901/30000], Step [1/1], Training Loss: 148.4193, Valid Loss: 166.7714

 End Time: 2021/04/19, 15:55:34




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=512 	layers=3

Start Time = 2021/04/19, 15:55:34
##########################################################


[Epoch 0] Rounded prediction: 
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([27., 29., 30., 25., 27., 27., 26., 30., 31., 33., 35., 27., 32., 30.,
        26., 29., 14., 19., 15., 19., 28., 20., 25., 28., 14., 11., 18., 18.,
        17., 16., 24.,  9., 12., 21., 14., 16., 12., 17.,  9., 17., 14., 38.,
        18., 23., 11., 13., 14., 17., 15., 16., 15., 17., 28., 13., 39., 13.,
        13., 15., 16., 19., 13., 22., 11., 27., 13., 33., 17., 34., 27., 25.,
        27., 28., 25., 27., 25., 34., 26., 45., 21., 43., 34., 26., 46., 38.,
        34., 36., 31., 34., 36., 34., 32., 41., 42., 41., 34., 40., 38., 36.,
        38., 39., 47., 38., 44., 51., 41.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([34., 32., 22., 23., 23., 25., 24., 22., 28., 23., 27., 15., 23., 19.,
        16., 23.,  7., 16.,  8., 15., 23., 14., 22., 26., 10.,  8., 15., 12.,
        14., 13., 24.,  6.,  8., 18., 10., 14.,  8., 14.,  4., 16., 11., 41.,
        13., 26.,  4., 11., 10., 12., 10., 11., 11., 12., 24.,  7., 41.,  7.,
        12., 11., 11., 16.,  8., 20.,  5., 24.,  5., 32.,  8., 31., 18., 16.,
        19., 18., 19., 19., 18., 33., 17., 43., 11., 41., 27., 17., 49., 26.,
        26., 32., 21., 25., 24., 30., 37., 43., 43., 39., 37., 35., 36., 34.,
        36., 36., 44., 40., 26., 55., 41.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128679.9609, Valid Loss: 231.3048
Epoch [101/30000], Step [1/1], Training Loss: 121376.6328, Valid Loss: 107.8762
Epoch [201/30000], Step [1/1], Training Loss: 118977.5781, Valid Loss: 174.3048
Epoch [301/30000], Step [1/1], Training Loss: 116719.3438, Valid Loss: 320.0191
Epoch [401/30000], Step [1/1], Training Loss: 114555.3594, Valid Loss: 496.4476
Epoch [501/30000], Step [1/1], Training Loss: 112466.1250, Valid Loss: 722.8762
Epoch [601/30000], Step [1/1], Training Loss: 110442.3750, Valid Loss: 999.3048
Epoch [701/30000], Step [1/1], Training Loss: 108480.8281, Valid Loss: 1325.7334
Epoch [801/30000], Step [1/1], Training Loss: 106579.2500, Valid Loss: 1702.1620
Epoch [901/30000], Step [1/1], Training Loss: 104729.1250, Valid Loss: 2039.3048
Epoch [1001/30000], Step [1/1], Training Loss: 102931.1641, Valid Loss: 2504.6763
Epoch [1101/30000], Step [1/1], Training Loss: 101176.0469, Valid Loss: 1551.3524
Epoch [1201/30000], Step [1/1], Training Loss: 99467.4219, Valid Loss: 2073.0476
Epoch [1301/30000], Step [1/1], Training Loss: 97804.5859, Valid Loss: 2336.3525
Epoch [1401/30000], Step [1/1], Training Loss: 96185.3594, Valid Loss: 3460.7048
Epoch [1501/30000], Step [1/1], Training Loss: 94606.3594, Valid Loss: 4135.4004
Epoch [1601/30000], Step [1/1], Training Loss: 93073.2500, Valid Loss: 4230.0762
Epoch [1701/30000], Step [1/1], Training Loss: 91579.3828, Valid Loss: 4331.1714
Epoch [1801/30000], Step [1/1], Training Loss: 90123.8906, Valid Loss: 5057.0571
Epoch [1901/30000], Step [1/1], Training Loss: 88706.9219, Valid Loss: 5200.3145
Epoch [2001/30000], Step [1/1], Training Loss: 87328.4219, Valid Loss: 5191.6479
Epoch [2101/30000], Step [1/1], Training Loss: 85989.4141, Valid Loss: 5842.2671
Epoch [2201/30000], Step [1/1], Training Loss: 84686.5469, Valid Loss: 6698.4766
Epoch [2301/30000], Step [1/1], Training Loss: 83422.1328, Valid Loss: 4918.7905
Epoch [2401/30000], Step [1/1], Training Loss: 82191.0625, Valid Loss: 6993.1909
Epoch [2501/30000], Step [1/1], Training Loss: 79430.5234, Valid Loss: 342.9524
Epoch [2601/30000], Step [1/1], Training Loss: 77958.0234, Valid Loss: 284.2762
Epoch [2701/30000], Step [1/1], Training Loss: 76515.4219, Valid Loss: 250.9714
Epoch [2801/30000], Step [1/1], Training Loss: 75107.7500, Valid Loss: 342.7238
Epoch [2901/30000], Step [1/1], Training Loss: 73747.9922, Valid Loss: 396.1334
Epoch [3001/30000], Step [1/1], Training Loss: 72415.8672, Valid Loss: 394.0286
Epoch [3101/30000], Step [1/1], Training Loss: 71134.3516, Valid Loss: 265.2095
Epoch [3201/30000], Step [1/1], Training Loss: 69848.4766, Valid Loss: 298.4286
Epoch [3301/30000], Step [1/1], Training Loss: 68609.7578, Valid Loss: 318.8476
Epoch [3401/30000], Step [1/1], Training Loss: 67396.4531, Valid Loss: 299.3714
Epoch [3501/30000], Step [1/1], Training Loss: 66212.6719, Valid Loss: 304.8286
Epoch [3601/30000], Step [1/1], Training Loss: 65056.0312, Valid Loss: 328.7619
Epoch [3701/30000], Step [1/1], Training Loss: 63921.0586, Valid Loss: 305.4000
Epoch [3801/30000], Step [1/1], Training Loss: 62818.2188, Valid Loss: 314.6857
Epoch [3901/30000], Step [1/1], Training Loss: 61799.5938, Valid Loss: 678.4000
Epoch [4001/30000], Step [1/1], Training Loss: 60684.7773, Valid Loss: 231.2667
Epoch [4101/30000], Step [1/1], Training Loss: 59622.4570, Valid Loss: 276.0000
Epoch [4201/30000], Step [1/1], Training Loss: 58537.5742, Valid Loss: 247.1048
Epoch [4301/30000], Step [1/1], Training Loss: 57502.1445, Valid Loss: 247.3429
Epoch [4401/30000], Step [1/1], Training Loss: 56503.5664, Valid Loss: 236.9048
Epoch [4501/30000], Step [1/1], Training Loss: 55510.5430, Valid Loss: 272.7619
Epoch [4601/30000], Step [1/1], Training Loss: 54543.7617, Valid Loss: 266.3143
Epoch [4701/30000], Step [1/1], Training Loss: 53599.4766, Valid Loss: 270.9905
Epoch [4801/30000], Step [1/1], Training Loss: 52678.1562, Valid Loss: 280.0286
Epoch [4901/30000], Step [1/1], Training Loss: 51773.4531, Valid Loss: 275.6857
Epoch [5001/30000], Step [1/1], Training Loss: 50888.5078, Valid Loss: 277.0572
Epoch [5101/30000], Step [1/1], Training Loss: 50023.1953, Valid Loss: 308.4762
Epoch [5201/30000], Step [1/1], Training Loss: 49177.9570, Valid Loss: 324.7619
Epoch [5301/30000], Step [1/1], Training Loss: 48336.6094, Valid Loss: 300.2762
Epoch [5401/30000], Step [1/1], Training Loss: 47501.5117, Valid Loss: 238.2476
Epoch [5501/30000], Step [1/1], Training Loss: 46601.4844, Valid Loss: 195.7333
Epoch [5601/30000], Step [1/1], Training Loss: 45744.2656, Valid Loss: 184.2476
Epoch [5701/30000], Step [1/1], Training Loss: 44927.6055, Valid Loss: 211.9810
Epoch [5801/30000], Step [1/1], Training Loss: 44110.2891, Valid Loss: 189.2476
Epoch [5901/30000], Step [1/1], Training Loss: 43327.5977, Valid Loss: 199.5524
Epoch [6001/30000], Step [1/1], Training Loss: 42572.3242, Valid Loss: 201.7905
Epoch [6101/30000], Step [1/1], Training Loss: 41774.4023, Valid Loss: 200.8762
Epoch [6201/30000], Step [1/1], Training Loss: 41072.8008, Valid Loss: 177.2572
Epoch [6301/30000], Step [1/1], Training Loss: 40524.4102, Valid Loss: 216.2381
Epoch [6401/30000], Step [1/1], Training Loss: 39474.7578, Valid Loss: 190.2476
Epoch [6501/30000], Step [1/1], Training Loss: 38721.7344, Valid Loss: 184.9143
Epoch [6601/30000], Step [1/1], Training Loss: 38007.1523, Valid Loss: 179.4572
Epoch [6701/30000], Step [1/1], Training Loss: 37318.6328, Valid Loss: 201.2667
Epoch [6801/30000], Step [1/1], Training Loss: 36647.4297, Valid Loss: 199.5333
Epoch [6901/30000], Step [1/1], Training Loss: 35989.8008, Valid Loss: 202.6190
Epoch [7001/30000], Step [1/1], Training Loss: 35349.5742, Valid Loss: 202.2191
Epoch [7101/30000], Step [1/1], Training Loss: 34711.9336, Valid Loss: 205.5524
Epoch [7201/30000], Step [1/1], Training Loss: 33965.4023, Valid Loss: 175.7810
Epoch [7301/30000], Step [1/1], Training Loss: 33235.8047, Valid Loss: 224.6476
Epoch [7401/30000], Step [1/1], Training Loss: 32588.0293, Valid Loss: 212.5524
Epoch [7501/30000], Step [1/1], Training Loss: 31955.8965, Valid Loss: 207.4286
Epoch [7601/30000], Step [1/1], Training Loss: 31347.4922, Valid Loss: 205.9333
Epoch [7701/30000], Step [1/1], Training Loss: 30745.7285, Valid Loss: 214.7333
Epoch [7801/30000], Step [1/1], Training Loss: 30155.7637, Valid Loss: 212.5810
Epoch [7901/30000], Step [1/1], Training Loss: 29587.1074, Valid Loss: 205.3714
Epoch [8001/30000], Step [1/1], Training Loss: 29025.6816, Valid Loss: 206.1905
Epoch [8101/30000], Step [1/1], Training Loss: 28481.5605, Valid Loss: 214.4857
Epoch [8201/30000], Step [1/1], Training Loss: 27947.2402, Valid Loss: 197.9714
Epoch [8301/30000], Step [1/1], Training Loss: 27424.2051, Valid Loss: 210.6953
Epoch [8401/30000], Step [1/1], Training Loss: 26911.3438, Valid Loss: 203.7429
Epoch [8501/30000], Step [1/1], Training Loss: 26407.0977, Valid Loss: 193.3429
Epoch [8601/30000], Step [1/1], Training Loss: 25914.9531, Valid Loss: 208.3429
Epoch [8701/30000], Step [1/1], Training Loss: 25546.2832, Valid Loss: 175.2381
Epoch [8801/30000], Step [1/1], Training Loss: 24953.8828, Valid Loss: 158.9238
Epoch [8901/30000], Step [1/1], Training Loss: 24416.1660, Valid Loss: 158.8191
Epoch [9001/30000], Step [1/1], Training Loss: 23925.4141, Valid Loss: 208.5905
Epoch [9101/30000], Step [1/1], Training Loss: 23341.2598, Valid Loss: 173.1810
Epoch [9201/30000], Step [1/1], Training Loss: 22865.0332, Valid Loss: 186.5619
Epoch [9301/30000], Step [1/1], Training Loss: 22403.7598, Valid Loss: 182.4667
Epoch [9401/30000], Step [1/1], Training Loss: 21955.8594, Valid Loss: 179.6762
Epoch [9501/30000], Step [1/1], Training Loss: 21516.0879, Valid Loss: 188.5048
Epoch [9601/30000], Step [1/1], Training Loss: 21088.7402, Valid Loss: 182.3905
Epoch [9701/30000], Step [1/1], Training Loss: 20667.8770, Valid Loss: 181.1524
Epoch [9801/30000], Step [1/1], Training Loss: 20259.3027, Valid Loss: 197.4381
Epoch [9901/30000], Step [1/1], Training Loss: 19848.8555, Valid Loss: 185.2476
Epoch [10001/30000], Step [1/1], Training Loss: 19452.9551, Valid Loss: 185.0286

[Epoch 15000] Rounded prediction: 
tensor([26., 23., 24., 21., 23., 24., 22., 25., 25., 22., 26., 15., 24., 18.,
        15., 22.,  7., 15.,  7., 13., 21., 13., 19., 24.,  7.,  5., 13., 11.,
        11., 12., 21.,  3.,  7., 15.,  8., 12.,  6., 12.,  3., 14.,  9., 39.,
        11., 23.,  2.,  9.,  8., 10.,  9.,  9.,  9., 11., 21.,  6., 38.,  5.,
         9.,  9.,  9., 14.,  7., 18.,  3., 21.,  3., 29.,  6., 30., 17., 16.,
        17., 17., 17., 18., 17., 32., 15., 46.,  8., 39., 28., 15., 50., 25.,
        27., 30., 22., 23., 22., 27., 36., 47., 45., 37., 36., 36., 35., 35.,
        40., 32., 48., 46., 23., 46., 49.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([26., 20., 24., 18., 19., 21., 17., 19., 20., 19., 22., 13., 21., 14.,
        13., 16.,  5., 11.,  4., 10., 16., 10., 15., 19.,  6.,  4.,  9.,  7.,
         9., 10., 18.,  3.,  4., 12.,  6., 10.,  4.,  9.,  1., 12.,  7., 35.,
         8., 20.,  1.,  6.,  5.,  8.,  6.,  6.,  6.,  7., 16.,  5., 33.,  3.,
         8.,  6.,  6., 11.,  5., 14.,  1., 17.,  1., 24.,  3., 24., 12., 12.,
        13., 13., 13., 13., 13., 23., 12., 41.,  3., 33., 20., 12., 45., 15.,
        20., 24., 18., 22., 16., 20., 32., 44., 41., 35., 34., 18., 34., 31.,
        39., 19., 48., 51., 15., 38., 55.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [10101/30000], Step [1/1], Training Loss: 19066.2500, Valid Loss: 187.9143
Epoch [10201/30000], Step [1/1], Training Loss: 18689.1016, Valid Loss: 180.5810
Epoch [10301/30000], Step [1/1], Training Loss: 18317.7930, Valid Loss: 191.1048
Epoch [10401/30000], Step [1/1], Training Loss: 17956.3047, Valid Loss: 181.4572
Epoch [10501/30000], Step [1/1], Training Loss: 17602.4922, Valid Loss: 183.7143
Epoch [10601/30000], Step [1/1], Training Loss: 17250.3770, Valid Loss: 183.3238
Epoch [10701/30000], Step [1/1], Training Loss: 16908.8047, Valid Loss: 184.2191
Epoch [10801/30000], Step [1/1], Training Loss: 16675.6348, Valid Loss: 182.9048
Epoch [10901/30000], Step [1/1], Training Loss: 17850.3398, Valid Loss: 253.4000
Epoch [11001/30000], Step [1/1], Training Loss: 15945.9883, Valid Loss: 156.5714
Epoch [11101/30000], Step [1/1], Training Loss: 15637.8369, Valid Loss: 161.3429
Epoch [11201/30000], Step [1/1], Training Loss: 15318.6943, Valid Loss: 173.0762
Epoch [11301/30000], Step [1/1], Training Loss: 15047.2793, Valid Loss: 168.4095
Epoch [11401/30000], Step [1/1], Training Loss: 14722.4531, Valid Loss: 169.8286
Epoch [11501/30000], Step [1/1], Training Loss: 14420.5576, Valid Loss: 174.7333
Epoch [11601/30000], Step [1/1], Training Loss: 14136.7246, Valid Loss: 173.3143
Epoch [11701/30000], Step [1/1], Training Loss: 13861.2754, Valid Loss: 175.6286
Epoch [11801/30000], Step [1/1], Training Loss: 13593.3496, Valid Loss: 175.4952
Epoch [11901/30000], Step [1/1], Training Loss: 13331.0654, Valid Loss: 177.2857
Epoch [12001/30000], Step [1/1], Training Loss: 13065.9648, Valid Loss: 178.8286
Epoch [12101/30000], Step [1/1], Training Loss: 13151.1133, Valid Loss: 145.6476
Epoch [12201/30000], Step [1/1], Training Loss: 12554.3994, Valid Loss: 175.5333
Epoch [12301/30000], Step [1/1], Training Loss: 12304.3438, Valid Loss: 171.5524
Epoch [12401/30000], Step [1/1], Training Loss: 12769.0137, Valid Loss: 169.2381
Epoch [12501/30000], Step [1/1], Training Loss: 11838.2803, Valid Loss: 164.7429
Epoch [12601/30000], Step [1/1], Training Loss: 11599.0322, Valid Loss: 164.6953
Epoch [12701/30000], Step [1/1], Training Loss: 11369.7646, Valid Loss: 164.5238
Epoch [12801/30000], Step [1/1], Training Loss: 11139.7764, Valid Loss: 168.1524
Epoch [12901/30000], Step [1/1], Training Loss: 10920.1895, Valid Loss: 165.7429
Epoch [13001/30000], Step [1/1], Training Loss: 10708.1826, Valid Loss: 166.8191
Epoch [13101/30000], Step [1/1], Training Loss: 10500.2061, Valid Loss: 166.0857
Epoch [13201/30000], Step [1/1], Training Loss: 10296.3525, Valid Loss: 169.4667
Epoch [13301/30000], Step [1/1], Training Loss: 10098.4355, Valid Loss: 165.2191
Epoch [13401/30000], Step [1/1], Training Loss: 9904.2812, Valid Loss: 165.1429
Epoch [13501/30000], Step [1/1], Training Loss: 9716.2227, Valid Loss: 168.2952
Epoch [13601/30000], Step [1/1], Training Loss: 9532.8447, Valid Loss: 169.3905
Epoch [13701/30000], Step [1/1], Training Loss: 9354.5166, Valid Loss: 168.6190
Epoch [13801/30000], Step [1/1], Training Loss: 9180.6299, Valid Loss: 175.7619
Epoch [13901/30000], Step [1/1], Training Loss: 9013.0752, Valid Loss: 167.2572
Epoch [14001/30000], Step [1/1], Training Loss: 8849.1768, Valid Loss: 169.6095
Epoch [14101/30000], Step [1/1], Training Loss: 9389.1953, Valid Loss: 153.4000
Epoch [14201/30000], Step [1/1], Training Loss: 8006.4922, Valid Loss: 173.7810
Epoch [14301/30000], Step [1/1], Training Loss: 7803.7007, Valid Loss: 167.4286
Epoch [14401/30000], Step [1/1], Training Loss: 7630.9395, Valid Loss: 159.9238
Epoch [14501/30000], Step [1/1], Training Loss: 7461.5054, Valid Loss: 163.8286
Epoch [14601/30000], Step [1/1], Training Loss: 7298.3047, Valid Loss: 166.1143
Epoch [14701/30000], Step [1/1], Training Loss: 7141.2681, Valid Loss: 162.8095
Epoch [14801/30000], Step [1/1], Training Loss: 6987.3809, Valid Loss: 160.2952
Epoch [14901/30000], Step [1/1], Training Loss: 6839.9170, Valid Loss: 166.0476
Epoch [15001/30000], Step [1/1], Training Loss: 6694.5684, Valid Loss: 162.5238
Epoch [15101/30000], Step [1/1], Training Loss: 6554.6245, Valid Loss: 159.9143
Epoch [15201/30000], Step [1/1], Training Loss: 6417.7202, Valid Loss: 166.8952
Epoch [15301/30000], Step [1/1], Training Loss: 6287.0649, Valid Loss: 162.8191
Epoch [15401/30000], Step [1/1], Training Loss: 6158.9521, Valid Loss: 161.5714
Epoch [15501/30000], Step [1/1], Training Loss: 5893.7617, Valid Loss: 176.6381
Epoch [15601/30000], Step [1/1], Training Loss: 5751.1821, Valid Loss: 165.0762
Epoch [15701/30000], Step [1/1], Training Loss: 5623.9395, Valid Loss: 165.4572
Epoch [15801/30000], Step [1/1], Training Loss: 5499.5352, Valid Loss: 167.2000
Epoch [15901/30000], Step [1/1], Training Loss: 5380.8496, Valid Loss: 179.2286
Epoch [16001/30000], Step [1/1], Training Loss: 5263.4951, Valid Loss: 165.0762
Epoch [16101/30000], Step [1/1], Training Loss: 5150.9038, Valid Loss: 169.8952
Epoch [16201/30000], Step [1/1], Training Loss: 5041.4062, Valid Loss: 172.4000
Epoch [16301/30000], Step [1/1], Training Loss: 4932.0127, Valid Loss: 166.8857
Epoch [16401/30000], Step [1/1], Training Loss: 4827.2759, Valid Loss: 164.7048
Epoch [16501/30000], Step [1/1], Training Loss: 4726.4673, Valid Loss: 162.6953
Epoch [16601/30000], Step [1/1], Training Loss: 4628.8770, Valid Loss: 163.2476
Epoch [16701/30000], Step [1/1], Training Loss: 4524.9629, Valid Loss: 171.4095
Epoch [16801/30000], Step [1/1], Training Loss: 4378.7397, Valid Loss: 168.5429
Epoch [16901/30000], Step [1/1], Training Loss: 4221.5542, Valid Loss: 146.5429
Epoch [17001/30000], Step [1/1], Training Loss: 4120.7754, Valid Loss: 158.5048
Epoch [17101/30000], Step [1/1], Training Loss: 4024.3486, Valid Loss: 155.8952
Epoch [17201/30000], Step [1/1], Training Loss: 3931.7041, Valid Loss: 148.7429
Epoch [17301/30000], Step [1/1], Training Loss: 3842.1379, Valid Loss: 150.0095
Epoch [17401/30000], Step [1/1], Training Loss: 3755.7476, Valid Loss: 145.8762
Epoch [17501/30000], Step [1/1], Training Loss: 3670.8562, Valid Loss: 146.9810
Epoch [17601/30000], Step [1/1], Training Loss: 3588.3794, Valid Loss: 141.4572
Epoch [17701/30000], Step [1/1], Training Loss: 3509.3372, Valid Loss: 150.4381
Epoch [17801/30000], Step [1/1], Training Loss: 3431.2144, Valid Loss: 145.8190
Epoch [17901/30000], Step [1/1], Training Loss: 3355.8582, Valid Loss: 143.1429
Epoch [18001/30000], Step [1/1], Training Loss: 3282.5327, Valid Loss: 142.8286
Epoch [18101/30000], Step [1/1], Training Loss: 3211.7712, Valid Loss: 137.6762
Epoch [18201/30000], Step [1/1], Training Loss: 3142.7458, Valid Loss: 145.4952
Epoch [18301/30000], Step [1/1], Training Loss: 3074.8718, Valid Loss: 143.9048
Epoch [18401/30000], Step [1/1], Training Loss: 3296.3721, Valid Loss: 164.3333
Epoch [18501/30000], Step [1/1], Training Loss: 2843.5200, Valid Loss: 128.4286
Epoch [18601/30000], Step [1/1], Training Loss: 2760.8945, Valid Loss: 123.3238
Epoch [18701/30000], Step [1/1], Training Loss: 2686.3816, Valid Loss: 127.5810
Epoch [18801/30000], Step [1/1], Training Loss: 2617.2979, Valid Loss: 123.5238
Epoch [18901/30000], Step [1/1], Training Loss: 2548.9844, Valid Loss: 123.4667
Epoch [19001/30000], Step [1/1], Training Loss: 2484.8489, Valid Loss: 122.2095
Epoch [19101/30000], Step [1/1], Training Loss: 2421.2388, Valid Loss: 121.4952
Epoch [19201/30000], Step [1/1], Training Loss: 2357.5146, Valid Loss: 122.9048
Epoch [19301/30000], Step [1/1], Training Loss: 2296.4297, Valid Loss: 121.3143
Epoch [19401/30000], Step [1/1], Training Loss: 2238.5112, Valid Loss: 123.1524
Epoch [19501/30000], Step [1/1], Training Loss: 2180.7012, Valid Loss: 120.1524
Epoch [19601/30000], Step [1/1], Training Loss: 2125.4478, Valid Loss: 120.1333
Epoch [19701/30000], Step [1/1], Training Loss: 2070.9133, Valid Loss: 122.1333
Epoch [19801/30000], Step [1/1], Training Loss: 2018.4950, Valid Loss: 120.6667
Epoch [19901/30000], Step [1/1], Training Loss: 1968.6943, Valid Loss: 116.6476
Epoch [20001/30000], Step [1/1], Training Loss: 1918.8479, Valid Loss: 111.8857
Epoch [20101/30000], Step [1/1], Training Loss: 1871.0519, Valid Loss: 124.1429

[Epoch 25000] Rounded prediction: 
tensor([25., 24., 23., 19., 19., 21., 18., 19., 20., 19., 21., 13., 20., 14.,
        13., 16.,  6., 12.,  5., 10., 17., 10., 16., 20.,  6.,  6., 10.,  8.,
        10., 10., 18.,  4.,  5., 12.,  6., 10.,  5., 10.,  2., 11.,  8., 36.,
         8., 21.,  1.,  7.,  5.,  8.,  6.,  6.,  6.,  8., 17.,  5., 35.,  3.,
         9.,  7.,  7., 11.,  6., 15.,  2., 17.,  2., 24.,  3., 24., 12., 11.,
        13., 12., 13., 13., 13., 24., 11., 46.,  2., 34., 20., 10., 49., 14.,
        17., 22., 16., 21., 16., 20., 33., 43., 43., 34., 32., 20., 31., 27.,
        35., 18., 44., 50., 12., 35., 53.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [20201/30000], Step [1/1], Training Loss: 1826.0573, Valid Loss: 115.7048
Epoch [20301/30000], Step [1/1], Training Loss: 1780.8804, Valid Loss: 119.3143
Epoch [20401/30000], Step [1/1], Training Loss: 1737.8636, Valid Loss: 118.4762
Epoch [20501/30000], Step [1/1], Training Loss: 1696.8510, Valid Loss: 118.2095
Epoch [20601/30000], Step [1/1], Training Loss: 1656.7429, Valid Loss: 115.8191
Epoch [20701/30000], Step [1/1], Training Loss: 1618.3612, Valid Loss: 117.7714
Epoch [20801/30000], Step [1/1], Training Loss: 1581.8049, Valid Loss: 119.0381
Epoch [20901/30000], Step [1/1], Training Loss: 1545.6984, Valid Loss: 114.1714
Epoch [21001/30000], Step [1/1], Training Loss: 1510.8483, Valid Loss: 120.2667
Epoch [21101/30000], Step [1/1], Training Loss: 1476.2360, Valid Loss: 118.4381
Epoch [21201/30000], Step [1/1], Training Loss: 1443.8839, Valid Loss: 114.4095
Epoch [21301/30000], Step [1/1], Training Loss: 1411.7589, Valid Loss: 115.9714
Epoch [21401/30000], Step [1/1], Training Loss: 1380.8779, Valid Loss: 114.5048
Epoch [21501/30000], Step [1/1], Training Loss: 1350.6000, Valid Loss: 118.8857
Epoch [21601/30000], Step [1/1], Training Loss: 1321.4889, Valid Loss: 116.2857
Epoch [21701/30000], Step [1/1], Training Loss: 1293.1368, Valid Loss: 115.6286
Epoch [21801/30000], Step [1/1], Training Loss: 1264.8530, Valid Loss: 114.5810
Epoch [21901/30000], Step [1/1], Training Loss: 1237.7880, Valid Loss: 118.5048
Epoch [22001/30000], Step [1/1], Training Loss: 1210.7550, Valid Loss: 113.5429
Epoch [22101/30000], Step [1/1], Training Loss: 1185.6750, Valid Loss: 115.3524
Epoch [22201/30000], Step [1/1], Training Loss: 1160.4250, Valid Loss: 112.5810
Epoch [22301/30000], Step [1/1], Training Loss: 1135.7218, Valid Loss: 116.8476
Epoch [22401/30000], Step [1/1], Training Loss: 1111.1349, Valid Loss: 114.6095
Epoch [22501/30000], Step [1/1], Training Loss: 1087.4210, Valid Loss: 118.5524
Epoch [22601/30000], Step [1/1], Training Loss: 1063.7087, Valid Loss: 119.6762
Epoch [22701/30000], Step [1/1], Training Loss: 1040.2615, Valid Loss: 112.6190
Epoch [22801/30000], Step [1/1], Training Loss: 1017.7983, Valid Loss: 116.2381
Epoch [22901/30000], Step [1/1], Training Loss: 994.5547, Valid Loss: 113.9524
Epoch [23001/30000], Step [1/1], Training Loss: 972.0786, Valid Loss: 119.9810
Epoch [23101/30000], Step [1/1], Training Loss: 950.3002, Valid Loss: 119.6572
Epoch [23201/30000], Step [1/1], Training Loss: 928.9866, Valid Loss: 114.1714
Epoch [23301/30000], Step [1/1], Training Loss: 907.8179, Valid Loss: 115.4952
Epoch [23401/30000], Step [1/1], Training Loss: 887.0640, Valid Loss: 115.7048
Epoch [23501/30000], Step [1/1], Training Loss: 867.0394, Valid Loss: 118.6572
Epoch [23601/30000], Step [1/1], Training Loss: 847.2938, Valid Loss: 119.0667
Epoch [23701/30000], Step [1/1], Training Loss: 828.1329, Valid Loss: 116.6095
Epoch [23801/30000], Step [1/1], Training Loss: 809.7189, Valid Loss: 116.7619
Epoch [23901/30000], Step [1/1], Training Loss: 791.3207, Valid Loss: 119.7048
Epoch [24001/30000], Step [1/1], Training Loss: 773.7168, Valid Loss: 123.8762
Epoch [24101/30000], Step [1/1], Training Loss: 756.5382, Valid Loss: 116.5810
Epoch [24201/30000], Step [1/1], Training Loss: 740.0211, Valid Loss: 122.7429
Epoch [24301/30000], Step [1/1], Training Loss: 723.6194, Valid Loss: 114.6286
Epoch [24401/30000], Step [1/1], Training Loss: 707.9166, Valid Loss: 117.9810
Epoch [24501/30000], Step [1/1], Training Loss: 693.0051, Valid Loss: 117.3714
Epoch [24601/30000], Step [1/1], Training Loss: 677.6238, Valid Loss: 117.6190
Epoch [24701/30000], Step [1/1], Training Loss: 662.8244, Valid Loss: 120.3905
Epoch [24801/30000], Step [1/1], Training Loss: 648.2978, Valid Loss: 117.5143
Epoch [24901/30000], Step [1/1], Training Loss: 634.2054, Valid Loss: 112.1429
Epoch [25001/30000], Step [1/1], Training Loss: 620.4696, Valid Loss: 117.5619
Epoch [25101/30000], Step [1/1], Training Loss: 606.3411, Valid Loss: 121.0667
Epoch [25201/30000], Step [1/1], Training Loss: 592.8649, Valid Loss: 121.6572
Epoch [25301/30000], Step [1/1], Training Loss: 579.1832, Valid Loss: 124.5238
Epoch [25401/30000], Step [1/1], Training Loss: 566.0722, Valid Loss: 122.5619
Epoch [25501/30000], Step [1/1], Training Loss: 552.6567, Valid Loss: 121.6381
Epoch [25601/30000], Step [1/1], Training Loss: 540.0372, Valid Loss: 119.4857
Epoch [25701/30000], Step [1/1], Training Loss: 527.1638, Valid Loss: 121.1714
Epoch [25801/30000], Step [1/1], Training Loss: 514.9304, Valid Loss: 119.5143
Epoch [25901/30000], Step [1/1], Training Loss: 502.4153, Valid Loss: 120.2952
Epoch [26001/30000], Step [1/1], Training Loss: 490.1520, Valid Loss: 119.9143
Epoch [26101/30000], Step [1/1], Training Loss: 478.3964, Valid Loss: 123.1429
Epoch [26201/30000], Step [1/1], Training Loss: 467.1151, Valid Loss: 122.9333
Epoch [26301/30000], Step [1/1], Training Loss: 455.8609, Valid Loss: 121.9619
Epoch [26401/30000], Step [1/1], Training Loss: 444.5812, Valid Loss: 122.6762
Epoch [26501/30000], Step [1/1], Training Loss: 434.0243, Valid Loss: 116.5524
Epoch [26601/30000], Step [1/1], Training Loss: 423.2138, Valid Loss: 119.5524
Epoch [26701/30000], Step [1/1], Training Loss: 412.9948, Valid Loss: 120.6095
Epoch [26801/30000], Step [1/1], Training Loss: 403.0058, Valid Loss: 122.9238
Epoch [26901/30000], Step [1/1], Training Loss: 393.3947, Valid Loss: 118.9619
Epoch [27001/30000], Step [1/1], Training Loss: 383.5631, Valid Loss: 125.8476
Epoch [27101/30000], Step [1/1], Training Loss: 373.5583, Valid Loss: 119.7524
Epoch [27201/30000], Step [1/1], Training Loss: 363.8992, Valid Loss: 121.7333
Epoch [27301/30000], Step [1/1], Training Loss: 354.2158, Valid Loss: 117.9619
Epoch [27401/30000], Step [1/1], Training Loss: 344.6366, Valid Loss: 124.1524
Epoch [27501/30000], Step [1/1], Training Loss: 335.4232, Valid Loss: 120.0571
Epoch [27601/30000], Step [1/1], Training Loss: 325.7014, Valid Loss: 119.1048
Epoch [27701/30000], Step [1/1], Training Loss: 316.4153, Valid Loss: 121.2762
Epoch [27801/30000], Step [1/1], Training Loss: 307.3111, Valid Loss: 117.0667
Epoch [27901/30000], Step [1/1], Training Loss: 298.0950, Valid Loss: 117.7905
Epoch [28001/30000], Step [1/1], Training Loss: 289.1993, Valid Loss: 119.3524
Epoch [28101/30000], Step [1/1], Training Loss: 280.1789, Valid Loss: 120.5333
Epoch [28201/30000], Step [1/1], Training Loss: 271.5310, Valid Loss: 117.4095
Epoch [28301/30000], Step [1/1], Training Loss: 262.9904, Valid Loss: 124.6381
Epoch [28401/30000], Step [1/1], Training Loss: 254.5437, Valid Loss: 118.6190
Epoch [28501/30000], Step [1/1], Training Loss: 246.2863, Valid Loss: 115.8095
Epoch [28601/30000], Step [1/1], Training Loss: 237.9364, Valid Loss: 121.6190
Epoch [28701/30000], Step [1/1], Training Loss: 229.7624, Valid Loss: 123.5619
Epoch [28801/30000], Step [1/1], Training Loss: 221.8810, Valid Loss: 120.7048
Epoch [28901/30000], Step [1/1], Training Loss: 214.1404, Valid Loss: 122.5143
Epoch [29001/30000], Step [1/1], Training Loss: 206.5609, Valid Loss: 117.1048
Epoch [29101/30000], Step [1/1], Training Loss: 199.0366, Valid Loss: 118.7048
Epoch [29201/30000], Step [1/1], Training Loss: 191.6799, Valid Loss: 120.7714
Epoch [29301/30000], Step [1/1], Training Loss: 184.5844, Valid Loss: 120.8952
Epoch [29401/30000], Step [1/1], Training Loss: 177.5173, Valid Loss: 119.0571
Epoch [29501/30000], Step [1/1], Training Loss: 170.5476, Valid Loss: 120.9619
Epoch [29601/30000], Step [1/1], Training Loss: 163.8273, Valid Loss: 120.6952
Epoch [29701/30000], Step [1/1], Training Loss: 157.1856, Valid Loss: 117.0762
Epoch [29801/30000], Step [1/1], Training Loss: 484.8581, Valid Loss: 168.9524
Epoch [29901/30000], Step [1/1], Training Loss: 176.3095, Valid Loss: 152.2476

 End Time: 2021/04/19, 16:03:50




##########################################################

Epochs=30000 	batch=245 	lr=0.0001
window=2 	seq_len=7 	hidden_size=512 	layers=3

Start Time = 2021/04/19, 16:03:50
##########################################################


[Epoch 0] Rounded prediction: 
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 5000] Rounded prediction: 
tensor([29., 26., 27., 22., 22., 23., 24., 20., 19., 20., 18., 15., 19., 17.,
        14., 16., 11., 14., 13., 16., 20., 18., 19., 23., 18., 13., 14., 16.,
        15., 15., 20., 15., 12., 17., 14., 14., 12., 14., 10., 14., 13., 28.,
        22., 21., 17., 13., 12., 13., 13., 14., 13., 14., 19., 14., 26., 20.,
        14., 16., 13., 15., 13., 18., 14., 20., 13., 21., 17., 23., 21., 19.,
        18., 17., 17., 18., 18., 21., 20., 33., 23., 27., 27., 24., 34., 29.,
        25., 25., 22., 22., 20., 19., 26., 42., 47., 42., 33., 28., 32., 32.,
        36., 36., 38., 38., 34., 46., 41.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 10000] Rounded prediction: 
tensor([25., 20., 20., 20., 17., 22., 17., 17., 17., 15., 17., 10., 15., 12.,
        11., 12.,  7., 11.,  9., 13., 18., 14., 17., 20., 12.,  5., 12., 12.,
        12., 10., 21.,  7.,  6., 13., 10., 11.,  7., 11.,  6., 10., 10., 31.,
        15., 16.,  8.,  7.,  8., 10.,  9., 10.,  9., 10., 18.,  8., 25., 13.,
         7., 13.,  8., 12.,  9., 16.,  8., 17.,  7., 20., 13., 21., 21., 16.,
        13., 13., 15., 15., 13., 20., 20., 35., 19., 27., 32., 20., 40., 33.,
        23., 20., 16., 15., 12., 15., 32., 46., 49., 43., 38., 25., 31., 33.,
        35., 31., 35., 42., 27., 40., 45.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128672.2422, Valid Loss: 231.3048
Epoch [101/30000], Step [1/1], Training Loss: 121103.0000, Valid Loss: 117.1619
Epoch [201/30000], Step [1/1], Training Loss: 118707.1406, Valid Loss: 193.5905
Epoch [301/30000], Step [1/1], Training Loss: 116459.7812, Valid Loss: 320.0191
Epoch [401/30000], Step [1/1], Training Loss: 114303.0703, Valid Loss: 496.4476
Epoch [501/30000], Step [1/1], Training Loss: 112216.1094, Valid Loss: 722.8762
Epoch [601/30000], Step [1/1], Training Loss: 110197.5703, Valid Loss: 999.3048
Epoch [701/30000], Step [1/1], Training Loss: 108242.5781, Valid Loss: 1325.7334
Epoch [801/30000], Step [1/1], Training Loss: 106345.2031, Valid Loss: 1702.1620
Epoch [901/30000], Step [1/1], Training Loss: 104500.0234, Valid Loss: 2128.5906
Epoch [1001/30000], Step [1/1], Training Loss: 102706.4375, Valid Loss: 2560.5525
Epoch [1101/30000], Step [1/1], Training Loss: 100954.3828, Valid Loss: 1520.6001
Epoch [1201/30000], Step [1/1], Training Loss: 99250.8203, Valid Loss: 1783.4954
Epoch [1301/30000], Step [1/1], Training Loss: 97590.6406, Valid Loss: 2770.6096
Epoch [1401/30000], Step [1/1], Training Loss: 95975.7812, Valid Loss: 2897.7144
Epoch [1501/30000], Step [1/1], Training Loss: 94402.8281, Valid Loss: 3157.7239
Epoch [1601/30000], Step [1/1], Training Loss: 92872.8672, Valid Loss: 3713.7239
Epoch [1701/30000], Step [1/1], Training Loss: 91382.5000, Valid Loss: 3371.8000
Epoch [1801/30000], Step [1/1], Training Loss: 89931.1172, Valid Loss: 3107.1526
Epoch [1901/30000], Step [1/1], Training Loss: 87866.8203, Valid Loss: 736.0858
Epoch [2001/30000], Step [1/1], Training Loss: 86204.1641, Valid Loss: 288.6667
Epoch [2101/30000], Step [1/1], Training Loss: 84628.9297, Valid Loss: 231.6190
Epoch [2201/30000], Step [1/1], Training Loss: 83097.8906, Valid Loss: 200.9048
Epoch [2301/30000], Step [1/1], Training Loss: 81602.1172, Valid Loss: 275.7524
Epoch [2401/30000], Step [1/1], Training Loss: 80137.2891, Valid Loss: 333.6572
Epoch [2501/30000], Step [1/1], Training Loss: 78703.1172, Valid Loss: 392.4857
Epoch [2601/30000], Step [1/1], Training Loss: 77306.0000, Valid Loss: 347.7143
Epoch [2701/30000], Step [1/1], Training Loss: 75927.9141, Valid Loss: 284.2476
Epoch [2801/30000], Step [1/1], Training Loss: 74584.6875, Valid Loss: 257.8667
Epoch [2901/30000], Step [1/1], Training Loss: 73266.5625, Valid Loss: 228.0095
Epoch [3001/30000], Step [1/1], Training Loss: 71976.4766, Valid Loss: 247.0572
Epoch [3101/30000], Step [1/1], Training Loss: 70712.7812, Valid Loss: 222.5810
Epoch [3201/30000], Step [1/1], Training Loss: 69475.1172, Valid Loss: 241.8286
Epoch [3301/30000], Step [1/1], Training Loss: 68267.7500, Valid Loss: 212.2667
Epoch [3401/30000], Step [1/1], Training Loss: 67077.4844, Valid Loss: 236.9619
Epoch [3501/30000], Step [1/1], Training Loss: 65914.2266, Valid Loss: 242.9810
Epoch [3601/30000], Step [1/1], Training Loss: 64776.7070, Valid Loss: 239.8476
Epoch [3701/30000], Step [1/1], Training Loss: 63753.3906, Valid Loss: 250.0762
Epoch [3801/30000], Step [1/1], Training Loss: 62590.0508, Valid Loss: 134.9048
Epoch [3901/30000], Step [1/1], Training Loss: 61516.8125, Valid Loss: 133.7048
Epoch [4001/30000], Step [1/1], Training Loss: 60447.6250, Valid Loss: 137.0857
Epoch [4101/30000], Step [1/1], Training Loss: 59422.9023, Valid Loss: 137.0191
Epoch [4201/30000], Step [1/1], Training Loss: 58380.2734, Valid Loss: 96.2476
Epoch [4301/30000], Step [1/1], Training Loss: 57326.8008, Valid Loss: 183.9810
Epoch [4401/30000], Step [1/1], Training Loss: 56302.1055, Valid Loss: 106.1238
Epoch [4501/30000], Step [1/1], Training Loss: 55329.8086, Valid Loss: 119.6667
Epoch [4601/30000], Step [1/1], Training Loss: 54330.7148, Valid Loss: 113.8571
Epoch [4701/30000], Step [1/1], Training Loss: 53373.1406, Valid Loss: 120.8476
Epoch [4801/30000], Step [1/1], Training Loss: 52440.8359, Valid Loss: 112.7333
Epoch [4901/30000], Step [1/1], Training Loss: 51527.9258, Valid Loss: 115.2762
Epoch [5001/30000], Step [1/1], Training Loss: 50621.7773, Valid Loss: 126.4571
Epoch [5101/30000], Step [1/1], Training Loss: 49735.6172, Valid Loss: 134.8571
Epoch [5201/30000], Step [1/1], Training Loss: 48873.0117, Valid Loss: 143.0000
Epoch [5301/30000], Step [1/1], Training Loss: 48232.5977, Valid Loss: 118.7619
Epoch [5401/30000], Step [1/1], Training Loss: 47317.3594, Valid Loss: 136.2571
Epoch [5501/30000], Step [1/1], Training Loss: 46480.2617, Valid Loss: 124.4476
Epoch [5601/30000], Step [1/1], Training Loss: 45651.5195, Valid Loss: 135.0571
Epoch [5701/30000], Step [1/1], Training Loss: 44823.6719, Valid Loss: 135.7333
Epoch [5801/30000], Step [1/1], Training Loss: 44035.1992, Valid Loss: 151.4000
Epoch [5901/30000], Step [1/1], Training Loss: 43271.0078, Valid Loss: 139.3619
Epoch [6001/30000], Step [1/1], Training Loss: 42519.1875, Valid Loss: 135.6095
Epoch [6101/30000], Step [1/1], Training Loss: 41781.4961, Valid Loss: 139.0667
Epoch [6201/30000], Step [1/1], Training Loss: 41065.8711, Valid Loss: 131.8952
Epoch [6301/30000], Step [1/1], Training Loss: 40390.6758, Valid Loss: 146.8095
Epoch [6401/30000], Step [1/1], Training Loss: 39688.8945, Valid Loss: 137.3238
Epoch [6501/30000], Step [1/1], Training Loss: 39022.7695, Valid Loss: 146.1905
Epoch [6601/30000], Step [1/1], Training Loss: 38653.9492, Valid Loss: 134.4857
Epoch [6701/30000], Step [1/1], Training Loss: 37706.4727, Valid Loss: 85.1714
Epoch [6801/30000], Step [1/1], Training Loss: 36955.8516, Valid Loss: 88.6762
Epoch [6901/30000], Step [1/1], Training Loss: 36296.5508, Valid Loss: 128.5048
Epoch [7001/30000], Step [1/1], Training Loss: 35537.8398, Valid Loss: 109.8857
Epoch [7101/30000], Step [1/1], Training Loss: 34889.8281, Valid Loss: 136.4476
Epoch [7201/30000], Step [1/1], Training Loss: 34222.3281, Valid Loss: 142.7238
Epoch [7301/30000], Step [1/1], Training Loss: 33614.1523, Valid Loss: 118.3905
Epoch [7401/30000], Step [1/1], Training Loss: 33034.6289, Valid Loss: 141.9143
Epoch [7501/30000], Step [1/1], Training Loss: 32458.0918, Valid Loss: 130.0952
Epoch [7601/30000], Step [1/1], Training Loss: 31894.0938, Valid Loss: 137.6286
Epoch [7701/30000], Step [1/1], Training Loss: 31351.3320, Valid Loss: 136.6000
Epoch [7801/30000], Step [1/1], Training Loss: 30822.5410, Valid Loss: 133.2667
Epoch [7901/30000], Step [1/1], Training Loss: 30298.4961, Valid Loss: 113.3810
Epoch [8001/30000], Step [1/1], Training Loss: 29776.6074, Valid Loss: 134.3905
Epoch [8101/30000], Step [1/1], Training Loss: 29270.2559, Valid Loss: 109.4476
Epoch [8201/30000], Step [1/1], Training Loss: 28779.9805, Valid Loss: 116.5619
Epoch [8301/30000], Step [1/1], Training Loss: 28302.0332, Valid Loss: 115.7429
Epoch [8401/30000], Step [1/1], Training Loss: 27840.0078, Valid Loss: 107.4571
Epoch [8501/30000], Step [1/1], Training Loss: 27389.1836, Valid Loss: 115.2095
Epoch [8601/30000], Step [1/1], Training Loss: 26951.5332, Valid Loss: 123.9524
Epoch [8701/30000], Step [1/1], Training Loss: 26524.0645, Valid Loss: 117.8762
Epoch [8801/30000], Step [1/1], Training Loss: 26352.4219, Valid Loss: 140.6000
Epoch [8901/30000], Step [1/1], Training Loss: 25653.5840, Valid Loss: 112.2952
Epoch [9001/30000], Step [1/1], Training Loss: 24437.6270, Valid Loss: 101.9810
Epoch [9101/30000], Step [1/1], Training Loss: 23854.8438, Valid Loss: 97.2095
Epoch [9201/30000], Step [1/1], Training Loss: 23196.4043, Valid Loss: 87.7524
Epoch [9301/30000], Step [1/1], Training Loss: 22668.7402, Valid Loss: 95.2190
Epoch [9401/30000], Step [1/1], Training Loss: 22201.0293, Valid Loss: 95.4476
Epoch [9501/30000], Step [1/1], Training Loss: 21745.4453, Valid Loss: 91.8095
Epoch [9601/30000], Step [1/1], Training Loss: 21313.9199, Valid Loss: 89.4667
Epoch [9701/30000], Step [1/1], Training Loss: 20878.1777, Valid Loss: 83.7143
Epoch [9801/30000], Step [1/1], Training Loss: 20462.2422, Valid Loss: 88.1143
Epoch [9901/30000], Step [1/1], Training Loss: 20053.2754, Valid Loss: 90.3810
Epoch [10001/30000], Step [1/1], Training Loss: 19670.0371, Valid Loss: 91.9333
Epoch [10101/30000], Step [1/1], Training Loss: 19273.9922, Valid Loss: 100.4191

[Epoch 15000] Rounded prediction: 
tensor([24., 19., 19., 20., 20., 21., 20., 18., 17., 16., 17., 10., 15., 12.,
        12., 11.,  5., 11.,  8., 13., 17., 16., 15., 21., 13.,  4., 10., 12.,
        11., 10., 20.,  8.,  5., 11., 11., 11.,  7., 10.,  5., 10., 10., 32.,
        18., 16.,  9.,  5.,  8., 10.,  9., 10.,  9., 10., 17.,  9., 25., 13.,
         6., 11.,  7., 12.,  9., 14.,  9., 15.,  7., 18., 15., 20., 23., 16.,
        12., 12., 15., 14., 12., 16., 22., 40., 16., 28., 33., 19., 41., 31.,
        17., 16., 14., 14., 12., 11., 31., 53., 54., 46., 40., 20., 28., 28.,
        31., 28., 29., 41., 25., 34., 39.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')


[Epoch 20000] Rounded prediction: 
tensor([25., 21., 20., 18., 20., 18., 20., 18., 19., 20., 19., 18., 21., 15.,
        20., 17., 12., 14., 14., 15., 20., 20., 15., 24., 13.,  1., 10., 14.,
        11.,  9., 22.,  7.,  3., 12., 12., 10.,  7., 10.,  6.,  9., 11., 35.,
        19., 13., 10.,  2.,  9., 10., 10., 11.,  9., 12., 19., 10., 26., 15.,
         4., 12.,  7., 13.,  9., 14., 11., 14., 10., 22., 19., 19., 23., 18.,
        11., 17., 20., 17., 17., 19., 22., 41., 17., 24., 33., 20., 39., 31.,
        16., 16., 18., 17., 13., 14., 34., 54., 55., 51., 45., 19., 26., 35.,
        37., 31., 32., 47., 27., 34., 37.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [10201/30000], Step [1/1], Training Loss: 19842.6641, Valid Loss: 149.0286
Epoch [10301/30000], Step [1/1], Training Loss: 18679.4277, Valid Loss: 81.1429
Epoch [10401/30000], Step [1/1], Training Loss: 18468.7363, Valid Loss: 83.2000
Epoch [10501/30000], Step [1/1], Training Loss: 17770.6582, Valid Loss: 83.8191
Epoch [10601/30000], Step [1/1], Training Loss: 17519.9395, Valid Loss: 78.5714
Epoch [10701/30000], Step [1/1], Training Loss: 17059.9473, Valid Loss: 81.2667
Epoch [10801/30000], Step [1/1], Training Loss: 16667.3242, Valid Loss: 85.6476
Epoch [10901/30000], Step [1/1], Training Loss: 16326.2959, Valid Loss: 85.2952
Epoch [11001/30000], Step [1/1], Training Loss: 16027.1230, Valid Loss: 84.1333
Epoch [11101/30000], Step [1/1], Training Loss: 15683.2412, Valid Loss: 88.5238
Epoch [11201/30000], Step [1/1], Training Loss: 15491.2891, Valid Loss: 81.8381
Epoch [11301/30000], Step [1/1], Training Loss: 15042.3887, Valid Loss: 89.7714
Epoch [11401/30000], Step [1/1], Training Loss: 14739.3135, Valid Loss: 95.2190
Epoch [11501/30000], Step [1/1], Training Loss: 14440.9961, Valid Loss: 86.5714
Epoch [11601/30000], Step [1/1], Training Loss: 14152.8701, Valid Loss: 90.9524
Epoch [11701/30000], Step [1/1], Training Loss: 13878.2363, Valid Loss: 97.5143
Epoch [11801/30000], Step [1/1], Training Loss: 13590.1787, Valid Loss: 89.7714
Epoch [11901/30000], Step [1/1], Training Loss: 13311.8418, Valid Loss: 98.4762
Epoch [12001/30000], Step [1/1], Training Loss: 13046.4395, Valid Loss: 88.7619
Epoch [12101/30000], Step [1/1], Training Loss: 12786.6592, Valid Loss: 101.0762
Epoch [12201/30000], Step [1/1], Training Loss: 12737.5479, Valid Loss: 88.9619
Epoch [12301/30000], Step [1/1], Training Loss: 12344.5352, Valid Loss: 86.3905
Epoch [12401/30000], Step [1/1], Training Loss: 12070.7188, Valid Loss: 94.3048
Epoch [12501/30000], Step [1/1], Training Loss: 11823.7236, Valid Loss: 79.6381
Epoch [12601/30000], Step [1/1], Training Loss: 11595.7070, Valid Loss: 93.1524
Epoch [12701/30000], Step [1/1], Training Loss: 11354.2783, Valid Loss: 87.5429
Epoch [12801/30000], Step [1/1], Training Loss: 11129.8936, Valid Loss: 92.4286
Epoch [12901/30000], Step [1/1], Training Loss: 11044.7607, Valid Loss: 77.5905
Epoch [13001/30000], Step [1/1], Training Loss: 10705.9336, Valid Loss: 82.3714
Epoch [13101/30000], Step [1/1], Training Loss: 10497.0264, Valid Loss: 86.3810
Epoch [13201/30000], Step [1/1], Training Loss: 10289.9385, Valid Loss: 85.2952
Epoch [13301/30000], Step [1/1], Training Loss: 10092.3896, Valid Loss: 82.5905
Epoch [13401/30000], Step [1/1], Training Loss: 9895.7139, Valid Loss: 86.4476
Epoch [13501/30000], Step [1/1], Training Loss: 9703.6318, Valid Loss: 86.6571
Epoch [13601/30000], Step [1/1], Training Loss: 9519.2051, Valid Loss: 89.3905
Epoch [13701/30000], Step [1/1], Training Loss: 9338.0918, Valid Loss: 86.6095
Epoch [13801/30000], Step [1/1], Training Loss: 9162.5420, Valid Loss: 89.0667
Epoch [13901/30000], Step [1/1], Training Loss: 8991.1758, Valid Loss: 88.2095
Epoch [14001/30000], Step [1/1], Training Loss: 8824.0977, Valid Loss: 91.0000
Epoch [14101/30000], Step [1/1], Training Loss: 8663.8301, Valid Loss: 90.6286
Epoch [14201/30000], Step [1/1], Training Loss: 8504.5977, Valid Loss: 91.6381
Epoch [14301/30000], Step [1/1], Training Loss: 8349.4375, Valid Loss: 96.0667
Epoch [14401/30000], Step [1/1], Training Loss: 8201.2305, Valid Loss: 86.3048
Epoch [14501/30000], Step [1/1], Training Loss: 8056.1509, Valid Loss: 90.6190
Epoch [14601/30000], Step [1/1], Training Loss: 7915.1582, Valid Loss: 97.7619
Epoch [14701/30000], Step [1/1], Training Loss: 7778.1084, Valid Loss: 88.6952
Epoch [14801/30000], Step [1/1], Training Loss: 7645.2139, Valid Loss: 89.3905
Epoch [14901/30000], Step [1/1], Training Loss: 7511.8818, Valid Loss: 97.5429
Epoch [15001/30000], Step [1/1], Training Loss: 7378.5093, Valid Loss: 98.8571
Epoch [15101/30000], Step [1/1], Training Loss: 7251.3965, Valid Loss: 91.0762
Epoch [15201/30000], Step [1/1], Training Loss: 7126.3872, Valid Loss: 99.2095
Epoch [15301/30000], Step [1/1], Training Loss: 6553.0825, Valid Loss: 101.6572
Epoch [15401/30000], Step [1/1], Training Loss: 6431.6899, Valid Loss: 79.2857
Epoch [15501/30000], Step [1/1], Training Loss: 5902.9629, Valid Loss: 101.1429
Epoch [15601/30000], Step [1/1], Training Loss: 5744.9956, Valid Loss: 103.7143
Epoch [15701/30000], Step [1/1], Training Loss: 5602.3589, Valid Loss: 100.5905
Epoch [15801/30000], Step [1/1], Training Loss: 5463.7729, Valid Loss: 97.2286
Epoch [15901/30000], Step [1/1], Training Loss: 5327.4204, Valid Loss: 96.8667
Epoch [16001/30000], Step [1/1], Training Loss: 5198.4863, Valid Loss: 101.8952
Epoch [16101/30000], Step [1/1], Training Loss: 5072.7139, Valid Loss: 93.8667
Epoch [16201/30000], Step [1/1], Training Loss: 4949.7881, Valid Loss: 90.4000
Epoch [16301/30000], Step [1/1], Training Loss: 4829.7627, Valid Loss: 97.8667
Epoch [16401/30000], Step [1/1], Training Loss: 4713.7861, Valid Loss: 94.9714
Epoch [16501/30000], Step [1/1], Training Loss: 4607.9917, Valid Loss: 83.9905
Epoch [16601/30000], Step [1/1], Training Loss: 4493.0654, Valid Loss: 94.0286
Epoch [16701/30000], Step [1/1], Training Loss: 4387.0698, Valid Loss: 92.7048
Epoch [16801/30000], Step [1/1], Training Loss: 4284.3989, Valid Loss: 92.9524
Epoch [16901/30000], Step [1/1], Training Loss: 4186.1636, Valid Loss: 93.6571
Epoch [17001/30000], Step [1/1], Training Loss: 4089.5000, Valid Loss: 89.8476
Epoch [17101/30000], Step [1/1], Training Loss: 3996.7427, Valid Loss: 92.8191
Epoch [17201/30000], Step [1/1], Training Loss: 3907.2065, Valid Loss: 84.6381
Epoch [17301/30000], Step [1/1], Training Loss: 3819.6870, Valid Loss: 89.5619
Epoch [17401/30000], Step [1/1], Training Loss: 3735.0627, Valid Loss: 88.7429
Epoch [17501/30000], Step [1/1], Training Loss: 3654.0051, Valid Loss: 89.9238
Epoch [17601/30000], Step [1/1], Training Loss: 3573.3269, Valid Loss: 91.7810
Epoch [17701/30000], Step [1/1], Training Loss: 3496.8928, Valid Loss: 92.8286
Epoch [17801/30000], Step [1/1], Training Loss: 3416.7197, Valid Loss: 89.9333
Epoch [17901/30000], Step [1/1], Training Loss: 3342.9260, Valid Loss: 93.1143
Epoch [18001/30000], Step [1/1], Training Loss: 3270.5654, Valid Loss: 90.9238
Epoch [18101/30000], Step [1/1], Training Loss: 3200.1147, Valid Loss: 91.8762
Epoch [18201/30000], Step [1/1], Training Loss: 3132.0276, Valid Loss: 89.9714
Epoch [18301/30000], Step [1/1], Training Loss: 3065.7622, Valid Loss: 92.0191
Epoch [18401/30000], Step [1/1], Training Loss: 3001.3794, Valid Loss: 95.9905
Epoch [18501/30000], Step [1/1], Training Loss: 2939.0549, Valid Loss: 97.4952
Epoch [18601/30000], Step [1/1], Training Loss: 2877.7239, Valid Loss: 96.2095
Epoch [18701/30000], Step [1/1], Training Loss: 2818.8767, Valid Loss: 94.1143
Epoch [18801/30000], Step [1/1], Training Loss: 2761.1196, Valid Loss: 94.8857
Epoch [18901/30000], Step [1/1], Training Loss: 2706.9768, Valid Loss: 98.1524
Epoch [19001/30000], Step [1/1], Training Loss: 3068.1555, Valid Loss: 113.4762
Epoch [19101/30000], Step [1/1], Training Loss: 2659.1221, Valid Loss: 117.9810
Epoch [19201/30000], Step [1/1], Training Loss: 2590.0630, Valid Loss: 112.6000
Epoch [19301/30000], Step [1/1], Training Loss: 2521.7065, Valid Loss: 117.6286
Epoch [19401/30000], Step [1/1], Training Loss: 2466.8530, Valid Loss: 120.7524
Epoch [19501/30000], Step [1/1], Training Loss: 2417.0986, Valid Loss: 124.9619
Epoch [19601/30000], Step [1/1], Training Loss: 2368.6511, Valid Loss: 118.3333
Epoch [19701/30000], Step [1/1], Training Loss: 2316.7798, Valid Loss: 123.2667
Epoch [19801/30000], Step [1/1], Training Loss: 2265.2346, Valid Loss: 119.6476
Epoch [19901/30000], Step [1/1], Training Loss: 2220.8042, Valid Loss: 118.2857
Epoch [20001/30000], Step [1/1], Training Loss: 2181.0205, Valid Loss: 124.5524
Epoch [20101/30000], Step [1/1], Training Loss: 2142.9192, Valid Loss: 119.6000
Epoch [20201/30000], Step [1/1], Training Loss: 2101.7639, Valid Loss: 116.7429
Epoch [20301/30000], Step [1/1], Training Loss: 2065.1262, Valid Loss: 114.0191

[Epoch 25000] Rounded prediction: 
tensor([22., 20., 21., 19., 22., 20., 20., 18., 18., 20., 18., 18., 20., 18.,
        21., 15., 10., 10., 12., 13., 12., 17., 10., 15., 13.,  1.,  6.,  9.,
         8.,  6., 15.,  7.,  3.,  7.,  9.,  7.,  5.,  6.,  6.,  6.,  7., 28.,
        16.,  8.,  8.,  2.,  6.,  7.,  7.,  8.,  8.,  9., 11., 11., 16., 10.,
         2.,  7.,  6.,  8.,  8.,  8., 11.,  9., 12., 11., 17., 12., 22., 19.,
        10., 13., 17., 16., 17., 11., 21., 33., 14., 16., 27., 21., 28., 28.,
        17., 15., 17., 18., 15., 10., 25., 52., 49., 46., 35., 20., 26., 31.,
        35., 34., 31., 37., 32., 32., 28.], device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [20401/30000], Step [1/1], Training Loss: 2030.7388, Valid Loss: 112.6762
Epoch [20501/30000], Step [1/1], Training Loss: 1997.4564, Valid Loss: 114.9238
Epoch [20601/30000], Step [1/1], Training Loss: 1966.0059, Valid Loss: 110.2000
Epoch [20701/30000], Step [1/1], Training Loss: 1935.4717, Valid Loss: 110.5143
Epoch [20801/30000], Step [1/1], Training Loss: 1895.3423, Valid Loss: 108.0762
Epoch [20901/30000], Step [1/1], Training Loss: 1872.3032, Valid Loss: 104.7048
Epoch [21001/30000], Step [1/1], Training Loss: 1840.0472, Valid Loss: 109.0667
Epoch [21101/30000], Step [1/1], Training Loss: 1805.6024, Valid Loss: 102.6857
Epoch [21201/30000], Step [1/1], Training Loss: 1779.2755, Valid Loss: 104.5810
Epoch [21301/30000], Step [1/1], Training Loss: 1756.2402, Valid Loss: 104.2000
Epoch [21401/30000], Step [1/1], Training Loss: 1728.0796, Valid Loss: 96.0571
Epoch [21501/30000], Step [1/1], Training Loss: 1704.1296, Valid Loss: 102.2381
Epoch [21601/30000], Step [1/1], Training Loss: 1829.3571, Valid Loss: 67.6190
Epoch [21701/30000], Step [1/1], Training Loss: 1655.9358, Valid Loss: 75.2000
Epoch [21801/30000], Step [1/1], Training Loss: 1625.8022, Valid Loss: 72.6476
Epoch [21901/30000], Step [1/1], Training Loss: 1596.3112, Valid Loss: 76.4857
Epoch [22001/30000], Step [1/1], Training Loss: 1288.6276, Valid Loss: 80.3714
Epoch [22101/30000], Step [1/1], Training Loss: 1250.3230, Valid Loss: 72.3048
Epoch [22201/30000], Step [1/1], Training Loss: 1217.2216, Valid Loss: 77.7905
Epoch [22301/30000], Step [1/1], Training Loss: 1186.5631, Valid Loss: 76.4762
Epoch [22401/30000], Step [1/1], Training Loss: 1157.7708, Valid Loss: 73.7238
Epoch [22501/30000], Step [1/1], Training Loss: 1130.2465, Valid Loss: 75.4476
Epoch [22601/30000], Step [1/1], Training Loss: 1103.0950, Valid Loss: 76.9905
Epoch [22701/30000], Step [1/1], Training Loss: 1076.7456, Valid Loss: 78.9238
Epoch [22801/30000], Step [1/1], Training Loss: 1051.0775, Valid Loss: 72.6667
Epoch [22901/30000], Step [1/1], Training Loss: 1025.0267, Valid Loss: 74.6381
Epoch [23001/30000], Step [1/1], Training Loss: 1000.2191, Valid Loss: 77.9810
Epoch [23101/30000], Step [1/1], Training Loss: 976.5162, Valid Loss: 77.9143
Epoch [23201/30000], Step [1/1], Training Loss: 952.6357, Valid Loss: 75.8476
Epoch [23301/30000], Step [1/1], Training Loss: 929.5585, Valid Loss: 77.8571
Epoch [23401/30000], Step [1/1], Training Loss: 907.4193, Valid Loss: 80.8000
Epoch [23501/30000], Step [1/1], Training Loss: 885.2769, Valid Loss: 81.4095
Epoch [23601/30000], Step [1/1], Training Loss: 864.2573, Valid Loss: 79.5524
Epoch [23701/30000], Step [1/1], Training Loss: 843.8693, Valid Loss: 79.5333
Epoch [23801/30000], Step [1/1], Training Loss: 823.8847, Valid Loss: 79.2381
Epoch [23901/30000], Step [1/1], Training Loss: 804.6957, Valid Loss: 84.9905
Epoch [24001/30000], Step [1/1], Training Loss: 785.8474, Valid Loss: 80.3333
Epoch [24101/30000], Step [1/1], Training Loss: 767.7535, Valid Loss: 82.2381
Epoch [24201/30000], Step [1/1], Training Loss: 750.2369, Valid Loss: 84.2095
Epoch [24301/30000], Step [1/1], Training Loss: 733.4571, Valid Loss: 81.0952
Epoch [24401/30000], Step [1/1], Training Loss: 716.8416, Valid Loss: 79.8381
Epoch [24501/30000], Step [1/1], Training Loss: 701.0479, Valid Loss: 82.5714
Epoch [24601/30000], Step [1/1], Training Loss: 685.7667, Valid Loss: 82.2000
Epoch [24701/30000], Step [1/1], Training Loss: 671.3040, Valid Loss: 81.8762
Epoch [24801/30000], Step [1/1], Training Loss: 656.9843, Valid Loss: 81.7048
Epoch [24901/30000], Step [1/1], Training Loss: 642.8906, Valid Loss: 82.8667
Epoch [25001/30000], Step [1/1], Training Loss: 628.5947, Valid Loss: 81.8952
Epoch [25101/30000], Step [1/1], Training Loss: 613.9982, Valid Loss: 82.7524
Epoch [25201/30000], Step [1/1], Training Loss: 599.9004, Valid Loss: 84.2667
Epoch [25301/30000], Step [1/1], Training Loss: 586.1379, Valid Loss: 86.3238
Epoch [25401/30000], Step [1/1], Training Loss: 572.3707, Valid Loss: 85.5619
Epoch [25501/30000], Step [1/1], Training Loss: 558.9968, Valid Loss: 87.4762
Epoch [25601/30000], Step [1/1], Training Loss: 545.5251, Valid Loss: 86.5714
Epoch [25701/30000], Step [1/1], Training Loss: 533.0490, Valid Loss: 86.7143
Epoch [25801/30000], Step [1/1], Training Loss: 519.9689, Valid Loss: 90.9048
Epoch [25901/30000], Step [1/1], Training Loss: 507.5081, Valid Loss: 93.3524
Epoch [26001/30000], Step [1/1], Training Loss: 495.3414, Valid Loss: 92.1143
Epoch [26101/30000], Step [1/1], Training Loss: 483.4803, Valid Loss: 97.6190
Epoch [26201/30000], Step [1/1], Training Loss: 471.6651, Valid Loss: 99.7905
Epoch [26301/30000], Step [1/1], Training Loss: 460.0437, Valid Loss: 97.5333
Epoch [26401/30000], Step [1/1], Training Loss: 448.7821, Valid Loss: 99.7238
Epoch [26501/30000], Step [1/1], Training Loss: 437.8691, Valid Loss: 97.9905
Epoch [26601/30000], Step [1/1], Training Loss: 427.0241, Valid Loss: 100.0571
Epoch [26701/30000], Step [1/1], Training Loss: 416.4437, Valid Loss: 105.4095
Epoch [26801/30000], Step [1/1], Training Loss: 406.4688, Valid Loss: 94.3238
Epoch [26901/30000], Step [1/1], Training Loss: 396.7653, Valid Loss: 97.9714
Epoch [27001/30000], Step [1/1], Training Loss: 386.4202, Valid Loss: 104.9905
Epoch [27101/30000], Step [1/1], Training Loss: 376.6063, Valid Loss: 101.9429
Epoch [27201/30000], Step [1/1], Training Loss: 366.8594, Valid Loss: 103.7905
Epoch [27301/30000], Step [1/1], Training Loss: 357.0680, Valid Loss: 101.0476
Epoch [27401/30000], Step [1/1], Training Loss: 347.3402, Valid Loss: 105.1619
Epoch [27501/30000], Step [1/1], Training Loss: 337.6138, Valid Loss: 105.3429
Epoch [27601/30000], Step [1/1], Training Loss: 328.1689, Valid Loss: 102.3810
Epoch [27701/30000], Step [1/1], Training Loss: 318.8992, Valid Loss: 98.4000
Epoch [27801/30000], Step [1/1], Training Loss: 309.5232, Valid Loss: 96.3905
Epoch [27901/30000], Step [1/1], Training Loss: 300.3134, Valid Loss: 110.5714
Epoch [28001/30000], Step [1/1], Training Loss: 291.2650, Valid Loss: 102.2667
Epoch [28101/30000], Step [1/1], Training Loss: 282.3607, Valid Loss: 107.6381
Epoch [28201/30000], Step [1/1], Training Loss: 273.5327, Valid Loss: 103.2000
Epoch [28301/30000], Step [1/1], Training Loss: 264.8584, Valid Loss: 108.3238
Epoch [28401/30000], Step [1/1], Training Loss: 256.3272, Valid Loss: 106.1143
Epoch [28501/30000], Step [1/1], Training Loss: 247.8871, Valid Loss: 100.6762
Epoch [28601/30000], Step [1/1], Training Loss: 239.5353, Valid Loss: 109.8857
Epoch [28701/30000], Step [1/1], Training Loss: 231.4233, Valid Loss: 110.0667
Epoch [28801/30000], Step [1/1], Training Loss: 223.4333, Valid Loss: 99.6381
Epoch [28901/30000], Step [1/1], Training Loss: 215.5746, Valid Loss: 96.2190
Epoch [29001/30000], Step [1/1], Training Loss: 207.8656, Valid Loss: 101.6667
Epoch [29101/30000], Step [1/1], Training Loss: 200.2952, Valid Loss: 101.7619
Epoch [29201/30000], Step [1/1], Training Loss: 193.0012, Valid Loss: 101.6476
Epoch [29301/30000], Step [1/1], Training Loss: 185.7919, Valid Loss: 102.3905
Epoch [29401/30000], Step [1/1], Training Loss: 178.5137, Valid Loss: 99.1810
Epoch [29501/30000], Step [1/1], Training Loss: 171.6604, Valid Loss: 99.1619
Epoch [29601/30000], Step [1/1], Training Loss: 164.7561, Valid Loss: 102.7905
Epoch [29701/30000], Step [1/1], Training Loss: 158.2290, Valid Loss: 97.0000
Epoch [29801/30000], Step [1/1], Training Loss: 151.6961, Valid Loss: 102.3238
Epoch [29901/30000], Step [1/1], Training Loss: 145.4155, Valid Loss: 103.5905

 End Time: 2021/04/19, 16:12:07




##########################################################

Epochs=30000 	batch=245 	lr=0.0003
window=2 	seq_len=7 	hidden_size=512 	layers=2

Start Time = 2021/04/19, 16:27:45
##########################################################


[Epoch 0] Rounded prediction: 
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       device='cuda:0')
Target: 
tensor([10.,  6., 12.,  7., 11., 10.,  9., 10.,  7., 10.,  4.,  4.,  5.,  3.,
         9.,  3.,  7.,  4.,  6., 12.,  8., 10., 14.,  5.,  3.,  7.,  7.,  7.,
         9., 12.,  4.,  1.,  9.,  7.,  7.,  4.,  7.,  2.,  8.,  9., 18., 11.,
        12.,  2.,  3.,  5.,  6.,  5.,  4.,  4.,  5., 12.,  5., 18.,  7.,  5.,
         4.,  6.,  8.,  5., 10.,  2.,  9.,  3., 13.,  5., 13., 12.,  6.,  6.,
         8.,  8.,  7.,  5., 16., 12., 24.,  9., 17., 19., 10., 29., 21., 13.,
        14., 10.,  5.,  5., 13., 27., 30., 30., 33., 35., 24., 28., 31., 33.,
        23., 29., 42., 22., 17., 38., 45.], device='cuda:0')

Epoch [1/30000], Step [1/1], Training Loss: 128623.5703, Valid Loss: 208.5905
Epoch [101/30000], Step [1/1], Training Loss: 116774.1250, Valid Loss: 320.0191
